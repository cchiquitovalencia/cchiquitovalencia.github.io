{
  "hash": "6215507310ddc5c7bff11af4c0c87aa4",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Entendiendo la matriz de confusión\"\ndescription: \"TRADING Serie - Parte 2\"\nauthor:\n  - name: Cristian Chiquito Valencia\n    url: https://cchiquitovalencia.github.io/\n    affiliation: Independent @ CHV\ndate: 04-08-2025\ncategories: [Machine Learning, Trading, Regresión Logística] # self-defined categories\ncitation: \n  url: https://cchiquitovalencia.github.io/posts/2025-04-08-predictions_on_stocks2/\nimage: stocks1.jpeg\ndraft: false # setting this to `true` will prevent your post from appearing on your listing page until you're ready!\n---\n\n\n\nLa matriz de confusión tiene las claves para entender cualquier modelo de machine learning, una mina de oro con 25 métricas, pero hay 7 de ellas que son especialmente importantes: **recall** (sensibilidad), **specificity** (especificidad), el **índice J de Youden**, **precision** (precisión), **NPV** (Valor Negativo Predicho), **accuracy** (exactitud) y **balanced accuracy** (exactitud equilibrada). En este post, exploramos qué hace que estos siete sean esenciales, cómo funcionan y por qué son la columna vertebral del aprendizaje automático.\n\nUsaremos los datos de este [post](https://cchiquitovalencia.github.io/posts/2025-04-07-predictions_on_stocks/ \"Modelando stocks financieros\"). Lo que he hecho es crear un paquete de R para que puedas instalarlo con el siguiente comando:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndevtools::install_github(\"cchiquitovalencia/myfinance\")\n```\n:::\n\n\n\nSi obtienes algo parecido a esto, estás listo para continuar:\n\n[![Detalle de instalación del paquete myfinance](images/myfinance_devtools.png){#fig-1 fig-align=\"center\" width=\"670\"}](https://github.com/cchiquitovalencia/myfinance/tree/master)\n\nA grandes rasgos lo que hace este paquete es replicar el flujo de trabajo visto en la primera parte de la serie, para que usar los mismos datos en la evaluación del modelo. Si te sientes un poco aventurer\\@ puedes crear un branch para modificar la función `main_analysis()` y aplicar el flujo a otros datos, no tiene que ser el **DJI**, puedes usar el que desees.\n\nY con el siguiente código ya tendras el resultado del modelo de regresión logística.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(myfinance)\nlibrary(caret)\n\n# Función para calcular los resultados tanto de train como de test\ncalculate_results <- function(model, data) {\n  # Realizar predicción\n  predictions <- predict(model, data)\n  \n  # Convertir predicciones en probabilidades\n  probabilities <- 1 / (1 + exp(-predictions))\n  \n  # Determinar la dirección basada en el umbral de 0.5\n  direction <- ifelse(probabilities > 0.5, 1, 0)\n  \n  # Crear la matriz de confusión\n  confusion <- confusionMatrix(factor(direction), factor(data$Direction), mode = \"everything\")\n  \n  # Devolver los resultados\n  list(\n    predicted_direction = direction,\n    confusion_matrix = confusion,\n    predictions = predictions\n  )\n}\n\n# Ejecutar el análisis principal\nmodelo <- main_analysis()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Iniciando el análisis principal...\"\n[1] \"Cargando datos...\"\n[1] \"Datos cargados exitosamente. Número de filas: 4594\"\n[1] \"Creando variables predictoras...\"\n[1] \"Variables predictoras creadas exitosamente.\"\n[1] \"Creando tabla de datos...\"\n[1] \"Tabla de datos creada exitosamente.\"\n[1] \"Dividiendo datos en train y test...\"\n[1] \"Datos divididos exitosamente. Train: 3675 Test: 919\"\n[1] \"Normalizando datos...\"\n[1] \"Normalizados\"\n[1] \"Datos normalizados exitosamente.\"\n[1] \"Construyendo y entrenando el modelo...\"\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Modelo construido y entrenado exitosamente.\"\n[1] \"Haciendo predicciones para train...\"\n[1] \"Predicciones para train completadas.\"\n[1] \"Evaluando modelo en train...\"\n[1] \"Evaluación en train:\"\n[1] \"Haciendo predicciones para test...\"\n[1] \"Predicciones para test completadas.\"\n[1] \"Evaluando modelo en test...\"\n[1] \"Evaluación en test:\"\n[1] \"Análisis completado exitosamente.\"\n[1] \"Proceso finalizado.\"\n```\n\n\n:::\n\n```{.r .cell-code}\n# Calcular resultados para train\ntrain_results <- calculate_results(modelo$modelo, modelo$normalized$train)\ntrain_confusion <- train_results$confusion_matrix\n\n# Calcular resultados para test\ntest_results <- calculate_results(modelo$modelo, modelo$normalized$test)\ntest_confusion <- test_results$confusion_matrix\n```\n:::\n\n\n\nRevisamos resultados de los datos de entrenamiento del modelo:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain_confusion\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 1152  108\n         1  134 2248\n                                         \n               Accuracy : 0.9336         \n                 95% CI : (0.925, 0.9414)\n    No Information Rate : 0.6469         \n    P-Value [Acc > NIR] : <2e-16         \n                                         \n                  Kappa : 0.8539         \n                                         \n Mcnemar's Test P-Value : 0.108          \n                                         \n            Sensitivity : 0.8958         \n            Specificity : 0.9542         \n         Pos Pred Value : 0.9143         \n         Neg Pred Value : 0.9437         \n              Precision : 0.9143         \n                 Recall : 0.8958         \n                     F1 : 0.9049         \n             Prevalence : 0.3531         \n         Detection Rate : 0.3163         \n   Detection Prevalence : 0.3460         \n      Balanced Accuracy : 0.9250         \n                                         \n       'Positive' Class : 0              \n                                         \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntest_confusion\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 369  37\n         1  26 487\n                                          \n               Accuracy : 0.9314          \n                 95% CI : (0.9131, 0.9469)\n    No Information Rate : 0.5702          \n    P-Value [Acc > NIR] : <2e-16          \n                                          \n                  Kappa : 0.8606          \n                                          \n Mcnemar's Test P-Value : 0.2077          \n                                          \n            Sensitivity : 0.9342          \n            Specificity : 0.9294          \n         Pos Pred Value : 0.9089          \n         Neg Pred Value : 0.9493          \n              Precision : 0.9089          \n                 Recall : 0.9342          \n                     F1 : 0.9213          \n             Prevalence : 0.4298          \n         Detection Rate : 0.4015          \n   Detection Prevalence : 0.4418          \n      Balanced Accuracy : 0.9318          \n                                          \n       'Positive' Class : 0               \n                                          \n```\n\n\n:::\n:::\n\n\n\nUn problema que debemos resolver desde un principio es que estas métricas tienen múltiples nombres dependiendo del campo en el que te encuentres. Por ejemplo, la sensibilidad se llama **recall** en aprendizaje automático, **tasa de positivos verdaderos** en medicina y **probabilidad de detección** en ingeniería. Es la misma cosa, pero los nombres cambian dependiendo de con quién estés hablando, y eso puede ser confuso.\n\nPara calcular la sensibilidad, solo necesitamos la columna izquierda de la matriz de confusión. Dividimos los verdaderos positivos entre todos los casos positivos reales. En otras palabras, la sensibilidad mide el porcentaje de verdaderos positivos que el modelo identifica correctamente. Por eso, el segundo nombre para la sensibilidad es **tasa de positivos verdaderos**.\n\n$$\nSensibilidad=TPR=\\frac{TP}{TP+FN}\n$$\n\nEn nuestro ejemplo del DJI, se trata del porcentaje de subidas de la acción que nuestro modelo detectó, lo que explica la tercera definición: **probabilidad de detección**. La sensibilidad oscila entre 0 y 1, o entre 0% y 100%, donde 1 indica una sensibilidad perfecta (sin falsos negativos) y 0 significa que no se puede detectar ningún caso positivo.\n\nEn nuestro ejemplo, la sensibilidad es alta 89.58% porque detectamos a 1152 subidas de precio, y una alta sensibilidad es lo que usualmente queremos. Especialmente en medicina, la sensibilidad es crucial para pruebas de detección como la detección de cáncer o enfermedades infecciosas como COVID-19. Si una prueba tiene baja sensibilidad, significa que muchos pacientes con cáncer son mal diagnosticados como sanos, lo que lleva a retrasos peligrosos en el tratamiento. Una prueba con alta sensibilidad asegura que la mayoría de los pacientes con la condición son identificados, incluso si genera algunos falsos positivos, que pueden ser seguidos con pruebas más específicas.\n\nEn aprendizaje automático, la sensibilidad es esencial para la detección de fraude o la detección de anomalías, donde los casos positivos, como las transacciones fraudulentas con tarjetas de crédito, son *raros pero críticos*. Un modelo con alta sensibilidad asegura que la mayoría de las actividades fraudulentas son detectadas, incluso si genera algunas falsas alarmas.\n\nSí, podemos maximizar la sensibilidad aumentando el costo de los falsos negativos con el paquete **`cutpointr`** y la función **`cutpoint()`**.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nd2 <- modelo$normalized$test |> \n    as.data.frame() |> \n    mutate(pred_probs = test_results$predictions,\n           pred_classes = factor(test_results$predicted_direction))\n    \n\nlibrary(cutpointr, verbose = FALSE)\nsensitive_case <- cutpointr(\n    data = d2,\n    x = pred_probs,\n    class = Direction,\n    method = minimize_metric,\n    metric = misclassification_cost,\n    cost_fp = 1,\n    cost_fn = 5\n)\n\nsensitive_case |> \n    t()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                       [,1]             \ndirection              \">=\"             \noptimal_cutpoint       -1.049363        \nmethod                 \"minimize_metric\"\nmisclassification_cost 110              \nacc                    0.9368879        \nsensitivity            0.9751908        \nspecificity            0.8860759        \nAUC                    0.9839067        \npos_class              1                \nneg_class              0                \nprevalence             0.570185         \noutcome                \"Direction\"      \npredictor              \"pred_probs\"     \ndata                   tbl_df,2         \nroc_curve              roc_cutpointr,10 \nboot                   NA               \n```\n\n\n:::\n\n```{.r .cell-code}\nsensitive_case |> \n    plot_roc()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n\nPor ejemplo, si establecemos el costo de los falsos negativos en cinco veces el costo de los falsos positivos, podemos aumentar la sensibilidad de un 89.58% a un asombroso 97.52%.\n\nLa sensibilidad nos ayuda a detectar tantos positivos verdaderos como sea posible, lo cual es crucial para escenarios como la detección del cáncer, pero aquí está el problema: aumentar demasiado la sensibilidad a menudo aumenta los falsos positivos, lo que puede ser peligroso en otros casos, como en la conducción autónoma, donde un coche autónomo podría confundir una sombra con un peatón, activando una frenada de emergencia innecesaria y un riesgo de accidente. En situaciones donde minimizar los falsos positivos y maximizar los verdaderos negativos es lo que más importa, una alta **especificidad** es clave. Así que hablemos de la especificidad.\n\nDesafortunadamente, la especificidad también tiene muchos nombres. En medicina, se le llama **tasa de negativos verdaderos**; en aprendizaje automático, a veces se la conoce como **selectividad**; en ingeniería, algunos la llaman **probabilidad de predicción correcta**, un término que personalmente encuentro particularmente intuitivo. Para calcular la especificidad, solo necesitamos la columna derecha de la matriz de confusión. Dividimos los verdaderos negativos entre todos los casos negativos reales.\n\n$$\nEspecificidad=TNR=\\frac{TN}{TN+FP}\n$$\n\nEn palabras sencillas, la especificidad mide el porcentaje de negativos reales que el modelo identifica correctamente como negativos. Por eso, otro nombre para la especificidad es la **tasa de negativos verdaderos**. En nuestro ejemplo, la especificidad nos dice **cuántos no sobrevivientes** el modelo clasificó correctamente como tales. La especificidad oscila entre 0 y 1, o entre 0% y 100%, donde 1 indica un modelo perfecto, sin falsos positivos, y 0 significa que no puede descartar los casos negativos en absoluto.\n\nEn nuestro ejemplo, la especificidad es sólida, con un 95.42%, porque solo etiquetamos incorrectamente a 108 bajadas como subidas, **mientras que la sensibilidad se centra en los positivos, la especificidad se centra en evitar las falsas alarmas, lo cual es crucial en ciertos escenarios de alto riesgo**. Por ejemplo, en medicina, una prueba con baja especificidad podría etiquetar falsamente a personas sanas como tener cáncer, lo que lleva a ansiedad innecesaria, biopsias, quimioterapia o incluso cirugía. Además, una baja especificidad en una prueba de una enfermedad rara puede abrumar a los sistemas de salud con falsas alarmas. Por eso, a veces necesitamos maximizar la especificidad y mantener los falsos positivos tan bajos como sea posible.\n\nSí, podemos hacerlo aumentando el costo de los falsos positivos usando el paquete **cutpointr** en R. Podemos desplazar el umbral de decisión para minimizar los falsos positivos y priorizar los verdaderos negativos, incluso si eso significa perder algunos verdaderos positivos.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsensitive_case <- cutpointr(\n    data = d2,\n    x = pred_probs,\n    class = Direction,\n    method = minimize_metric,\n    metric = misclassification_cost,\n    cost_fp = 5,\n    cost_fn = 1\n)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nAssuming the positive class is 1\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nAssuming the positive class has higher x values\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nMultiple optimal cutpoints found, applying break_ties.\n```\n\n\n:::\n\n```{.r .cell-code}\nsensitive_case |> \n    t()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                       [,1]             \ndirection              \">=\"             \noptimal_cutpoint       1.727427         \nmethod                 \"minimize_metric\"\nmisclassification_cost 125              \nacc                    0.9075082        \nsensitivity            0.8568702        \nspecificity            0.9746835        \nAUC                    0.9839067        \npos_class              1                \nneg_class              0                \nprevalence             0.570185         \noutcome                \"Direction\"      \npredictor              \"pred_probs\"     \ndata                   tbl_df,2         \nroc_curve              roc_cutpointr,10 \nboot                   NA               \n```\n\n\n:::\n\n```{.r .cell-code}\nsensitive_case |> \n    plot_roc()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n\nPor ejemplo, si establecemos el costo de los falsos positivos en cinco veces el costo de los falsos negativos, podemos hacer que la especificidad pase de un impresionante 95.42% a un increíble 97.47%.\n\nComo puedes ver, los científicos de datos enfrentan un desafío complejo: aumentar la sensibilidad para detectar todos los positivos posible corre el riesgo de aumentar las falsas alarmas, mientras que aumentar la especificidad para proteger las transacciones legítimas podría significar perder algunas actividades fraudulentas. Es aquí donde entra en juego el **índice J de Youden**. El índice J de Youden ayuda a encontrar un punto óptimo entre sensibilidad y especificidad, maximizando la efectividad general del modelo. Así que hablemos de eso.\n\n**El índice J de Youden es increíblemente útil cuando tanto los falsos positivos como los falsos negativos tienen consecuencias significativas**. Es por eso que el índice J de Youden maximiza los verdaderos positivos y minimiza los falsos positivos. Un dato curioso: el índice J de Youden también se conoce como **información basada en corredores de apuestas** porque mide cuánto más informado está una prueba o modelo en comparación con el azar. El término proviene del mundo de las apuestas, donde los corredores de apuestas dependen de la información para predecir los resultados mejor que el azar.\n\nPara calcular el índice J de Youden, combinamos sensibilidad y especificidad. Dado que la suma simple de sensibilidad y especificidad oscila entre 1 y 2, lo que no es fácil de interpretar, el menos uno en la fórmula de J normaliza la escala para que oscile entre 0 y 1, lo que es fácil de interpretar.\n\n$$\nJ=Sensibilidad+Especificidad-1\n$$\n\nEspecíficamente, J igual a 0 indica que la prueba no funciona mejor que el azar y, por lo tanto, no tiene información útil. J igual a 1 indica que la prueba distingue perfectamente entre positivos y negativos. En resumen, el índice J de Youden o **información** nos dice qué tan bien una prueba o modelo mejora la toma de decisiones en comparación con el azar.\n\nEn R, hay dos formas fáciles de calcular el índice J de Youden: una es usando la función **youden** del paquete **cutpointr**,\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nindexJ <- youden(tp = train_confusion$table[1],\n       tn = train_confusion$table[4],\n       fp = train_confusion$table[3],\n       fn = train_confusion$table[2])\n\nindexJ\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        youden\n[1,] 0.8499605\n```\n\n\n:::\n:::\n\n\n\ny la otra es usando el resumen de la función **epi.tests** del paquete **epiR**:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(epiR::epi.tests(train_confusion$table)) |> \n    gt::gt() |> \n    gt::tab_style(\n    style = list(\n      gt::cell_fill(color = \"orange\"),\n      gt::cell_text(weight = \"bold\")\n      ),\n    locations = gt::cells_body(\n      columns = statistic,\n      rows = statistic >= \"youden\"\n    )\n  )\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"krdkxevwfh\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>#krdkxevwfh table {\n  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#krdkxevwfh thead, #krdkxevwfh tbody, #krdkxevwfh tfoot, #krdkxevwfh tr, #krdkxevwfh td, #krdkxevwfh th {\n  border-style: none;\n}\n\n#krdkxevwfh p {\n  margin: 0;\n  padding: 0;\n}\n\n#krdkxevwfh .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#krdkxevwfh .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#krdkxevwfh .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#krdkxevwfh .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#krdkxevwfh .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#krdkxevwfh .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#krdkxevwfh .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#krdkxevwfh .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#krdkxevwfh .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#krdkxevwfh .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#krdkxevwfh .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#krdkxevwfh .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#krdkxevwfh .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#krdkxevwfh .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#krdkxevwfh .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#krdkxevwfh .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#krdkxevwfh .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#krdkxevwfh .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#krdkxevwfh .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#krdkxevwfh .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#krdkxevwfh .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#krdkxevwfh .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#krdkxevwfh .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#krdkxevwfh .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#krdkxevwfh .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#krdkxevwfh .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#krdkxevwfh .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#krdkxevwfh .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#krdkxevwfh .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#krdkxevwfh .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#krdkxevwfh .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#krdkxevwfh .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#krdkxevwfh .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#krdkxevwfh .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#krdkxevwfh .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#krdkxevwfh .gt_left {\n  text-align: left;\n}\n\n#krdkxevwfh .gt_center {\n  text-align: center;\n}\n\n#krdkxevwfh .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#krdkxevwfh .gt_font_normal {\n  font-weight: normal;\n}\n\n#krdkxevwfh .gt_font_bold {\n  font-weight: bold;\n}\n\n#krdkxevwfh .gt_font_italic {\n  font-style: italic;\n}\n\n#krdkxevwfh .gt_super {\n  font-size: 65%;\n}\n\n#krdkxevwfh .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#krdkxevwfh .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#krdkxevwfh .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#krdkxevwfh .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#krdkxevwfh .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#krdkxevwfh .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#krdkxevwfh .gt_indent_5 {\n  text-indent: 25px;\n}\n\n#krdkxevwfh .katex-display {\n  display: inline-flex !important;\n  margin-bottom: 0.75em !important;\n}\n\n#krdkxevwfh div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after {\n  height: 0px !important;\n}\n</style>\n<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n  <thead>\n    <tr class=\"gt_col_headings\">\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"statistic\">statistic</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"est\">est</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"lower\">lower</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"upper\">upper</th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr><td headers=\"statistic\" class=\"gt_row gt_left\">ap</td>\n<td headers=\"est\" class=\"gt_row gt_right\">0.34596376</td>\n<td headers=\"lower\" class=\"gt_row gt_right\">0.33050644</td>\n<td headers=\"upper\" class=\"gt_row gt_right\">0.36166868</td></tr>\n    <tr><td headers=\"statistic\" class=\"gt_row gt_left\">tp</td>\n<td headers=\"est\" class=\"gt_row gt_right\">0.35310269</td>\n<td headers=\"lower\" class=\"gt_row gt_right\">0.33756651</td>\n<td headers=\"upper\" class=\"gt_row gt_right\">0.36887498</td></tr>\n    <tr><td headers=\"statistic\" class=\"gt_row gt_left\">se</td>\n<td headers=\"est\" class=\"gt_row gt_right\">0.89580093</td>\n<td headers=\"lower\" class=\"gt_row gt_right\">0.87779966</td>\n<td headers=\"upper\" class=\"gt_row gt_right\">0.91196838</td></tr>\n    <tr><td headers=\"statistic\" class=\"gt_row gt_left\">sp</td>\n<td headers=\"est\" class=\"gt_row gt_right\">0.95415959</td>\n<td headers=\"lower\" class=\"gt_row gt_right\">0.94492020</td>\n<td headers=\"upper\" class=\"gt_row gt_right\">0.96224718</td></tr>\n    <tr><td headers=\"statistic\" class=\"gt_row gt_left\">diag.ac</td>\n<td headers=\"est\" class=\"gt_row gt_right\">0.93355299</td>\n<td headers=\"lower\" class=\"gt_row gt_right\">0.92497323</td>\n<td headers=\"upper\" class=\"gt_row gt_right\">0.94142858</td></tr>\n    <tr><td headers=\"statistic\" class=\"gt_row gt_left\">diag.or</td>\n<td headers=\"est\" class=\"gt_row gt_right\">178.94527363</td>\n<td headers=\"lower\" class=\"gt_row gt_right\">137.53368835</td>\n<td headers=\"upper\" class=\"gt_row gt_right\">232.82594497</td></tr>\n    <tr><td headers=\"statistic\" class=\"gt_row gt_left\">nndx</td>\n<td headers=\"est\" class=\"gt_row gt_right\">1.17652523</td>\n<td headers=\"lower\" class=\"gt_row gt_right\">1.14388264</td>\n<td headers=\"upper\" class=\"gt_row gt_right\">1.21548056</td></tr>\n    <tr><td headers=\"statistic\" class=\"gt_row gt_left\" style=\"background-color: #FFA500; font-weight: bold;\">youden</td>\n<td headers=\"est\" class=\"gt_row gt_right\">0.84996053</td>\n<td headers=\"lower\" class=\"gt_row gt_right\">0.82271986</td>\n<td headers=\"upper\" class=\"gt_row gt_right\">0.87421556</td></tr>\n    <tr><td headers=\"statistic\" class=\"gt_row gt_left\">pv.pos</td>\n<td headers=\"est\" class=\"gt_row gt_right\">0.91428571</td>\n<td headers=\"lower\" class=\"gt_row gt_right\">0.89744763</td>\n<td headers=\"upper\" class=\"gt_row gt_right\">0.92915893</td></tr>\n    <tr><td headers=\"statistic\" class=\"gt_row gt_left\">pv.neg</td>\n<td headers=\"est\" class=\"gt_row gt_right\">0.94374475</td>\n<td headers=\"lower\" class=\"gt_row gt_right\">0.93372253</td>\n<td headers=\"upper\" class=\"gt_row gt_right\">0.95265725</td></tr>\n    <tr><td headers=\"statistic\" class=\"gt_row gt_left\">lr.pos</td>\n<td headers=\"est\" class=\"gt_row gt_right\">19.54173147</td>\n<td headers=\"lower\" class=\"gt_row gt_right\">16.23853945</td>\n<td headers=\"upper\" class=\"gt_row gt_right\">23.51684830</td></tr>\n    <tr><td headers=\"statistic\" class=\"gt_row gt_left\">lr.neg</td>\n<td headers=\"est\" class=\"gt_row gt_right\">0.10920507</td>\n<td headers=\"lower\" class=\"gt_row gt_right\">0.09301233</td>\n<td headers=\"upper\" class=\"gt_row gt_right\">0.12821685</td></tr>\n    <tr><td headers=\"statistic\" class=\"gt_row gt_left\">p.rout</td>\n<td headers=\"est\" class=\"gt_row gt_right\">0.65403624</td>\n<td headers=\"lower\" class=\"gt_row gt_right\">0.63833132</td>\n<td headers=\"upper\" class=\"gt_row gt_right\">0.66949356</td></tr>\n    <tr><td headers=\"statistic\" class=\"gt_row gt_left\">p.rin</td>\n<td headers=\"est\" class=\"gt_row gt_right\">0.34596376</td>\n<td headers=\"lower\" class=\"gt_row gt_right\">0.33050644</td>\n<td headers=\"upper\" class=\"gt_row gt_right\">0.36166868</td></tr>\n    <tr><td headers=\"statistic\" class=\"gt_row gt_left\">p.tpdn</td>\n<td headers=\"est\" class=\"gt_row gt_right\">0.04584041</td>\n<td headers=\"lower\" class=\"gt_row gt_right\">0.03775282</td>\n<td headers=\"upper\" class=\"gt_row gt_right\">0.05507980</td></tr>\n    <tr><td headers=\"statistic\" class=\"gt_row gt_left\">p.tndp</td>\n<td headers=\"est\" class=\"gt_row gt_right\">0.10419907</td>\n<td headers=\"lower\" class=\"gt_row gt_right\">0.08803162</td>\n<td headers=\"upper\" class=\"gt_row gt_right\">0.12220034</td></tr>\n    <tr><td headers=\"statistic\" class=\"gt_row gt_left\">p.dntp</td>\n<td headers=\"est\" class=\"gt_row gt_right\">0.08571429</td>\n<td headers=\"lower\" class=\"gt_row gt_right\">0.07084107</td>\n<td headers=\"upper\" class=\"gt_row gt_right\">0.10255237</td></tr>\n    <tr><td headers=\"statistic\" class=\"gt_row gt_left\">p.dptn</td>\n<td headers=\"est\" class=\"gt_row gt_right\">0.05625525</td>\n<td headers=\"lower\" class=\"gt_row gt_right\">0.04734275</td>\n<td headers=\"upper\" class=\"gt_row gt_right\">0.06627747</td></tr>\n  </tbody>\n  \n  \n</table>\n</div>\n```\n\n:::\n:::\n\n\n\nUn $J$ de 85.00% es fuerte. Nos dice que el modelo funciona mejor que el azar, pero podría ser perfeccionado para equilibrar mejor la sensibilidad y la especificidad. Si te preguntas cómo maximizar el índice J de Youden, la respuesta es usando la misma función **cutpointr** que usamos para maximizar la sensibilidad y la especificidad.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nimprove_j <- cutpointr(\n    data = d2,\n    x = pred_probs,\n    class = Direction,\n    method = maximize_metric,\n    metric = youden,\n    boot_runs = 1000\n)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nAssuming the positive class is 1\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nAssuming the positive class has higher x values\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRunning bootstrap...\n```\n\n\n:::\n\n```{.r .cell-code}\nimprove_j |> t()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                 [,1]             \ndirection        \">=\"             \noptimal_cutpoint -0.2763423       \nmethod           \"maximize_metric\"\nyouden           0.8724853        \nacc              0.9368879        \nsensitivity      0.9408397        \nspecificity      0.9316456        \nAUC              0.9839067        \npos_class        1                \nneg_class        0                \nprevalence       0.570185         \noutcome          \"Direction\"      \npredictor        \"pred_probs\"     \ndata             tbl_df,2         \nroc_curve        roc_cutpointr,10 \nboot             tbl_df,23        \n```\n\n\n:::\n\n```{.r .cell-code}\nimprove_j |> \n    plot_metric()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n\nLo que quiero mostrarte es que, aumentando ligeramente la sensibilidad del 89.58% al 94.08% y disminuyendo ligeramente la especificidad del 95.42% al 93.16%, podríamos aumentar el índice J de Youden del 85.00% al 87.25%. ¡Genial!, lo que hace que nuestro modelo sea más preciso.\n\nY hablando de precisión, debemos discutirla a continuación, porque la precisión es una de las métricas más importantes y ampliamente utilizadas derivadas de la matriz de confusión. La precisión, también conocida como **valor predictivo positivo**, mide qué tan precisas son las predicciones positivas. Es el porcentaje de resultados positivos que son correctos, lo que muestra qué tan probable es que un resultado positivo sea verdadero.\n\nDurante los primeros días de la pandemia de COVID-19, la sensibilidad fue clave para detectar a tantas personas infectadas como posible, pero más tarde, cuando la propagación se desaceleró y las pruebas se multiplicaron, la precisión se convirtió en el foco de atención.\n\nPara calcular la precisión, nos centramos en la primera fila de la [matriz de confusión](https://cchiquitovalencia.github.io/posts/2025-04-07-predictions_on_stocks/#fig-1), los positivos predichos. Es la proporción de verdaderos positivos entre todos los casos positivos predichos. La precisión oscila entre 0 y 1, o entre 0% y 100%. Un puntaje de 1 significa que todas las predicciones positivas fueron correctas, sin falsos positivos, mientras que 0 significa que todas fueron incorrectas.\n\n$$\nPrecisión=PPV=\\frac{TP}{TP+FP}\n$$\n\nEn nuestro ejemplo, una precisión del 91.43% nos dice que el 91.43% de las acciones que el modelo etiquetó como subidas realmente subieron. Eso es sólido, ya que solo 108 de los 1260 movimientos hacia arriba predichos fueron mal clasificados.\n\nPero, ¿por qué la precisión es tan importante? Piensa en los filtros de correo no deseado. Una alta precisión asegura que cuando un correo aterriza en tu bandeja de spam, es casi seguro que es basura. Por otro lado, si tienes una baja precisión, te encontrarás revolviendo spam para encontrar ese correo urgente de tu jefe. Es un infierno, ¿no? La precisión también se puede calcular usando sensibilidad, especificidad y prevalencia, aunque idealmente, es un poco pesado y difícil de recordar.\n\n$$\nPPV=\\frac{Sensibilidad*Prevalencia}{Sensitividad*Prevalencia+(1-Especificidad)*(1-Prevalencia)}\n$$\n\nLo que es fácil de recordar es que cuando hay un valor predictivo positivo, también debe haber un valor predictivo negativo. De hecho, el valor predictivo negativo nos dice cuántos resultados de prueba negativos son precisos.\n\nPara calcular el **valor predictivo negativo (VPV)**, solo necesitamos la fila inferior de la matriz de confusión, los negativos predichos. Dividimos el número de verdaderos negativos entre el total de predicciones negativas. El valor predictivo negativo es crucial porque construye confianza en los resultados negativos.\n\n$$\nNPV=\\frac{TN}{TN+FN}\n$$\n\nPor ejemplo, en la detección del cáncer, si tu prueba da negativo y el VPV es del 99%, hay un 99% de probabilidad de que realmente no tengas cáncer. Eso es muy tranquilizador. Solo hay un 1% de posibilidad de que haya un error. Pero si el VPV es del 94.37%, como en nuestro ejemplo, significa que el 94.37% de las veces un resultado negativo es correcto, pero que hay un 5.63% de probabilidad de que el resultado negativo sea incorrecto y que realmente tengas cáncer. Eso probablemente no te tranquilizaría mucho, ya que es un riesgo bastante grande. Por eso, el VPV es realmente importante porque afecta directamente cuánto puedes confiar en un resultado negativo.\n\nEl valor predictivo positivo nos dice cuántas de nuestras predicciones positivas son realmente correctas, mientras que el valor predictivo negativo mide cuántas de nuestras predicciones negativas son precisas. Ambas son útiles, pero se centran solo en un lado de los resultados de las predicciones, ya sean positivos o negativos. Pero, **¿qué pasa si necesitamos evaluar la corrección general de todas las predicciones, tanto positivas como negativas?**\n\nAhí es donde entra en juego la **exactitud**. La exactitud nos da una visión general del rendimiento midiendo la proporción de todas las predicciones correctas, independientemente de la clase. De hecho, ¿qué métricas usas y cuáles son las principales en tu opinión? Realmente quiero saber tus pensamientos. La fórmula para la exactitud es sencilla: suma los verdaderos positivos y los verdaderos negativos, y divide entre el número total de casos.\n\n$$\nExactitud=\\frac{TP+TN}{total}\n$$\n\nEso es todo, bastante sencillo, ¿verdad? Mientras que una mayor exactitud es generalmente lo que queremos, la exactitud **puede ser engañosa al lidiar con clases ligeramente desequilibradas,** donde un resultado sobrepasa ligeramente al otro. Es por eso que tenemos una métrica más robusta como la **exactitud equilibrada**.\n\n$$\n\\text{Exactitud equilibrada}=\\frac{Sensibilidad+Especificidad}{2}\n$$\n\nLa exactitud equilibrada ofrece una solución promediando la sensibilidad y la especificidad, asegurando que ambas clases reciban una consideración igual. En nuestro ejemplo, una exactitud equilibrada del 92.50% está solo 0.86% por debajo de la exactitud general del 93.36%, lo que sugiere que las clases están relativamente equilibradas, pero eso no es siempre el caso. Por eso, no confío en la exactitud si no veo una matriz de confusión o una exactitud equilibrada comparada con la exactitud. Podemos calcular fácilmente la exactitud equilibrada usando la función de `confusionMatrix()` del paquete **`caret`**.\n\nMientras que la exactitud equilibrada es útil para conjuntos de datos ligeramente desequilibrados, a veces la exactitud equilibrada puede ser casi la mitad de la exactitud, lo que indica que nuestro conjunto de datos está muy sesgado y no balanceado.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncasos <- 10000\nprop_positivos <- 0.05\ncant_positivos <- casos * prop_positivos\ncant_negativos <- casos - cant_positivos\n\nactual <- c(rep(1, cant_positivos), rep(0, cant_negativos))\npredicciones <- rep(0, casos)\n\nejemplo <- confusionMatrix(factor(predicciones), factor(actual))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in confusionMatrix.default(factor(predicciones), factor(actual)):\nLevels are not in the same order for reference and data. Refactoring data to\nmatch.\n```\n\n\n:::\n\n```{.r .cell-code}\nejemplo\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 9500  500\n         1    0    0\n                                          \n               Accuracy : 0.95            \n                 95% CI : (0.9455, 0.9542)\n    No Information Rate : 0.95            \n    P-Value [Acc > NIR] : 0.5119          \n                                          \n                  Kappa : 0               \n                                          \n Mcnemar's Test P-Value : <2e-16          \n                                          \n            Sensitivity : 1.00            \n            Specificity : 0.00            \n         Pos Pred Value : 0.95            \n         Neg Pred Value :  NaN            \n             Prevalence : 0.95            \n         Detection Rate : 0.95            \n   Detection Prevalence : 1.00            \n      Balanced Accuracy : 0.50            \n                                          \n       'Positive' Class : 0               \n                                          \n```\n\n\n:::\n:::\n\n\n\nPor ejemplo, consideremos un conjunto de datos con 10^{4} casos, donde solo el 5% son positivos. En este caso, un modelo puede lograr una asombrosa exactitud del 95.00% simplemente prediciendo negativo todas las veces, pero falla al detectar cualquier positivo, lo que resulta en un 100% de predicciones positivas incorrectas, lo cual es **inaceptable**. Sin ver la matriz de confusión, no somos conscientes de este desastre.\n\nSin embargo, la exactitud equilibrada de 50.00% revela esta debilidad al dar una puntuación mucho más baja, indicando que algo está seriamente mal. **Centrarse solo en la exactitud puede ocultar muchos errores**, lo que lleva a malas decisiones. A veces, **saber cuán impreciso es nuestro modelo puede ser muy útil porque revela dónde y cuántas veces nuestro modelo está equivocado**.\n\nMétricas como la **tasa de malclasificación** y la **tasa de descubrimiento falso** son increíblemente prácticas y merecen su propio espacio de expliación. Por lo tanto, si quieres que tu modelo sea sólido y confiable, o si necesitas explicar por qué algunos resultados del modelo no deben confiarse, debes ver otros de mis posts.\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}