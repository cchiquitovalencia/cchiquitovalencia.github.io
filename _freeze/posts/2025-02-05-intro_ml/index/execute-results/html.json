{
  "hash": "35ae5390e34039da1c4020b9ee3b0793",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Introducci√≥n al Machine Learning\"\ndescription: \"Principios en ingenier√≠a\"\nauthor:\n  - name: Cristian Chiquito Valencia\n    url: https://cchiquitovalencia.github.io/\n    affiliation: Independent @ CHV\ndate: 02-05-2025\ncategories: [Machine Learning, Artificial Intelligence, Data Science, Deep Learning] # self-defined categories\ncitation: \n  url: https://cchiquitovalencia.github.io/posts/2025-02-05-intro_ml/\nimage: concepts_ML.jpeg\ndraft: false # setting this to `true` will prevent your post from appearing on your listing page until you're ready!\ncode-fold: true    \n---\n\n\n\n## Introducci√≥n\n\nEl aprendizaje autom√°tico puede parecer intimidante para aquellos que son nuevos en este campo. Este post tiene como objetivo familiarizar a los lectores con los fundamentos del aprendizaje autom√°tico y hacer que se d√© cuenta de lo maravilloso que es este tema. Ey, date cuenta! Vamos a explorar los conceptos preliminares del aprendizaje autom√°tico y establecer los fundamentos para aprender conceptos avanzados. Primero, los conceptos b√°sicos del aprendizaje autom√°tico y algunas perspectivas sobre la inteligencia artificial y el aprendizaje profundo (deep learning). Luego, la evoluci√≥n gradual del aprendizaje autom√°tico a lo largo de la historia, en orden cronol√≥gico desde 1940 hasta la actualidad. Despu√©s, veremos la motivaci√≥n, el prop√≥sito y la importancia del aprendizaje autom√°tico en funci√≥n de algunas aplicaciones pr√°cticas en la vida real. A continuaci√≥n, se introduce el conocimiento previo necesario para dominar el aprendizaje autom√°tico, para asegurarse de que los lectores sean conscientes qu√© necesitan saber antes de comenzar su curso sobre aprendizaje autom√°tico. Finalmente discutimos los lenguajes de programaci√≥n y herramientas asociadas necesarias para utilizar el aprendizaje autom√°tico. Todo es lo hacemos utilizando `R` como lenguaje de programaci√≥n, `RStudio` como editor de c√≥digo o compilador, y esta escrito en documento de `Quarto` (.qmd). Antes de la conclusi√≥n, revisamos algunos ejemplos reales de aprendizaje autom√°tico que todos los lectores de ingenier√≠a podr√°n relacionar, lo que despertar√° su curiosidad para entrar en el mundo del aprendizaje autom√°tico.\n\n## Qu√© es Machine Learning?\n\nLa tecnolog√≠a moderna est√° mejorando y aceler√°ndose gracias a la investigaci√≥n, experimentaci√≥n y desarrollo extensivos y continuos. Por ejemplo, las m√°quinas est√°n volvi√©ndose inteligentes y realizan tareas de manera mucho m√°s eficiente. El aprendizaje autom√°tico ha estado evolucionando a un ritmo sin precedentes, y los resultados son evidentes en nuestros tel√©fonos y computadoras, que se est√°n convirtiendo en m√°s multifuncionales cada d√≠a, los sistemas de automatizaci√≥n est√°n volvi√©ndose omnipresentes, se est√°n construyendo robots inteligentes y as√≠ sucesivamente.\n\nEn 1959, el cient√≠fico de la computadora y pionero del aprendizaje autom√°tico Arthur Samuel defini√≥ el aprendizaje autom√°tico como el \"*campo de estudio que le da a los ordenadores la capacidad de aprender sin ser programados expl√≠citamente*\". El libro de Tom Mitchell de 1997 sobre aprendizaje autom√°tico defini√≥ el aprendizaje autom√°tico como \"*el estudio de los algoritmos de computadora que permiten a los programas de computadora mejorar autom√°ticamente a trav√©s de la experiencia*\". Define el aprendizaje de la siguiente manera: \"*Un programa de computadora se dice que aprende de la experiencia E con respecto a alguna clase de tareas T y medida de rendimiento P, si su rendimiento en tareas en T, medido por P, mejora con la experiencia E*\". El aprendizaje autom√°tico (**ML**) es una rama del aprendizaje artificial (**AI**) que permite a los ordenadores y m√°quinas aprender de la informaci√≥n existente y aplicar ese aprendizaje para realizar otras tareas similares. Sin `programaci√≥n expl√≠cita`, la m√°quina aprende a partir de los datos que se le proporcionan. La m√°quina identifica o aprende patrones, tendencias o caracter√≠sticas esenciales a partir de datos previos y hace una predicci√≥n sobre nuevos datos. Un ejemplo de aplicaci√≥n real del aprendizaje autom√°tico es los **sistemas de recomendaci√≥n**. Por ejemplo, un sitio de streaming de pel√≠culas recomendar√° pel√≠culas al usuario basadas en su lista de pel√≠culas vistas previamente.\n\nLos algoritmos de ML se clasifican ampliamente como **aprendizaje supervisado** y **aprendizaje no supervisado**, con otros tipos como el **aprendizaje por refuerzo** y **aprendizaje semisupervisado**. Lo m√°s seguro es que tendr√°s otros posts sobre estos temas.\n\n### Flujo de trabajo de Machine Learning\n\nAntes de profundizar en los detalles, un principiante debe tener una visi√≥n hol√≠stica del flujo de trabajo completo del aprendizaje autom√°tico. La visi√≥n general del proceso revela que hay cuatro pasos principales en un flujo de trabajo t√≠pico de ML: **recopilaci√≥n de conjuntos de datos, preprocesamiento de datos, entrenamiento del modelo** y, finalmente, **evaluaci√≥n del modelo**. La [figura 1](#fig-diagram) muestra el diagrama de bloques de los cuatro pasos del flujo de trabajo de ML. Estos pasos se siguen generalmente en todas las aplicaciones de ML:\n\n\n\n```{mermaid}\n%%| label: fig-diagram\n%%| fig-cap: \"El diagrama de bloques del flujo de trabajo de aprendizaje autom√°tico\"\nflowchart LR\n    A(Paso 1: Recopilaci√≥n de conjunto de datos) --> B(Paso 2: Preprocesamiento de conjunto de datos)\n    B(Paso 2: Preprocesamiento de conjunto de datos) --> C(Paso 3: Entrenamiento del modelo)\n    C(Paso 3: Entrenamiento del modelo) --> D(Paso 4: Evaluaci√≥n del modelo)\n    D(Paso 4: Evaluaci√≥n del modelo) --> B(Paso 2: Preprocesamiento de conjunto de datos)\n    D(Paso 4: Evaluaci√≥n del modelo) --> C(Paso 3: Entrenamiento del modelo)\n    D(Paso 4: Evaluaci√≥n del modelo) --> A(Paso 1: Recopilaci√≥n de conjunto de datos)\n```\n\n\n\n1.  Recopilaci√≥n de conjuntos de datos: El primer paso del ML es recopilar el conjunto de datos. Este paso depende del tipo de experimentos o proyectos que se desean realizar. Diferentes experimentos o proyectos requieren diferentes datos. Tambi√©n se debe decidir qu√© tipo de datos se requieren. ¬øSer√°n datos num√©ricos o categ√≥ricos? Por ejemplo, si queremos realizar una predicci√≥n sobre los precios de las casas, necesitar√≠amos la siguiente informaci√≥n: el precio de las casas, la direcci√≥n de las casas, el n√∫mero de habitaciones, el estado de la casa, el tama√±o de la casa, etc. Luego surge la pregunta: ¬øqu√© unidad de precio deber√≠a ser? ¬øD√≥lares, libras o alguna otra moneda?\n\n2.  Preprocesamiento de datos: Los datos que recopilamos a menudo est√°n desorganizados y no pueden ser utilizados directamente para entrenar modelos. Antes de proceder al siguiente paso, los datos necesitan ser preprocesados. Primero, el conjunto de datos puede contener datos faltantes o ruidosos. Este problema necesita ser resuelto antes de pasar los datos al modelo. Diferentes datos pueden estar en diferentes rangos, lo que podr√≠a ser un problema para los modelos, por lo que los datos necesitan ser estandarizados para que todos los datos est√©n en el mismo rango. Adem√°s, no todos los datos ser√≠an igualmente importantes para predecir la variable objetivo. Necesitamos encontrar y seleccionar los datos que contribuyen m√°s a encontrar las variables objetivo. Finalmente, el conjunto de datos debe ser dividido en dos conjuntos: el conjunto de entrenamiento y el conjunto de prueba. La divisi√≥n se hace generalmente en una relaci√≥n de 80:20, donde el 80% del conjunto de datos es el conjunto de entrenamiento y el 20% es el conjunto de prueba. Esta relaci√≥n puede variar seg√∫n el tama√±o del conjunto de datos y la naturaleza del problema. Aqu√≠, el conjunto de entrenamiento se utilizar√° para entrenar los modelos, y el conjunto de prueba se utilizar√° para evaluar los modelos. A menudo, el conjunto de datos se divide en conjuntos de entrenamiento, validaci√≥n y prueba. El conjunto de validaci√≥n se utiliza para ajustar los hiperpar√°metros, lo que se discutir√° en el Cap√≠tulo 2 de este libro. La [figura 2](#fig-diagram2) muestra los diferentes pasos de preprocesamiento de datos. Estos pasos se explicar√°n en el Cap√≠tulo 3.\n\n3.  Entrenamiento del modelo: Basado en el problema, se debe seleccionar el tipo de modelo requerido primero. Mientras se selecciona el modelo, se debe considerar la informaci√≥n disponible sobre el conjunto de datos. Por ejemplo, la clasificaci√≥n supervisada se puede abordar si el conjunto de datos contiene informaci√≥n sobre ambos valores de entrada y salida. A veces, se necesitan utilizar m√°s de un modelo para entrenar y hacer el trabajo. El modelo ajusta o aprende los datos. Este paso es muy importante porque el rendimiento del modelo depende mucho de c√≥mo bien los datos han sido ajustados o aprendidos por el modelo. Mientras se entrena el modelo, se debe tener cuidado de no subajustar o sobreadjustar el modelo. Subajustar y sobreadjustar se han explicado en el Cap√≠tulo 2.\n\n4.  Evaluaci√≥n del modelo: Una vez que el modelo se ha construido y entrenado, es esencial entender c√≥mo bien se ha entrenado el modelo, c√≥mo bien funcionar√° y si el modelo ser√° √∫til para el experimento. Ser√≠a in√∫til si el modelo no funciona bien o no cumple con su prop√≥sito. Por lo tanto, se utiliza el conjunto de prueba para probar el modelo, y se utilizan diferentes m√©tricas de evaluaci√≥n para evaluar y comprender el modelo. Las m√©tricas de evaluaci√≥n incluyen precisi√≥n, recall y algunas otras, que se utilizan para obtener una visi√≥n general de c√≥mo bien funcionar√° el modelo. Las m√©tricas de evaluaci√≥n se han discutido en el Cap√≠tulo 2. Basado en la evaluaci√≥n del modelo, puede ser necesario regresar a los pasos anteriores y realizarlos de nuevo seg√∫n sea necesario.\n\n\n\n```{mermaid}\n%%| label: fig-diagram2\n%%| fig-cap: \"El diagrama de bloques de preprocesamiento de datos\"\n%%| fig-height: 18\n\nflowchart LR\n    A[\"`**Prepocesamiento de Datos**`\"] --> B(\"`**Integraci√≥n de Datos**\n    - Integraci√≥n de esquemas\n    - Problema de identificaci√≥n de entidad\n    - Detecci√≥n y resoluci√≥n de conceptos de valores de datos`\")\n    A[\"`**Prepocesamiento de Datos**`\"] --> C(\"`**Reducci√≥n de Datos o Dimensi√≥n**\n    - Agregaci√≥n de cubo de Datos\n    - Selecci√≥n de subconjunto de Atributos\n    - Reducci√≥n de numerosidad\n    - Reducci√≥n de dimensionalidad`\")\n    A[\"`**Prepocesamiento de Datos**`\"] --> D(\"`**Transformaci√≥n de Datos**\n    - Normalizaci√≥n\n    - Selecci√≥n de Atributos\n    - Discretizaci√≥n\n    - Generaci√≥n de Jerarqu√≠a de Conceptos`\")\n    A[\"`**Prepocesamiento de Datos**`\"] --> E(\"`**Limpieza de Datos**\n    - Datos faltantes\n    - Datos ruidosos`\")\n```\n\n\n\n### Qu√© no es Machine Learning?\n\nEl aprendizaje autom√°tico es un t√©rmino en boga en el mundo actual. Casi todos los campos de la ciencia y la tecnolog√≠a involucran uno o m√°s aspectos del ML. Sin embargo, es necesario distinguir entre lo que es ML y lo que no lo es. Por ejemplo, el `programar en sentido general no es ML`, ya que un programa expl√≠citamente indica o instruye a una m√°quina qu√© hacer y cu√°ndo hacerlo sin permitir que la m√°quina aprenda por s√≠ misma y aplique el aprendizaje en un entorno similar pero nuevo. Un sistema de recomendaci√≥n que est√° dise√±ado expl√≠citamente para dar recomendaciones no es una aplicaci√≥n de ML. Si el sistema est√° dise√±ado de manera que se le d√© un conjunto espec√≠fico de pel√≠culas como condiciones y se le sugiera una pel√≠cula expl√≠citamente, como:\n\n> Si la persona ha visto Harry Potter o Pirates of the Caribbean o El Se√±or de los Anillos, entonces recomiende Animales Fant√°sticos a la persona. Tambi√©n si la persona ha visto Divergente o Maze Runner, recomiende Juegos del Hambre.\n\nEste sistema de recomendaci√≥n no es una aplicaci√≥n de ML. Aqu√≠, *la m√°quina no explora ni aprende tendencias*, caracter√≠sticas o caracter√≠sticas de pel√≠culas previamente vistas. En su lugar, simplemente se basa en las condiciones dadas y sugiere la pel√≠cula dada. Para un sistema de recomendaci√≥n basado en ML, el programa no indica expl√≠citamente al sistema qu√© pel√≠cula recomendar basada en la lista de pel√≠culas vistas previamente. En su lugar, se programa de manera que el sistema explore la lista de pel√≠culas vistas previamente. Busca caracter√≠sticas significativas o caracter√≠sticas como g√©neros, actores, directores, productores, etc. Tambi√©n verifica qu√© pel√≠culas han sido vistas por otros usuarios para que el sistema pueda formar un tipo de grupo. Basado en este aprendizaje y observaci√≥n, el sistema concluye y da una recomendaci√≥n. Por ejemplo, la lista de pel√≠culas de una persona es como sigue: [Sully](https://www.imdb.com/title/tt3263904/?ref_=nv_sr_srsg_0_tt_1_nm_7_in_0_q_sully), [Catch Me If You Can](https://www.imdb.com/title/tt0264464/?ref_=nv_sr_srsg_0_tt_8_nm_0_in_0_q_catch%2520me%2520if%2520), [Captain Philips](https://www.imdb.com/title/tt1535109/?ref_=nv_sr_srsg_0_tt_5_nm_3_in_0_q_captain%2520ph), [Inception](https://www.imdb.com/title/tt1375666/?ref_=nv_sr_srsg_0_tt_8_nm_0_in_0_q_inceptio) y [Interstellar](https://www.imdb.com/title/tt0816692/?ref_=nv_sr_srsg_0_tt_7_nm_1_in_0_q_inters). Se pueden extraer las siguientes conclusiones de esta lista:\n\n‚Ä¢ Tres de las pel√≠culas son de g√©nero biogr√°fico; las otras dos son de ciencia ficci√≥n.\n\n‚Ä¢ Tres de las pel√≠culas tienen a Tom Hanks en ellas.\n\n‚Ä¢ Las pel√≠culas de ciencia ficci√≥n en la lista est√°n dirigidas por Christopher Nolan.\n\nBasado en este patr√≥n, el sistema puede recomendar pel√≠culas biogr√°ficas que no incluyan a Tom Hanks. El sistema tambi√©n recomendar√° m√°s pel√≠culas de Tom Hanks que pueden ser biogr√°ficas o de otros g√©neros. Tambi√©n puede recomendar pel√≠culas de ciencia ficci√≥n que hayan estrellado a Tom Hanks. El sistema tambi√©n recomendar√° m√°s pel√≠culas dirigidas por Christopher Nolan. Como este sistema decide por aprender los patrones de la lista de pel√≠culas vistas, se considerar√° una aplicaci√≥n de ML.\n\n### Jerga de Machine Learning\n\nMientras vamos a trav√©s estos posts, vamos a encontrar muchos t√©rminos relacionados con el aprendizaje autom√°tico. Por lo tanto, es esencial que entendamos este jargon. Los t√©rminos que necesitamos entender se discuten en esta secci√≥n.\n\n#### Caracter√≠sticas\n\nLas caracter√≠sticas, tambi√©n conocidas como **atributos**, **variables predictivas** o **variables independientes**, son simplemente las caracter√≠sticas o etiquetas del conjunto de datos. Supongamos que tenemos informaci√≥n sobre la altura y el peso de sesenta estudiantes en una clase. La altura y el peso son conocidos como caracter√≠sticas dentro del conjunto de datos. Estas caracter√≠sticas se extraen del conjunto de datos bruto y se alimentan a los modelos como entradas.\n\n#### Variable objetivo\n\nSimplemente, las variables objetivo son los **outputs** que los modelos deben dar. Por ejemplo, una rese√±a de pel√≠cula debe clasificarse como positiva o negativa. Aqu√≠, la variable positiva/negativa es la variable objetivo en este caso. Primero, esta variable objetivo debe ser determinada por el usuario. Luego, despu√©s de que se determine la variable objetivo, se debe entender la relaci√≥n entre las caracter√≠sticas y la variable objetivo para realizar operaciones adicionales.\n\n#### Problema de optimizaci√≥n\n\nLos problemas de optimizaci√≥n se definen como una clase de problemas que **buscan la** **soluci√≥n √≥ptima** bajo un conjunto de condiciones dadas. Estos problemas suelen involucrar un *trade-off* entre diferentes condiciones. Por ejemplo, un bater√≠a debe ser comprada para respaldo de energ√≠a en una residencia, pero estamos indecisos sobre el tama√±o adecuado de la bater√≠a, que viene en $6.4$ y $13.5$ kWh. Si compramos el tama√±o m√°s grande, podemos almacenar m√°s energ√≠a y disfrutar de una variedad de caracter√≠sticas adicionales de la bater√≠a, pero tambi√©n debemos pagar m√°s. Si compramos el tama√±o m√°s peque√±o, podemos almacenar menos energ√≠a y obtener poco o nada de caracter√≠sticas adicionales, pero ahorraremos m√°s dinero. Necesitamos optimizar nuestras necesidades en este escenario. Si solo requerimos respaldo de energ√≠a sin requisitos especiales para las caracter√≠sticas adicionales, el tama√±o m√°s peque√±o ser√° suficiente para satisfacer la necesidad. Esto ser√≠a la soluci√≥n √≥ptima para el dilema de la bater√≠a.\n\n#### Funci√≥n objetivo\n\nGeneralmente, m√°s de una soluci√≥n existe para un problema. Entre todas las soluciones, se requiere encontrar la soluci√≥n √≥ptima, lo que se hace usualmente midiendo una cantidad y requiriendo que se ajuste a un est√°ndar. La funci√≥n objetivo es el est√°ndar que la soluci√≥n √≥ptima debe cumplir. La funci√≥n objetivo se dise√±a para tomar par√°metros y evaluar el rendimiento de la soluci√≥n. El objetivo de la funci√≥n objetivo puede variar seg√∫n el problema en consideraci√≥n. **Maximizar** o **minimizar** un par√°metro particular puede ser necesario para calificar la soluci√≥n como √≥ptima. Por ejemplo, muchos algoritmos de aprendizaje autom√°tico utilizan una medida de distancia (*Euclideana*, *Manhattan* o *Minkowski*) como funci√≥n objetivo.\n\n#### Funci√≥n de costo\n\nLa funci√≥n de costo se utiliza para entender c√≥mo bien se desempe√±a el modelo en un conjunto de datos dado. La funci√≥n de costo tambi√©n calcula la diferencia entre los valores de salida predichos y los valores de salida reales. Por lo tanto, la funci√≥n de costo y la funci√≥n de p√©rdida pueden parecer similares. Sin embargo, la funci√≥n de p√©rdida se calcula para un solo punto de datos despu√©s de un solo entrenamiento, y la funci√≥n de costo se calcula para un conjunto de datos dado despu√©s de que se complete el entrenamiento del modelo. Por lo tanto, se puede inferir que la funci√≥n de costo es la **funci√≥n de p√©rdida promedio** para el conjunto de datos completo *despu√©s* del entrenamiento del modelo. Los t√©rminos funci√≥n de p√©rdida y funci√≥n de costo se utilizan a menudo de manera intercambiable en el aprendizaje autom√°tico. Al igual que las funciones de p√©rdida, se utilizan diferentes tipos de funciones de costo en diferentes contextos y algoritmos de aprendizaje autom√°tico.\n\nSupongamos que $J$ es una funci√≥n de costo utilizada para evaluar el rendimiento de un modelo. Generalmente se define con la funci√≥n de p√©rdida $L$. La forma generalizada de la funci√≥n de costo $J$ se da a continuaci√≥n:\n\n$$\nJ(ùõ≥)=‚àë^m_{i=1}L(h_{ùõ≥}(x^i),y^i)\n$$ {#eq-eq1}\n\nDonde $Œ∏$ es un par√°metro que se est√° optimizando, $m$ es el n√∫mero de muestras de entrenamiento, $i$ es el n√∫mero de ejemplos y salidas, $h$ es la funci√≥n de hip√≥tesis del modelo, $x$ es el valor predicho estimado, $y$ es el valor verdadero (ground truth value).\n\n#### Funci√≥n de p√©rdida\n\nSupongamos que se da una funci√≥n $L : (z, y) ‚àà ‚Ñù √ó Y ‚Üí L(z, y) ‚àà ‚Ñù$. La funci√≥n $L$ toma $z$ como entradas, donde $z$ es el valor predicho proporcionado por un modelo de aprendizaje autom√°tico. La funci√≥n luego compara $z$ con respecto a su valor real correspondiente $y$ y produce un valor que indica la diferencia entre el valor predicho y el valor real. Esta funci√≥n se conoce como una funci√≥n de p√©rdida.\n\nLa funci√≥n de p√©rdida es significativa porque expl√≠citamente explica c√≥mo los modelos se desempe√±an al modelar los datos que se les est√°n proporcionando. La funci√≥n de p√©rdida **calcula el error**, que es la diferencia entre el valor de salida predicho y el valor de salida real. Por lo tanto, es intuitivo que un valor m√°s bajo de la funci√≥n de p√©rdida indica un valor de error m√°s bajo, lo que implica que el modelo ha aprendido o ajustado los datos bien. Mientras se aprenden los datos, el objetivo del entrenamiento del modelo es siempre reducir el valor de la funci√≥n de p√©rdida.\n\nDespu√©s de cada iteraci√≥n de entrenamiento, el modelo sigue haciendo cambios necesarios basados en el valor de la funci√≥n de p√©rdida actual para minimizarla. Se utilizan diferentes tipos de funciones de p√©rdida para diferentes algoritmos de aprendizaje autom√°tico.\n\n#### Comparaci√≥n entre la funci√≥n de p√©rdida, la funci√≥n de costo y la funci√≥n objetivo\n\nAmbas, la funci√≥n de p√©rdida y la funci√≥n de costo, representan el valor de error, es decir, la diferencia entre el valor de salida y el valor real, para determinar c√≥mo de bien un modelo de aprendizaje autom√°tico se desempe√±a al ajustarse a los datos. Sin embargo, la diferencia entre las funciones de p√©rdida y costo es que **la funci√≥n de p√©rdida mide el error para un solo punto de datos solo, mientras que la funci√≥n de costo mide el error para todo el conjunto de datos**. La funci√≥n de costo suele ser la suma de la funci√≥n de p√©rdida y alg√∫n tipo de penalizaci√≥n.\n\nPor otro lado, la funci√≥n objetivo es una funci√≥n que necesita ser optimizada, es decir, maximizada o minimizada, para obtener el objetivo deseado. **La funci√≥n de p√©rdida es parte de la funci√≥n de costo; al mismo tiempo, la funci√≥n de costo se puede utilizar como parte de la funci√≥n objetivo**.\n\nEn resumen, la funci√≥n de p√©rdida mide el error para un solo punto de datos, la funci√≥n de costo mide el error para todo el conjunto de datos y la funci√≥n objetivo es una funci√≥n que necesita ser optimizada para obtener el objetivo deseado.\n\n#### Algoritmo, modelo/hip√≥tesis y t√©cnica\n\nComo principiante, es esencial poder diferenciar entre modelos y algoritmos de aprendizaje autom√°tico. Un algoritmo en ML es la instrucci√≥n paso a paso proporcionada en forma de c√≥digo y ejecutada en un conjunto de datos espec√≠fico. Este algoritmo es an√°logo a un c√≥digo de programaci√≥n general. Por ejemplo, encontrar el promedio aritm√©tico de un conjunto de n√∫meros. De manera similar, en ML, un algoritmo se puede aplicar para aprender las estad√≠sticas de un conjunto de datos o aplicar estad√≠sticas actuales para predecir cualquier dato futuro.\n\nPor otro lado, un modelo de ML puede ser representado como un conjunto de par√°metros que se aprenden a partir de datos dados. Por ejemplo, supongamos una funci√≥n $f (x) = xŒ∏$, donde $Œ∏$ es el par√°metro de la funci√≥n dada y $x$ es la entrada. As√≠, para una entrada $x$ dado, el output depende del par√°metro de la funci√≥n $Œ∏$. De manera similar, en ML, la entrada $x$ se etiqueta como la caracter√≠stica de entrada, y $Œ∏$ se define como un par√°metro de modelo de ML. El objetivo de cualquier algoritmo de ML es aprender el conjunto de par√°metros de un modelo dado. En algunos casos, el modelo tambi√©n se conoce como una **hip√≥tesis**. Supongamos que la hip√≥tesis o modelo se denota por $h_Œ∏$. Si se ingiere datos $x(i)$ al modelo, el output predicho ser√° $h_Œ∏ (x(i))$.\n\nEn contraste, una t√©cnica de ML puede verse como un enfoque general para intentar resolver un problema en particular. En muchos casos, puede ser necesario combinar una amplia variedad de algoritmos para desarrollar una t√©cnica para resolver un problema de ML.\n\n### Diferencia entre la ciencia de datos, el aprendizaje autom√°tico, la inteligencia artificial y el aprendizaje profundo\n\nLa ciencia de datos (**DS**), la inteligencia artificial (**AI**), el aprendizaje autom√°tico (**ML**) y el aprendizaje profund (**DL**) o son t√©rminos relacionados estrechamente, y las personas suelen confundirlos o utilizarlos de manera alternativa. Sin embargo, estos son campos de tecnolog√≠a claramente separados. El aprendizaje autom√°tico cae dentro del subconjunto de la inteligencia artificial, mientras que el aprendizaje profundo se considera que cae dentro del subconjunto del aprendizaje autom√°tico, como se demuestra en la [Fig. 3.](#fig-venn)\n\n![Figure 3. El aprendizaje profundo cae dentro del subconjunto del aprendizaje autom√°tico, y el aprendizaje autom√°tico cae dentro del subconjunto de la inteligencia artificial. La ciencia de datos implica una parte de todos estos tres campos.](images/clipboard-76734573.png){#fig-venn width=\"250\"}\n\nLa diferencia entre el aprendizaje autom√°tico y el aprendizaje profundo radica en el hecho de que el aprendizaje profundo requiere m√°s recursos de computaci√≥n y conjuntos de datos muy grandes. Gracias al avance de los recursos de computaci√≥n en hardware, las personas est√°n pasando hacia enfoques de aprendizaje profundo para resolver problemas similares que el aprendizaje autom√°tico puede resolver. El aprendizaje profundo es especialmente √∫til para manejar grandes vol√∫menes de texto o im√°genes.\n\nLa ciencia de datos es un campo interdisciplinario que implica identificar patrones en los datos y hacer inferencias, predicciones o insights a partir de ellos. La ciencia de datos est√° estrechamente relacionada con el aprendizaje profundo, el miner√≠a de datos y los grandes datos. Aqu√≠, la miner√≠a de datos es el campo que se ocupa de identificar patrones y extraer informaci√≥n de conjuntos de datos grandes utilizando t√©cnicas que combinan estad√≠stica, sistemas de bases de datos y ML, y por definici√≥n, los grandes datos se refieren a datos vastos y complejos que son demasiado grandes para ser procesados por sistemas tradicionales utilizando algoritmos tradicionales. El ML es una de los principales herramientas utilizadas para ayudar al proceso de an√°lisis de datos en la ciencia de datos, especialmente para hacer extrapolaciones o predicciones sobre tendencias futuras de datos.\n\nPor ejemplo, predecir el precio del mercado de casas en el pr√≥ximo a√±o es una aplicaci√≥n de ML. Considere un conjunto de datos de muestra como se muestra en la tabla 1.1.\n\n| A√±o  | Precio |\n|:----:|:------:|\n| 2001 | \\$200  |\n| 2002 | \\$400  |\n| 2003 | \\$800  |\n\n: Tabla 1.1. Muestra de datos de precios de casas. {#tbl-estimacasas}\n\nLa observaci√≥n de los datos en la tabla 1.1 nos permite formar la intuici√≥n de que el pr√≥ximo precio en 2004 ser√° de \\$1600. Esta intuici√≥n se forma basada en los precios de las casas de los a√±os anteriores, que muestran una tendencia clara de duplicar el precio cada a√±o.\n\nSin embargo, para conjuntos de datos grandes y complejos, esta predicci√≥n no puede ser tan sencilla. Luego, requerimos un modelo de predicci√≥n de ML para predecir los precios de las casas.\n\nCon suficientes recursos de computaci√≥n, estos problemas pueden ser resueltos utilizando modelos de aprendizaje profundo categorizados bajo aprendizaje profundo. En general, el aprendizaje autom√°tico y el aprendizaje profundo caen dentro de la inteligencia artificial, pero todos requieren el procesamiento, preparaci√≥n y limpieza de los datos disponibles; por lo tanto, la ciencia de datos es una parte integral de todos estos tres ramas.\n\n## Desarrollo hist√≥rico de Machine Learning\n\nEl aprendizaje autom√°tico ha estado en desarrollo desde la d√©cada de 1940. No es el fruto de la mente de un humano ingenioso ni el resultado de un evento en particular. La ciencia multifac√©tica del aprendizaje autom√°tico ha sido moldeada por a√±os de estudios y investigaci√≥n, y por los esfuerzos dedicados de numerosos cient√≠ficos, ingenieros, matem√°ticos, programadores, investigadores y estudiantes. El aprendizaje autom√°tico es un campo en constante progreso y sigue en desarrollo. La tabla 1.2 enumera los hitos m√°s significativos marcados en la historia del desarrollo del aprendizaje autom√°tico. No te asustes si no conoces a√∫n algunos de los t√©rminos mencionados en la tabla. Los exploraremos m√°s adelante.\n\n+--------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| A√±o    | Desarrollo                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |\n+:======:+:==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================+\n| 1940s  | El art√≠culo \"*A logical calculus of the ideas immanent in nervous activity*\", credao por Walter Pitts y Warren McCulloch en 1943, es el primero en discutir el modelo matem√°tico de redes neuronales.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n+--------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| 1950s  | ‚Ä¢ El t√©rmino \"*Aprendizaje Autom√°tico*\" es utilizado por primera vez por Arthur Samuel. Dise√±√≥ un programa de ajedrez por computadora que estaba a la altura de los juegos de nivel superior. ‚Ä¢ En 1951, Marvin Minsky y Dean Edmonds desarrollaron la primera red neuronal artificial compuesta por 40 neuronas. La red neuronal ten√≠a capacidades de memoria a corto y largo plazo. ‚Ä¢ El taller de dos meses en Dartmouth en 1956 introduce por primera vez la investigaci√≥n en Inteligencia Artificial (IA) y Aprendizaje Autom√°tico (AA). Muchos reconocen este taller como el \"*lugar de nacimiento de la IA*\".                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n+--------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| 1960s  | ‚Ä¢ En 1960, Alexey (Oleksii) Ivakhnenko y Valentin Lapa presentan la representaci√≥n jer√°rquica de una red neuronal. Alexey Ivakhnenko se considera el padre del aprendizaje profundo. ‚Ä¢ Thomas Cover y Peter E. Hart publicaron un art√≠culo sobre los algoritmos de vecino m√°s cercano en 1967. Estos algoritmos se utilizan ahora para tareas de regresi√≥n y clasificaci√≥n en el aprendizaje autom√°tico. ‚Ä¢ Un proyecto relacionado con un robot inteligente, Stanford Cart, comenz√≥ en esta d√©cada. El objetivo era navegar a trav√©s de un espacio 3D de manera aut√≥noma.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |\n+--------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| 1970s  | ‚Ä¢ Kunihiko Fukushima, un cient√≠fico inform√°tico japon√©s, public√≥ un trabajo sobre reconocimiento de patrones utilizando redes neuronales jer√°rquicas y multilayered. Este trabajo m√°s tarde sent√≥ las bases para las redes neuronales convolucionales. ‚Ä¢ El proyecto Stanford Cart finalmente logr√≥ recorrer una habitaci√≥n llena de sillas durante cinco horas sin intervenci√≥n humana en 1979.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |\n+--------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| 1980s  | ‚Ä¢ En 1985, se inventa la red neuronal artificial llamada NETtalk por Terrence Sejnowski. NETtalk puede simplificar modelos de tareas cognitivas humanas de manera que las m√°quinas puedan aprender a hacerlas. ‚Ä¢ La m√°quina de Boltzmann restringida (RBM), inicialmente llamada Harmonium, inventada por Paul Smolensky, se introduce en 1986. Puede analizar un conjunto de entrada y aprender distribuci√≥n de probabilidades a partir de √©l. En la actualidad, la RBM modificada por Geoffrey Hinton se utiliza para modelado de temas, recomendaciones impulsadas por inteligencia artificial, clasificaci√≥n, regresi√≥n, reducci√≥n de dimensionalidad, filtrado colaborativo, etc.                                                                                                                                                                                                                                                                                                                                                                        |\n+--------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| 1990s  | ‚Ä¢ El boosting para el aprendizaje autom√°tico se introduce en el papel \"*The Strength of Weak Learnability*\", creado por Robert Schapire y Yoav Freund en 1990. El algoritmo de boosting aumenta la capacidad predictiva de los modelos de inteligencia artificial. El algoritmo genera y combina muchos modelos d√©biles utilizando t√©cnicas como la media o la votaci√≥n en las predicciones. ‚Ä¢ En 1995, Tin Kam Ho introduce bosques de decisiones aleatorios en su art√≠culo. El algoritmo crea m√∫ltiples √°rboles de decisi√≥n aleatoriamente y los combina para crear un \"bosque\". El uso de m√∫ltiples √°rboles de decisi√≥n mejora significativamente la precisi√≥n de los modelos. ‚Ä¢ En 1997, Christoph Bregler, Michele Covell y Malcolm Slaney desarrollan el software \"deepfake\" m√°s antiguo del mundo. ‚Ä¢ El a√±o 1997 ser√° un hito importante en el AI. El programa de ajedrez basado en IA, Deep Blue, derrot√≥ a uno de los mejores jugadores de ajedrez de la historia humana, Garry Kasparov. Este incidente arroj√≥ nueva luz sobre la tecnolog√≠a de IA. |\n+--------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| 2000   | Igor Aizenberg, un investigador de redes neuronales, introduce por primera vez el t√©rmino \"*aprendizaje profundo*\". Utiliz√≥ este t√©rmino para describir las redes m√°s grandes compuestas por neuronas de umbral booleano.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |\n+--------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| 2009   | Fei-Fei Li lanz√≥ el conjunto de datos m√°s extenso de im√°genes etiquetadas, ImageNet. Fue dise√±ado para contribuir a proporcionar datos de entrenamiento vers√°tiles y reales para modelos de IA y ML. The Economist ha comentado sobre ImageNet como un evento excepcional para popularizar la IA a lo largo de la comunidad tecnol√≥gica y dar un paso hacia un nuevo era de historia del aprendizaje profundo.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |\n+--------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| 2011   | El equipo de X Lab de Google desarrolla un algoritmo de inteligencia artificial llamado Google Brain para el procesamiento de im√°genes, que es capaz de identificar gatos en im√°genes.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |\n+--------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| 2014   | 1.  Ian Goodfellow y sus colegas desarrollaron redes neuronales generadoras adversarias (GANs). Los marcos se utilizan para que los modelos de IA sean capaces de generar datos enteramente nuevos dados su conjunto de entrenamiento.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |\n|        |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |\n|        | 2.  El equipo de investigaci√≥n de Facebook desarroll√≥ DeepFace, que puede distinguir caras humanas casi tan bien como los seres humanos con una tasa de precisi√≥n del 97,35%. DeepFace es una red neuronal compuesta por nueve capas. La red se entrena en m√°s de 4 millones de im√°genes tomadas de usuarios de Facebook.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |\n|        |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |\n|        | 3.  Google ha comenzado a utilizar Sibyl para hacer predicciones para sus productos. Sibyl es un sistema de aprendizaje autom√°tico a escala m√°s amplia. El sistema consta de muchos nuevos algoritmos combinados. Ha mejorado significativamente el rendimiento a trav√©s de boosting paralelo y datos orientados a columnas. Adem√°s, utiliza el comportamiento de los usuarios para clasificar productos y publicidad.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |\n|        |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |\n|        | 4.  Eugene Goostman, un chatbot de IA desarrollado por tres amigos de San Petersburgo en 2001, se considera el primer chatbot de IA que se asemeja a la inteligencia humana. Este personaje de IA se representa como un ni√±o de 13 a√±os de Odessa, Ucrania, que tiene un conejo de Indias y un padre ginec√≥logo. Eugene Goostman super√≥ la competencia del test de Turing el 7 de junio de 2014 en la Royal Society.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n+--------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| 2015   | El primer programa de IA \"*AlphaGo*\" supera a un jugador profesional de Go. Go era un juego que inicialmente era imposible ense√±ar a una computadora.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n+--------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| 2016   | Un grupo de cient√≠ficos presenta Face2Face durante la Conferencia sobre Visi√≥n por Computadora y Reconocimiento de Patrones. La mayor√≠a del software \"*deepfake*\" utilizado en la actualidad se basa en la l√≥gica y los algoritmos de Face2Face.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |\n+--------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| 2017   | 1.  Se introducen coches aut√≥nomos o sin conductor en EE. UU. por parte de Waymo.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n|        |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |\n|        | 2.  Se publica el famoso papel \"*Attention is All You Need*\", que introduce la arquitectura del Transformer basada en el mecanismo de autoatenci√≥n, lo que conduce a un progreso significativo en el procesamiento de lenguaje natural.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n+--------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| 2021   | Google DeepMind‚Äôs AlphaFold 2 model places first in the CASP13 protein folding competition in the free modeling (FM) category, bringing a breakthrough in deep-learning-based protein structure prediction.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |\n+--------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| 2022   | OpenAI y Google revolucionan los modelos de lenguaje grande para uso masivo. Diversas aplicaciones del aprendizaje autom√°tico han comenzado a convertirse en parte de las actividades diarias.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |\n+--------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n: Tabla 1.2. Desarrollo hist√≥rico de Machine Learning {#tbl-historia}\n\n## Por qu√© Machine Learning?\n\nAntes de profundizar m√°s, es importante tener una visi√≥n clara de la finalidad y los motivos detr√°s del aprendizaje autom√°tico. Por lo tanto, las secciones siguientes discutir√°n la finalidad, los motivos y la importancia del aprendizaje autom√°tico para que pueda implementarse en escenarios de vida real.\n\n### Motivaci√≥n\n\nLa motivaci√≥n para crear un campo multidimensional como el aprendizaje autom√°tico surgi√≥ del trabajo mon√≥tono que los seres humanos ten√≠an que realizar. Con el aumento del uso de sistemas de comunicaci√≥n digital, dispositivos inteligentes y la Internet, se generan grandes cantidades de datos cada momento. Buscar y organizar todos esos datos cada vez que se necesita resolver un tarea es exhaustivo, tiempo consumidor y mon√≥tono. Por lo tanto, en lugar de ir a trav√©s del proceso laborioso de revisar billones de datos, los seres humanos optaron por un proceso m√°s automatizado. El proceso automatizado busca encontrar patrones relevantes en los datos y luego utilizar estos patrones para evaluar y resolver tareas. Fue entonces cuando surgi√≥ el concepto de programaci√≥n. Sin embargo, incluso con la programaci√≥n, los seres humanos ten√≠an que codificar expl√≠citamente o instruir a las m√°quinas sobre qu√© hacer, cu√°ndo y c√≥mo hacerlo. Para superar el nuevo problema de codificar cada comando para que las m√°quinas lo entiendan, los seres humanos desarrollaron la idea de hacer que las m√°quinas aprendieran ellas mismas de la manera en que los seres humanos lo hacen - simplemente reconociendo patrones.\n\n### Prop√≥sito\n\nEl prop√≥sito del aprendizaje autom√°tico es hacer que las m√°quinas inteligentes y automatizar tareas que de otra manera ser√≠an tediosas y propensas a errores humanos. El uso de modelos de aprendizaje autom√°tico puede hacer que las tareas sean m√°s accesibles y eficientes en el tiempo.\n\nPor ejemplo, considere un conjunto de datos $(x, y) = (0, 0);(1, 1);(2, 2);(3, ?)$. Aqu√≠, para definir la relaci√≥n entre $x$ y $y$, $y$ se puede expresar como una funci√≥n de $x$, es decir, $y = f (x) = Œ∏ x$. Esta representaci√≥n de los dos elementos del conjunto de datos se conoce como el modelo. El prop√≥sito del aprendizaje autom√°tico es aprender qu√© es $Œ∏$ a partir de los datos existentes y luego aplicar el aprendizaje autom√°tico para determinar que $Œ∏ = 1$. Este conocimiento se puede utilizar luego para encontrar el valor del valor desconocido de $y$ cuando $x = 3$. Seguro aprender√°s c√≥mo formular el modelo hipot√©tico y c√≥mo resolver los valores de $Œ∏$.\n\n### Importancia\n\nAl igual que las m√°quinas, la ciencia del aprendizaje autom√°tico se cre√≥ con el fin de hacer que las tareas humanas m√°s f√°ciles. El an√°lisis de datos era un trabajo tedioso y laborioso, propenso a muchos errores cuando se hac√≠a manualmente. Pero gracias al aprendizaje autom√°tico, todos los seres humanos tienen que hacer es proporcionar la m√°quina con el conjunto de datos o la fuente del conjunto de datos, y la m√°quina puede analizar los datos, reconocer un patr√≥n y tomar decisiones valiosas sobre los datos.\n\nOtra ventaja del aprendizaje autom√°tico es que los seres humanos no necesitan decirle a la m√°quina cada paso del trabajo. La m√°quina misma genera las instrucciones despu√©s de aprender de la entrada del conjunto de datos. Por ejemplo, un modelo de reconocimiento de im√°genes no requiere decirle a la m√°quina sobre cada objeto en una imagen. En el caso del aprendizaje supervisado, solo necesitamos decirle a la m√°quina sobre los etiquetas (como vaca o perro) junto con sus atributos (como proporciones faciales, tama√±o del cuerpo, tama√±o de las orejas, presencia de cuernos, etc.), y la m√°quina identificar√° autom√°ticamente los objetos etiquetados en cualquier imagen basada en los atributos marcados.\n\nEl aprendizaje autom√°tico tambi√©n es esencial en el caso de la predicci√≥n de tendencias de datos desconocidos o futuras. Esta aplicaci√≥n es extremadamente valiosa para crear planes de negocio y esquemas de marketing, y preparar recursos para el futuro. Por ejemplo, el aprendizaje autom√°tico puede ayudar a predecir el crecimiento futuro de las instalaciones de m√≥dulos solares, incluso hasta 2050 o 2100, basado en tendencias hist√≥ricas de precios. En comparaci√≥n con otras herramientas de predicci√≥n y t√©cnicas, el aprendizaje autom√°tico puede predecir valores con mayor precisi√≥n y considerar muchos par√°metros adicionales que no se pueden incorporar en f√≥rmulas de predicci√≥n definidas utilizadas en herramientas de predicci√≥n tradicionales, como la extrapolaci√≥n de datos estad√≠sticos.\n\n## Conocimientos previos para aprender Machine Learning\n\nEl aprendizaje autom√°tico es una **ciencia avanzada**; una persona no puede simplemente sumergirse en el mundo del ML sin tener alg√∫n conocimiento y habilidades b√°sicos. Para poder entender los conceptos de ML, utilizar los algoritmos y aplicar t√©cnicas de ML en casos pr√°cticos, una persona debe estar equipada con varios temas en matem√°ticas y ciencias avanzadas, algunos de los cuales se discuten en las siguientes secciones.\n\nEsta secci√≥n muestra solo los temas que un entusiasta de ML debe conocer antes de aprender ML. Los temas no se cubren en detalle aqu√≠.\n\n### √Ålgebra Lineal\n\nLa √°lgebra lineal es la rama de matem√°ticas que se ocupa de las transformaciones lineales. Estas transformaciones lineales se realizan utilizando ecuaciones lineales y funciones lineales. Vectores y matrices se utilizan para notar las ecuaciones lineales y funciones lineales necesarias. Una buena base en √°lgebra lineal es requerida para entender la intuici√≥n m√°s profunda detr√°s de diferentes algoritmos de ML. Es la base para resolver problemas como aquel de nuestra [app de mantenimiento](https://cchiquitovalencia.github.io/posts/2025-01-27-maintenance_management/).\n\n#### Ecuaciones Lineales\n\nLas ecuaciones lineales son m√°s f√°ciles de describir matem√°ticamente y pueden combinarse con transformaciones de modelos no lineales. Hay dos propiedades de una ecuaci√≥n para ser denominada lineal - **homogeneidad** y **superposici√≥n**. El conocimiento de ecuaciones lineales puede ser conveniente para modelar sistemas lineales. Un ejemplo de ecuaci√≥n lineal es $p_1x_1 + p_2x_2 + ... + p_nx_n + q = 0$, donde $x_1, x_2 ..., x_n$ son las variables, $p_1, p_2 ..., p_n$ son los coeficientes y $q$ es un constante.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\n\np <- ggplot(data = data.frame(x = 0), mapping = aes(x = x))+\n  theme(legend.position = \"none\",\n        panel.background = element_blank())\n\nlm_eq1 <- function(x) (3/5) * x + 2\nlm_eq2 <- function(x) 5 - x\n\np + stat_function(fun = lm_eq1, aes(colour = \"darkred\"), size = 1) + \n  stat_function(fun = lm_eq2, aes(colour = \"darkblue\"), size = 1) +\n  xlim(-5, 6)+ylim(-5,10)+\n  geom_hline(yintercept = 0, size = 1, col = \"gray\")+\n  geom_vline(xintercept = 0, size = 1, col = \"gray\")+\n  geom_text(x = -2, y = 4,\n            label = paste0(\"y = (3/5)x + 2\"),\n            color = \"darkred\")+\n  geom_text(x = 2, y = 1,\n            label = paste0(\"(x/5)+(y/5) = 1\"),\n            color = \"darkblue\")\n```\n\n::: {.cell-output-display}\n![Fig. 1.4. Ejemplos de dos l√≠neas rectas con ecuaciones lineales](index_files/figure-html/fig-eq-1.png){#fig-eq width=672}\n:::\n:::\n\n\n\nUtilizando √°lgebra lineal, podemos resolver las ecuaciones de la [Fig. 1.4](#fig-eq), es decir, podemos encontrar la intersecci√≥n de estas dos l√≠neas. Las ecuaciones para las dos l√≠neas son las siguientes:\n\n$$\ny=\\frac{3}{5}x+2, (1.2)\n$$ {#eq-1.2}\n\n$$\\frac{x}{5} + \\frac{y}{5} = 1.  (1.3)$$ {#eq-1.3}\n\nAhora, al resolver la ecuaci√≥n $(1.3)$, obtenemos:\n\n$$\nx+y=5,\n$$\n\n$$\n‚üπx+(\\frac{3}{5}x+2)=5,\n$$\n\n$$\n‚üπ8x=15,\n$$\n\n$$\n‚üπx=1.875.\n$$\n\nPoniendo el valor de $x$ en la ecuaci√≥n [$(1.2)$](#eq-1.2), obtenemos $y = 3.125$. Por lo tanto, el punto de intersecci√≥n es $(x, y) = (1.875, 3.125)$.\n\n#### Tensor y Rango de Tensor\n\nUn tensor es un t√©rmino general para vectores y matrices. Es la estructura de datos utilizada en modelos de ML. Un tensor puede tener cualquier dimensi√≥n. Un escalar es un tensor con cero dimensiones, un vector es un tensor con una dimensi√≥n y una matriz tiene dos dimensiones. Cualquier tensor con m√°s de dos dimensiones se llama tensor `n-dimensional`. Vectores y matrices se discuten a continuaci√≥n.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\n\n# Definir vector\ndf <- data.frame(x = 3,\n                 y = 5)\n\n# Graficar vector\nggplot(df, aes(x,y))+\n  geom_point(col = \"red\", size = 5)+\n  geom_segment(x = 0, xend = df$x, y = 0, yend = df$y,\n               arrow = grid::arrow(), size = 1)+\n  coord_cartesian(xlim = c(0,4), ylim = c(0,6))+\n  theme(panel.background = element_blank(),\n        axis.line = element_line(linewidth = 1, colour = \"gray\"))+\n  annotate(geom = \"text\", x = 3.3, y = 5, label = \"A(3,5)\")+\n  labs(x = \"X1\", y = \"X2\")+\n  geom_segment(x = 3, y = 0, yend = 5, col = \"gray50\", lty = 2)+\n  geom_segment(x = 0, y = 5, xend = 3, col = \"gray50\", lty = 2)\n```\n\n::: {.cell-output-display}\n![Fig. 1.5. Ejemplo de un vector](index_files/figure-html/fig-vec-1.png){#fig-vec width=672}\n:::\n:::\n\n\n\n##### Vector\n\nUn vector es un array unidimensional de n√∫meros, t√©rminos o elementos. Las caracter√≠sticas del conjunto de datos se representan como vectores. Un vector se puede representar en dimensiones geom√©tricas. Por ejemplo, un vector $[3, 5]$ se puede representar geom√©tricamente en un espacio `2-dimensional`, como se muestra en la [Fig. 1.5](#fig-vec). Este espacio se puede llamar espacio de vectores o espacio de caracter√≠sticas. En el espacio de vectores, un vector se puede visualizar como una l√≠nea con direcci√≥n y magnitud.\n\n##### Matriz\n\nUna matriz es un array bidimensional de escalares con una o m√°s columnas y una o m√°s filas. Un vector con m√°s de una dimensi√≥n se llama matriz. El n√∫mero de filas y columnas se expresa como la dimensi√≥n de esa matriz. Por ejemplo, una matriz con una dimensi√≥n de $4 √ó 3$ contiene 4 filas y 3 columnas. Las operaciones de matrices proporcionan c√°lculos m√°s eficientes que operaciones piecemeal para modelos de aprendizaje autom√°tico. Los matrices deben tener la misma dimensi√≥n para la suma y resta. Para la multiplicaci√≥n de matrices, el tama√±o de la columna del primer matriz y el tama√±o de la fila del segundo matriz deben ser id√©nticos. Si se multiplica una matriz con dimensi√≥n $m √ó n$ por una matriz con dimensi√≥n $n √ó p$, entonces el resultado de esta multiplicaci√≥n ser√° una matriz con dimensi√≥n $m √ó p$.\n\nLa [ecuaci√≥n 1.4](#eq-1.4) muestra la matriz $A$ con una dimensi√≥n de $2 √ó 3$ y la matriz $B$ con una dimensi√≥n de $3 √ó 1$. Por lo tanto, estas dos matrices se pueden multiplicar porque cumplen con la condici√≥n de multiplicaci√≥n de matrices. El resultado de la multiplicaci√≥n ser√° la matriz $C$, mostrada en la [ecuaci√≥n 1.5](#eq-1.5). Tiene una dimensi√≥n de $2 √ó 1$.\n\n$$A=\\begin{bmatrix}1&2&3\\\\4&5&6\\end{bmatrix}; B=\\begin{bmatrix}11\\\\12\\\\13\\end{bmatrix}.¬†¬†¬†(1.4)$$ {#eq-1.4}\n\n$$\nProducto, C=\\begin{bmatrix}74\\\\182\\end{bmatrix}.¬†¬†¬†(1.5)\n$$ {#eq-1.5}\n\nAlgunas matrices fundamentales se utilizan con frecuencia, como la matriz de fila, la matriz cuadrada, la matriz de columna, la matriz de identidad, etc. Por ejemplo, una matriz que consiste solo en una fila se conoce como matriz de fila, y una matriz que consiste solo en una columna se conoce como matriz de columna. Una matriz que consiste en un n√∫mero igual de filas y columnas se llama matriz cuadrada. Una matriz cuadrada con todos los **1**'s a lo largo de su diagonal principal y todos los **0**'s en todos los elementos no diagonales es una **matriz de identidad**. Se muestran ejemplos de matrices diferentes en la Fig. 1.6.\n\n##### Rango vs. Dimensi√≥n\n\nRango y dimensi√≥n son dos t√©rminos relacionados pero distinos en √°lgebra lineal, aunque a menudo se utilizan indistintamente en aprendizaje autom√°tico. En perspectiva de aprendizaje autom√°tico, cada columna de una matriz o tensor representa cada caracter√≠stica o subespacio. Por lo tanto, la dimensi√≥n de su columna (es decir, subespacio) ser√° el rango de esa matriz o tensor.\n\n##### Comparaci√≥n entre Escalar, Vector, Matriz y Tensor\n\nUn escalar es simplemente un valor num√©rico sin direcci√≥n asignada. Un vector es un array de n√∫meros de una dimensi√≥n que denota una direcci√≥n espec√≠fica. Una matriz es un array de n√∫meros de dos dimensiones. Finalmente, un tensor es un array de datos de $n$ dimensiones.\n\nSeg√∫n las cantidades mencionadas, escalares, vectores y matrices tambi√©n pueden considerarse tensors, pero limitados a 0, 1 y 2 dimensiones, respectivamente. Las tablas 1.3 y 1.4 resumen las diferencias en el rango o dimensi√≥n de estas cuatro cantidades con ejemplos.\n\n¬†\n\n::: {#fig-diffmatrix}\n$$\\text{Cuadrada 2x2}\\begin{bmatrix}5&2\\\\-6&1\\end{bmatrix};\\\\\n\\text{Rectangular 3x2}\\begin{bmatrix}4&1\\\\2&-1\\\\-7&5\\end{bmatrix};\\\\\n\\text{Ceros 3x5}\\begin{bmatrix}0&0&0&0&0\\\\0&0&0&0&0\\\\0&0&0&0&0\\end{bmatrix};\\\\\n\\text{Fila 1x4}\\begin{bmatrix}5&-1&0&3\\end{bmatrix};\\\\\n\\text{Columna 3x1}\\begin{bmatrix}1\\\\2\\\\-7\\end{bmatrix};\\\\\n\\text{Identidad 3x3}\\begin{bmatrix}1&0&0\\\\0&1&0\\\\0&0&1\\end{bmatrix}$$\n:::\n\n| Rango/Dimensi√≥n |     Objeto     |\n|:---------------:|:--------------:|\n|        0        |    Escalar     |\n|        1        |     Vector     |\n|     2 o m√°s     | Matriz $m * n$ |\n|   Cualquiera    |     Tensor     |\n\n: Tabla 1.3. Comparaci√≥n entre escalar, vector, matrix y tensor. {#tbl-comparaciones}\n\n¬†\n\n+---------+------------------------------------+----------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| Escalar | Vector                             | Matriz                                 | Tensor                                                                                                                                                         |\n+:=======:+:==================================:+:======================================:+:==============================================================================================================================================================:+\n| $1$     | $\\begin{bmatrix}1\\\\2\\end{bmatrix}$ | $\\begin{bmatrix}1&2\\\\3&4\\end{bmatrix}$ | $\\begin{bmatrix}\\begin{bmatrix}1&2\\end{bmatrix}&\\begin{bmatrix}3&4\\end{bmatrix}\\\\\\begin{bmatrix}5&6\\end{bmatrix}&\\begin{bmatrix}7&8\\end{bmatrix}\\end{bmatrix}$ |\n+---------+------------------------------------+----------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n: Tabla 1.4. Ejemplos de escalar, vector, matriz y tensor. {#tbl-ejemplos}\n\n¬†\n\n| Nombre  |          Definici√≥n           |\n|:-------:|:-----------------------------:|\n|  Media  | El valor promedio aritm√©tico. |\n| Mediana |      El valor del medio.      |\n|  Moda   |      El valor m√°s com√∫n.      |\n\n: Tabla 1.5. Defici√≥n de media, mediana y moda. {#tbl-defmeds}\n\n¬†\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Librer√≠as necesarias\nlibrary(ggplot2)\nlibrary(gridExtra)\n\n# Crear funci√≥n moda, no existe en R base.\ngetmode <- function(v) {\n  uniqv <- unique(v)\n  uniqv[which.max(tabulate(match(v, uniqv)))]\n}\n\n# Generar datos sesgados a la izquirda\nx <- round(100 * rbeta(10000, 5, 2))\ndata_x <- data.frame(x = x)\n\n# Generar datos sesgados a la derecha\ny <- round(100 * rbeta(10000, 2, 5))\ndata_y <- data.frame(x = y)\n\n# Generar datos distribuidos normal\nz <- round(100 * rbeta(10000, 5, 5))\ndata_z <- data.frame(x = z)\n\n# Genera gr√°fico\ngridExtra::grid.arrange(\n  \nggplot(data_x, aes(x = x))+\n  geom_histogram(fill = \"gray\")+\n  geom_vline(xintercept = mean(x), col = \"red\", lty = 2)+\n  geom_vline(xintercept = median(x), col = \"blue\", lty = 1)+\n  geom_vline(xintercept = getmode(x), col = \"green\", lty = 4)+\n  labs(x = \"Sesgada a la izquierda\", y = NULL)+\n  theme(panel.background = element_blank())\n,\n\nggplot(data_z, aes(x = x))+\n  geom_histogram(fill = \"gray\")+\n  geom_vline(xintercept = mean(z), col = \"red\", lty = 2)+\n  geom_vline(xintercept = median(z), col = \"blue\", lty = 3)+\n  geom_vline(xintercept = getmode(z), col = \"green\", lty = 4)+\n  labs(x = \"Normal\", y = NULL)+\n  theme(panel.background = element_blank())\n,\n\nggplot(data_y, aes(x = x))+\n  geom_histogram(fill = \"gray\")+\n  geom_vline(xintercept = mean(y), col = \"red\", lty = 2)+\n  geom_vline(xintercept = median(y), col = \"blue\", lty = 1)+\n  geom_vline(xintercept = getmode(y), col = \"green\", lty = 4)+\n  labs(x = \"Sesgada a la derecha\", y = NULL)+\n  theme(panel.background = element_blank())\n,\n\nncol = 3\n)\n```\n\n::: {.cell-output-display}\n![Fig. 1.7. Representaci√≥n gr√°fica de la media, mediana y moda](index_files/figure-html/fig-dist-1.png){#fig-dist width=672}\n:::\n:::\n\n\n\n### Estad√≠stica\n\nLa estad√≠stica es un campo vasto de las matem√°ticas que ayuda a organizar y analizar conjuntos de datos. El an√°lisis de datos es mucho m√°s f√°cil, r√°pido y preciso cuando las m√°quinas lo realizan. Por lo tanto, el aprendizaje autom√°tico se utiliza predominantemente para encontrar patrones dentro de los datos. La estad√≠stica es el componente fundamental del aprendizaje autom√°tico. Por lo tanto, es necesario tener conocimientos de t√©rminos estad√≠sticos para aprovechar plenamente los beneficios del aprendizaje autom√°tico.\n\n#### Medidas de Tendencia Central\n\nLos tres t√©rminos estad√≠sticos m√°s comunes utilizados ampliamente en diversas aplicaciones son la media, la mediana y la moda. Estas tres funciones son las medidas de tendencia central de cualquier conjunto de datos, que denotan los valores centrales o medios del conjunto de datos. La tabla 1.5 establece las distinciones entre estos tres t√©rminos. Estas son las medidas de tendencia central de un conjunto de datos. La figura 1.7 proporciona una representaci√≥n gr√°fica de la media, la mediana y la moda.\n\nSe presentan tres ejemplos aqu√≠ y en la tabla 1.6. Vamos a considerar el primer conjunto de datos: $\\{1, 2, 9, 2, 13, 15\\}$. Para encontrar la media de este conjunto de datos, debemos calcular la suma de los n√∫meros. Aqu√≠, la suma es 42. El conjunto de datos tiene seis puntos de datos. Por lo tanto, la media de este conjunto de datos ser√° 42 √∑ 6 = 7. A continuaci√≥n, para encontrar la mediana del conjunto de datos, el conjunto de datos necesita ser ordenado en orden ascendente: $\\{1, 2, 2, 9, 13, 15\\}$.\n\n| Conjuntos | {1,2,9,2,13,15} | {0,5,5,10} | {18,22,24,24,25} |\n|:---------:|:---------------:|:----------:|:----------------:|\n|   Media   |        7        |     5      |       22.6       |\n|  Mediana  |       5.5       |     5      |        24        |\n|   Moda    |        2        |     5      |        24        |\n\n: Tabla 1.6. Varios conjuntos de datos y sus medidas de tendencia central {#tbl-varios}\n\nDado que el n√∫mero de puntos de datos es par, tomaremos los dos valores medios y los promediamos para calcular la mediana. Para este conjunto de datos, el valor de mediana ser√≠a $(2 + 9) √∑ 2 = 5.5$. Para la moda, el punto de datos m√°s repetido debe considerarse. Aqu√≠, $2$ es la moda para este conjunto de datos. Este conjunto de datos est√° desviado hacia la izquierda, es decir, la distribuci√≥n de los datos es m√°s larga hacia la izquierda o tiene una cola izquierda larga.\n\nDe manera similar, si consideramos el conjunto de datos $\\{0, 5, 5, 10\\}$, la media, la mediana y la moda todos son $5$. Este conjunto de datos est√° distribuido normalmente. ¬øPuedes calcular la media, la mediana y la moda para el conjunto de datos desviado hacia la derecha $\\{18, 22, 24, 24, 25\\}$?\n\n#### Desviaci√≥n Est√°ndar\n\nLa desviaci√≥n est√°ndar (SD) se utiliza para medir la estimaci√≥n de la variaci√≥n de los puntos de datos en un conjunto de datos en relaci√≥n con la media aritm√©tica. Un conjunto de datos completo se conoce como una poblaci√≥n, mientras que un subconjunto del conjunto de datos se conoce como una muestra. Las ecuaciones para calcular la desviaci√≥n est√°ndar de la poblaci√≥n y la desviaci√≥n est√°ndar de la muestra se expresan como Ecuaciones [1.6](#eq-1.6) y [1.7](#eq-1.7), respectivamente.\n\n$$\n\\text{Desviaci√≥n est√°ndar poblacional, } \\sigma=\\sqrt{\\frac{1}{N}\\sum_{i=1}^N{(x_i-\\mu)^2}}.\n$$ {#eq-1.6}\n\nDonde $\\sigma$ simboliza la desviaci√≥n est√°ndar de la poblaci√≥n, $i$ es una variable que enumera los puntos de datos, $x_i$ denota cualquier punto de datos particular, $\\mu$ es la media aritm√©tica de la poblaci√≥n y $N$ es el n√∫mero total de puntos de datos en la poblaci√≥n.\n\n$$\n\\text{Desviaci√≥n est√°ndar muestral, } s=\\sqrt{\\frac{1}{N-1}\\sum_{i=1}^N{(x_i-\\overline{x})^2}}.\n$$ {#eq-1.7}\n\nDonde $s$ simboliza la desviaci√≥n est√°ndar de la muestra, $i$ es una variable que enumera los puntos de datos, $x_i$ denota cualquier punto de datos particular, $x$ es la media aritm√©tica de la muestra y $N$ es el n√∫mero total de puntos de datos en la muestra.\n\nUn valor bajo de la desviaci√≥n est√°ndar indica que los puntos de datos se encuentran razonablemente cerca de la media del conjunto de datos, como se muestra en la Fig. 1.8a. Por otro lado, un valor alto de la desviaci√≥n est√°ndar indica que los puntos de datos se encuentran lejos de la media del conjunto de datos, cubriendo un rango amplio, como se muestra en la Fig. 1.8b.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\nbajo <- data.frame(label = \"bajo\", x = rnorm(500, 0, 5))\nalto <- data.frame(label = \"alto\", x = rnorm(500, 0, 20))\ndata <- rbind(bajo, alto)\n\ngridExtra::grid.arrange(\nbajo |> \n  ggplot(aes(x = x))+\n  geom_histogram(aes(fill = label), alpha = 0.5)+\n  theme(panel.background = element_blank(),\n        legend.position = \"top\")+\n  scale_fill_brewer(palette = \"Dark2\")+\n  labs(x = \"X\", y = \"f(X)\")+\n  guides(fill = guide_legend(\"Menor valor desviaci√≥n est√°ndar\"))+\n  scale_x_continuous(breaks = c(seq(-200, 200, by = 20)))+\n  coord_cartesian(xlim = c(-100,100))\n\n,\n\nalto |> \n  ggplot(aes(x = x))+\n  geom_histogram(aes(fill = label), alpha = 0.5)+\n  theme(panel.background = element_blank(),\n        legend.position = \"top\")+\n  scale_fill_brewer(palette = \"Set1\")+\n  labs(x = \"X\", y = \"f(X)\")+\n  guides(fill = guide_legend(\"Mayor valor desviaci√≥n est√°ndar\"))+\n  scale_x_continuous(breaks = c(seq(-200, 200, by = 20)))+\n  coord_cartesian(xlim = c(-100,100))\n\n,\nncol = 2\n)\n```\n\n::: {.cell-output-display}\n![Fig. 1.8. Desviaci√≥n est√°ndas de los datos](index_files/figure-html/fig-desvest-1.png){#fig-desvest width=672}\n:::\n:::\n\n\n\n#### Correlaci√≥n\n\nLa correlaci√≥n muestra c√≥mo de fuerte es la relaci√≥n entre dos variables. Es una medida estad√≠stica de la relaci√≥n entre dos (y a veces m√°s) variables. Por ejemplo, si una persona puede nadar, probablemente puede sobrevivir despu√©s de caerse de un barco. Sin embargo, la correlaci√≥n no es causalidad. Una correlaci√≥n fuerte no siempre significa una relaci√≥n fuerte entre dos variables; podr√≠a ser pura coincidencia. Un ejemplo famoso en este sentido es la correlaci√≥n entre las ventas de helado y los ataques de tiburones. Hay una correlaci√≥n fuerte entre las ventas de helado y los ataques de tiburones, **pero** los ataques de tiburones ciertamente no ocurren debido a las ventas de helado.\n\nLa correlaci√≥n se puede clasificar de muchas maneras, como se describe en las secciones siguientes.\n\n##### Correlaci√≥n Positiva, Negativa y Cero\n\nEn una correlaci√≥n positiva, la direcci√≥n del cambio es la misma para ambas variables, es decir, cuando el valor de una variable aumenta o disminuye, el valor de la otra variable tambi√©n aumenta o disminuye, respectivamente. En una correlaci√≥n negativa, la direcci√≥n del cambio es opuesta para ambas variables, es decir, cuando el valor de una variable aumenta, el valor de la otra variable disminuye, y viceversa. Para una correlaci√≥n cero, las dos variables son independientes, es decir, no existe correlaci√≥n entre ellas. Estos conceptos se presentan detalladamente en la Fig. 1.9.\n\n##### Correlaci√≥n Simple, Parcial y Multiple\n\nLa correlaci√≥n entre dos variables es una correlaci√≥n simple. Pero si el n√∫mero de variables es de tres o m√°s, es una correlaci√≥n parcial o m√∫ltiple. En una correlaci√≥n parcial, la correlaci√≥n entre dos variables de inter√©s se determina mientras se mantiene constante la otra variable. Por ejemplo, la correlaci√≥n entre la cantidad de comida ingerida y la presi√≥n arterial para un grupo de edad espec√≠fico se puede considerar como una correlaci√≥n parcial. Cuando se determina la correlaci√≥n entre tres o m√°s variables al mismo tiempo, se llama correlaci√≥n m√∫ltiple. Por ejemplo, la relaci√≥n entre la cantidad de comida comida, la altura, el peso y la presi√≥n arterial se puede considerar como un caso de correlaci√≥n m√∫ltiple.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Generar datos aleatorios\nset.seed(123)\nx <- rnorm(100, mean = 0, sd = 1)\ny <- rnorm(100, mean = 0, sd = 1)\n\n# Crear un data frame\ndf <- data.frame(x, y)\n\n# Crear la gr√°fica\nga <- ggplot(df, aes(x = x, y = y)) +\n  geom_point(aes(col = \"lightgreen\")) +\n  theme(legend.position = \"none\",\n        panel.background = element_blank(),\n        axis.text.x = element_blank(),\n        axis.ticks.x = element_blank(),\n        axis.text.y = element_blank(),\n        axis.ticks.y = element_blank()) +\n  labs(title = \"No hay correlaci√≥n (0)\",\n       x = \"Variable x\",\n       y = \"Variable y\")+\n  scale_color_brewer(palette = \"Set1\")\n\n\n# Generar datos aleatorios\nset.seed(123)\nx <- rnorm(100, mean = 0, sd = 1)\ny <- 2*x + rnorm(100, mean = 0, sd = 0.5)\n\n# Crear un data frame\ndf <- data.frame(x, y)\n# Crear la gr√°fica\ngb <- ggplot(df, aes(x = x, y = y)) +\n  geom_point(aes(col = \"lightgreen\")) +\n  theme(legend.position = \"none\",\n        panel.background = element_blank(),\n        axis.text.x = element_blank(),\n        axis.ticks.x = element_blank(),\n        axis.text.y = element_blank(),\n        axis.ticks.y = element_blank()) +\n  labs(title = \"Correlaci√≥n positiva alta (0.9)\",\n       x = \"Variable x\",\n       y = \"Variable y\")+\n  scale_color_brewer(palette = \"Set1\")\n\n\n# Generar datos aleatorios\nset.seed(123)\nx <- rnorm(100, mean = 0, sd = 1)\ny <- 2*x + 0.5\n\n# Crear un data frame\ndf <- data.frame(x, y)\n\n# Crear la gr√°fica\ngc <- ggplot(df, aes(x = x, y = y)) +\n  geom_point(aes(colour = \"lightgreen\")) +\n  theme(legend.position = \"none\",\n        panel.background = element_blank(),\n        axis.text.x = element_blank(),\n        axis.ticks.x = element_blank(),\n        axis.text.y = element_blank(),\n        axis.ticks.y = element_blank()) +\n  labs(title = \"Correlaci√≥n positiva perfecta (1)\",\n       x = \"Variable x\",\n       y = \"Variable y\")+\n  scale_color_brewer(palette = \"Set1\")\n\n\n# Generar datos aleatorios\nset.seed(123)\nx <- rnorm(100, mean = 0, sd = 1)\ny <- 0.5*x + rnorm(100, mean = 0, sd = 0.3)\n\n# Crear un data frame\ndf <- data.frame(x, y)\n# Crear la gr√°fica\ngd <- ggplot(df, aes(x = x, y = y)) +\n  geom_point(aes(colour = \"lightgreen\")) +\n  theme(legend.position = \"none\",\n        panel.background = element_blank(),\n        axis.text.x = element_blank(),\n        axis.ticks.x = element_blank(),\n        axis.text.y = element_blank(),\n        axis.ticks.y = element_blank()) +\n  labs(title = \"Correlaci√≥n positiva baja (0.5)\",\n       x = \"Variable x\",\n       y = \"Variable y\")+\n  scale_color_brewer(palette = \"Set1\")\n\n\n\n# Generar datos aleatorios\nset.seed(123)\nx <- rnorm(100, mean = 0, sd = 1)\ny <- -2*x + 2\n\n# Crear un data frame\ndf <- data.frame(x, y)\n\n# Crear la gr√°fica\nge <- ggplot(df, aes(x = x, y = y)) +\n  geom_point(aes(colour = \"lightgreen\")) +\n  theme(legend.position = \"none\",\n        panel.background = element_blank(),\n        axis.text.x = element_blank(),\n        axis.ticks.x = element_blank(),\n        axis.text.y = element_blank(),\n        axis.ticks.y = element_blank()) +\n  labs(title = \"Correlaci√≥n negativa perfecta (-1)\",\n       x = \"Variable x\",\n       y = \"Variable y\")+\n  scale_color_brewer(palette = \"Set1\")\n\n\n\n# Generar datos aleatorios\nset.seed(123)\nx <- rnorm(100, mean = 0, sd = 1)\ny <- -0.8*x + rnorm(100, mean = 0, sd = 0.5)\n\n# Crear un data frame\ndf <- data.frame(x, y)\n\n# Crear la gr√°fica\ngf <- ggplot(df, aes(x = x, y = y)) +\n  geom_point(aes(colour = \"lightgreen\")) +\n  theme(legend.position = \"none\",\n        panel.background = element_blank(),\n        axis.text.x = element_blank(),\n        axis.ticks.x = element_blank(),\n        axis.text.y = element_blank(),\n        axis.ticks.y = element_blank()) +\n  labs(title = \"Correlaci√≥n negativa alta (-0.9)\",\n       x = \"Variable x\",\n       y = \"Variable y\")+\n  scale_color_brewer(palette = \"Set1\")\n\n\n\n# Generar datos aleatorios\nset.seed(123)\nx <- rnorm(100, mean = 0, sd = 1)\ny <- -0.2*x + rnorm(100, mean = 0, sd = 0.7)\n\n# Crear un data frame\ndf <- data.frame(x, y)\n\n# Crear la gr√°fica\ngg <- ggplot(df, aes(x = x, y = y)) +\n  geom_point(aes(colour = \"lightgreen\")) +\n  theme(legend.position = \"none\",\n        panel.background = element_blank(),\n        axis.text.x = element_blank(),\n        axis.ticks.x = element_blank(),\n        axis.text.y = element_blank(),\n        axis.ticks.y = element_blank()) +\n  labs(title = \"Correlaci√≥n positiva baja (-0.5)\",\n       x = \"Variable x\",\n       y = \"Variable y\")+\n  scale_color_brewer(palette = \"Set1\")\n\ngridExtra::grid.arrange(\n  ga,gb,gc,gd,ge,gf,gg,\n  ncol = 2\n)\n```\n\n::: {.cell-output-display}\n![Fig. 1.9. Visualizaci√≥n de correlaci√≥n cero, positiva y negativa a diferentes niveles](index_files/figure-html/fig-correlaciones-1.png){#fig-correlaciones width=672}\n:::\n:::\n\n\n\n##### Correlaci√≥n Lineal y No Lineal\n\nCuando la direcci√≥n del cambio es constante en todos los puntos para todas las variables, la correlaci√≥n entre ellas es lineal. Si la direcci√≥n del cambio cambia, es decir, no es constante en todos los puntos, entonces se conoce como correlaci√≥n no lineal, tambi√©n conocida como correlaci√≥n curvil√≠nea. Un ejemplo de correlaci√≥n no lineal ser√≠a la relaci√≥n entre la satisfacci√≥n del cliente y la alegr√≠a del personal. La alegr√≠a del personal podr√≠a mejorar la experiencia del cliente, pero demasiada alegr√≠a podr√≠a tener un efecto negativo.\n\n##### Coeficiente de Correlaci√≥n\n\nEl coeficiente de correlaci√≥n se utiliza para representar la correlaci√≥n de manera num√©rica. Indica la fuerza de la relaci√≥n entre las variables. Hay muchos tipos de coeficientes de correlaci√≥n. Sin embargo, los dos m√°s utilizados y m√°s importantes se discuten brevemente aqu√≠.\n\n*Coeficiente de Correlaci√≥n de Pearson*\n\nEl Coeficiente de Correlaci√≥n de Pearson, tambi√©n conocido como $\\text{r de Pearson}$, es el m√°s popular y ampliamente utilizado para determinar la correlaci√≥n lineal entre dos variables. En otras palabras, describe la fuerza de la relaci√≥n entre dos variables basada en la direcci√≥n del cambio en las variables.\n\nPara el coeficiente de correlaci√≥n de una muestra,\n\n$$\nr_{xy}=\\frac{Cov(x,y)}{s_xs_y}=\\frac{\\frac{\\sum{(x_i-\\overline{x})(y_i-\\overline{y})}}{n-1}}{\\sqrt{\\frac{(x_i-\\overline{x})^2}{n-1}}\\sqrt{\\frac{y_i-\\overline{y})^2}{n-1}}}=\\frac{\\sum{(x_i-\\overline{x})(y_i-\\overline{y})}}{\\sum{(x_i-\\overline{x})^2(y_i-\\overline{y})^2}}\n$$ {#eq-1.8}\n\nAqu√≠, $r_{xy}$ es el coeficiente de correlaci√≥n de muestra entre dos variables $x$ y $y$; $Cov(x, y)$ es la covarianza de muestra entre dos variables $x$ y $y$; $s_x$ , $s_y$ son la desviaci√≥n est√°ndar de muestra de $x$ y $y$; $\\overline{x}$, $\\overline{y}$ son el valor promedio de $x$ y el valor promedio de $y$; $n$ es el n√∫mero de puntos de datos en $x$ y $y$.\n\nPara el coeficiente de correlaci√≥n de una poblaci√≥n,\n\n$$\n\\rho_{xy}=\\frac{Cov(x,y)}{\\sigma_x\\sigma_y}=\\frac{\\frac{\\sum{(x_i-\\overline{x})(y_i-\\overline{y})}}{n}}{\\sqrt{\\frac{(x_i-\\overline{x})^2}{n}}\\sqrt{\\frac{y_i-\\overline{y})^2}{n}}}=\\frac{\\sum{(x_i-\\overline{x})(y_i-\\overline{y})}}{\\sum{(x_i-\\overline{x})^2(y_i-\\overline{y})^2}}\n$$ {#eq-1.9}\n\nAqu√≠, $\\rho_{xy}$ es el coeficiente de correlaci√≥n de poblaci√≥n entre dos variables $x$ y $y$; $Cov(x, y)$ es la covarianza de poblaci√≥n entre dos variables $x$ y $y$; $\\sigma_x$ , $\\sigma_y$ son la desviaci√≥n est√°ndar de poblaci√≥n de $x$ y $y$; $\\overline{x}$, $\\overline{y}$ son el valor promedio de $x$ y el valor promedio de $y$ y $n$ es el n√∫mero de puntos de datos en $x$ y $y$.\n\nEl valor del coeficiente de correlaci√≥n de Pearson var√≠a entre -1 y 1. Aqu√≠, -1 indica una correlaci√≥n negativa perfecta, y el valor 1 indica una correlaci√≥n positiva perfecta. Un coeficiente de correlaci√≥n de 0 significa que no hay correlaci√≥n. El coeficiente de correlaci√≥n de Pearson se aplica cuando los datos de ambas variables provienen de una distribuci√≥n normal, no hay outliers en los datos y la relaci√≥n entre las dos variables es lineal.\n\n*Coeficiente de Correlaci√≥n de Spearman*\n\nEl Coeficiente de Correlaci√≥n de Spearman determina la relaci√≥n no-param√©trica entre los rangos de dos variables, es decir, el c√°lculo se realiza entre los rangos de las dos variables en lugar de los datos en s√≠ mismos. Los rangos se determinan generalmente asignando el rango 1 al dato m√°s peque√±o, el rango 2 al siguiente dato m√°s peque√±o y as√≠ sucesivamente hasta el dato m√°s grande. Por ejemplo, los datos contenidos en una variable son {55, 25, 78, 100, 96, 54}. Por lo tanto, el rango para esa variable particular ser√° {3, 1, 4, 6, 5, 2}. Al calcular los rangos de ambas variables, se puede calcular el coeficiente de correlaci√≥n de Spearman como sigue:\n\n$$\n\\rho=1-\\frac{6\\sum{d_i^2}}{n(n^2-1)}.\n$$ {#eq-1.10}\n\nAqu√≠, $\\rho$ es el coeficiente de correlaci√≥n de Spearman, $n$ es el n√∫mero de puntos de datos en las variables y $d_i$ es la diferencia de rango en el i-√©simo dato.\n\nEl coeficiente de correlaci√≥n de Pearson determina la linealidad de la relaci√≥n, mientras que el coeficiente de correlaci√≥n de Spearman determina la monotonicidad de la relaci√≥n. La representaci√≥n gr√°fica de la monotonicidad de la relaci√≥n se muestra en la Fig. 1.10.\n\nA diferencia de una relaci√≥n lineal, el ritmo de cambio de los datos no es siempre el mismo en una relaci√≥n monot√≥nica. Si el ritmo de cambio es en la misma direcci√≥n para ambas variables, la relaci√≥n es positiva monot√≥nica. Por otro lado, si la direcci√≥n es opuesta para ambas variables, la relaci√≥n es negativa monot√≥nica. La relaci√≥n se llama no-monot√≥nica cuando la direcci√≥n del cambio no es siempre la misma o opuesta, sino una combinaci√≥n.\n\nEl valor del coeficiente de correlaci√≥n de Spearman var√≠a entre -1 y 1. Un valor de -1 indica una correlaci√≥n negativa perfecta (correlaci√≥n negativa de rango), un valor de 1 indica una correlaci√≥n positiva perfecta (correlaci√≥n positiva de rango) y un valor de 0 indica que no hay correlaci√≥n. El coeficiente de correlaci√≥n de Spearman se utiliza cuando se cumplen uno o m√°s condiciones del coeficiente de correlaci√≥n de Pearson.\n\nAdem√°s de estos dos coeficientes de correlaci√≥n, tambi√©n se utilizan otros como: coeficiente de correlaci√≥n de rango de Cramer (Cramer's $\\tau$), coeficiente de correlaci√≥n de Kendall (Kendall's $\\varphi$), coeficiente biserial de punto. El uso de los diferentes coeficientes de correlaci√≥n depende del tipo de aplicaci√≥n y del tipo de datos.\n\n#### Anomal√≠as\n\nUna anomal√≠a es un punto de datos en el conjunto de datos que posee propiedades diferentes a todas las dem√°s y, por lo tanto, var√≠a significativamente del patr√≥n de otras observaciones. Se trata del valor que tiene la mayor deviaci√≥n del patr√≥n t√≠pico seguido por todos los dem√°s valores en el conjunto de datos.\n\nLos algoritmos de ML tienen una alta sensibilidad a la distribuci√≥n y el rango de valores de atributos. Las anomal√≠as tienen la tendencia a confundir el proceso de entrenamiento del algoritmo, lo que eventualmente conduce a observaciones err√≥neas, resultados inexactos, tiempos de entrenamiento m√°s largos y resultados pobres.\n\nConsidera el conjunto de datos $(x, y)$. Aqu√≠, $x$ es la tasa de consumo de agua por d√≠a y $y$ es la tasa de consumo de electricidad por d√≠a. En la [Figura 1.11](#fig-outliers), podemos ver que estos datos se distribuyen en 2 grupos diferentes, pero uno de los puntos de datos no puede agruparse con ninguno de estos grupos. Este punto de datos act√∫a como una anomal√≠a en este caso.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\nx <- rnorm(100, mean = 1.5, sd = 0.1)\ny <- rnorm(100, mean = 5, sd = 0.1)\nw <- rnorm(100, mean = 3, sd = 0.1)\nz <- rnorm(100, mean = 3, sd = 0.2)\n\n# Agrupar datos en 3 clusters con k-means\nkmeans_result1 <- kmeans(cbind(x, y), centers = 1)\n\n# Crear datos para los c√≠rculos\ncircles1 <- data.frame(x = kmeans_result1$centers[, 1], \n                      y = kmeans_result1$centers[, 2], \n                      radius = 5)\n\nkmeans_result2 <- kmeans(cbind(w, z), centers = 1)\n\n# Crear datos para los c√≠rculos\ncircles2 <- data.frame(w = kmeans_result2$centers[, 1], \n                      z = kmeans_result2$centers[, 2], \n                      radius = 5)\n\n# Crear datos para el punto at√≠pico\noutlier <- data.frame(x = 2, y = 3.5, label = paste(\"(\", x, \", \", y, \")\", sep = \"\"))\n\n# Crear gr√°fico\nggplot() +\n  geom_point(data = data.frame(x, y), aes(x = x, y = y), color = \"gray\") +\n  geom_point(data = data.frame(w, z), aes(x = w, y = z), color = \"gray\") +\n  geom_point(data = circles1, aes(x = x, y = y), color = \"red\", size = 40, alpha = 0.2) +\n  geom_point(data = circles2, aes(x = w, y = z), color = \"green\", size = 40, alpha = 0.2) +\n  geom_point(data = outlier, aes(x = x, y = y), color = \"blue\", size = 5) +\n  geom_text(data = outlier, aes(label = \"(2, 3.5)\", x = 2, y = 3.3))+\n  theme_classic() +\n  labs(x = \"Consumo de agua (Litros)\",\n       y = \"Consumo de electricidad (kW)\")\n```\n\n::: {.cell-output-display}\n![Fig. 1.11. Representaci√≥n de un valor at√≠pico. Los puntos negros se encuentran dentro de l√≠mites espec√≠ficos, pero un punto azul est√° m√°s all√° de esos c√≠rculos de datos. El punto azul es un valor at√≠pico.](index_files/figure-html/fig-outliers-1.png){#fig-outliers width=672}\n:::\n:::\n\n\n\nEs importante destacar que ruido y anomal√≠as son dos cosas diferentes. Mientras que una anomal√≠a es un valor de datos significativamente desviado, el ruido es simplemente un valor err√≥neo.\n\nLa [Figura 1.12](#fig-anomalia) visualiza la diferencia entre anomal√≠a y ruido utilizando una se√±al.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplottimeseries)\n\n# Cargamos los datos\ndata(sst)\n\n# Organizamos los datos\nx <- sst$date\ny <- sst$sst\nz <- 365.25 #number of days in a year\n\n# Creamos un at√≠pico artificialmente\ny[950] <- 40\n\n# Usamos la funci√≥n para la serie de tiempo\ndf <- dts1(x,y,z, type = \"additive\")\n\n# Modificamos la funci√≥n ggdecompose\nplot_decompose <- function (x) \n{\n  if (!require(ggplot2)) {\n    install.packages(\"ggplot2\")\n    library(ggplot2)\n  }\n  if (!require(tidyr)) {\n    install.packages(\"tidyr\")\n    library(tidyr)\n  }\n  n <- tidyr::gather(x, key = \"components\", value = \"estimate\", \n                     observation, trend, seasonal, random)\n  n$components_f = factor(n$components, levels = c(\"observation\", \n                                                   \"trend\", \"seasonal\", \"random\"))\n  ggplot(n, aes(x = date, y = estimate)) + \n    geom_line(col = \"gray30\") + \n    theme(panel.background = element_blank())+\n    facet_grid(components_f ~., \n               scales = \"free_y\",\n               labeller = as_labeller(c(observation = \"original\",\n                                      trend = \"tendencia\",\n                                      seasonal = \"estacionalidad\",\n                                      random = \"ruido\")))\n}\n\n# Graficamos\nplot_decompose(df)+\n  labs(x = \"Fecha\", y = NULL)+\n  scale_x_date(date_breaks = \"1 year\", date_labels = \"%Y\")\n```\n\n::: {.cell-output-display}\n![Fig. 1.12. Diferencia entre anomal√≠a y ruido.](index_files/figure-html/fig-anomalia-1.png){#fig-anomalia width=672}\n:::\n:::\n\n\n\nConsidera una lista de 100 precios de casas, que principalmente incluye precios que van desde los 3000 hasta los 5000 d√≥lares. Primero, hay una casa en la lista con un precio de 20,000 d√≥lares. Luego, hay una casa en la lista con un precio de -100 d√≥lares. 20,000 es una anomal√≠a aqu√≠, ya que difiere significativamente de los dem√°s precios de casas. Por otro lado, -100 es un ruido, ya que el precio de algo no puede ser un valor negativo. Dado que la anomal√≠a distorsiona significativamente la media aritm√©tica del conjunto de datos y conduce a observaciones err√≥neas, eliminar anomal√≠as del conjunto de datos es el requisito previo para lograr el resultado correcto.\n\n#### Histograma\n\nUn histograma se asemeja a un gr√°fico de columnas y representa la distribuci√≥n de frecuencia de los datos en barras verticales en un sistema de ejes bidimensional. Los histogramas tienen la capacidad de expresar los datos de manera estructurada, lo que facilita la visualizaci√≥n de datos. Las barras en un histograma se colocan al lado uno del otro sin espacios en blanco entre ellas. El histograma agrupa los datos en barras, lo que proporciona una comprensi√≥n clara de la distribuci√≥n de los datos. La disposici√≥n tambi√©n proporciona una comprensi√≥n clara de la distribuci√≥n de los datos seg√∫n sus caracter√≠sticas en el conjunto de datos.\n\nLa Figura 1.13 ilustra tres tipos de histogramas, con una distribuci√≥n desviada a la izquierda, una distribuci√≥n normal y una distribuci√≥n desviada a la derecha.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Librer√≠as necesarias\nlibrary(ggplot2)\nlibrary(gridExtra)\n\n\n# Generar datos sesgados a la izquirda\nx <- round(100 * rbeta(10000, 15, 12))\ndata_x <- data.frame(x = x)\n\n# Generar datos sesgados a la derecha\ny <- round(100 * rbeta(10000, 12, 15))\ndata_y <- data.frame(x = y)\n\n# Generar datos distribuidos normal\nz <- round(100 * rbeta(10000, 15, 15))\ndata_z <- data.frame(x = z)\n\n# Genera gr√°fico\ngridExtra::grid.arrange(\n  \nggplot(data_x, aes(x = x))+\n  geom_histogram(fill = \"gray\")+\n  labs(x = \"Sesgada a la izquierda\", y = NULL)+\n  theme(panel.background = element_blank())\n,\n\nggplot(data_z, aes(x = x))+\n  geom_histogram(fill = \"gray\")+\n  labs(x = \"Normal\", y = NULL)+\n  theme(panel.background = element_blank())\n,\n\nggplot(data_y, aes(x = x))+\n  geom_histogram(fill = \"gray\")+\n  labs(x = \"Sesgada a la derecha\", y = NULL)+\n  theme(panel.background = element_blank())\n,\n\nncol = 3\n)\n```\n\n::: {.cell-output-display}\n![Fig. 1.13. Representaci√≥n de varias distribuciones usando histogramas.](index_files/figure-html/fig-histogramas-1.png){#fig-histogramas width=672}\n:::\n:::\n\n\n\n#### Errores\n\nEl conocimiento de los errores es √∫til al evaluar la precisi√≥n de un modelo de aprendizaje autom√°tico (ML). En particular, cuando se prueba el modelo entrenado contra un conjunto de datos de prueba, se compara el resultado del modelo con el resultado conocido del conjunto de datos de prueba. La deviaci√≥n entre los datos predichos y los datos reales se conoce como el error. Si el error est√° dentro de los l√≠mites tolerables, entonces el modelo est√° listo para usar; en caso contrario, debe ser reentrenado para mejorar su precisi√≥n.\n\nHay varios m√©todos para estimar la precisi√≥n del rendimiento de un modelo de ML. Algunos de los m√©todos m√°s populares son medir el porcentaje de error absoluto promedio (MAPE), el error cuadrado medio (MSE), el error absoluto medio (MAE) y el error raiz cuadrado medio (RMSE). En las ecuaciones de la Tabla 1.7, $n$ representa el n√∫mero total de veces que ocurre la iteraci√≥n, $t$ representa una iteraci√≥n espec√≠fica o una instancia del conjunto de datos, $e_t$ es la diferencia entre el valor real y el valor predicho del punto de datos, y $y_t$ es el valor real.\n\n+---------------------------------+---------------------------------------------------------+\n| Nombre del error                | Ecuaci√≥n                                                |\n+:===============================:+:=======================================================:+\n| Error cuadr√°tico medio          | $$                                                      |\n|                                 | MSE=\\frac{1}{n}\\sum_{t=1}^ne_t^2                        |\n|                                 | $$                                                      |\n+---------------------------------+---------------------------------------------------------+\n| Ra√≠z del error cuadr√°tico medio | $$                                                      |\n|                                 | RMSE=\\sqrt{\\frac{1}{n}\\sum_{t=1}^ne_t^2}                |\n|                                 | $$                                                      |\n+---------------------------------+---------------------------------------------------------+\n| Error absoluto medio            | $$                                                      |\n|                                 | MAE=\\sqrt{\\frac{1}{n}\\sum_{t=1}^n|e_t|}                 |\n|                                 | $$                                                      |\n+---------------------------------+---------------------------------------------------------+\n| Error porcentual absoluto medio | $$                                                      |\n|                                 | MAPE=\\frac{100%}{n}\\sqrt{\\sum_{t=1}^n|\\frac{e_t}{y_t}|} |\n|                                 | $$                                                      |\n+---------------------------------+---------------------------------------------------------+\n\n: Tabla 1.7. Diferentes tipos de errores {#tbl-errores}\n\nEl concepto de errores es vital para crear un modelo de ML preciso para varios prop√≥sitos. Estos se describen con mayor profundidad en la Secci√≥n 2.2 del Cap√≠tulo 2.\n\n### Teor√≠a de la Probabilidad\n\nLa probabilidad es una medida de la probabilidad de que un evento espec√≠fico ocurra.\n\nLa probabilidad se encuentra entre 0 y 1, donde 0 significa que el evento nunca ocurrir√° y 1 significa que el evento es seguro de ocurrir. La probabilidad se define como la ratio del n√∫mero de resultados deseados al n√∫mero total de resultados.\n\n$$P(A)=\\frac{n(A)}{n}.$$ {#eq-1.11}\n\nDonde $P (A)$ denota la probabilidad de un evento $A$, $n (A)$ denota el n√∫mero de ocurrencias del evento $A$ y $n$ denota el n√∫mero total de resultados posibles, tambi√©n conocido como el espacio muestral.\n\nVamos a ver un ejemplo com√∫n. Un dado est√°ndar con seis caras contiene un n√∫mero entre 1 y 6 en cada una de las caras. Cuando se lanza un dado, cualquier uno de los seis n√∫meros puede aparecer en la cara superior. Por lo tanto, la probabilidad de obtener un 6 en el dado se determina seg√∫n se muestra en la ecuaci√≥n 1.12.\n\n$$\nP(6)=\\frac{1}{6}=0.167=16.7\\text{%}\n$$ {#eq-1.12}\n\nLa teor√≠a de la probabilidad es el campo que abarca las matem√°ticas relacionadas con la probabilidad. Cualquier algoritmo de aprendizaje depende de la suposici√≥n probabil√≠stica de los datos. Como los modelos de ML manejan la incertidumbre de los datos, el ruido, la distribuci√≥n de probabilidad, etc., varios conceptos fundamentales de la teor√≠a de la probabilidad son necesarios, que se cubren en esta secci√≥n 1.5.3.\n\n#### Distribuci√≥n de Probabilidad\n\nEn la teor√≠a de la probabilidad, todos los posibles resultados num√©ricos de cualquier experimento se representan mediante variables aleatorias. Una funci√≥n de distribuci√≥n de probabilidad produce los valores num√©ricos posibles de una variable aleatoria dentro de un rango espec√≠fico. Las variables aleatorias son de dos tipos: discretas y continuas. Por lo tanto, la distribuci√≥n de probabilidad se puede categorizar en dos tipos seg√∫n el tipo de variable aleatoria involucrada‚Äîfunci√≥n de densidad de probabilidad y funci√≥n de masa de probabilidad.\n\n##### Funci√≥n de Densidad de Probabilidad\n\nLos valores num√©ricos posibles de una variable aleatoria continua se pueden calcular utilizando la funci√≥n de densidad de probabilidad (PDF). La representaci√≥n gr√°fica de esta distribuci√≥n es continua. Por ejemplo, en la [Figura 1.14](#fig-funcionFDP), cuando un modelo busca la probabilidad de la altura de las personas en el rango de 160-170 cm, podr√≠a utilizar una PDF para indicar la probabilidad total de que el rango de la variable aleatoria continua ocurra. Aqu√≠, f (x) es la PDF de la variable aleatoria x.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(purrr)\ndat <- data.frame(dens = c(rnorm(1000, 165, 2))\n                  , group = rep(c(\"dx\"), each = 100))\n\nas.data.frame.density <- function(x) data.frame(x = x$x, y = x$y)\n\ndensities <- dat %>% \n  group_nest(group) %>% \n  mutate(dens = map(data, ~as.data.frame(density(.$dens)))) %>% \n  unnest(dens)\n\nggplot(densities, aes(x = x, y = y, group = group)) + \n  geom_density(stat = 'identity') +\n  geom_density(\n    aes(fill = group),\n    . %>% filter((group == \"dx\" & between(x, 165, 166)) | (group == \"P\" & between(x, 0.5, 2.8))),\n    stat = 'identity',\n    alpha = 0.75\n  )+\n  geom_text(aes(x = 165.5, y = 0.05), label = \"dx\")+\n  geom_segment(aes(x = 164, y = 0.05, xend = 165, yend = 0.05),\n               arrow = arrow(length = unit(0.25, \"cm\")))+\n  geom_segment(aes(x = 167, y = 0.05, xend = 166, yend = 0.05),\n               arrow = arrow(length = unit(0.25, \"cm\")))+\n  theme(panel.background = element_blank(),\n        legend.position = \"top\")+\n  labs(x = \"Altura (cm)\", y = \"Funci√≥n Densidad Probabilidad\")+\n  guides(fill = guide_legend(\"Probabilidad que personas en este rango de altura se encuentren\"))\n```\n\n::: {.cell-output-display}\n![Fig. 1.14. Ejemplo de funci√≥n de densidad de probabilidad.](index_files/figure-html/fig-funcionFDP-1.png){#fig-funcionFDP width=672}\n:::\n:::\n\n\n\n##### Funci√≥n de Masa de Probabilidad\n\nCuando se implementa una funci√≥n para encontrar los valores num√©ricos posibles de una variable aleatoria discreta, la funci√≥n se conoce como funci√≥n de masa de probabilidad (PMF). Las variables aleatorias discretas tienen un n√∫mero finito de valores. Por lo tanto, no obtenemos una curva continua cuando se representa gr√°ficamente la PMF. Por ejemplo, si consideramos el lanzamiento de un dado de seis caras, tendremos un n√∫mero finito de resultados, como se muestra en la [Figura 1.15](#fig-funcionFMP).\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Crear un vector con los valores posibles del dado\nvalues <- c(1, 2, 3, 4, 5, 6)\n\n# Crear un vector con las probabilidades correspondientes a cada valor\nprobabilities <- c(0.2, 0.3, 0.1, 0.1, 0.1, 0.2)\n\n# Crear un data frame con los valores y probabilidades\ndf <- data.frame(values, probabilities)\n\n# Crear la gr√°fica\nggplot(df, aes(x = values, y = probabilities)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  labs(x = \"Valor del dado\", y = \"Probabilidad\", title = \"Funci√≥n de Masa de Probabilidad\", subtitle = \"Lanzamiento de un Dado con Diferentes Probabilidades\") +\n  theme_classic()\n```\n\n::: {.cell-output-display}\n![Fig. 1.15. Ejemplo de funci√≥n de masa de probabilidad.](index_files/figure-html/fig-funcionFMP-1.png){#fig-funcionFMP width=672}\n:::\n:::\n\n\n\n#### Distribuci√≥n Gaussiana o Distribuci√≥n Normal\n\nLa probabilidad acumulada de variables aleatorias normales se presenta en la distribuci√≥n Gaussiana o normal. El gr√°fico depende de la media y la distribuci√≥n est√°ndar de los datos. En una distribuci√≥n est√°ndar, la media de los datos es 0 y la desviaci√≥n est√°ndar es 1. Un gr√°fico de distribuci√≥n normal es una curva en forma de campana, como se muestra en la [Fig. 1.16](#fig-normalDistr). Por lo tanto, tambi√©n se conoce como distribuci√≥n de curva en forma de campana.\n\nLa ecuaci√≥n que representa la distribuci√≥n Gaussiana o normal es:\n\n$$\nP(x)=\\frac{1}{\\alpha\\sqrt{2\\pi}}e^{\\frac{-(x+\\mu)^2}{2\\alpha^2}}\n$$ {#eq-1.13}\n\nDonde $P(x)$ denota la densidad de probabilidad de la distribuci√≥n normal, $Œ±$ denota la desviaci√≥n est√°ndar, $Œº$ denota la media del conjunto de datos y $x$ denota un punto de datos.\n\n#### Distribuci√≥n de Bernoulli\n\nUna distribuci√≥n de probabilidad sobre el ensayo de Bernoulli es la distribuci√≥n de Bernoulli. El ensayo de Bernoulli es un experimento o evento que solo tiene dos resultados. Por ejemplo, lanzar una moneda se puede considerar como un ensayo de Bernoulli, ya que solo puede tener dos resultados - cara o sello. Normalmente, los resultados se observan en t√©rminos de √©xito o fracaso. En este caso, podemos decir que obtener una cara ser√° un √©xito. Por otro lado, no obtener una cara o obtener un sello ser√≠a un fracaso. La distribuci√≥n de Bernoulli se ha visualizado en la [Fig. 1.17](#fig-bernoulliDistr), que plotea la probabilidad de dos ensayos.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Carga la biblioteca ggplot2\nlibrary(ggplot2)\n\n# Crea un data frame con los valores de la distribuci√≥n normal\nx <- seq(-3, 3, by = 0.01)\ny <- dnorm(x, mean = 0, sd = 1)\n\n# Crea un data frame con los valores de la distribuci√≥n normal\nnormal_data <- data.frame(x = x, y = y)\n\n# Crea el gr√°fico\nggplot(normal_data, aes(x = x, y = y)) +\n  geom_line(color = \"steelblue\", size = 1) +\n  labs(x = \"Valor\", y = \"Probabilidad de densidad\") +\n  theme_classic() +\n  geom_vline(xintercept = 0, lty = 2)+\n  scale_x_continuous(breaks = c(seq(-3, 3, by = 1)))\n```\n\n::: {.cell-output-display}\n![Fig. 1.16. Distribuci√≥n normal.](index_files/figure-html/fig-normalDistr-1.png){#fig-normalDistr width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Carga la biblioteca ggplot2\nlibrary(ggplot2)\n\n# Crea un data frame con los resultados del lanzamiento de la moneda\nmoneda <- data.frame(side = factor(c(\"Cara\", \"Sello\"), levels = c(\"Cara\", \"Sello\")),\n                     probability = c(0.7, 0.3))\n\n# Crea el gr√°fico\nggplot(moneda, aes(x = side, y = probability)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  labs(x = \"Lado de la moneda\", y = \"Probabilidad\") +\n  theme_classic() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n```\n\n::: {.cell-output-display}\n![Fig. 1.17. Distribuci√≥n de Bernoulli](index_files/figure-html/fig-bernoulliDistr-1.png){#fig-bernoulliDistr width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nlibrary(stats)\n# Crear la distribuci√≥n de Moyal\nx <- seq(-10, 10, by = 0.1)\ny <- dnorm(x, mean = 0, sd = 1) + dnorm(x, mean = 2, sd = 0.5) + dnorm(x, mean = -5, sd = 0.5)\n\n# Crear el dataframe\ndf <- data.frame(x = x, y = y)\n\n# Generar muestras aleatorias de la distribuci√≥n de Moyal\nset.seed(123)\nn_samples <- 1000\nsample_size <- 30\nmeans <- numeric(n_samples)\nfor (i in 1:n_samples) {\n  sample <- sample(df$y, size = sample_size, replace = TRUE)\n  means[i] <- mean(sample)\n}\n\ngridExtra::grid.arrange(\n# Graficar la distribuci√≥n\nggplot(df, aes(x = x, y = y)) +\n  geom_line(colour = \"blue\") +\n  labs(x = \"Distribuci√≥n de la poblaci√≥n\", y = \"Probabilidad\") +\n  theme_classic()\n,\n# Graficar la distribuci√≥n de las medias\nggplot(data.frame(x = means), aes(x = x)) +\n  geom_density(colour = \"blue\") +\n  labs(x = \"Media aritm√©tica\", y = \"Frecuencia\") +\n  theme_classic()\n,\nncol = 2\n)\n```\n\n::: {.cell-output-display}\n![Fig. 1.18. Demostraci√≥n gr√°fica del teorema del l√≠mite central.](index_files/figure-html/fig-centralTeorema-1.png){#fig-centralTeorema width=672}\n:::\n:::\n\n\n\n#### Teorema del L√≠mite Central\n\nConsidera un conjunto de datos grande de cualquier distribuci√≥n. El teorema del l√≠mite central afirma que, independientemente de la distribuci√≥n de los n√∫meros en el conjunto de datos, la media aritm√©tica de las muestras de datos extra√≠das del conjunto de datos principal tendr√° una distribuci√≥n normal. Cuanto mayor sea el tama√±o de la muestra, m√°s cerca estar√° la media de una distribuci√≥n normal. El teorema se ha demostrado en la [Fig. 1.18](#fig-centralTeorema). Se puede ver que la poblaci√≥n no sigue una distribuci√≥n normal, pero cuando se muestrea la media, la muestra forma una distribuci√≥n normal.\n\n### C√°lculo\n\nEl c√°lculo de Newton es ampliamente √∫til para resolver una variedad de problemas. Uno de los algoritmos m√°s populares de ML es el algoritmo de **descenso de gradientes**. El algoritmo de descenso de gradientes, junto con la retropropagaci√≥n (backpropagation), es √∫til en el proceso de entrenamiento de modelos de ML, que dependen intensivamente del c√°lculo. Por lo tanto, el c√°lculo diferencial, el c√°lculo integral y las ecuaciones diferenciales son todos aspectos necesarios para familiarizarse con antes de estudiar ML.\n\n#### Derivada y Pendiente\n\nLa derivada se define como la tasa de cambio de una funci√≥n con respecto a una variable. Por ejemplo, la velocidad de un coche es la derivada de la desplazamiento del coche con respecto al tiempo. La derivada es equivalente a la pendiente de una l√≠nea en un punto espec√≠fico. La pendiente ayuda a visualizar c√≥mo empinada es una l√≠nea. Una l√≠nea con una pendiente m√°s alta es m√°s empinada que una l√≠nea con una pendiente m√°s baja. El concepto de pendiente se muestra en la [Figura 1.19](#fig-pendiente).\n\n$$\npendiente, m =\\frac{\\Delta{y}}{\\Delta{x}}\n$$ {#eq-1.14}\n\nSe utiliza ampliamente la derivada en ML, especialmente en problemas de optimizaci√≥n, como el descenso de gradientes. Por ejemplo, en el descenso de gradientes, se utilizan derivadas para encontrar el camino m√°s empinado para maximizar o minimizar una funci√≥n objetivo (por ejemplo, la precisi√≥n o funci√≥n de error de un modelo).\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\n\n# Crear los datos para el tri√°ngulo\nx_values <- c(0, 1, 1)\ny_values <- c(0, 1, 0)\n\n# Crear la gr√°fica\nggplot(data.frame(x = x_values, y = y_values), aes(x = x, y = y)) +\n  geom_polygon(fill = \"lightblue\") +\n  labs(x = \"X\", y = \"Y\") +\n  theme_classic()+\n  annotate(\"text\", x = 0.5, y = 0.1, label = \"Cambio en X\", hjust = 0) +\n  annotate(\"text\", x = 0.9, y = 0.5, label = \"Cambio en Y\", vjust = 0, angle = 90) +\n  annotate(\"text\", x = 0.4, y = 0.5, label = \"Pendiente\", hjust = 0, vjust = 1, angle = 35)\n```\n\n::: {.cell-output-display}\n![Fig. 1.19. Ilustraci√≥n concepto de pendiente.](index_files/figure-html/fig-pendiente-1.png){#fig-pendiente width=672}\n:::\n:::\n\n\n\n#### Derivadas Parciales\n\nSi una funci√≥n depende de dos o m√°s variables, entonces la derivada parcial de la funci√≥n es su derivada con respecto a una de las variables, manteniendo las otras variables constantes. Las derivadas parciales se requieren para t√©cnicas de optimizaci√≥n en ML, que utilizan derivadas parciales para ajustar los pesos para cumplir con la funci√≥n objetivo. Las funciones objetivo son diferentes para cada problema. Por lo tanto, la derivada parcial ayuda a decidir si aumentar o disminuir los pesos para hacer un ajuste a la funci√≥n objetivo.\n\n#### M√°ximos y M√≠nimos\n\nPara una funci√≥n no lineal, el pico m√°s alto o el valor m√°ximo se refiere a los m√°ximos, y el pico m√°s bajo o el valor m√≠nimo se refiere a los m√≠nimos. En otras palabras, el punto en el que la derivada de una funci√≥n es cero se define como los m√°ximos o los m√≠nimos. Estos son los puntos en los que el valor de la funci√≥n se mantiene constante, es decir, la tasa de cambio es cero. Este concepto de m√°ximos y m√≠nimos es necesario para minimizar la funci√≥n de coste (diferencia entre el valor verdadero y el valor de salida) de cualquier modelo de ML. Un m√≠nimo local es el valor de una funci√≥n que es menor que los puntos vecinos, pero no necesariamente menor que todos los puntos en el espacio de soluci√≥n. Un m√≠nimo global es el valor m√°s peque√±o de la funci√≥n que existe en ese espacio de soluci√≥n. El caso es el mismo para m√°ximos globales y locales. Un m√°ximo local es el valor de una funci√≥n que es mayor que los puntos vecinos, pero no necesariamente mayor que todos los puntos en el espacio de soluci√≥n. Un m√°ximo global es el valor m√°s grande de la funci√≥n que existe en ese espacio de soluci√≥n. La [figura 1.20](#fig-derivadas) muestra m√°ximos y m√≠nimos globales y locales en un espacio de soluci√≥n.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(Deriv)\nlibrary(rootSolve)\n\nf <- function(x){exp(x)+(2.5^x*sin(2*pi*x)-10)}\na <- 6\nb <- 8\nf_p <- Deriv::Deriv(f)\nf_pp <- Deriv::Deriv(f, n = 2)\nroot_derive <- uniroot.all(f_p, c(a,b))\nkeyPoints <- c(a, b, root_derive)\n#f(keyPoints)\nroot_derive2 <- uniroot.all(f_pp, c(a,b))\nkeyPoints2 <- c(a, b, root_derive2)\n#f_p(keyPoints2)\n\npar(mar=c(5,6,2,2))\ncurve(f, a, b, lwd = 2, ylab = expression(f(x)==e^x+(2.5)^x*sin(2*pi*x)-10))\ngrid(NULL, NULL, col = \"black\")\ngMax <- c(keyPoints[2])\ngMin <- c(keyPoints[4])\npoints(gMax, f(gMax), pch = 15, cex = 2, col = \"green\")\npoints(gMin, f(gMin), pch = 17, cex = 2.5, col = \"green\")\npoints(root_derive, f(root_derive), pch = 16, cex = 1.5, col = \"red2\")\npoints(root_derive2, f(root_derive2), pch = 16, cex = 1.5, col = \"blue2\")\n```\n\n::: {.cell-output-display}\n![Fig. 1.20. Representaci√≥n de m√°ximos y m√≠nimos.](index_files/figure-html/fig-derivadas-1.png){#fig-derivadas width=672}\n:::\n:::\n\n\n\n#### Ecuaci√≥n Diferencial\n\nUna ecuaci√≥n diferencial (ED) representa la relaci√≥n entre una o m√°s funciones y sus derivadas con respecto a una o m√°s variables. Las EDs son muy √∫tiles en el modelado de sistemas y, por lo tanto, se pueden utilizar en ML para modelado din√°mico, especialmente en redes neuronales.\n\nEl siguiente es un ejemplo de una ecuaci√≥n diferencial:\n\n$$\n\\frac{d^2y}{dx^2}+4=1.\n$$ {#eq-1.15}\n\n##### Orden y Grado\n\nEn ecuaciones diferenciales, el orden m√°s alto de la derivada utilizada en la ecuaci√≥n es el orden de la ecuaci√≥n. El grado de una ecuaci√≥n diferencial es el poder de su derivada m√°s alta. Por ejemplo, esta es una ecuaci√≥n diferencial de cuarto orden y primer grado:\n\n$$\n\\frac{d^4y}{dx^4}+(\\frac{d^2y}{dx^2})^2+4\\frac{dy}{dx}+6x=0.\n$$ {#eq-1.16}\n\naqu√≠, la derivada m√°s alta es $\\frac{d^4y}{dx^4}$. El orden de la derivada m√°s alta es 4, por lo que esta es una ecuaci√≥n diferencial de cuarto orden. El poder de la derivada m√°s alta es 1, y por lo tanto, esta es una ecuaci√≥n diferencial de primer grado. Algunos ejemplos adicionales se muestran en la Tabla 1.8\n\n+--------------------------------------------+-------------+-------------+\n| Ecuaci√≥n                                   | Orden       | Grado       |\n+:==========================================:+:===========:+:===========:+\n| $$                                         | 3           | 1           |\n|     \\frac{d^3y}{dx^3}+6x\\frac{dy}{dx}=e^y  |             |             |\n|                               $$           |             |             |\n+--------------------------------------------+-------------+-------------+\n| $$                                         | 2           | 3           |\n|     \\frac{dy}{dx}+(\\frac{d^2y}{dx^2})^3=7x |             |             |\n|                               $$           |             |             |\n+--------------------------------------------+-------------+-------------+\n| $$                                         | 2           | 1           |\n|     \\frac{d^2y}{dx^2}+(\\frac{dy}{dx})^3=7x |             |             |\n|                               $$           |             |             |\n+--------------------------------------------+-------------+-------------+\n\n: Tabla 1.8. Ecuaciones diferenciales con su grado y orden. {#tbl-ecuacionesDiff}\n\n##### Ecuaci√≥n Diferencial Ordinaria y Parcial\n\nComo se discuti√≥ anteriormente, las ecuaciones diferenciales pueden tener m√°s de una variable. Cuando una ecuaci√≥n consiste en diferenciales con respecto a una variable, se llama ecuaci√≥n diferencial ordinaria (EDO). Por otro lado, cuando la ecuaci√≥n involucra diferenciales con respecto a m√°s de una variable, se conoce como ecuaci√≥n diferencial parcial (EDP). El s√≠mbolo $d$ se utiliza para ecuaciones diferenciales ordinarias y el s√≠mbolo $\\partial$ se utiliza para ecuaciones diferenciales parciales.\n\nPor ejemplo: $\\frac{d^2y}{dx^2} + \\frac{dy}{dx} + 1 = 0$ es una EDO y $\\frac{\\partial^2y}{\\partial{x}^2} + \\frac{\\partial{y}}{\\partial{x}} + 1 = 0$ es una EDP.\n\n##### Ecuaci√≥n Lineal y No Lineal\n\nLas ecuaciones pueden tener variables dependientes e independientes. Estas variables pueden tener grados m√°s altos dependiendo del tipo de ecuaci√≥n. Cuando las ecuaciones diferenciales contienen variables dependientes con grado 1, se consideran ecuaciones diferenciales lineales. Por otro lado, si las ecuaciones diferenciales contienen variables dependientes con un grado m√°s alto, se consideran ecuaciones diferenciales no lineales.\n\nPor ejemplo, en la ecuaci√≥n $\\frac{d^2y}{dx^2} + \\frac{dy}{dx} + 1 = 0$, el grado de la derivada m√°s alta es 1. Por lo tanto, es una ecuaci√≥n lineal. De nuevo, la ecuaci√≥n $(\\frac{dy}{dx})^2 + x = 0$ tiene 2 como su grado de la derivada m√°s alta. Por lo tanto, es un ejemplo de ecuaci√≥n no lineal.\n\nHasta aqu√≠ tienes los conceptos b√°sicos que deber√≠as revisar, repasar, aprender o profundizar, para lograr aplicar ML.\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}