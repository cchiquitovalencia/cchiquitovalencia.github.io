<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Cristian Chiquito Valencia">
<meta name="dcterms.date" content="2025-02-05">
<meta name="description" content="Principios en ingenier√≠a">

<title>Introducci√≥n al Machine Learning ‚Äì Cristian Chiquito Valencia</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../logo_2.png" rel="icon" type="image/png">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "Sin resultados",
    "search-matching-documents-text": "documentos encontrados",
    "search-copy-link-title": "Copiar el enlace en la b√∫squeda",
    "search-hide-matches-text": "Ocultar resultados adicionales",
    "search-more-match-text": "resultado adicional en este documento",
    "search-more-matches-text": "resultados adicionales en este documento",
    "search-clear-button-title": "Borrar",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancelar",
    "search-submit-button-title": "Enviar",
    "search-label": "Buscar"
  }
}</script>
<script src="../../site_libs/quarto-diagram/mermaid.min.js"></script>
<script src="../../site_libs/quarto-diagram/mermaid-init.js"></script>
<link href="../../site_libs/quarto-diagram/mermaid.css" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
<meta property="og:title" content="Introducci√≥n al Machine Learning ‚Äì Cristian Chiquito Valencia">
<meta property="og:description" content="Principios en ingenier√≠a">
<meta property="og:image" content="https://cchiquitovalencia.github.io/posts/2025-02-05-intro_ml/concepts_ML.jpeg">
<meta property="og:site_name" content="Cristian Chiquito Valencia">
<meta name="twitter:title" content="Introducci√≥n al Machine Learning ‚Äì Cristian Chiquito Valencia">
<meta name="twitter:description" content="Principios en ingenier√≠a">
<meta name="twitter:image" content="https://cchiquitovalencia.github.io/posts/2025-02-05-intro_ml/concepts_ML.jpeg">
<meta name="twitter:creator" content="@cchiquitov">
<meta name="twitter:card" content="summary">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Cristian Chiquito Valencia</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Buscar"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Navegaci√≥n de palanca" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html"> 
<span class="menu-text">Acerca de mi</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../posts.html"> 
<span class="menu-text">Aqu√≠ mi Blog</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-page-left">
      <h1 class="title">Introducci√≥n al Machine Learning</h1>
                  <div>
        <div class="description">
          Principios en ingenier√≠a
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">Machine Learning</div>
                <div class="quarto-category">Artificial Intelligence</div>
                <div class="quarto-category">Data Science</div>
                <div class="quarto-category">Deep Learning</div>
              </div>
                  </div>
  </div>
    
  <div class="quarto-title-meta-author column-page-left">
    <div class="quarto-title-meta-heading">Autor</div>
    <div class="quarto-title-meta-heading">Afiliaci√≥n</div>
    
      <div class="quarto-title-meta-contents">
      <p class="author"><a href="https://cchiquitovalencia.github.io/">Cristian Chiquito Valencia</a> </p>
    </div>
    <div class="quarto-title-meta-contents">
          <p class="affiliation">
              Independent @ CHV
            </p>
        </div>
    </div>

  <div class="quarto-title-meta column-page-left">

        
      <div>
      <div class="quarto-title-meta-heading">Fecha de publicaci√≥n</div>
      <div class="quarto-title-meta-contents">
        <p class="date">February 5, 2025</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">En esta p√°gina</h2>
   
  <ul>
  <li><a href="#introducci√≥n" id="toc-introducci√≥n" class="nav-link active" data-scroll-target="#introducci√≥n">Introducci√≥n</a></li>
  <li><a href="#qu√©-es-machine-learning" id="toc-qu√©-es-machine-learning" class="nav-link" data-scroll-target="#qu√©-es-machine-learning">Qu√© es Machine Learning?</a>
  <ul>
  <li><a href="#flujo-de-trabajo-de-machine-learning" id="toc-flujo-de-trabajo-de-machine-learning" class="nav-link" data-scroll-target="#flujo-de-trabajo-de-machine-learning">Flujo de trabajo de Machine Learning</a></li>
  <li><a href="#qu√©-no-es-machine-learning" id="toc-qu√©-no-es-machine-learning" class="nav-link" data-scroll-target="#qu√©-no-es-machine-learning">Qu√© no es Machine Learning?</a></li>
  <li><a href="#jerga-de-machine-learning" id="toc-jerga-de-machine-learning" class="nav-link" data-scroll-target="#jerga-de-machine-learning">Jerga de Machine Learning</a>
  <ul class="collapse">
  <li><a href="#caracter√≠sticas" id="toc-caracter√≠sticas" class="nav-link" data-scroll-target="#caracter√≠sticas">Caracter√≠sticas</a></li>
  <li><a href="#variable-objetivo" id="toc-variable-objetivo" class="nav-link" data-scroll-target="#variable-objetivo">Variable objetivo</a></li>
  <li><a href="#problema-de-optimizaci√≥n" id="toc-problema-de-optimizaci√≥n" class="nav-link" data-scroll-target="#problema-de-optimizaci√≥n">Problema de optimizaci√≥n</a></li>
  <li><a href="#funci√≥n-objetivo" id="toc-funci√≥n-objetivo" class="nav-link" data-scroll-target="#funci√≥n-objetivo">Funci√≥n objetivo</a></li>
  <li><a href="#funci√≥n-de-costo" id="toc-funci√≥n-de-costo" class="nav-link" data-scroll-target="#funci√≥n-de-costo">Funci√≥n de costo</a></li>
  <li><a href="#funci√≥n-de-p√©rdida" id="toc-funci√≥n-de-p√©rdida" class="nav-link" data-scroll-target="#funci√≥n-de-p√©rdida">Funci√≥n de p√©rdida</a></li>
  <li><a href="#comparaci√≥n-entre-la-funci√≥n-de-p√©rdida-la-funci√≥n-de-costo-y-la-funci√≥n-objetivo" id="toc-comparaci√≥n-entre-la-funci√≥n-de-p√©rdida-la-funci√≥n-de-costo-y-la-funci√≥n-objetivo" class="nav-link" data-scroll-target="#comparaci√≥n-entre-la-funci√≥n-de-p√©rdida-la-funci√≥n-de-costo-y-la-funci√≥n-objetivo">Comparaci√≥n entre la funci√≥n de p√©rdida, la funci√≥n de costo y la funci√≥n objetivo</a></li>
  <li><a href="#algoritmo-modelohip√≥tesis-y-t√©cnica" id="toc-algoritmo-modelohip√≥tesis-y-t√©cnica" class="nav-link" data-scroll-target="#algoritmo-modelohip√≥tesis-y-t√©cnica">Algoritmo, modelo/hip√≥tesis y t√©cnica</a></li>
  </ul></li>
  <li><a href="#diferencia-entre-la-ciencia-de-datos-el-aprendizaje-autom√°tico-la-inteligencia-artificial-y-el-aprendizaje-profundo" id="toc-diferencia-entre-la-ciencia-de-datos-el-aprendizaje-autom√°tico-la-inteligencia-artificial-y-el-aprendizaje-profundo" class="nav-link" data-scroll-target="#diferencia-entre-la-ciencia-de-datos-el-aprendizaje-autom√°tico-la-inteligencia-artificial-y-el-aprendizaje-profundo">Diferencia entre la ciencia de datos, el aprendizaje autom√°tico, la inteligencia artificial y el aprendizaje profundo</a></li>
  </ul></li>
  <li><a href="#desarrollo-hist√≥rico-de-machine-learning" id="toc-desarrollo-hist√≥rico-de-machine-learning" class="nav-link" data-scroll-target="#desarrollo-hist√≥rico-de-machine-learning">Desarrollo hist√≥rico de Machine Learning</a></li>
  <li><a href="#por-qu√©-machine-learning" id="toc-por-qu√©-machine-learning" class="nav-link" data-scroll-target="#por-qu√©-machine-learning">Por qu√© Machine Learning?</a>
  <ul>
  <li><a href="#motivaci√≥n" id="toc-motivaci√≥n" class="nav-link" data-scroll-target="#motivaci√≥n">Motivaci√≥n</a></li>
  <li><a href="#prop√≥sito" id="toc-prop√≥sito" class="nav-link" data-scroll-target="#prop√≥sito">Prop√≥sito</a></li>
  <li><a href="#importancia" id="toc-importancia" class="nav-link" data-scroll-target="#importancia">Importancia</a></li>
  </ul></li>
  <li><a href="#conocimientos-previos-para-aprender-machine-learning" id="toc-conocimientos-previos-para-aprender-machine-learning" class="nav-link" data-scroll-target="#conocimientos-previos-para-aprender-machine-learning">Conocimientos previos para aprender Machine Learning</a>
  <ul>
  <li><a href="#√°lgebra-lineal" id="toc-√°lgebra-lineal" class="nav-link" data-scroll-target="#√°lgebra-lineal">√Ålgebra Lineal</a>
  <ul class="collapse">
  <li><a href="#ecuaciones-lineales" id="toc-ecuaciones-lineales" class="nav-link" data-scroll-target="#ecuaciones-lineales">Ecuaciones Lineales</a></li>
  <li><a href="#tensor-y-rango-de-tensor" id="toc-tensor-y-rango-de-tensor" class="nav-link" data-scroll-target="#tensor-y-rango-de-tensor">Tensor y Rango de Tensor</a></li>
  </ul></li>
  <li><a href="#estad√≠stica" id="toc-estad√≠stica" class="nav-link" data-scroll-target="#estad√≠stica">Estad√≠stica</a>
  <ul class="collapse">
  <li><a href="#medidas-de-tendencia-central" id="toc-medidas-de-tendencia-central" class="nav-link" data-scroll-target="#medidas-de-tendencia-central">Medidas de Tendencia Central</a></li>
  <li><a href="#desviaci√≥n-est√°ndar" id="toc-desviaci√≥n-est√°ndar" class="nav-link" data-scroll-target="#desviaci√≥n-est√°ndar">Desviaci√≥n Est√°ndar</a></li>
  <li><a href="#correlaci√≥n" id="toc-correlaci√≥n" class="nav-link" data-scroll-target="#correlaci√≥n">Correlaci√≥n</a></li>
  <li><a href="#anomal√≠as" id="toc-anomal√≠as" class="nav-link" data-scroll-target="#anomal√≠as">Anomal√≠as</a></li>
  <li><a href="#histograma" id="toc-histograma" class="nav-link" data-scroll-target="#histograma">Histograma</a></li>
  <li><a href="#errores" id="toc-errores" class="nav-link" data-scroll-target="#errores">Errores</a></li>
  </ul></li>
  <li><a href="#teor√≠a-de-la-probabilidad" id="toc-teor√≠a-de-la-probabilidad" class="nav-link" data-scroll-target="#teor√≠a-de-la-probabilidad">Teor√≠a de la Probabilidad</a>
  <ul class="collapse">
  <li><a href="#distribuci√≥n-de-probabilidad" id="toc-distribuci√≥n-de-probabilidad" class="nav-link" data-scroll-target="#distribuci√≥n-de-probabilidad">Distribuci√≥n de Probabilidad</a></li>
  <li><a href="#distribuci√≥n-gaussiana-o-distribuci√≥n-normal" id="toc-distribuci√≥n-gaussiana-o-distribuci√≥n-normal" class="nav-link" data-scroll-target="#distribuci√≥n-gaussiana-o-distribuci√≥n-normal">Distribuci√≥n Gaussiana o Distribuci√≥n Normal</a></li>
  <li><a href="#distribuci√≥n-de-bernoulli" id="toc-distribuci√≥n-de-bernoulli" class="nav-link" data-scroll-target="#distribuci√≥n-de-bernoulli">Distribuci√≥n de Bernoulli</a></li>
  <li><a href="#teorema-del-l√≠mite-central" id="toc-teorema-del-l√≠mite-central" class="nav-link" data-scroll-target="#teorema-del-l√≠mite-central">Teorema del L√≠mite Central</a></li>
  </ul></li>
  <li><a href="#c√°lculo" id="toc-c√°lculo" class="nav-link" data-scroll-target="#c√°lculo">C√°lculo</a>
  <ul class="collapse">
  <li><a href="#derivada-y-pendiente" id="toc-derivada-y-pendiente" class="nav-link" data-scroll-target="#derivada-y-pendiente">Derivada y Pendiente</a></li>
  <li><a href="#derivadas-parciales" id="toc-derivadas-parciales" class="nav-link" data-scroll-target="#derivadas-parciales">Derivadas Parciales</a></li>
  <li><a href="#m√°ximos-y-m√≠nimos" id="toc-m√°ximos-y-m√≠nimos" class="nav-link" data-scroll-target="#m√°ximos-y-m√≠nimos">M√°ximos y M√≠nimos</a></li>
  <li><a href="#ecuaci√≥n-diferencial" id="toc-ecuaci√≥n-diferencial" class="nav-link" data-scroll-target="#ecuaci√≥n-diferencial">Ecuaci√≥n Diferencial</a></li>
  </ul></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block column-page-left" id="quarto-document-content">





<section id="introducci√≥n" class="level2">
<h2 class="anchored" data-anchor-id="introducci√≥n">Introducci√≥n</h2>
<p>El aprendizaje autom√°tico puede parecer intimidante para aquellos que son nuevos en este campo. Este post tiene como objetivo familiarizar a los lectores con los fundamentos del aprendizaje autom√°tico y hacer que se d√© cuenta de lo maravilloso que es este tema. Ey, date cuenta! Vamos a explorar los conceptos preliminares del aprendizaje autom√°tico y establecer los fundamentos para aprender conceptos avanzados. Primero, los conceptos b√°sicos del aprendizaje autom√°tico y algunas perspectivas sobre la inteligencia artificial y el aprendizaje profundo (deep learning). Luego, la evoluci√≥n gradual del aprendizaje autom√°tico a lo largo de la historia, en orden cronol√≥gico desde 1940 hasta la actualidad. Despu√©s, veremos la motivaci√≥n, el prop√≥sito y la importancia del aprendizaje autom√°tico en funci√≥n de algunas aplicaciones pr√°cticas en la vida real. A continuaci√≥n, se introduce el conocimiento previo necesario para dominar el aprendizaje autom√°tico, para asegurarse de que los lectores sean conscientes qu√© necesitan saber antes de comenzar su curso sobre aprendizaje autom√°tico. Finalmente discutimos los lenguajes de programaci√≥n y herramientas asociadas necesarias para utilizar el aprendizaje autom√°tico. Todo es lo hacemos utilizando <code>R</code> como lenguaje de programaci√≥n, <code>RStudio</code> como editor de c√≥digo o compilador, y esta escrito en documento de <code>Quarto</code> (.qmd). Antes de la conclusi√≥n, revisamos algunos ejemplos reales de aprendizaje autom√°tico que todos los lectores de ingenier√≠a podr√°n relacionar, lo que despertar√° su curiosidad para entrar en el mundo del aprendizaje autom√°tico.</p>
</section>
<section id="qu√©-es-machine-learning" class="level2">
<h2 class="anchored" data-anchor-id="qu√©-es-machine-learning">Qu√© es Machine Learning?</h2>
<p>La tecnolog√≠a moderna est√° mejorando y aceler√°ndose gracias a la investigaci√≥n, experimentaci√≥n y desarrollo extensivos y continuos. Por ejemplo, las m√°quinas est√°n volvi√©ndose inteligentes y realizan tareas de manera mucho m√°s eficiente. El aprendizaje autom√°tico ha estado evolucionando a un ritmo sin precedentes, y los resultados son evidentes en nuestros tel√©fonos y computadoras, que se est√°n convirtiendo en m√°s multifuncionales cada d√≠a, los sistemas de automatizaci√≥n est√°n volvi√©ndose omnipresentes, se est√°n construyendo robots inteligentes y as√≠ sucesivamente.</p>
<p>En 1959, el cient√≠fico de la computadora y pionero del aprendizaje autom√°tico Arthur Samuel defini√≥ el aprendizaje autom√°tico como el ‚Äú<em>campo de estudio que le da a los ordenadores la capacidad de aprender sin ser programados expl√≠citamente</em>‚Äù. El libro de Tom Mitchell de 1997 sobre aprendizaje autom√°tico defini√≥ el aprendizaje autom√°tico como ‚Äú<em>el estudio de los algoritmos de computadora que permiten a los programas de computadora mejorar autom√°ticamente a trav√©s de la experiencia</em>‚Äù. Define el aprendizaje de la siguiente manera: ‚Äú<em>Un programa de computadora se dice que aprende de la experiencia E con respecto a alguna clase de tareas T y medida de rendimiento P, si su rendimiento en tareas en T, medido por P, mejora con la experiencia E</em>‚Äù. El aprendizaje autom√°tico (<strong>ML</strong>) es una rama del aprendizaje artificial (<strong>AI</strong>) que permite a los ordenadores y m√°quinas aprender de la informaci√≥n existente y aplicar ese aprendizaje para realizar otras tareas similares. Sin <code>programaci√≥n expl√≠cita</code>, la m√°quina aprende a partir de los datos que se le proporcionan. La m√°quina identifica o aprende patrones, tendencias o caracter√≠sticas esenciales a partir de datos previos y hace una predicci√≥n sobre nuevos datos. Un ejemplo de aplicaci√≥n real del aprendizaje autom√°tico es los <strong>sistemas de recomendaci√≥n</strong>. Por ejemplo, un sitio de streaming de pel√≠culas recomendar√° pel√≠culas al usuario basadas en su lista de pel√≠culas vistas previamente.</p>
<p>Los algoritmos de ML se clasifican ampliamente como <strong>aprendizaje supervisado</strong> y <strong>aprendizaje no supervisado</strong>, con otros tipos como el <strong>aprendizaje por refuerzo</strong> y <strong>aprendizaje semisupervisado</strong>. Lo m√°s seguro es que tendr√°s otros posts sobre estos temas.</p>
<section id="flujo-de-trabajo-de-machine-learning" class="level3">
<h3 class="anchored" data-anchor-id="flujo-de-trabajo-de-machine-learning">Flujo de trabajo de Machine Learning</h3>
<p>Antes de profundizar en los detalles, un principiante debe tener una visi√≥n hol√≠stica del flujo de trabajo completo del aprendizaje autom√°tico. La visi√≥n general del proceso revela que hay cuatro pasos principales en un flujo de trabajo t√≠pico de ML: <strong>recopilaci√≥n de conjuntos de datos, preprocesamiento de datos, entrenamiento del modelo</strong> y, finalmente, <strong>evaluaci√≥n del modelo</strong>. La <a href="#fig-diagram">figura 1</a> muestra el diagrama de bloques de los cuatro pasos del flujo de trabajo de ML. Estos pasos se siguen generalmente en todas las aplicaciones de ML:</p>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div id="fig-diagram" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-diagram-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div>
<pre class="mermaid mermaid-js" data-label="fig-diagram">flowchart LR
    A(Paso 1: Recopilaci√≥n de conjunto de datos) --&gt; B(Paso 2: Preprocesamiento de conjunto de datos)
    B(Paso 2: Preprocesamiento de conjunto de datos) --&gt; C(Paso 3: Entrenamiento del modelo)
    C(Paso 3: Entrenamiento del modelo) --&gt; D(Paso 4: Evaluaci√≥n del modelo)
    D(Paso 4: Evaluaci√≥n del modelo) --&gt; B(Paso 2: Preprocesamiento de conjunto de datos)
    D(Paso 4: Evaluaci√≥n del modelo) --&gt; C(Paso 3: Entrenamiento del modelo)
    D(Paso 4: Evaluaci√≥n del modelo) --&gt; A(Paso 1: Recopilaci√≥n de conjunto de datos)
</pre>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-diagram-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;1: El diagrama de bloques del flujo de trabajo de aprendizaje autom√°tico
</figcaption>
</figure>
</div>
</div>
</div>
<ol type="1">
<li><p>Recopilaci√≥n de conjuntos de datos: El primer paso del ML es recopilar el conjunto de datos. Este paso depende del tipo de experimentos o proyectos que se desean realizar. Diferentes experimentos o proyectos requieren diferentes datos. Tambi√©n se debe decidir qu√© tipo de datos se requieren. ¬øSer√°n datos num√©ricos o categ√≥ricos? Por ejemplo, si queremos realizar una predicci√≥n sobre los precios de las casas, necesitar√≠amos la siguiente informaci√≥n: el precio de las casas, la direcci√≥n de las casas, el n√∫mero de habitaciones, el estado de la casa, el tama√±o de la casa, etc. Luego surge la pregunta: ¬øqu√© unidad de precio deber√≠a ser? ¬øD√≥lares, libras o alguna otra moneda?</p></li>
<li><p>Preprocesamiento de datos: Los datos que recopilamos a menudo est√°n desorganizados y no pueden ser utilizados directamente para entrenar modelos. Antes de proceder al siguiente paso, los datos necesitan ser preprocesados. Primero, el conjunto de datos puede contener datos faltantes o ruidosos. Este problema necesita ser resuelto antes de pasar los datos al modelo. Diferentes datos pueden estar en diferentes rangos, lo que podr√≠a ser un problema para los modelos, por lo que los datos necesitan ser estandarizados para que todos los datos est√©n en el mismo rango. Adem√°s, no todos los datos ser√≠an igualmente importantes para predecir la variable objetivo. Necesitamos encontrar y seleccionar los datos que contribuyen m√°s a encontrar las variables objetivo. Finalmente, el conjunto de datos debe ser dividido en dos conjuntos: el conjunto de entrenamiento y el conjunto de prueba. La divisi√≥n se hace generalmente en una relaci√≥n de 80:20, donde el 80% del conjunto de datos es el conjunto de entrenamiento y el 20% es el conjunto de prueba. Esta relaci√≥n puede variar seg√∫n el tama√±o del conjunto de datos y la naturaleza del problema. Aqu√≠, el conjunto de entrenamiento se utilizar√° para entrenar los modelos, y el conjunto de prueba se utilizar√° para evaluar los modelos. A menudo, el conjunto de datos se divide en conjuntos de entrenamiento, validaci√≥n y prueba. El conjunto de validaci√≥n se utiliza para ajustar los hiperpar√°metros, lo que se discutir√° en el Cap√≠tulo 2 de este libro. La <a href="#fig-diagram2">figura 2</a> muestra los diferentes pasos de preprocesamiento de datos. Estos pasos se explicar√°n en el Cap√≠tulo 3.</p></li>
<li><p>Entrenamiento del modelo: Basado en el problema, se debe seleccionar el tipo de modelo requerido primero. Mientras se selecciona el modelo, se debe considerar la informaci√≥n disponible sobre el conjunto de datos. Por ejemplo, la clasificaci√≥n supervisada se puede abordar si el conjunto de datos contiene informaci√≥n sobre ambos valores de entrada y salida. A veces, se necesitan utilizar m√°s de un modelo para entrenar y hacer el trabajo. El modelo ajusta o aprende los datos. Este paso es muy importante porque el rendimiento del modelo depende mucho de c√≥mo bien los datos han sido ajustados o aprendidos por el modelo. Mientras se entrena el modelo, se debe tener cuidado de no subajustar o sobreadjustar el modelo. Subajustar y sobreadjustar se han explicado en el Cap√≠tulo 2.</p></li>
<li><p>Evaluaci√≥n del modelo: Una vez que el modelo se ha construido y entrenado, es esencial entender c√≥mo bien se ha entrenado el modelo, c√≥mo bien funcionar√° y si el modelo ser√° √∫til para el experimento. Ser√≠a in√∫til si el modelo no funciona bien o no cumple con su prop√≥sito. Por lo tanto, se utiliza el conjunto de prueba para probar el modelo, y se utilizan diferentes m√©tricas de evaluaci√≥n para evaluar y comprender el modelo. Las m√©tricas de evaluaci√≥n incluyen precisi√≥n, recall y algunas otras, que se utilizan para obtener una visi√≥n general de c√≥mo bien funcionar√° el modelo. Las m√©tricas de evaluaci√≥n se han discutido en el Cap√≠tulo 2. Basado en la evaluaci√≥n del modelo, puede ser necesario regresar a los pasos anteriores y realizarlos de nuevo seg√∫n sea necesario.</p></li>
</ol>
<div class="cell" data-fig-height="18" data-layout-align="default">
<div class="cell-output-display">
<div id="fig-diagram2" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-diagram2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div>
<pre class="mermaid mermaid-js" data-label="fig-diagram2">flowchart LR
    A["`**Prepocesamiento de Datos**`"] --&gt; B("`**Integraci√≥n de Datos**
    - Integraci√≥n de esquemas
    - Problema de identificaci√≥n de entidad
    - Detecci√≥n y resoluci√≥n de conceptos de valores de datos`")
    A["`**Prepocesamiento de Datos**`"] --&gt; C("`**Reducci√≥n de Datos o Dimensi√≥n**
    - Agregaci√≥n de cubo de Datos
    - Selecci√≥n de subconjunto de Atributos
    - Reducci√≥n de numerosidad
    - Reducci√≥n de dimensionalidad`")
    A["`**Prepocesamiento de Datos**`"] --&gt; D("`**Transformaci√≥n de Datos**
    - Normalizaci√≥n
    - Selecci√≥n de Atributos
    - Discretizaci√≥n
    - Generaci√≥n de Jerarqu√≠a de Conceptos`")
    A["`**Prepocesamiento de Datos**`"] --&gt; E("`**Limpieza de Datos**
    - Datos faltantes
    - Datos ruidosos`")
</pre>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-diagram2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;2: El diagrama de bloques de preprocesamiento de datos
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="qu√©-no-es-machine-learning" class="level3">
<h3 class="anchored" data-anchor-id="qu√©-no-es-machine-learning">Qu√© no es Machine Learning?</h3>
<p>El aprendizaje autom√°tico es un t√©rmino en boga en el mundo actual. Casi todos los campos de la ciencia y la tecnolog√≠a involucran uno o m√°s aspectos del ML. Sin embargo, es necesario distinguir entre lo que es ML y lo que no lo es. Por ejemplo, el <code>programar en sentido general no es ML</code>, ya que un programa expl√≠citamente indica o instruye a una m√°quina qu√© hacer y cu√°ndo hacerlo sin permitir que la m√°quina aprenda por s√≠ misma y aplique el aprendizaje en un entorno similar pero nuevo. Un sistema de recomendaci√≥n que est√° dise√±ado expl√≠citamente para dar recomendaciones no es una aplicaci√≥n de ML. Si el sistema est√° dise√±ado de manera que se le d√© un conjunto espec√≠fico de pel√≠culas como condiciones y se le sugiera una pel√≠cula expl√≠citamente, como:</p>
<blockquote class="blockquote">
<p>Si la persona ha visto Harry Potter o Pirates of the Caribbean o El Se√±or de los Anillos, entonces recomiende Animales Fant√°sticos a la persona. Tambi√©n si la persona ha visto Divergente o Maze Runner, recomiende Juegos del Hambre.</p>
</blockquote>
<p>Este sistema de recomendaci√≥n no es una aplicaci√≥n de ML. Aqu√≠, <em>la m√°quina no explora ni aprende tendencias</em>, caracter√≠sticas o caracter√≠sticas de pel√≠culas previamente vistas. En su lugar, simplemente se basa en las condiciones dadas y sugiere la pel√≠cula dada. Para un sistema de recomendaci√≥n basado en ML, el programa no indica expl√≠citamente al sistema qu√© pel√≠cula recomendar basada en la lista de pel√≠culas vistas previamente. En su lugar, se programa de manera que el sistema explore la lista de pel√≠culas vistas previamente. Busca caracter√≠sticas significativas o caracter√≠sticas como g√©neros, actores, directores, productores, etc. Tambi√©n verifica qu√© pel√≠culas han sido vistas por otros usuarios para que el sistema pueda formar un tipo de grupo. Basado en este aprendizaje y observaci√≥n, el sistema concluye y da una recomendaci√≥n. Por ejemplo, la lista de pel√≠culas de una persona es como sigue: <a href="https://www.imdb.com/title/tt3263904/?ref_=nv_sr_srsg_0_tt_1_nm_7_in_0_q_sully">Sully</a>, <a href="https://www.imdb.com/title/tt0264464/?ref_=nv_sr_srsg_0_tt_8_nm_0_in_0_q_catch%2520me%2520if%2520">Catch Me If You Can</a>, <a href="https://www.imdb.com/title/tt1535109/?ref_=nv_sr_srsg_0_tt_5_nm_3_in_0_q_captain%2520ph">Captain Philips</a>, <a href="https://www.imdb.com/title/tt1375666/?ref_=nv_sr_srsg_0_tt_8_nm_0_in_0_q_inceptio">Inception</a> y <a href="https://www.imdb.com/title/tt0816692/?ref_=nv_sr_srsg_0_tt_7_nm_1_in_0_q_inters">Interstellar</a>. Se pueden extraer las siguientes conclusiones de esta lista:</p>
<p>‚Ä¢ Tres de las pel√≠culas son de g√©nero biogr√°fico; las otras dos son de ciencia ficci√≥n.</p>
<p>‚Ä¢ Tres de las pel√≠culas tienen a Tom Hanks en ellas.</p>
<p>‚Ä¢ Las pel√≠culas de ciencia ficci√≥n en la lista est√°n dirigidas por Christopher Nolan.</p>
<p>Basado en este patr√≥n, el sistema puede recomendar pel√≠culas biogr√°ficas que no incluyan a Tom Hanks. El sistema tambi√©n recomendar√° m√°s pel√≠culas de Tom Hanks que pueden ser biogr√°ficas o de otros g√©neros. Tambi√©n puede recomendar pel√≠culas de ciencia ficci√≥n que hayan estrellado a Tom Hanks. El sistema tambi√©n recomendar√° m√°s pel√≠culas dirigidas por Christopher Nolan. Como este sistema decide por aprender los patrones de la lista de pel√≠culas vistas, se considerar√° una aplicaci√≥n de ML.</p>
</section>
<section id="jerga-de-machine-learning" class="level3">
<h3 class="anchored" data-anchor-id="jerga-de-machine-learning">Jerga de Machine Learning</h3>
<p>Mientras vamos a trav√©s estos posts, vamos a encontrar muchos t√©rminos relacionados con el aprendizaje autom√°tico. Por lo tanto, es esencial que entendamos este jargon. Los t√©rminos que necesitamos entender se discuten en esta secci√≥n.</p>
<section id="caracter√≠sticas" class="level4">
<h4 class="anchored" data-anchor-id="caracter√≠sticas">Caracter√≠sticas</h4>
<p>Las caracter√≠sticas, tambi√©n conocidas como <strong>atributos</strong>, <strong>variables predictivas</strong> o <strong>variables independientes</strong>, son simplemente las caracter√≠sticas o etiquetas del conjunto de datos. Supongamos que tenemos informaci√≥n sobre la altura y el peso de sesenta estudiantes en una clase. La altura y el peso son conocidos como caracter√≠sticas dentro del conjunto de datos. Estas caracter√≠sticas se extraen del conjunto de datos bruto y se alimentan a los modelos como entradas.</p>
</section>
<section id="variable-objetivo" class="level4">
<h4 class="anchored" data-anchor-id="variable-objetivo">Variable objetivo</h4>
<p>Simplemente, las variables objetivo son los <strong>outputs</strong> que los modelos deben dar. Por ejemplo, una rese√±a de pel√≠cula debe clasificarse como positiva o negativa. Aqu√≠, la variable positiva/negativa es la variable objetivo en este caso. Primero, esta variable objetivo debe ser determinada por el usuario. Luego, despu√©s de que se determine la variable objetivo, se debe entender la relaci√≥n entre las caracter√≠sticas y la variable objetivo para realizar operaciones adicionales.</p>
</section>
<section id="problema-de-optimizaci√≥n" class="level4">
<h4 class="anchored" data-anchor-id="problema-de-optimizaci√≥n">Problema de optimizaci√≥n</h4>
<p>Los problemas de optimizaci√≥n se definen como una clase de problemas que <strong>buscan la</strong> <strong>soluci√≥n √≥ptima</strong> bajo un conjunto de condiciones dadas. Estos problemas suelen involucrar un <em>trade-off</em> entre diferentes condiciones. Por ejemplo, un bater√≠a debe ser comprada para respaldo de energ√≠a en una residencia, pero estamos indecisos sobre el tama√±o adecuado de la bater√≠a, que viene en <span class="math inline">\(6.4\)</span> y <span class="math inline">\(13.5\)</span> kWh. Si compramos el tama√±o m√°s grande, podemos almacenar m√°s energ√≠a y disfrutar de una variedad de caracter√≠sticas adicionales de la bater√≠a, pero tambi√©n debemos pagar m√°s. Si compramos el tama√±o m√°s peque√±o, podemos almacenar menos energ√≠a y obtener poco o nada de caracter√≠sticas adicionales, pero ahorraremos m√°s dinero. Necesitamos optimizar nuestras necesidades en este escenario. Si solo requerimos respaldo de energ√≠a sin requisitos especiales para las caracter√≠sticas adicionales, el tama√±o m√°s peque√±o ser√° suficiente para satisfacer la necesidad. Esto ser√≠a la soluci√≥n √≥ptima para el dilema de la bater√≠a.</p>
</section>
<section id="funci√≥n-objetivo" class="level4">
<h4 class="anchored" data-anchor-id="funci√≥n-objetivo">Funci√≥n objetivo</h4>
<p>Generalmente, m√°s de una soluci√≥n existe para un problema. Entre todas las soluciones, se requiere encontrar la soluci√≥n √≥ptima, lo que se hace usualmente midiendo una cantidad y requiriendo que se ajuste a un est√°ndar. La funci√≥n objetivo es el est√°ndar que la soluci√≥n √≥ptima debe cumplir. La funci√≥n objetivo se dise√±a para tomar par√°metros y evaluar el rendimiento de la soluci√≥n. El objetivo de la funci√≥n objetivo puede variar seg√∫n el problema en consideraci√≥n. <strong>Maximizar</strong> o <strong>minimizar</strong> un par√°metro particular puede ser necesario para calificar la soluci√≥n como √≥ptima. Por ejemplo, muchos algoritmos de aprendizaje autom√°tico utilizan una medida de distancia (<em>Euclideana</em>, <em>Manhattan</em> o <em>Minkowski</em>) como funci√≥n objetivo.</p>
</section>
<section id="funci√≥n-de-costo" class="level4">
<h4 class="anchored" data-anchor-id="funci√≥n-de-costo">Funci√≥n de costo</h4>
<p>La funci√≥n de costo se utiliza para entender c√≥mo bien se desempe√±a el modelo en un conjunto de datos dado. La funci√≥n de costo tambi√©n calcula la diferencia entre los valores de salida predichos y los valores de salida reales. Por lo tanto, la funci√≥n de costo y la funci√≥n de p√©rdida pueden parecer similares. Sin embargo, la funci√≥n de p√©rdida se calcula para un solo punto de datos despu√©s de un solo entrenamiento, y la funci√≥n de costo se calcula para un conjunto de datos dado despu√©s de que se complete el entrenamiento del modelo. Por lo tanto, se puede inferir que la funci√≥n de costo es la <strong>funci√≥n de p√©rdida promedio</strong> para el conjunto de datos completo <em>despu√©s</em> del entrenamiento del modelo. Los t√©rminos funci√≥n de p√©rdida y funci√≥n de costo se utilizan a menudo de manera intercambiable en el aprendizaje autom√°tico. Al igual que las funciones de p√©rdida, se utilizan diferentes tipos de funciones de costo en diferentes contextos y algoritmos de aprendizaje autom√°tico.</p>
<p>Supongamos que <span class="math inline">\(J\)</span> es una funci√≥n de costo utilizada para evaluar el rendimiento de un modelo. Generalmente se define con la funci√≥n de p√©rdida <span class="math inline">\(L\)</span>. La forma generalizada de la funci√≥n de costo <span class="math inline">\(J\)</span> se da a continuaci√≥n:</p>
<p><span id="eq-eq1"><span class="math display">\[
J(ùõ≥)=‚àë^m_{i=1}L(h_{ùõ≥}(x^i),y^i)
\tag{1}\]</span></span></p>
<p>Donde <span class="math inline">\(Œ∏\)</span> es un par√°metro que se est√° optimizando, <span class="math inline">\(m\)</span> es el n√∫mero de muestras de entrenamiento, <span class="math inline">\(i\)</span> es el n√∫mero de ejemplos y salidas, <span class="math inline">\(h\)</span> es la funci√≥n de hip√≥tesis del modelo, <span class="math inline">\(x\)</span> es el valor predicho estimado, <span class="math inline">\(y\)</span> es el valor verdadero (ground truth value).</p>
</section>
<section id="funci√≥n-de-p√©rdida" class="level4">
<h4 class="anchored" data-anchor-id="funci√≥n-de-p√©rdida">Funci√≥n de p√©rdida</h4>
<p>Supongamos que se da una funci√≥n <span class="math inline">\(L : (z, y) ‚àà ‚Ñù √ó Y ‚Üí L(z, y) ‚àà ‚Ñù\)</span>. La funci√≥n <span class="math inline">\(L\)</span> toma <span class="math inline">\(z\)</span> como entradas, donde <span class="math inline">\(z\)</span> es el valor predicho proporcionado por un modelo de aprendizaje autom√°tico. La funci√≥n luego compara <span class="math inline">\(z\)</span> con respecto a su valor real correspondiente <span class="math inline">\(y\)</span> y produce un valor que indica la diferencia entre el valor predicho y el valor real. Esta funci√≥n se conoce como una funci√≥n de p√©rdida.</p>
<p>La funci√≥n de p√©rdida es significativa porque expl√≠citamente explica c√≥mo los modelos se desempe√±an al modelar los datos que se les est√°n proporcionando. La funci√≥n de p√©rdida <strong>calcula el error</strong>, que es la diferencia entre el valor de salida predicho y el valor de salida real. Por lo tanto, es intuitivo que un valor m√°s bajo de la funci√≥n de p√©rdida indica un valor de error m√°s bajo, lo que implica que el modelo ha aprendido o ajustado los datos bien. Mientras se aprenden los datos, el objetivo del entrenamiento del modelo es siempre reducir el valor de la funci√≥n de p√©rdida.</p>
<p>Despu√©s de cada iteraci√≥n de entrenamiento, el modelo sigue haciendo cambios necesarios basados en el valor de la funci√≥n de p√©rdida actual para minimizarla. Se utilizan diferentes tipos de funciones de p√©rdida para diferentes algoritmos de aprendizaje autom√°tico.</p>
</section>
<section id="comparaci√≥n-entre-la-funci√≥n-de-p√©rdida-la-funci√≥n-de-costo-y-la-funci√≥n-objetivo" class="level4">
<h4 class="anchored" data-anchor-id="comparaci√≥n-entre-la-funci√≥n-de-p√©rdida-la-funci√≥n-de-costo-y-la-funci√≥n-objetivo">Comparaci√≥n entre la funci√≥n de p√©rdida, la funci√≥n de costo y la funci√≥n objetivo</h4>
<p>Ambas, la funci√≥n de p√©rdida y la funci√≥n de costo, representan el valor de error, es decir, la diferencia entre el valor de salida y el valor real, para determinar c√≥mo de bien un modelo de aprendizaje autom√°tico se desempe√±a al ajustarse a los datos. Sin embargo, la diferencia entre las funciones de p√©rdida y costo es que <strong>la funci√≥n de p√©rdida mide el error para un solo punto de datos solo, mientras que la funci√≥n de costo mide el error para todo el conjunto de datos</strong>. La funci√≥n de costo suele ser la suma de la funci√≥n de p√©rdida y alg√∫n tipo de penalizaci√≥n.</p>
<p>Por otro lado, la funci√≥n objetivo es una funci√≥n que necesita ser optimizada, es decir, maximizada o minimizada, para obtener el objetivo deseado. <strong>La funci√≥n de p√©rdida es parte de la funci√≥n de costo; al mismo tiempo, la funci√≥n de costo se puede utilizar como parte de la funci√≥n objetivo</strong>.</p>
<p>En resumen, la funci√≥n de p√©rdida mide el error para un solo punto de datos, la funci√≥n de costo mide el error para todo el conjunto de datos y la funci√≥n objetivo es una funci√≥n que necesita ser optimizada para obtener el objetivo deseado.</p>
</section>
<section id="algoritmo-modelohip√≥tesis-y-t√©cnica" class="level4">
<h4 class="anchored" data-anchor-id="algoritmo-modelohip√≥tesis-y-t√©cnica">Algoritmo, modelo/hip√≥tesis y t√©cnica</h4>
<p>Como principiante, es esencial poder diferenciar entre modelos y algoritmos de aprendizaje autom√°tico. Un algoritmo en ML es la instrucci√≥n paso a paso proporcionada en forma de c√≥digo y ejecutada en un conjunto de datos espec√≠fico. Este algoritmo es an√°logo a un c√≥digo de programaci√≥n general. Por ejemplo, encontrar el promedio aritm√©tico de un conjunto de n√∫meros. De manera similar, en ML, un algoritmo se puede aplicar para aprender las estad√≠sticas de un conjunto de datos o aplicar estad√≠sticas actuales para predecir cualquier dato futuro.</p>
<p>Por otro lado, un modelo de ML puede ser representado como un conjunto de par√°metros que se aprenden a partir de datos dados. Por ejemplo, supongamos una funci√≥n <span class="math inline">\(f (x) = xŒ∏\)</span>, donde <span class="math inline">\(Œ∏\)</span> es el par√°metro de la funci√≥n dada y <span class="math inline">\(x\)</span> es la entrada. As√≠, para una entrada <span class="math inline">\(x\)</span> dado, el output depende del par√°metro de la funci√≥n <span class="math inline">\(Œ∏\)</span>. De manera similar, en ML, la entrada <span class="math inline">\(x\)</span> se etiqueta como la caracter√≠stica de entrada, y <span class="math inline">\(Œ∏\)</span> se define como un par√°metro de modelo de ML. El objetivo de cualquier algoritmo de ML es aprender el conjunto de par√°metros de un modelo dado. En algunos casos, el modelo tambi√©n se conoce como una <strong>hip√≥tesis</strong>. Supongamos que la hip√≥tesis o modelo se denota por <span class="math inline">\(h_Œ∏\)</span>. Si se ingiere datos <span class="math inline">\(x(i)\)</span> al modelo, el output predicho ser√° <span class="math inline">\(h_Œ∏ (x(i))\)</span>.</p>
<p>En contraste, una t√©cnica de ML puede verse como un enfoque general para intentar resolver un problema en particular. En muchos casos, puede ser necesario combinar una amplia variedad de algoritmos para desarrollar una t√©cnica para resolver un problema de ML.</p>
</section>
</section>
<section id="diferencia-entre-la-ciencia-de-datos-el-aprendizaje-autom√°tico-la-inteligencia-artificial-y-el-aprendizaje-profundo" class="level3">
<h3 class="anchored" data-anchor-id="diferencia-entre-la-ciencia-de-datos-el-aprendizaje-autom√°tico-la-inteligencia-artificial-y-el-aprendizaje-profundo">Diferencia entre la ciencia de datos, el aprendizaje autom√°tico, la inteligencia artificial y el aprendizaje profundo</h3>
<p>La ciencia de datos (<strong>DS</strong>), la inteligencia artificial (<strong>AI</strong>), el aprendizaje autom√°tico (<strong>ML</strong>) y el aprendizaje profund (<strong>DL</strong>) o son t√©rminos relacionados estrechamente, y las personas suelen confundirlos o utilizarlos de manera alternativa. Sin embargo, estos son campos de tecnolog√≠a claramente separados. El aprendizaje autom√°tico cae dentro del subconjunto de la inteligencia artificial, mientras que el aprendizaje profundo se considera que cae dentro del subconjunto del aprendizaje autom√°tico, como se demuestra en la <a href="#fig-venn">Fig. 3.</a></p>
<div id="fig-venn" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-venn-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/clipboard-76734573.png" class="img-fluid figure-img" width="250">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-venn-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;3: Figure 3. El aprendizaje profundo cae dentro del subconjunto del aprendizaje autom√°tico, y el aprendizaje autom√°tico cae dentro del subconjunto de la inteligencia artificial. La ciencia de datos implica una parte de todos estos tres campos.
</figcaption>
</figure>
</div>
<p>La diferencia entre el aprendizaje autom√°tico y el aprendizaje profundo radica en el hecho de que el aprendizaje profundo requiere m√°s recursos de computaci√≥n y conjuntos de datos muy grandes. Gracias al avance de los recursos de computaci√≥n en hardware, las personas est√°n pasando hacia enfoques de aprendizaje profundo para resolver problemas similares que el aprendizaje autom√°tico puede resolver. El aprendizaje profundo es especialmente √∫til para manejar grandes vol√∫menes de texto o im√°genes.</p>
<p>La ciencia de datos es un campo interdisciplinario que implica identificar patrones en los datos y hacer inferencias, predicciones o insights a partir de ellos. La ciencia de datos est√° estrechamente relacionada con el aprendizaje profundo, el miner√≠a de datos y los grandes datos. Aqu√≠, la miner√≠a de datos es el campo que se ocupa de identificar patrones y extraer informaci√≥n de conjuntos de datos grandes utilizando t√©cnicas que combinan estad√≠stica, sistemas de bases de datos y ML, y por definici√≥n, los grandes datos se refieren a datos vastos y complejos que son demasiado grandes para ser procesados por sistemas tradicionales utilizando algoritmos tradicionales. El ML es una de los principales herramientas utilizadas para ayudar al proceso de an√°lisis de datos en la ciencia de datos, especialmente para hacer extrapolaciones o predicciones sobre tendencias futuras de datos.</p>
<p>Por ejemplo, predecir el precio del mercado de casas en el pr√≥ximo a√±o es una aplicaci√≥n de ML. Considere un conjunto de datos de muestra como se muestra en la tabla 1.1.</p>
<div id="tbl-estimacasas" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-estimacasas-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Tabla&nbsp;1: Tabla 1.1. Muestra de datos de precios de casas.
</figcaption>
<div aria-describedby="tbl-estimacasas-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: center;">A√±o</th>
<th style="text-align: center;">Precio</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">2001</td>
<td style="text-align: center;">$200</td>
</tr>
<tr class="even">
<td style="text-align: center;">2002</td>
<td style="text-align: center;">$400</td>
</tr>
<tr class="odd">
<td style="text-align: center;">2003</td>
<td style="text-align: center;">$800</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>La observaci√≥n de los datos en la tabla 1.1 nos permite formar la intuici√≥n de que el pr√≥ximo precio en 2004 ser√° de $1600. Esta intuici√≥n se forma basada en los precios de las casas de los a√±os anteriores, que muestran una tendencia clara de duplicar el precio cada a√±o.</p>
<p>Sin embargo, para conjuntos de datos grandes y complejos, esta predicci√≥n no puede ser tan sencilla. Luego, requerimos un modelo de predicci√≥n de ML para predecir los precios de las casas.</p>
<p>Con suficientes recursos de computaci√≥n, estos problemas pueden ser resueltos utilizando modelos de aprendizaje profundo categorizados bajo aprendizaje profundo. En general, el aprendizaje autom√°tico y el aprendizaje profundo caen dentro de la inteligencia artificial, pero todos requieren el procesamiento, preparaci√≥n y limpieza de los datos disponibles; por lo tanto, la ciencia de datos es una parte integral de todos estos tres ramas.</p>
</section>
</section>
<section id="desarrollo-hist√≥rico-de-machine-learning" class="level2">
<h2 class="anchored" data-anchor-id="desarrollo-hist√≥rico-de-machine-learning">Desarrollo hist√≥rico de Machine Learning</h2>
<p>El aprendizaje autom√°tico ha estado en desarrollo desde la d√©cada de 1940. No es el fruto de la mente de un humano ingenioso ni el resultado de un evento en particular. La ciencia multifac√©tica del aprendizaje autom√°tico ha sido moldeada por a√±os de estudios y investigaci√≥n, y por los esfuerzos dedicados de numerosos cient√≠ficos, ingenieros, matem√°ticos, programadores, investigadores y estudiantes. El aprendizaje autom√°tico es un campo en constante progreso y sigue en desarrollo. La tabla 1.2 enumera los hitos m√°s significativos marcados en la historia del desarrollo del aprendizaje autom√°tico. No te asustes si no conoces a√∫n algunos de los t√©rminos mencionados en la tabla. Los exploraremos m√°s adelante.</p>
<div id="tbl-historia" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-historia-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Tabla&nbsp;2: Tabla 1.2. Desarrollo hist√≥rico de Machine Learning
</figcaption>
<div aria-describedby="tbl-historia-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 0%">
<col style="width: 99%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">A√±o</th>
<th style="text-align: left;">Desarrollo</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">1940s</td>
<td style="text-align: left;">El art√≠culo ‚Äú<em>A logical calculus of the ideas immanent in nervous activity</em>‚Äù, credao por Walter Pitts y Warren McCulloch en 1943, es el primero en discutir el modelo matem√°tico de redes neuronales.</td>
</tr>
<tr class="even">
<td style="text-align: center;">1950s</td>
<td style="text-align: left;">‚Ä¢ El t√©rmino ‚Äú<em>Aprendizaje Autom√°tico</em>‚Äù es utilizado por primera vez por Arthur Samuel. Dise√±√≥ un programa de ajedrez por computadora que estaba a la altura de los juegos de nivel superior. ‚Ä¢ En 1951, Marvin Minsky y Dean Edmonds desarrollaron la primera red neuronal artificial compuesta por 40 neuronas. La red neuronal ten√≠a capacidades de memoria a corto y largo plazo. ‚Ä¢ El taller de dos meses en Dartmouth en 1956 introduce por primera vez la investigaci√≥n en Inteligencia Artificial (IA) y Aprendizaje Autom√°tico (AA). Muchos reconocen este taller como el ‚Äú<em>lugar de nacimiento de la IA</em>‚Äù.</td>
</tr>
<tr class="odd">
<td style="text-align: center;">1960s</td>
<td style="text-align: left;">‚Ä¢ En 1960, Alexey (Oleksii) Ivakhnenko y Valentin Lapa presentan la representaci√≥n jer√°rquica de una red neuronal. Alexey Ivakhnenko se considera el padre del aprendizaje profundo. ‚Ä¢ Thomas Cover y Peter E. Hart publicaron un art√≠culo sobre los algoritmos de vecino m√°s cercano en 1967. Estos algoritmos se utilizan ahora para tareas de regresi√≥n y clasificaci√≥n en el aprendizaje autom√°tico. ‚Ä¢ Un proyecto relacionado con un robot inteligente, Stanford Cart, comenz√≥ en esta d√©cada. El objetivo era navegar a trav√©s de un espacio 3D de manera aut√≥noma.</td>
</tr>
<tr class="even">
<td style="text-align: center;">1970s</td>
<td style="text-align: left;">‚Ä¢ Kunihiko Fukushima, un cient√≠fico inform√°tico japon√©s, public√≥ un trabajo sobre reconocimiento de patrones utilizando redes neuronales jer√°rquicas y multilayered. Este trabajo m√°s tarde sent√≥ las bases para las redes neuronales convolucionales. ‚Ä¢ El proyecto Stanford Cart finalmente logr√≥ recorrer una habitaci√≥n llena de sillas durante cinco horas sin intervenci√≥n humana en 1979.</td>
</tr>
<tr class="odd">
<td style="text-align: center;">1980s</td>
<td style="text-align: left;">‚Ä¢ En 1985, se inventa la red neuronal artificial llamada NETtalk por Terrence Sejnowski. NETtalk puede simplificar modelos de tareas cognitivas humanas de manera que las m√°quinas puedan aprender a hacerlas. ‚Ä¢ La m√°quina de Boltzmann restringida (RBM), inicialmente llamada Harmonium, inventada por Paul Smolensky, se introduce en 1986. Puede analizar un conjunto de entrada y aprender distribuci√≥n de probabilidades a partir de √©l. En la actualidad, la RBM modificada por Geoffrey Hinton se utiliza para modelado de temas, recomendaciones impulsadas por inteligencia artificial, clasificaci√≥n, regresi√≥n, reducci√≥n de dimensionalidad, filtrado colaborativo, etc.</td>
</tr>
<tr class="even">
<td style="text-align: center;">1990s</td>
<td style="text-align: left;">‚Ä¢ El boosting para el aprendizaje autom√°tico se introduce en el papel ‚Äú<em>The Strength of Weak Learnability</em>‚Äù, creado por Robert Schapire y Yoav Freund en 1990. El algoritmo de boosting aumenta la capacidad predictiva de los modelos de inteligencia artificial. El algoritmo genera y combina muchos modelos d√©biles utilizando t√©cnicas como la media o la votaci√≥n en las predicciones. ‚Ä¢ En 1995, Tin Kam Ho introduce bosques de decisiones aleatorios en su art√≠culo. El algoritmo crea m√∫ltiples √°rboles de decisi√≥n aleatoriamente y los combina para crear un ‚Äúbosque‚Äù. El uso de m√∫ltiples √°rboles de decisi√≥n mejora significativamente la precisi√≥n de los modelos. ‚Ä¢ En 1997, Christoph Bregler, Michele Covell y Malcolm Slaney desarrollan el software ‚Äúdeepfake‚Äù m√°s antiguo del mundo. ‚Ä¢ El a√±o 1997 ser√° un hito importante en el AI. El programa de ajedrez basado en IA, Deep Blue, derrot√≥ a uno de los mejores jugadores de ajedrez de la historia humana, Garry Kasparov. Este incidente arroj√≥ nueva luz sobre la tecnolog√≠a de IA.</td>
</tr>
<tr class="odd">
<td style="text-align: center;">2000</td>
<td style="text-align: left;">Igor Aizenberg, un investigador de redes neuronales, introduce por primera vez el t√©rmino ‚Äú<em>aprendizaje profundo</em>‚Äù. Utiliz√≥ este t√©rmino para describir las redes m√°s grandes compuestas por neuronas de umbral booleano.</td>
</tr>
<tr class="even">
<td style="text-align: center;">2009</td>
<td style="text-align: left;">Fei-Fei Li lanz√≥ el conjunto de datos m√°s extenso de im√°genes etiquetadas, ImageNet. Fue dise√±ado para contribuir a proporcionar datos de entrenamiento vers√°tiles y reales para modelos de IA y ML. The Economist ha comentado sobre ImageNet como un evento excepcional para popularizar la IA a lo largo de la comunidad tecnol√≥gica y dar un paso hacia un nuevo era de historia del aprendizaje profundo.</td>
</tr>
<tr class="odd">
<td style="text-align: center;">2011</td>
<td style="text-align: left;">El equipo de X Lab de Google desarrolla un algoritmo de inteligencia artificial llamado Google Brain para el procesamiento de im√°genes, que es capaz de identificar gatos en im√°genes.</td>
</tr>
<tr class="even">
<td style="text-align: center;">2014</td>
<td style="text-align: left;"><ol type="1">
<li><p>Ian Goodfellow y sus colegas desarrollaron redes neuronales generadoras adversarias (GANs). Los marcos se utilizan para que los modelos de IA sean capaces de generar datos enteramente nuevos dados su conjunto de entrenamiento.</p></li>
<li><p>El equipo de investigaci√≥n de Facebook desarroll√≥ DeepFace, que puede distinguir caras humanas casi tan bien como los seres humanos con una tasa de precisi√≥n del 97,35%. DeepFace es una red neuronal compuesta por nueve capas. La red se entrena en m√°s de 4 millones de im√°genes tomadas de usuarios de Facebook.</p></li>
<li><p>Google ha comenzado a utilizar Sibyl para hacer predicciones para sus productos. Sibyl es un sistema de aprendizaje autom√°tico a escala m√°s amplia. El sistema consta de muchos nuevos algoritmos combinados. Ha mejorado significativamente el rendimiento a trav√©s de boosting paralelo y datos orientados a columnas. Adem√°s, utiliza el comportamiento de los usuarios para clasificar productos y publicidad.</p></li>
<li><p>Eugene Goostman, un chatbot de IA desarrollado por tres amigos de San Petersburgo en 2001, se considera el primer chatbot de IA que se asemeja a la inteligencia humana. Este personaje de IA se representa como un ni√±o de 13 a√±os de Odessa, Ucrania, que tiene un conejo de Indias y un padre ginec√≥logo. Eugene Goostman super√≥ la competencia del test de Turing el 7 de junio de 2014 en la Royal Society.</p></li>
</ol></td>
</tr>
<tr class="odd">
<td style="text-align: center;">2015</td>
<td style="text-align: left;">El primer programa de IA ‚Äú<em>AlphaGo</em>‚Äù supera a un jugador profesional de Go. Go era un juego que inicialmente era imposible ense√±ar a una computadora.</td>
</tr>
<tr class="even">
<td style="text-align: center;">2016</td>
<td style="text-align: left;">Un grupo de cient√≠ficos presenta Face2Face durante la Conferencia sobre Visi√≥n por Computadora y Reconocimiento de Patrones. La mayor√≠a del software ‚Äú<em>deepfake</em>‚Äù utilizado en la actualidad se basa en la l√≥gica y los algoritmos de Face2Face.</td>
</tr>
<tr class="odd">
<td style="text-align: center;">2017</td>
<td style="text-align: left;"><ol type="1">
<li><p>Se introducen coches aut√≥nomos o sin conductor en EE. UU. por parte de Waymo.</p></li>
<li><p>Se publica el famoso papel ‚Äú<em>Attention is All You Need</em>‚Äù, que introduce la arquitectura del Transformer basada en el mecanismo de autoatenci√≥n, lo que conduce a un progreso significativo en el procesamiento de lenguaje natural.</p></li>
</ol></td>
</tr>
<tr class="even">
<td style="text-align: center;">2021</td>
<td style="text-align: left;">Google DeepMind‚Äôs AlphaFold 2 model places first in the CASP13 protein folding competition in the free modeling (FM) category, bringing a breakthrough in deep-learning-based protein structure prediction.</td>
</tr>
<tr class="odd">
<td style="text-align: center;">2022</td>
<td style="text-align: left;">OpenAI y Google revolucionan los modelos de lenguaje grande para uso masivo. Diversas aplicaciones del aprendizaje autom√°tico han comenzado a convertirse en parte de las actividades diarias.</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</section>
<section id="por-qu√©-machine-learning" class="level2">
<h2 class="anchored" data-anchor-id="por-qu√©-machine-learning">Por qu√© Machine Learning?</h2>
<p>Antes de profundizar m√°s, es importante tener una visi√≥n clara de la finalidad y los motivos detr√°s del aprendizaje autom√°tico. Por lo tanto, las secciones siguientes discutir√°n la finalidad, los motivos y la importancia del aprendizaje autom√°tico para que pueda implementarse en escenarios de vida real.</p>
<section id="motivaci√≥n" class="level3">
<h3 class="anchored" data-anchor-id="motivaci√≥n">Motivaci√≥n</h3>
<p>La motivaci√≥n para crear un campo multidimensional como el aprendizaje autom√°tico surgi√≥ del trabajo mon√≥tono que los seres humanos ten√≠an que realizar. Con el aumento del uso de sistemas de comunicaci√≥n digital, dispositivos inteligentes y la Internet, se generan grandes cantidades de datos cada momento. Buscar y organizar todos esos datos cada vez que se necesita resolver un tarea es exhaustivo, tiempo consumidor y mon√≥tono. Por lo tanto, en lugar de ir a trav√©s del proceso laborioso de revisar billones de datos, los seres humanos optaron por un proceso m√°s automatizado. El proceso automatizado busca encontrar patrones relevantes en los datos y luego utilizar estos patrones para evaluar y resolver tareas. Fue entonces cuando surgi√≥ el concepto de programaci√≥n. Sin embargo, incluso con la programaci√≥n, los seres humanos ten√≠an que codificar expl√≠citamente o instruir a las m√°quinas sobre qu√© hacer, cu√°ndo y c√≥mo hacerlo. Para superar el nuevo problema de codificar cada comando para que las m√°quinas lo entiendan, los seres humanos desarrollaron la idea de hacer que las m√°quinas aprendieran ellas mismas de la manera en que los seres humanos lo hacen - simplemente reconociendo patrones.</p>
</section>
<section id="prop√≥sito" class="level3">
<h3 class="anchored" data-anchor-id="prop√≥sito">Prop√≥sito</h3>
<p>El prop√≥sito del aprendizaje autom√°tico es hacer que las m√°quinas inteligentes y automatizar tareas que de otra manera ser√≠an tediosas y propensas a errores humanos. El uso de modelos de aprendizaje autom√°tico puede hacer que las tareas sean m√°s accesibles y eficientes en el tiempo.</p>
<p>Por ejemplo, considere un conjunto de datos <span class="math inline">\((x, y) = (0, 0);(1, 1);(2, 2);(3, ?)\)</span>. Aqu√≠, para definir la relaci√≥n entre <span class="math inline">\(x\)</span> y <span class="math inline">\(y\)</span>, <span class="math inline">\(y\)</span> se puede expresar como una funci√≥n de <span class="math inline">\(x\)</span>, es decir, <span class="math inline">\(y = f (x) = Œ∏ x\)</span>. Esta representaci√≥n de los dos elementos del conjunto de datos se conoce como el modelo. El prop√≥sito del aprendizaje autom√°tico es aprender qu√© es <span class="math inline">\(Œ∏\)</span> a partir de los datos existentes y luego aplicar el aprendizaje autom√°tico para determinar que <span class="math inline">\(Œ∏ = 1\)</span>. Este conocimiento se puede utilizar luego para encontrar el valor del valor desconocido de <span class="math inline">\(y\)</span> cuando <span class="math inline">\(x = 3\)</span>. Seguro aprender√°s c√≥mo formular el modelo hipot√©tico y c√≥mo resolver los valores de <span class="math inline">\(Œ∏\)</span>.</p>
</section>
<section id="importancia" class="level3">
<h3 class="anchored" data-anchor-id="importancia">Importancia</h3>
<p>Al igual que las m√°quinas, la ciencia del aprendizaje autom√°tico se cre√≥ con el fin de hacer que las tareas humanas m√°s f√°ciles. El an√°lisis de datos era un trabajo tedioso y laborioso, propenso a muchos errores cuando se hac√≠a manualmente. Pero gracias al aprendizaje autom√°tico, todos los seres humanos tienen que hacer es proporcionar la m√°quina con el conjunto de datos o la fuente del conjunto de datos, y la m√°quina puede analizar los datos, reconocer un patr√≥n y tomar decisiones valiosas sobre los datos.</p>
<p>Otra ventaja del aprendizaje autom√°tico es que los seres humanos no necesitan decirle a la m√°quina cada paso del trabajo. La m√°quina misma genera las instrucciones despu√©s de aprender de la entrada del conjunto de datos. Por ejemplo, un modelo de reconocimiento de im√°genes no requiere decirle a la m√°quina sobre cada objeto en una imagen. En el caso del aprendizaje supervisado, solo necesitamos decirle a la m√°quina sobre los etiquetas (como vaca o perro) junto con sus atributos (como proporciones faciales, tama√±o del cuerpo, tama√±o de las orejas, presencia de cuernos, etc.), y la m√°quina identificar√° autom√°ticamente los objetos etiquetados en cualquier imagen basada en los atributos marcados.</p>
<p>El aprendizaje autom√°tico tambi√©n es esencial en el caso de la predicci√≥n de tendencias de datos desconocidos o futuras. Esta aplicaci√≥n es extremadamente valiosa para crear planes de negocio y esquemas de marketing, y preparar recursos para el futuro. Por ejemplo, el aprendizaje autom√°tico puede ayudar a predecir el crecimiento futuro de las instalaciones de m√≥dulos solares, incluso hasta 2050 o 2100, basado en tendencias hist√≥ricas de precios. En comparaci√≥n con otras herramientas de predicci√≥n y t√©cnicas, el aprendizaje autom√°tico puede predecir valores con mayor precisi√≥n y considerar muchos par√°metros adicionales que no se pueden incorporar en f√≥rmulas de predicci√≥n definidas utilizadas en herramientas de predicci√≥n tradicionales, como la extrapolaci√≥n de datos estad√≠sticos.</p>
</section>
</section>
<section id="conocimientos-previos-para-aprender-machine-learning" class="level2">
<h2 class="anchored" data-anchor-id="conocimientos-previos-para-aprender-machine-learning">Conocimientos previos para aprender Machine Learning</h2>
<p>El aprendizaje autom√°tico es una <strong>ciencia avanzada</strong>; una persona no puede simplemente sumergirse en el mundo del ML sin tener alg√∫n conocimiento y habilidades b√°sicos. Para poder entender los conceptos de ML, utilizar los algoritmos y aplicar t√©cnicas de ML en casos pr√°cticos, una persona debe estar equipada con varios temas en matem√°ticas y ciencias avanzadas, algunos de los cuales se discuten en las siguientes secciones.</p>
<p>Esta secci√≥n muestra solo los temas que un entusiasta de ML debe conocer antes de aprender ML. Los temas no se cubren en detalle aqu√≠.</p>
<section id="√°lgebra-lineal" class="level3">
<h3 class="anchored" data-anchor-id="√°lgebra-lineal">√Ålgebra Lineal</h3>
<p>La √°lgebra lineal es la rama de matem√°ticas que se ocupa de las transformaciones lineales. Estas transformaciones lineales se realizan utilizando ecuaciones lineales y funciones lineales. Vectores y matrices se utilizan para notar las ecuaciones lineales y funciones lineales necesarias. Una buena base en √°lgebra lineal es requerida para entender la intuici√≥n m√°s profunda detr√°s de diferentes algoritmos de ML. Es la base para resolver problemas como aquel de nuestra <a href="https://cchiquitovalencia.github.io/posts/2025-01-27-maintenance_management/">app de mantenimiento</a>.</p>
<section id="ecuaciones-lineales" class="level4">
<h4 class="anchored" data-anchor-id="ecuaciones-lineales">Ecuaciones Lineales</h4>
<p>Las ecuaciones lineales son m√°s f√°ciles de describir matem√°ticamente y pueden combinarse con transformaciones de modelos no lineales. Hay dos propiedades de una ecuaci√≥n para ser denominada lineal - <strong>homogeneidad</strong> y <strong>superposici√≥n</strong>. El conocimiento de ecuaciones lineales puede ser conveniente para modelar sistemas lineales. Un ejemplo de ecuaci√≥n lineal es <span class="math inline">\(p_1x_1 + p_2x_2 + ... + p_nx_n + q = 0\)</span>, donde <span class="math inline">\(x_1, x_2 ..., x_n\)</span> son las variables, <span class="math inline">\(p_1, p_2 ..., p_n\)</span> son los coeficientes y <span class="math inline">\(q\)</span> es un constante.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-eq" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-eq-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="index_files/figure-html/fig-eq-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-eq-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;4: Fig. 1.4. Ejemplos de dos l√≠neas rectas con ecuaciones lineales
</figcaption>
</figure>
</div>
</div>
</div>
<p>Utilizando √°lgebra lineal, podemos resolver las ecuaciones de la <a href="#fig-eq">Fig. 1.4</a>, es decir, podemos encontrar la intersecci√≥n de estas dos l√≠neas. Las ecuaciones para las dos l√≠neas son las siguientes:</p>
<p><span id="eq-1.2"><span class="math display">\[
y=\frac{3}{5}x+2, (1.2)
\tag{2}\]</span></span></p>
<p><span id="eq-1.3"><span class="math display">\[\frac{x}{5} + \frac{y}{5} = 1.  (1.3) \tag{3}\]</span></span></p>
<p>Ahora, al resolver la ecuaci√≥n <span class="math inline">\((1.3)\)</span>, obtenemos:</p>
<p><span class="math display">\[
x+y=5,
\]</span></p>
<p><span class="math display">\[
‚üπx+(\frac{3}{5}x+2)=5,
\]</span></p>
<p><span class="math display">\[
‚üπ8x=15,
\]</span></p>
<p><span class="math display">\[
‚üπx=1.875.
\]</span></p>
<p>Poniendo el valor de <span class="math inline">\(x\)</span> en la ecuaci√≥n <a href="#eq-1.2"><span class="math inline">\((1.2)\)</span></a>, obtenemos <span class="math inline">\(y = 3.125\)</span>. Por lo tanto, el punto de intersecci√≥n es <span class="math inline">\((x, y) = (1.875, 3.125)\)</span>.</p>
</section>
<section id="tensor-y-rango-de-tensor" class="level4">
<h4 class="anchored" data-anchor-id="tensor-y-rango-de-tensor">Tensor y Rango de Tensor</h4>
<p>Un tensor es un t√©rmino general para vectores y matrices. Es la estructura de datos utilizada en modelos de ML. Un tensor puede tener cualquier dimensi√≥n. Un escalar es un tensor con cero dimensiones, un vector es un tensor con una dimensi√≥n y una matriz tiene dos dimensiones. Cualquier tensor con m√°s de dos dimensiones se llama tensor <code>n-dimensional</code>. Vectores y matrices se discuten a continuaci√≥n.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-vec" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-vec-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="index_files/figure-html/fig-vec-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-vec-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;5: Fig. 1.5. Ejemplo de un vector
</figcaption>
</figure>
</div>
</div>
</div>
<section id="vector" class="level5">
<h5 class="anchored" data-anchor-id="vector">Vector</h5>
<p>Un vector es un array unidimensional de n√∫meros, t√©rminos o elementos. Las caracter√≠sticas del conjunto de datos se representan como vectores. Un vector se puede representar en dimensiones geom√©tricas. Por ejemplo, un vector <span class="math inline">\([3, 5]\)</span> se puede representar geom√©tricamente en un espacio <code>2-dimensional</code>, como se muestra en la <a href="#fig-vec">Fig. 1.5</a>. Este espacio se puede llamar espacio de vectores o espacio de caracter√≠sticas. En el espacio de vectores, un vector se puede visualizar como una l√≠nea con direcci√≥n y magnitud.</p>
</section>
<section id="matriz" class="level5">
<h5 class="anchored" data-anchor-id="matriz">Matriz</h5>
<p>Una matriz es un array bidimensional de escalares con una o m√°s columnas y una o m√°s filas. Un vector con m√°s de una dimensi√≥n se llama matriz. El n√∫mero de filas y columnas se expresa como la dimensi√≥n de esa matriz. Por ejemplo, una matriz con una dimensi√≥n de <span class="math inline">\(4 √ó 3\)</span> contiene 4 filas y 3 columnas. Las operaciones de matrices proporcionan c√°lculos m√°s eficientes que operaciones piecemeal para modelos de aprendizaje autom√°tico. Los matrices deben tener la misma dimensi√≥n para la suma y resta. Para la multiplicaci√≥n de matrices, el tama√±o de la columna del primer matriz y el tama√±o de la fila del segundo matriz deben ser id√©nticos. Si se multiplica una matriz con dimensi√≥n <span class="math inline">\(m √ó n\)</span> por una matriz con dimensi√≥n <span class="math inline">\(n √ó p\)</span>, entonces el resultado de esta multiplicaci√≥n ser√° una matriz con dimensi√≥n <span class="math inline">\(m √ó p\)</span>.</p>
<p>La <a href="#eq-1.4">ecuaci√≥n 1.4</a> muestra la matriz <span class="math inline">\(A\)</span> con una dimensi√≥n de <span class="math inline">\(2 √ó 3\)</span> y la matriz <span class="math inline">\(B\)</span> con una dimensi√≥n de <span class="math inline">\(3 √ó 1\)</span>. Por lo tanto, estas dos matrices se pueden multiplicar porque cumplen con la condici√≥n de multiplicaci√≥n de matrices. El resultado de la multiplicaci√≥n ser√° la matriz <span class="math inline">\(C\)</span>, mostrada en la <a href="#eq-1.5">ecuaci√≥n 1.5</a>. Tiene una dimensi√≥n de <span class="math inline">\(2 √ó 1\)</span>.</p>
<p><span id="eq-1.4"><span class="math display">\[A=\begin{bmatrix}1&amp;2&amp;3\\4&amp;5&amp;6\end{bmatrix}; B=\begin{bmatrix}11\\12\\13\end{bmatrix}.&nbsp;&nbsp;&nbsp;(1.4) \tag{4}\]</span></span></p>
<p><span id="eq-1.5"><span class="math display">\[
Producto, C=\begin{bmatrix}74\\182\end{bmatrix}.&nbsp;&nbsp;&nbsp;(1.5)
\tag{5}\]</span></span></p>
<p>Algunas matrices fundamentales se utilizan con frecuencia, como la matriz de fila, la matriz cuadrada, la matriz de columna, la matriz de identidad, etc. Por ejemplo, una matriz que consiste solo en una fila se conoce como matriz de fila, y una matriz que consiste solo en una columna se conoce como matriz de columna. Una matriz que consiste en un n√∫mero igual de filas y columnas se llama matriz cuadrada. Una matriz cuadrada con todos los <strong>1</strong>‚Äôs a lo largo de su diagonal principal y todos los <strong>0</strong>‚Äôs en todos los elementos no diagonales es una <strong>matriz de identidad</strong>. Se muestran ejemplos de matrices diferentes en la Fig. 1.6.</p>
</section>
<section id="rango-vs.-dimensi√≥n" class="level5">
<h5 class="anchored" data-anchor-id="rango-vs.-dimensi√≥n">Rango vs.&nbsp;Dimensi√≥n</h5>
<p>Rango y dimensi√≥n son dos t√©rminos relacionados pero distinos en √°lgebra lineal, aunque a menudo se utilizan indistintamente en aprendizaje autom√°tico. En perspectiva de aprendizaje autom√°tico, cada columna de una matriz o tensor representa cada caracter√≠stica o subespacio. Por lo tanto, la dimensi√≥n de su columna (es decir, subespacio) ser√° el rango de esa matriz o tensor.</p>
</section>
<section id="comparaci√≥n-entre-escalar-vector-matriz-y-tensor" class="level5">
<h5 class="anchored" data-anchor-id="comparaci√≥n-entre-escalar-vector-matriz-y-tensor">Comparaci√≥n entre Escalar, Vector, Matriz y Tensor</h5>
<p>Un escalar es simplemente un valor num√©rico sin direcci√≥n asignada. Un vector es un array de n√∫meros de una dimensi√≥n que denota una direcci√≥n espec√≠fica. Una matriz es un array de n√∫meros de dos dimensiones. Finalmente, un tensor es un array de datos de <span class="math inline">\(n\)</span> dimensiones.</p>
<p>Seg√∫n las cantidades mencionadas, escalares, vectores y matrices tambi√©n pueden considerarse tensors, pero limitados a 0, 1 y 2 dimensiones, respectivamente. Las tablas 1.3 y 1.4 resumen las diferencias en el rango o dimensi√≥n de estas cuatro cantidades con ejemplos.</p>
<p>&nbsp;</p>
<div id="fig-diffmatrix" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-diffmatrix-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<p><span class="math display">\[\text{Cuadrada 2x2}\begin{bmatrix}5&amp;2\\-6&amp;1\end{bmatrix};\\
\text{Rectangular 3x2}\begin{bmatrix}4&amp;1\\2&amp;-1\\-7&amp;5\end{bmatrix};\\
\text{Ceros 3x5}\begin{bmatrix}0&amp;0&amp;0&amp;0&amp;0\\0&amp;0&amp;0&amp;0&amp;0\\0&amp;0&amp;0&amp;0&amp;0\end{bmatrix};\\
\text{Fila 1x4}\begin{bmatrix}5&amp;-1&amp;0&amp;3\end{bmatrix};\\
\text{Columna 3x1}\begin{bmatrix}1\\2\\-7\end{bmatrix};\\
\text{Identidad 3x3}\begin{bmatrix}1&amp;0&amp;0\\0&amp;1&amp;0\\0&amp;0&amp;1\end{bmatrix}\]</span></p>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-diffmatrix-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;6
</figcaption>
</figure>
</div>
<div id="tbl-comparaciones" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-comparaciones-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Tabla&nbsp;3: Tabla 1.3. Comparaci√≥n entre escalar, vector, matrix y tensor.
</figcaption>
<div aria-describedby="tbl-comparaciones-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: center;">Rango/Dimensi√≥n</th>
<th style="text-align: center;">Objeto</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">0</td>
<td style="text-align: center;">Escalar</td>
</tr>
<tr class="even">
<td style="text-align: center;">1</td>
<td style="text-align: center;">Vector</td>
</tr>
<tr class="odd">
<td style="text-align: center;">2 o m√°s</td>
<td style="text-align: center;">Matriz <span class="math inline">\(m * n\)</span></td>
</tr>
<tr class="even">
<td style="text-align: center;">Cualquiera</td>
<td style="text-align: center;">Tensor</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>&nbsp;</p>
<div id="tbl-ejemplos" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-ejemplos-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Tabla&nbsp;4: Tabla 1.4. Ejemplos de escalar, vector, matriz y tensor.
</figcaption>
<div aria-describedby="tbl-ejemplos-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 4%">
<col style="width: 14%">
<col style="width: 16%">
<col style="width: 63%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Escalar</th>
<th style="text-align: center;">Vector</th>
<th style="text-align: center;">Matriz</th>
<th style="text-align: center;">Tensor</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(1\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\begin{bmatrix}1\\2\end{bmatrix}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\begin{bmatrix}1&amp;2\\3&amp;4\end{bmatrix}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\begin{bmatrix}\begin{bmatrix}1&amp;2\end{bmatrix}&amp;\begin{bmatrix}3&amp;4\end{bmatrix}\\\begin{bmatrix}5&amp;6\end{bmatrix}&amp;\begin{bmatrix}7&amp;8\end{bmatrix}\end{bmatrix}\)</span></td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>&nbsp;</p>
<div id="tbl-defmeds" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-defmeds-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Tabla&nbsp;5: Tabla 1.5. Defici√≥n de media, mediana y moda.
</figcaption>
<div aria-describedby="tbl-defmeds-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: center;">Nombre</th>
<th style="text-align: center;">Definici√≥n</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Media</td>
<td style="text-align: center;">El valor promedio aritm√©tico.</td>
</tr>
<tr class="even">
<td style="text-align: center;">Mediana</td>
<td style="text-align: center;">El valor del medio.</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Moda</td>
<td style="text-align: center;">El valor m√°s com√∫n.</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>&nbsp;</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-dist" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-dist-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="index_files/figure-html/fig-dist-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-dist-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;7: Fig. 1.7. Representaci√≥n gr√°fica de la media, mediana y moda
</figcaption>
</figure>
</div>
</div>
</div>
</section>
</section>
</section>
<section id="estad√≠stica" class="level3">
<h3 class="anchored" data-anchor-id="estad√≠stica">Estad√≠stica</h3>
<p>La estad√≠stica es un campo vasto de las matem√°ticas que ayuda a organizar y analizar conjuntos de datos. El an√°lisis de datos es mucho m√°s f√°cil, r√°pido y preciso cuando las m√°quinas lo realizan. Por lo tanto, el aprendizaje autom√°tico se utiliza predominantemente para encontrar patrones dentro de los datos. La estad√≠stica es el componente fundamental del aprendizaje autom√°tico. Por lo tanto, es necesario tener conocimientos de t√©rminos estad√≠sticos para aprovechar plenamente los beneficios del aprendizaje autom√°tico.</p>
<section id="medidas-de-tendencia-central" class="level4">
<h4 class="anchored" data-anchor-id="medidas-de-tendencia-central">Medidas de Tendencia Central</h4>
<p>Los tres t√©rminos estad√≠sticos m√°s comunes utilizados ampliamente en diversas aplicaciones son la media, la mediana y la moda. Estas tres funciones son las medidas de tendencia central de cualquier conjunto de datos, que denotan los valores centrales o medios del conjunto de datos. La tabla 1.5 establece las distinciones entre estos tres t√©rminos. Estas son las medidas de tendencia central de un conjunto de datos. La figura 1.7 proporciona una representaci√≥n gr√°fica de la media, la mediana y la moda.</p>
<p>Se presentan tres ejemplos aqu√≠ y en la tabla 1.6. Vamos a considerar el primer conjunto de datos: <span class="math inline">\(\{1, 2, 9, 2, 13, 15\}\)</span>. Para encontrar la media de este conjunto de datos, debemos calcular la suma de los n√∫meros. Aqu√≠, la suma es 42. El conjunto de datos tiene seis puntos de datos. Por lo tanto, la media de este conjunto de datos ser√° 42 √∑ 6 = 7. A continuaci√≥n, para encontrar la mediana del conjunto de datos, el conjunto de datos necesita ser ordenado en orden ascendente: <span class="math inline">\(\{1, 2, 2, 9, 13, 15\}\)</span>.</p>
<div id="tbl-varios" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-varios-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Tabla&nbsp;6: Tabla 1.6. Varios conjuntos de datos y sus medidas de tendencia central
</figcaption>
<div aria-describedby="tbl-varios-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: center;">Conjuntos</th>
<th style="text-align: center;">{1,2,9,2,13,15}</th>
<th style="text-align: center;">{0,5,5,10}</th>
<th style="text-align: center;">{18,22,24,24,25}</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Media</td>
<td style="text-align: center;">7</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">22.6</td>
</tr>
<tr class="even">
<td style="text-align: center;">Mediana</td>
<td style="text-align: center;">5.5</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">24</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Moda</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">24</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>Dado que el n√∫mero de puntos de datos es par, tomaremos los dos valores medios y los promediamos para calcular la mediana. Para este conjunto de datos, el valor de mediana ser√≠a <span class="math inline">\((2 + 9) √∑ 2 = 5.5\)</span>. Para la moda, el punto de datos m√°s repetido debe considerarse. Aqu√≠, <span class="math inline">\(2\)</span> es la moda para este conjunto de datos. Este conjunto de datos est√° desviado hacia la izquierda, es decir, la distribuci√≥n de los datos es m√°s larga hacia la izquierda o tiene una cola izquierda larga.</p>
<p>De manera similar, si consideramos el conjunto de datos <span class="math inline">\(\{0, 5, 5, 10\}\)</span>, la media, la mediana y la moda todos son <span class="math inline">\(5\)</span>. Este conjunto de datos est√° distribuido normalmente. ¬øPuedes calcular la media, la mediana y la moda para el conjunto de datos desviado hacia la derecha <span class="math inline">\(\{18, 22, 24, 24, 25\}\)</span>?</p>
</section>
<section id="desviaci√≥n-est√°ndar" class="level4">
<h4 class="anchored" data-anchor-id="desviaci√≥n-est√°ndar">Desviaci√≥n Est√°ndar</h4>
<p>La desviaci√≥n est√°ndar (SD) se utiliza para medir la estimaci√≥n de la variaci√≥n de los puntos de datos en un conjunto de datos en relaci√≥n con la media aritm√©tica. Un conjunto de datos completo se conoce como una poblaci√≥n, mientras que un subconjunto del conjunto de datos se conoce como una muestra. Las ecuaciones para calcular la desviaci√≥n est√°ndar de la poblaci√≥n y la desviaci√≥n est√°ndar de la muestra se expresan como Ecuaciones <a href="#eq-1.6">1.6</a> y <a href="#eq-1.7">1.7</a>, respectivamente.</p>
<p><span id="eq-1.6"><span class="math display">\[
\text{Desviaci√≥n est√°ndar poblacional, } \sigma=\sqrt{\frac{1}{N}\sum_{i=1}^N{(x_i-\mu)^2}}.
\tag{6}\]</span></span></p>
<p>Donde <span class="math inline">\(\sigma\)</span> simboliza la desviaci√≥n est√°ndar de la poblaci√≥n, <span class="math inline">\(i\)</span> es una variable que enumera los puntos de datos, <span class="math inline">\(x_i\)</span> denota cualquier punto de datos particular, <span class="math inline">\(\mu\)</span> es la media aritm√©tica de la poblaci√≥n y <span class="math inline">\(N\)</span> es el n√∫mero total de puntos de datos en la poblaci√≥n.</p>
<p><span id="eq-1.7"><span class="math display">\[
\text{Desviaci√≥n est√°ndar muestral, } s=\sqrt{\frac{1}{N-1}\sum_{i=1}^N{(x_i-\overline{x})^2}}.
\tag{7}\]</span></span></p>
<p>Donde <span class="math inline">\(s\)</span> simboliza la desviaci√≥n est√°ndar de la muestra, <span class="math inline">\(i\)</span> es una variable que enumera los puntos de datos, <span class="math inline">\(x_i\)</span> denota cualquier punto de datos particular, <span class="math inline">\(x\)</span> es la media aritm√©tica de la muestra y <span class="math inline">\(N\)</span> es el n√∫mero total de puntos de datos en la muestra.</p>
<p>Un valor bajo de la desviaci√≥n est√°ndar indica que los puntos de datos se encuentran razonablemente cerca de la media del conjunto de datos, como se muestra en la Fig. 1.8a. Por otro lado, un valor alto de la desviaci√≥n est√°ndar indica que los puntos de datos se encuentran lejos de la media del conjunto de datos, cubriendo un rango amplio, como se muestra en la Fig. 1.8b.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-desvest" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-desvest-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="index_files/figure-html/fig-desvest-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-desvest-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;8: Fig. 1.8. Desviaci√≥n est√°ndas de los datos
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="correlaci√≥n" class="level4">
<h4 class="anchored" data-anchor-id="correlaci√≥n">Correlaci√≥n</h4>
<p>La correlaci√≥n muestra c√≥mo de fuerte es la relaci√≥n entre dos variables. Es una medida estad√≠stica de la relaci√≥n entre dos (y a veces m√°s) variables. Por ejemplo, si una persona puede nadar, probablemente puede sobrevivir despu√©s de caerse de un barco. Sin embargo, la correlaci√≥n no es causalidad. Una correlaci√≥n fuerte no siempre significa una relaci√≥n fuerte entre dos variables; podr√≠a ser pura coincidencia. Un ejemplo famoso en este sentido es la correlaci√≥n entre las ventas de helado y los ataques de tiburones. Hay una correlaci√≥n fuerte entre las ventas de helado y los ataques de tiburones, <strong>pero</strong> los ataques de tiburones ciertamente no ocurren debido a las ventas de helado.</p>
<p>La correlaci√≥n se puede clasificar de muchas maneras, como se describe en las secciones siguientes.</p>
<section id="correlaci√≥n-positiva-negativa-y-cero" class="level5">
<h5 class="anchored" data-anchor-id="correlaci√≥n-positiva-negativa-y-cero">Correlaci√≥n Positiva, Negativa y Cero</h5>
<p>En una correlaci√≥n positiva, la direcci√≥n del cambio es la misma para ambas variables, es decir, cuando el valor de una variable aumenta o disminuye, el valor de la otra variable tambi√©n aumenta o disminuye, respectivamente. En una correlaci√≥n negativa, la direcci√≥n del cambio es opuesta para ambas variables, es decir, cuando el valor de una variable aumenta, el valor de la otra variable disminuye, y viceversa. Para una correlaci√≥n cero, las dos variables son independientes, es decir, no existe correlaci√≥n entre ellas. Estos conceptos se presentan detalladamente en la Fig. 1.9.</p>
</section>
<section id="correlaci√≥n-simple-parcial-y-multiple" class="level5">
<h5 class="anchored" data-anchor-id="correlaci√≥n-simple-parcial-y-multiple">Correlaci√≥n Simple, Parcial y Multiple</h5>
<p>La correlaci√≥n entre dos variables es una correlaci√≥n simple. Pero si el n√∫mero de variables es de tres o m√°s, es una correlaci√≥n parcial o m√∫ltiple. En una correlaci√≥n parcial, la correlaci√≥n entre dos variables de inter√©s se determina mientras se mantiene constante la otra variable. Por ejemplo, la correlaci√≥n entre la cantidad de comida ingerida y la presi√≥n arterial para un grupo de edad espec√≠fico se puede considerar como una correlaci√≥n parcial. Cuando se determina la correlaci√≥n entre tres o m√°s variables al mismo tiempo, se llama correlaci√≥n m√∫ltiple. Por ejemplo, la relaci√≥n entre la cantidad de comida comida, la altura, el peso y la presi√≥n arterial se puede considerar como un caso de correlaci√≥n m√∫ltiple.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-correlaciones" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-correlaciones-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="index_files/figure-html/fig-correlaciones-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-correlaciones-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;9: Fig. 1.9. Visualizaci√≥n de correlaci√≥n cero, positiva y negativa a diferentes niveles
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="correlaci√≥n-lineal-y-no-lineal" class="level5">
<h5 class="anchored" data-anchor-id="correlaci√≥n-lineal-y-no-lineal">Correlaci√≥n Lineal y No Lineal</h5>
<p>Cuando la direcci√≥n del cambio es constante en todos los puntos para todas las variables, la correlaci√≥n entre ellas es lineal. Si la direcci√≥n del cambio cambia, es decir, no es constante en todos los puntos, entonces se conoce como correlaci√≥n no lineal, tambi√©n conocida como correlaci√≥n curvil√≠nea. Un ejemplo de correlaci√≥n no lineal ser√≠a la relaci√≥n entre la satisfacci√≥n del cliente y la alegr√≠a del personal. La alegr√≠a del personal podr√≠a mejorar la experiencia del cliente, pero demasiada alegr√≠a podr√≠a tener un efecto negativo.</p>
</section>
<section id="coeficiente-de-correlaci√≥n" class="level5">
<h5 class="anchored" data-anchor-id="coeficiente-de-correlaci√≥n">Coeficiente de Correlaci√≥n</h5>
<p>El coeficiente de correlaci√≥n se utiliza para representar la correlaci√≥n de manera num√©rica. Indica la fuerza de la relaci√≥n entre las variables. Hay muchos tipos de coeficientes de correlaci√≥n. Sin embargo, los dos m√°s utilizados y m√°s importantes se discuten brevemente aqu√≠.</p>
<p><em>Coeficiente de Correlaci√≥n de Pearson</em></p>
<p>El Coeficiente de Correlaci√≥n de Pearson, tambi√©n conocido como <span class="math inline">\(\text{r de Pearson}\)</span>, es el m√°s popular y ampliamente utilizado para determinar la correlaci√≥n lineal entre dos variables. En otras palabras, describe la fuerza de la relaci√≥n entre dos variables basada en la direcci√≥n del cambio en las variables.</p>
<p>Para el coeficiente de correlaci√≥n de una muestra,</p>
<p><span id="eq-1.8"><span class="math display">\[
r_{xy}=\frac{Cov(x,y)}{s_xs_y}=\frac{\frac{\sum{(x_i-\overline{x})(y_i-\overline{y})}}{n-1}}{\sqrt{\frac{(x_i-\overline{x})^2}{n-1}}\sqrt{\frac{y_i-\overline{y})^2}{n-1}}}=\frac{\sum{(x_i-\overline{x})(y_i-\overline{y})}}{\sum{(x_i-\overline{x})^2(y_i-\overline{y})^2}}
\tag{8}\]</span></span></p>
<p>Aqu√≠, <span class="math inline">\(r_{xy}\)</span> es el coeficiente de correlaci√≥n de muestra entre dos variables <span class="math inline">\(x\)</span> y <span class="math inline">\(y\)</span>; <span class="math inline">\(Cov(x, y)\)</span> es la covarianza de muestra entre dos variables <span class="math inline">\(x\)</span> y <span class="math inline">\(y\)</span>; <span class="math inline">\(s_x\)</span> , <span class="math inline">\(s_y\)</span> son la desviaci√≥n est√°ndar de muestra de <span class="math inline">\(x\)</span> y <span class="math inline">\(y\)</span>; <span class="math inline">\(\overline{x}\)</span>, <span class="math inline">\(\overline{y}\)</span> son el valor promedio de <span class="math inline">\(x\)</span> y el valor promedio de <span class="math inline">\(y\)</span>; <span class="math inline">\(n\)</span> es el n√∫mero de puntos de datos en <span class="math inline">\(x\)</span> y <span class="math inline">\(y\)</span>.</p>
<p>Para el coeficiente de correlaci√≥n de una poblaci√≥n,</p>
<p><span id="eq-1.9"><span class="math display">\[
\rho_{xy}=\frac{Cov(x,y)}{\sigma_x\sigma_y}=\frac{\frac{\sum{(x_i-\overline{x})(y_i-\overline{y})}}{n}}{\sqrt{\frac{(x_i-\overline{x})^2}{n}}\sqrt{\frac{y_i-\overline{y})^2}{n}}}=\frac{\sum{(x_i-\overline{x})(y_i-\overline{y})}}{\sum{(x_i-\overline{x})^2(y_i-\overline{y})^2}}
\tag{9}\]</span></span></p>
<p>Aqu√≠, <span class="math inline">\(\rho_{xy}\)</span> es el coeficiente de correlaci√≥n de poblaci√≥n entre dos variables <span class="math inline">\(x\)</span> y <span class="math inline">\(y\)</span>; <span class="math inline">\(Cov(x, y)\)</span> es la covarianza de poblaci√≥n entre dos variables <span class="math inline">\(x\)</span> y <span class="math inline">\(y\)</span>; <span class="math inline">\(\sigma_x\)</span> , <span class="math inline">\(\sigma_y\)</span> son la desviaci√≥n est√°ndar de poblaci√≥n de <span class="math inline">\(x\)</span> y <span class="math inline">\(y\)</span>; <span class="math inline">\(\overline{x}\)</span>, <span class="math inline">\(\overline{y}\)</span> son el valor promedio de <span class="math inline">\(x\)</span> y el valor promedio de <span class="math inline">\(y\)</span> y <span class="math inline">\(n\)</span> es el n√∫mero de puntos de datos en <span class="math inline">\(x\)</span> y <span class="math inline">\(y\)</span>.</p>
<p>El valor del coeficiente de correlaci√≥n de Pearson var√≠a entre -1 y 1. Aqu√≠, -1 indica una correlaci√≥n negativa perfecta, y el valor 1 indica una correlaci√≥n positiva perfecta. Un coeficiente de correlaci√≥n de 0 significa que no hay correlaci√≥n. El coeficiente de correlaci√≥n de Pearson se aplica cuando los datos de ambas variables provienen de una distribuci√≥n normal, no hay outliers en los datos y la relaci√≥n entre las dos variables es lineal.</p>
<p><em>Coeficiente de Correlaci√≥n de Spearman</em></p>
<p>El Coeficiente de Correlaci√≥n de Spearman determina la relaci√≥n no-param√©trica entre los rangos de dos variables, es decir, el c√°lculo se realiza entre los rangos de las dos variables en lugar de los datos en s√≠ mismos. Los rangos se determinan generalmente asignando el rango 1 al dato m√°s peque√±o, el rango 2 al siguiente dato m√°s peque√±o y as√≠ sucesivamente hasta el dato m√°s grande. Por ejemplo, los datos contenidos en una variable son {55, 25, 78, 100, 96, 54}. Por lo tanto, el rango para esa variable particular ser√° {3, 1, 4, 6, 5, 2}. Al calcular los rangos de ambas variables, se puede calcular el coeficiente de correlaci√≥n de Spearman como sigue:</p>
<p><span id="eq-1.10"><span class="math display">\[
\rho=1-\frac{6\sum{d_i^2}}{n(n^2-1)}.
\tag{10}\]</span></span></p>
<p>Aqu√≠, <span class="math inline">\(\rho\)</span> es el coeficiente de correlaci√≥n de Spearman, <span class="math inline">\(n\)</span> es el n√∫mero de puntos de datos en las variables y <span class="math inline">\(d_i\)</span> es la diferencia de rango en el i-√©simo dato.</p>
<p>El coeficiente de correlaci√≥n de Pearson determina la linealidad de la relaci√≥n, mientras que el coeficiente de correlaci√≥n de Spearman determina la monotonicidad de la relaci√≥n. La representaci√≥n gr√°fica de la monotonicidad de la relaci√≥n se muestra en la Fig. 1.10.</p>
<p>A diferencia de una relaci√≥n lineal, el ritmo de cambio de los datos no es siempre el mismo en una relaci√≥n monot√≥nica. Si el ritmo de cambio es en la misma direcci√≥n para ambas variables, la relaci√≥n es positiva monot√≥nica. Por otro lado, si la direcci√≥n es opuesta para ambas variables, la relaci√≥n es negativa monot√≥nica. La relaci√≥n se llama no-monot√≥nica cuando la direcci√≥n del cambio no es siempre la misma o opuesta, sino una combinaci√≥n.</p>
<p>El valor del coeficiente de correlaci√≥n de Spearman var√≠a entre -1 y 1. Un valor de -1 indica una correlaci√≥n negativa perfecta (correlaci√≥n negativa de rango), un valor de 1 indica una correlaci√≥n positiva perfecta (correlaci√≥n positiva de rango) y un valor de 0 indica que no hay correlaci√≥n. El coeficiente de correlaci√≥n de Spearman se utiliza cuando se cumplen uno o m√°s condiciones del coeficiente de correlaci√≥n de Pearson.</p>
<p>Adem√°s de estos dos coeficientes de correlaci√≥n, tambi√©n se utilizan otros como: coeficiente de correlaci√≥n de rango de Cramer (Cramer‚Äôs <span class="math inline">\(\tau\)</span>), coeficiente de correlaci√≥n de Kendall (Kendall‚Äôs <span class="math inline">\(\varphi\)</span>), coeficiente biserial de punto. El uso de los diferentes coeficientes de correlaci√≥n depende del tipo de aplicaci√≥n y del tipo de datos.</p>
</section>
</section>
<section id="anomal√≠as" class="level4">
<h4 class="anchored" data-anchor-id="anomal√≠as">Anomal√≠as</h4>
<p>Una anomal√≠a es un punto de datos en el conjunto de datos que posee propiedades diferentes a todas las dem√°s y, por lo tanto, var√≠a significativamente del patr√≥n de otras observaciones. Se trata del valor que tiene la mayor deviaci√≥n del patr√≥n t√≠pico seguido por todos los dem√°s valores en el conjunto de datos.</p>
<p>Los algoritmos de ML tienen una alta sensibilidad a la distribuci√≥n y el rango de valores de atributos. Las anomal√≠as tienen la tendencia a confundir el proceso de entrenamiento del algoritmo, lo que eventualmente conduce a observaciones err√≥neas, resultados inexactos, tiempos de entrenamiento m√°s largos y resultados pobres.</p>
<p>Considera el conjunto de datos <span class="math inline">\((x, y)\)</span>. Aqu√≠, <span class="math inline">\(x\)</span> es la tasa de consumo de agua por d√≠a y <span class="math inline">\(y\)</span> es la tasa de consumo de electricidad por d√≠a. En la <a href="#fig-outliers">Figura 1.11</a>, podemos ver que estos datos se distribuyen en 2 grupos diferentes, pero uno de los puntos de datos no puede agruparse con ninguno de estos grupos. Este punto de datos act√∫a como una anomal√≠a en este caso.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-outliers" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-outliers-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="index_files/figure-html/fig-outliers-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-outliers-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;10: Fig. 1.11. Representaci√≥n de un valor at√≠pico. Los puntos negros se encuentran dentro de l√≠mites espec√≠ficos, pero un punto azul est√° m√°s all√° de esos c√≠rculos de datos. El punto azul es un valor at√≠pico.
</figcaption>
</figure>
</div>
</div>
</div>
<p>Es importante destacar que ruido y anomal√≠as son dos cosas diferentes. Mientras que una anomal√≠a es un valor de datos significativamente desviado, el ruido es simplemente un valor err√≥neo.</p>
<p>La <a href="#fig-anomalia">Figura 1.12</a> visualiza la diferencia entre anomal√≠a y ruido utilizando una se√±al.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-anomalia" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-anomalia-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="index_files/figure-html/fig-anomalia-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-anomalia-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;11: Fig. 1.12. Diferencia entre anomal√≠a y ruido.
</figcaption>
</figure>
</div>
</div>
</div>
<p>Considera una lista de 100 precios de casas, que principalmente incluye precios que van desde los 3000 hasta los 5000 d√≥lares. Primero, hay una casa en la lista con un precio de 20,000 d√≥lares. Luego, hay una casa en la lista con un precio de -100 d√≥lares. 20,000 es una anomal√≠a aqu√≠, ya que difiere significativamente de los dem√°s precios de casas. Por otro lado, -100 es un ruido, ya que el precio de algo no puede ser un valor negativo. Dado que la anomal√≠a distorsiona significativamente la media aritm√©tica del conjunto de datos y conduce a observaciones err√≥neas, eliminar anomal√≠as del conjunto de datos es el requisito previo para lograr el resultado correcto.</p>
</section>
<section id="histograma" class="level4">
<h4 class="anchored" data-anchor-id="histograma">Histograma</h4>
<p>Un histograma se asemeja a un gr√°fico de columnas y representa la distribuci√≥n de frecuencia de los datos en barras verticales en un sistema de ejes bidimensional. Los histogramas tienen la capacidad de expresar los datos de manera estructurada, lo que facilita la visualizaci√≥n de datos. Las barras en un histograma se colocan al lado uno del otro sin espacios en blanco entre ellas. El histograma agrupa los datos en barras, lo que proporciona una comprensi√≥n clara de la distribuci√≥n de los datos. La disposici√≥n tambi√©n proporciona una comprensi√≥n clara de la distribuci√≥n de los datos seg√∫n sus caracter√≠sticas en el conjunto de datos.</p>
<p>La Figura 1.13 ilustra tres tipos de histogramas, con una distribuci√≥n desviada a la izquierda, una distribuci√≥n normal y una distribuci√≥n desviada a la derecha.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-histogramas" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-histogramas-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="index_files/figure-html/fig-histogramas-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-histogramas-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;12: Fig. 1.13. Representaci√≥n de varias distribuciones usando histogramas.
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="errores" class="level4">
<h4 class="anchored" data-anchor-id="errores">Errores</h4>
<p>El conocimiento de los errores es √∫til al evaluar la precisi√≥n de un modelo de aprendizaje autom√°tico (ML). En particular, cuando se prueba el modelo entrenado contra un conjunto de datos de prueba, se compara el resultado del modelo con el resultado conocido del conjunto de datos de prueba. La deviaci√≥n entre los datos predichos y los datos reales se conoce como el error. Si el error est√° dentro de los l√≠mites tolerables, entonces el modelo est√° listo para usar; en caso contrario, debe ser reentrenado para mejorar su precisi√≥n.</p>
<p>Hay varios m√©todos para estimar la precisi√≥n del rendimiento de un modelo de ML. Algunos de los m√©todos m√°s populares son medir el porcentaje de error absoluto promedio (MAPE), el error cuadrado medio (MSE), el error absoluto medio (MAE) y el error raiz cuadrado medio (RMSE). En las ecuaciones de la Tabla 1.7, <span class="math inline">\(n\)</span> representa el n√∫mero total de veces que ocurre la iteraci√≥n, <span class="math inline">\(t\)</span> representa una iteraci√≥n espec√≠fica o una instancia del conjunto de datos, <span class="math inline">\(e_t\)</span> es la diferencia entre el valor real y el valor predicho del punto de datos, y <span class="math inline">\(y_t\)</span> es el valor real.</p>
<div id="tbl-errores" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-errores-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Tabla&nbsp;7: Tabla 1.7. Diferentes tipos de errores
</figcaption>
<div aria-describedby="tbl-errores-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 36%">
<col style="width: 63%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Nombre del error</th>
<th style="text-align: center;">Ecuaci√≥n</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Error cuadr√°tico medio</td>
<td style="text-align: center;"><span class="math display">\[
MSE=\frac{1}{n}\sum_{t=1}^ne_t^2
\]</span></td>
</tr>
<tr class="even">
<td style="text-align: center;">Ra√≠z del error cuadr√°tico medio</td>
<td style="text-align: center;"><span class="math display">\[
RMSE=\sqrt{\frac{1}{n}\sum_{t=1}^ne_t^2}
\]</span></td>
</tr>
<tr class="odd">
<td style="text-align: center;">Error absoluto medio</td>
<td style="text-align: center;"><span class="math display">\[
MAE=\sqrt{\frac{1}{n}\sum_{t=1}^n|e_t|}
\]</span></td>
</tr>
<tr class="even">
<td style="text-align: center;">Error porcentual absoluto medio</td>
<td style="text-align: center;"><span class="math display">\[
MAPE=\frac{100%}{n}\sqrt{\sum_{t=1}^n|\frac{e_t}{y_t}|}
\]</span></td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>El concepto de errores es vital para crear un modelo de ML preciso para varios prop√≥sitos. Estos se describen con mayor profundidad en la Secci√≥n 2.2 del Cap√≠tulo 2.</p>
</section>
</section>
<section id="teor√≠a-de-la-probabilidad" class="level3">
<h3 class="anchored" data-anchor-id="teor√≠a-de-la-probabilidad">Teor√≠a de la Probabilidad</h3>
<p>La probabilidad es una medida de la probabilidad de que un evento espec√≠fico ocurra.</p>
<p>La probabilidad se encuentra entre 0 y 1, donde 0 significa que el evento nunca ocurrir√° y 1 significa que el evento es seguro de ocurrir. La probabilidad se define como la ratio del n√∫mero de resultados deseados al n√∫mero total de resultados.</p>
<p><span id="eq-1.11"><span class="math display">\[P(A)=\frac{n(A)}{n}. \tag{11}\]</span></span></p>
<p>Donde <span class="math inline">\(P (A)\)</span> denota la probabilidad de un evento <span class="math inline">\(A\)</span>, <span class="math inline">\(n (A)\)</span> denota el n√∫mero de ocurrencias del evento <span class="math inline">\(A\)</span> y <span class="math inline">\(n\)</span> denota el n√∫mero total de resultados posibles, tambi√©n conocido como el espacio muestral.</p>
<p>Vamos a ver un ejemplo com√∫n. Un dado est√°ndar con seis caras contiene un n√∫mero entre 1 y 6 en cada una de las caras. Cuando se lanza un dado, cualquier uno de los seis n√∫meros puede aparecer en la cara superior. Por lo tanto, la probabilidad de obtener un 6 en el dado se determina seg√∫n se muestra en la ecuaci√≥n 1.12.</p>
<p><span id="eq-1.12"><span class="math display">\[
P(6)=\frac{1}{6}=0.167=16.7\text{%}
\tag{12}\]</span></span></p>
<p>La teor√≠a de la probabilidad es el campo que abarca las matem√°ticas relacionadas con la probabilidad. Cualquier algoritmo de aprendizaje depende de la suposici√≥n probabil√≠stica de los datos. Como los modelos de ML manejan la incertidumbre de los datos, el ruido, la distribuci√≥n de probabilidad, etc., varios conceptos fundamentales de la teor√≠a de la probabilidad son necesarios, que se cubren en esta secci√≥n 1.5.3.</p>
<section id="distribuci√≥n-de-probabilidad" class="level4">
<h4 class="anchored" data-anchor-id="distribuci√≥n-de-probabilidad">Distribuci√≥n de Probabilidad</h4>
<p>En la teor√≠a de la probabilidad, todos los posibles resultados num√©ricos de cualquier experimento se representan mediante variables aleatorias. Una funci√≥n de distribuci√≥n de probabilidad produce los valores num√©ricos posibles de una variable aleatoria dentro de un rango espec√≠fico. Las variables aleatorias son de dos tipos: discretas y continuas. Por lo tanto, la distribuci√≥n de probabilidad se puede categorizar en dos tipos seg√∫n el tipo de variable aleatoria involucrada‚Äîfunci√≥n de densidad de probabilidad y funci√≥n de masa de probabilidad.</p>
<section id="funci√≥n-de-densidad-de-probabilidad" class="level5">
<h5 class="anchored" data-anchor-id="funci√≥n-de-densidad-de-probabilidad">Funci√≥n de Densidad de Probabilidad</h5>
<p>Los valores num√©ricos posibles de una variable aleatoria continua se pueden calcular utilizando la funci√≥n de densidad de probabilidad (PDF). La representaci√≥n gr√°fica de esta distribuci√≥n es continua. Por ejemplo, en la <a href="#fig-funcionFDP">Figura 1.14</a>, cuando un modelo busca la probabilidad de la altura de las personas en el rango de 160-170 cm, podr√≠a utilizar una PDF para indicar la probabilidad total de que el rango de la variable aleatoria continua ocurra. Aqu√≠, f (x) es la PDF de la variable aleatoria x.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-funcionFDP" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-funcionFDP-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="index_files/figure-html/fig-funcionFDP-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-funcionFDP-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;13: Fig. 1.14. Ejemplo de funci√≥n de densidad de probabilidad.
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="funci√≥n-de-masa-de-probabilidad" class="level5">
<h5 class="anchored" data-anchor-id="funci√≥n-de-masa-de-probabilidad">Funci√≥n de Masa de Probabilidad</h5>
<p>Cuando se implementa una funci√≥n para encontrar los valores num√©ricos posibles de una variable aleatoria discreta, la funci√≥n se conoce como funci√≥n de masa de probabilidad (PMF). Las variables aleatorias discretas tienen un n√∫mero finito de valores. Por lo tanto, no obtenemos una curva continua cuando se representa gr√°ficamente la PMF. Por ejemplo, si consideramos el lanzamiento de un dado de seis caras, tendremos un n√∫mero finito de resultados, como se muestra en la <a href="#fig-funcionFMP">Figura 1.15</a>.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-funcionFMP" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-funcionFMP-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="index_files/figure-html/fig-funcionFMP-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-funcionFMP-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;14: Fig. 1.15. Ejemplo de funci√≥n de masa de probabilidad.
</figcaption>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="distribuci√≥n-gaussiana-o-distribuci√≥n-normal" class="level4">
<h4 class="anchored" data-anchor-id="distribuci√≥n-gaussiana-o-distribuci√≥n-normal">Distribuci√≥n Gaussiana o Distribuci√≥n Normal</h4>
<p>La probabilidad acumulada de variables aleatorias normales se presenta en la distribuci√≥n Gaussiana o normal. El gr√°fico depende de la media y la distribuci√≥n est√°ndar de los datos. En una distribuci√≥n est√°ndar, la media de los datos es 0 y la desviaci√≥n est√°ndar es 1. Un gr√°fico de distribuci√≥n normal es una curva en forma de campana, como se muestra en la <a href="#fig-normalDistr">Fig. 1.16</a>. Por lo tanto, tambi√©n se conoce como distribuci√≥n de curva en forma de campana.</p>
<p>La ecuaci√≥n que representa la distribuci√≥n Gaussiana o normal es:</p>
<p><span id="eq-1.13"><span class="math display">\[
P(x)=\frac{1}{\alpha\sqrt{2\pi}}e^{\frac{-(x+\mu)^2}{2\alpha^2}}
\tag{13}\]</span></span></p>
<p>Donde <span class="math inline">\(P(x)\)</span> denota la densidad de probabilidad de la distribuci√≥n normal, <span class="math inline">\(Œ±\)</span> denota la desviaci√≥n est√°ndar, <span class="math inline">\(Œº\)</span> denota la media del conjunto de datos y <span class="math inline">\(x\)</span> denota un punto de datos.</p>
</section>
<section id="distribuci√≥n-de-bernoulli" class="level4">
<h4 class="anchored" data-anchor-id="distribuci√≥n-de-bernoulli">Distribuci√≥n de Bernoulli</h4>
<p>Una distribuci√≥n de probabilidad sobre el ensayo de Bernoulli es la distribuci√≥n de Bernoulli. El ensayo de Bernoulli es un experimento o evento que solo tiene dos resultados. Por ejemplo, lanzar una moneda se puede considerar como un ensayo de Bernoulli, ya que solo puede tener dos resultados - cara o sello. Normalmente, los resultados se observan en t√©rminos de √©xito o fracaso. En este caso, podemos decir que obtener una cara ser√° un √©xito. Por otro lado, no obtener una cara o obtener un sello ser√≠a un fracaso. La distribuci√≥n de Bernoulli se ha visualizado en la <a href="#fig-bernoulliDistr">Fig. 1.17</a>, que plotea la probabilidad de dos ensayos.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-normalDistr" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-normalDistr-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="index_files/figure-html/fig-normalDistr-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-normalDistr-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;15: Fig. 1.16. Distribuci√≥n normal.
</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="fig-bernoulliDistr" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-bernoulliDistr-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="index_files/figure-html/fig-bernoulliDistr-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-bernoulliDistr-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;16: Fig. 1.17. Distribuci√≥n de Bernoulli
</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="fig-centralTeorema" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-centralTeorema-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="index_files/figure-html/fig-centralTeorema-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-centralTeorema-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;17: Fig. 1.18. Demostraci√≥n gr√°fica del teorema del l√≠mite central.
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="teorema-del-l√≠mite-central" class="level4">
<h4 class="anchored" data-anchor-id="teorema-del-l√≠mite-central">Teorema del L√≠mite Central</h4>
<p>Considera un conjunto de datos grande de cualquier distribuci√≥n. El teorema del l√≠mite central afirma que, independientemente de la distribuci√≥n de los n√∫meros en el conjunto de datos, la media aritm√©tica de las muestras de datos extra√≠das del conjunto de datos principal tendr√° una distribuci√≥n normal. Cuanto mayor sea el tama√±o de la muestra, m√°s cerca estar√° la media de una distribuci√≥n normal. El teorema se ha demostrado en la <a href="#fig-centralTeorema">Fig. 1.18</a>. Se puede ver que la poblaci√≥n no sigue una distribuci√≥n normal, pero cuando se muestrea la media, la muestra forma una distribuci√≥n normal.</p>
</section>
</section>
<section id="c√°lculo" class="level3">
<h3 class="anchored" data-anchor-id="c√°lculo">C√°lculo</h3>
<p>El c√°lculo de Newton es ampliamente √∫til para resolver una variedad de problemas. Uno de los algoritmos m√°s populares de ML es el algoritmo de <strong>descenso de gradientes</strong>. El algoritmo de descenso de gradientes, junto con la retropropagaci√≥n (backpropagation), es √∫til en el proceso de entrenamiento de modelos de ML, que dependen intensivamente del c√°lculo. Por lo tanto, el c√°lculo diferencial, el c√°lculo integral y las ecuaciones diferenciales son todos aspectos necesarios para familiarizarse con antes de estudiar ML.</p>
<section id="derivada-y-pendiente" class="level4">
<h4 class="anchored" data-anchor-id="derivada-y-pendiente">Derivada y Pendiente</h4>
<p>La derivada se define como la tasa de cambio de una funci√≥n con respecto a una variable. Por ejemplo, la velocidad de un coche es la derivada de la desplazamiento del coche con respecto al tiempo. La derivada es equivalente a la pendiente de una l√≠nea en un punto espec√≠fico. La pendiente ayuda a visualizar c√≥mo empinada es una l√≠nea. Una l√≠nea con una pendiente m√°s alta es m√°s empinada que una l√≠nea con una pendiente m√°s baja. El concepto de pendiente se muestra en la <a href="#fig-pendiente">Figura 1.19</a>.</p>
<p><span id="eq-1.14"><span class="math display">\[
pendiente, m =\frac{\Delta{y}}{\Delta{x}}
\tag{14}\]</span></span></p>
<p>Se utiliza ampliamente la derivada en ML, especialmente en problemas de optimizaci√≥n, como el descenso de gradientes. Por ejemplo, en el descenso de gradientes, se utilizan derivadas para encontrar el camino m√°s empinado para maximizar o minimizar una funci√≥n objetivo (por ejemplo, la precisi√≥n o funci√≥n de error de un modelo).</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-pendiente" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-pendiente-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="index_files/figure-html/fig-pendiente-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-pendiente-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;18: Fig. 1.19. Ilustraci√≥n concepto de pendiente.
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="derivadas-parciales" class="level4">
<h4 class="anchored" data-anchor-id="derivadas-parciales">Derivadas Parciales</h4>
<p>Si una funci√≥n depende de dos o m√°s variables, entonces la derivada parcial de la funci√≥n es su derivada con respecto a una de las variables, manteniendo las otras variables constantes. Las derivadas parciales se requieren para t√©cnicas de optimizaci√≥n en ML, que utilizan derivadas parciales para ajustar los pesos para cumplir con la funci√≥n objetivo. Las funciones objetivo son diferentes para cada problema. Por lo tanto, la derivada parcial ayuda a decidir si aumentar o disminuir los pesos para hacer un ajuste a la funci√≥n objetivo.</p>
</section>
<section id="m√°ximos-y-m√≠nimos" class="level4">
<h4 class="anchored" data-anchor-id="m√°ximos-y-m√≠nimos">M√°ximos y M√≠nimos</h4>
<p>Para una funci√≥n no lineal, el pico m√°s alto o el valor m√°ximo se refiere a los m√°ximos, y el pico m√°s bajo o el valor m√≠nimo se refiere a los m√≠nimos. En otras palabras, el punto en el que la derivada de una funci√≥n es cero se define como los m√°ximos o los m√≠nimos. Estos son los puntos en los que el valor de la funci√≥n se mantiene constante, es decir, la tasa de cambio es cero. Este concepto de m√°ximos y m√≠nimos es necesario para minimizar la funci√≥n de coste (diferencia entre el valor verdadero y el valor de salida) de cualquier modelo de ML. Un m√≠nimo local es el valor de una funci√≥n que es menor que los puntos vecinos, pero no necesariamente menor que todos los puntos en el espacio de soluci√≥n. Un m√≠nimo global es el valor m√°s peque√±o de la funci√≥n que existe en ese espacio de soluci√≥n. El caso es el mismo para m√°ximos globales y locales. Un m√°ximo local es el valor de una funci√≥n que es mayor que los puntos vecinos, pero no necesariamente mayor que todos los puntos en el espacio de soluci√≥n. Un m√°ximo global es el valor m√°s grande de la funci√≥n que existe en ese espacio de soluci√≥n. La <a href="#fig-derivadas">figura 1.20</a> muestra m√°ximos y m√≠nimos globales y locales en un espacio de soluci√≥n.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-derivadas" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-derivadas-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="index_files/figure-html/fig-derivadas-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-derivadas-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;19: Fig. 1.20. Representaci√≥n de m√°ximos y m√≠nimos.
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="ecuaci√≥n-diferencial" class="level4">
<h4 class="anchored" data-anchor-id="ecuaci√≥n-diferencial">Ecuaci√≥n Diferencial</h4>
<p>Una ecuaci√≥n diferencial (ED) representa la relaci√≥n entre una o m√°s funciones y sus derivadas con respecto a una o m√°s variables. Las EDs son muy √∫tiles en el modelado de sistemas y, por lo tanto, se pueden utilizar en ML para modelado din√°mico, especialmente en redes neuronales.</p>
<p>El siguiente es un ejemplo de una ecuaci√≥n diferencial:</p>
<p><span id="eq-1.15"><span class="math display">\[
\frac{d^2y}{dx^2}+4=1.
\tag{15}\]</span></span></p>
<section id="orden-y-grado" class="level5">
<h5 class="anchored" data-anchor-id="orden-y-grado">Orden y Grado</h5>
<p>En ecuaciones diferenciales, el orden m√°s alto de la derivada utilizada en la ecuaci√≥n es el orden de la ecuaci√≥n. El grado de una ecuaci√≥n diferencial es el poder de su derivada m√°s alta. Por ejemplo, esta es una ecuaci√≥n diferencial de cuarto orden y primer grado:</p>
<p><span id="eq-1.16"><span class="math display">\[
\frac{d^4y}{dx^4}+(\frac{d^2y}{dx^2})^2+4\frac{dy}{dx}+6x=0.
\tag{16}\]</span></span></p>
<p>aqu√≠, la derivada m√°s alta es <span class="math inline">\(\frac{d^4y}{dx^4}\)</span>. El orden de la derivada m√°s alta es 4, por lo que esta es una ecuaci√≥n diferencial de cuarto orden. El poder de la derivada m√°s alta es 1, y por lo tanto, esta es una ecuaci√≥n diferencial de primer grado. Algunos ejemplos adicionales se muestran en la Tabla 1.8</p>
<div id="tbl-ecuacionesDiff" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-ecuacionesDiff-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Tabla&nbsp;8: Tabla 1.8. Ecuaciones diferenciales con su grado y orden.
</figcaption>
<div aria-describedby="tbl-ecuacionesDiff-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 62%">
<col style="width: 18%">
<col style="width: 18%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Ecuaci√≥n</th>
<th style="text-align: center;">Orden</th>
<th style="text-align: center;">Grado</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><span class="math display">\[
    \frac{d^3y}{dx^3}+6x\frac{dy}{dx}=e^y
                              \]</span></td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math display">\[
    \frac{dy}{dx}+(\frac{d^2y}{dx^2})^3=7x
                              \]</span></td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">3</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math display">\[
    \frac{d^2y}{dx^2}+(\frac{dy}{dx})^3=7x
                              \]</span></td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">1</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</section>
<section id="ecuaci√≥n-diferencial-ordinaria-y-parcial" class="level5">
<h5 class="anchored" data-anchor-id="ecuaci√≥n-diferencial-ordinaria-y-parcial">Ecuaci√≥n Diferencial Ordinaria y Parcial</h5>
<p>Como se discuti√≥ anteriormente, las ecuaciones diferenciales pueden tener m√°s de una variable. Cuando una ecuaci√≥n consiste en diferenciales con respecto a una variable, se llama ecuaci√≥n diferencial ordinaria (EDO). Por otro lado, cuando la ecuaci√≥n involucra diferenciales con respecto a m√°s de una variable, se conoce como ecuaci√≥n diferencial parcial (EDP). El s√≠mbolo <span class="math inline">\(d\)</span> se utiliza para ecuaciones diferenciales ordinarias y el s√≠mbolo <span class="math inline">\(\partial\)</span> se utiliza para ecuaciones diferenciales parciales.</p>
<p>Por ejemplo: <span class="math inline">\(\frac{d^2y}{dx^2} + \frac{dy}{dx} + 1 = 0\)</span> es una EDO y <span class="math inline">\(\frac{\partial^2y}{\partial{x}^2} + \frac{\partial{y}}{\partial{x}} + 1 = 0\)</span> es una EDP.</p>
</section>
<section id="ecuaci√≥n-lineal-y-no-lineal" class="level5">
<h5 class="anchored" data-anchor-id="ecuaci√≥n-lineal-y-no-lineal">Ecuaci√≥n Lineal y No Lineal</h5>
<p>Las ecuaciones pueden tener variables dependientes e independientes. Estas variables pueden tener grados m√°s altos dependiendo del tipo de ecuaci√≥n. Cuando las ecuaciones diferenciales contienen variables dependientes con grado 1, se consideran ecuaciones diferenciales lineales. Por otro lado, si las ecuaciones diferenciales contienen variables dependientes con un grado m√°s alto, se consideran ecuaciones diferenciales no lineales.</p>
<p>Por ejemplo, en la ecuaci√≥n <span class="math inline">\(\frac{d^2y}{dx^2} + \frac{dy}{dx} + 1 = 0\)</span>, el grado de la derivada m√°s alta es 1. Por lo tanto, es una ecuaci√≥n lineal. De nuevo, la ecuaci√≥n <span class="math inline">\((\frac{dy}{dx})^2 + x = 0\)</span> tiene 2 como su grado de la derivada m√°s alta. Por lo tanto, es un ejemplo de ecuaci√≥n no lineal.</p>
<p>Hasta aqu√≠ tienes los conceptos b√°sicos que deber√≠as revisar, repasar, aprender o profundizar, para lograr aplicar ML.</p>


</section>
</section>
</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">C√≥mo citar</h2><div><div class="quarto-appendix-secondary-label">BibTeX</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{chiquito_valencia2025,
  author = {Chiquito Valencia, Cristian},
  title = {Introducci√≥n Al {Machine} {Learning}},
  date = {2025-02-05},
  url = {https://cchiquitovalencia.github.io/posts/2025-02-05-intro_ml/},
  langid = {en}
}
</code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">Por favor, cita este trabajo como:</div><div id="ref-chiquito_valencia2025" class="csl-entry quarto-appendix-citeas" role="listitem">
Chiquito Valencia, Cristian. 2025. <span>‚ÄúIntroducci√≥n Al Machine
Learning.‚Äù</span> February 5, 2025. <a href="https://cchiquitovalencia.github.io/posts/2025-02-05-intro_ml/">https://cchiquitovalencia.github.io/posts/2025-02-05-intro_ml/</a>.
</div></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "Óßã";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copiado");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copiado");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/cchiquitovalencia\.github\.io\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
 Copyright 2025, Cristian Chiquito Valencia
  </li>  
</ul>
    </div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/cchiquitovalencia/">
      <i class="bi bi-linkedin" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/cchiquitovalencia/">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="mailto:cchiquito.valencia@gmail.com">
      <i class="bi bi-envelope-at-fill" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://x.com/cchiquitov">
      <i class="bi bi-twitter" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>




</body></html>