[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Cristian Chiquito Valencia",
    "section": "",
    "text": "Logistics, Specialist | Universidad del Valle (September 2019)\nIndustrial Engineer, B.S. | Universidad Icesi (February 2015)\n\n\n\nMaintenance Manager @ Grupo Integrado de Transporte Masivo S.A. (_August 2022 - Present)\n- Ensure compliance with the clauses of the current concession contract and its respective others that correspond to the Maintenance area for the provision of the public mass passenger transportation service within the integrated mass transportation system of Santiago de Cali of the Managing Entity. - Implement, standardize and improve the management of your process in order to guarantee compliance with the company’s objectives and the Integrated Management System. - Guarantee compliance with contractual commitments with the Managing Entity, guaranteeing the availability and reliability of the fleet as well as its preventive maintenance. - Develop strategies to increase the productivity levels of the process taking into account the associated resources available by the organization. - Coordinate and provide the necessary resources for the management carried out by the maintenance area collaborators. - Guarantee compliance with commitments with the integrated management system defined by the organization and establish improvement plans when necessary. - Develop knowledge management projects within the maintenance area through process automation and productivity improvement, as well as identify training and qualification needs of the collaborators in charge. - Synergistically ensure with the Operations Department the availability and reliability of the fleet. - Establish and supervise the execution of service agreements agreed upon with suppliers associated with the maintenance area, evaluating and reevaluating the management developed by them. - Plan the implementation, creation and development of projects, plans, activities and/or acquisition of new suppliers that aim to improve the Maintenance process.\nLeader of operational services plan and data analysis @ Grupo Integrado de Transporte Masivo S.A. (_February 2019 - July 2022)\n- Plan, propose and implement process improvement projects through the use of descriptive and inferential statistics. - Apply engineering techniques to achieve cost reduction in production management through resource optimization. - Analyze and evaluate the profitability of resources dedicated to production for decision making. - Presentation of reports, analysis and statistics on a regular basis. - Actively participate in the planning and programming of the distribution of kilometers. - Pose and establish process optimization models through the statistical analysis of distribution and programming data. - Schedule route trips in accordance with the designed offer defined in the Operation Services Plan. - Adjust opening and closing trips that guarantee service coverage to the user up to the times defined in the designed offer. - Determine necessary fleet by type of vehicle according to the designed service offer. - Prepare information to export data to the control center, vehicles and dispatches with part of the fleet operation support system. - Generate preliminary reports, input for optimizing operator shifts.\nProduction Engineer @ Grupo Integrado de Transporte Masivo S.A. (_March 2015 - February 2019)\n- Planning, control and administration of the vehicle fleet. - Programming of yard operators for different activities related to the production area. - Responsible for supervising and controlling operators and technicians, track inspectors and operation controllers. - Coordinate and evaluate operation processes in other yards. Analyze causes of non-compliance with company objectives. - Monitoring and control of corrective and preventive maintenance times.\n\n\n\nDevelopment and implementation of a methodology for detecting atypical trips through the use of control charts for transportation times in the city of Cali.\nCreation and administration of a linear programming model in R language to optimize the distribution of kilometers in service, guaranteeing the expected income and minimizing the cost per empty kilometers and the number of operator-hours."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "¿Qué puedes encontrar?",
    "section": "",
    "text": "¿Te gustaría aprender a usar la programación lineal para optimizar tus procesos y mejorar tus resultados? ¿Quieres conocer los beneficios de usar los lenguajes R y BI para el análisis de datos? ¿Te interesa saber cómo la estadística puede ayudarte a tomar mejores decisiones en tu negocio? Si la respuesta es sí, este blog es para ti.\nEn este blog, te enseñaré todo lo que necesitas saber sobre estadística, datos, programación lineal, lenguajes R y BI, mejora de procesos. Te mostraré cómo aplicar estas herramientas y técnicas en casos reales y prácticos, para que puedas resolver problemas complejos, reducir costos, aumentar ganancias, mejorar la calidad y la satisfacción de tus clientes.\nLa estadística es la ciencia que se encarga de recopilar, organizar, analizar e interpretar datos numéricos, con el fin de extraer conclusiones y hacer inferencias sobre una población o un fenómeno de interés. La estadística es fundamental para el diseño de experimentos, la prueba de hipótesis, la estimación de parámetros, la predicción de tendencias, etc.\nLa programación lineal es una técnica matemática que se utiliza para optimizar el rendimiento o la eficiencia de un sistema. Se basa en la idea de maximizar o minimizar una función lineal sujeta a un conjunto de restricciones lineales. En otras palabras, se trata de encontrar la mejor manera de asignar recursos limitados para lograr un objetivo específico.\nLos lenguajes R y BI son dos de los más populares y poderosos para el análisis de datos. R es un lenguaje de programación y un entorno de software libre que permite realizar todo tipo de operaciones estadísticas, gráficas y de modelado. BI (Business Intelligence) es un conjunto de herramientas y metodologías que permiten transformar los datos en información útil y relevante para la toma de decisiones.\nLa mejora de procesos es una estrategia de gestión que busca aumentar la eficacia y la eficiencia de los procesos de una organización, mediante la identificación, el análisis, la medición, el control y la mejora continua de los mismos. La mejora de procesos se basa en el uso de metodologías, herramientas y técnicas como el ciclo PDCA, el diagrama de Ishikawa, el análisis de Pareto, el Six Sigma, el Lean, etc.\nSi quieres aprender más sobre estos temas y ver cómo puedes aplicarlos en tu negocio, te invito a que sigas leyendo este blog y que te suscribas a mi newsletter(próximamente), donde te enviaré contenido exclusivo, consejos, recursos y ofertas especiales. También puedes dejarme un comentario, una pregunta o una sugerencia, y con gusto te responderé. Gracias por tu atención y hasta pronto."
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Cristian Chiquito Valencia",
    "section": "",
    "text": "Logistics, Specialist | Universidad del Valle (September 2019)\nIndustrial Engineer, B.S. | Universidad Icesi (February 2015)\n\n\n\nMaintenance Manager @ Grupo Integrado de Transporte Masivo S.A. (_August 2022 - Present)\n- Ensure compliance with the clauses of the current concession contract and its respective others that correspond to the Maintenance area for the provision of the public mass passenger transportation service within the integrated mass transportation system of Santiago de Cali of the Managing Entity. - Implement, standardize and improve the management of your process in order to guarantee compliance with the company’s objectives and the Integrated Management System. - Guarantee compliance with contractual commitments with the Managing Entity, guaranteeing the availability and reliability of the fleet as well as its preventive maintenance. - Develop strategies to increase the productivity levels of the process taking into account the associated resources available by the organization. - Coordinate and provide the necessary resources for the management carried out by the maintenance area collaborators. - Guarantee compliance with commitments with the integrated management system defined by the organization and establish improvement plans when necessary. - Develop knowledge management projects within the maintenance area through process automation and productivity improvement, as well as identify training and qualification needs of the collaborators in charge. - Synergistically ensure with the Operations Department the availability and reliability of the fleet. - Establish and supervise the execution of service agreements agreed upon with suppliers associated with the maintenance area, evaluating and reevaluating the management developed by them. - Plan the implementation, creation and development of projects, plans, activities and/or acquisition of new suppliers that aim to improve the Maintenance process.\nLeader of operational services plan and data analysis @ Grupo Integrado de Transporte Masivo S.A. (_February 2019 - July 2022)\n- Plan, propose and implement process improvement projects through the use of descriptive and inferential statistics. - Apply engineering techniques to achieve cost reduction in production management through resource optimization. - Analyze and evaluate the profitability of resources dedicated to production for decision making. - Presentation of reports, analysis and statistics on a regular basis. - Actively participate in the planning and programming of the distribution of kilometers. - Pose and establish process optimization models through the statistical analysis of distribution and programming data. - Schedule route trips in accordance with the designed offer defined in the Operation Services Plan. - Adjust opening and closing trips that guarantee service coverage to the user up to the times defined in the designed offer. - Determine necessary fleet by type of vehicle according to the designed service offer. - Prepare information to export data to the control center, vehicles and dispatches with part of the fleet operation support system. - Generate preliminary reports, input for optimizing operator shifts.\nProduction Engineer @ Grupo Integrado de Transporte Masivo S.A. (_March 2015 - February 2019)\n- Planning, control and administration of the vehicle fleet. - Programming of yard operators for different activities related to the production area. - Responsible for supervising and controlling operators and technicians, track inspectors and operation controllers. - Coordinate and evaluate operation processes in other yards. Analyze causes of non-compliance with company objectives. - Monitoring and control of corrective and preventive maintenance times.\n\n\n\nDevelopment and implementation of a methodology for detecting atypical trips through the use of control charts for transportation times in the city of Cali.\nCreation and administration of a linear programming model in R language to optimize the distribution of kilometers in service, guaranteeing the expected income and minimizing the cost per empty kilometers and the number of operator-hours."
  },
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Recursos",
    "section": "",
    "text": "Aquí se encuentran las ramas de creaciones."
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Mi Blog",
    "section": "",
    "text": "Iterated Local serach\n\n\n\nR\n\n\noptimización\n\n\n\nBúsqueda Local Iterada\n\n\n\nCristian Chiquito Valencia\n\n\nNov 18, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdaptative Random Search\n\n\n\nR\n\n\noptimización\n\n\n\nBúsqueda aleatoria adaptativa\n\n\n\nCristian Chiquito Valencia\n\n\nNov 13, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRandom Search\n\n\n\nR\n\n\noptimización\n\n\n\nBúsqueda aleatoria\n\n\n\nCristian Chiquito Valencia\n\n\nNov 13, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStochastic Hill Climbing\n\n\n\nR\n\n\noptimización\n\n\n\nEscalada estocástica\n\n\n\nCristian Chiquito Valencia\n\n\nNov 13, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n¿Cómo crear un post?\n\n\n\nQuarto\n\n\nR\n\n\n\nParece ser una buena manera de conservar un buen flujo de trabajo\n\n\n\nCristian Chiquito Valencia\n\n\nNov 12, 2023\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2023-11-12-crear_un_post/index.html",
    "href": "posts/2023-11-12-crear_un_post/index.html",
    "title": "¿Cómo crear un post?",
    "section": "",
    "text": "Ahora que ya tienes tu página configurada, puedes empezar a llenarla con entradas de blog. Repite los siguientes pasos cada vez que desees añadir un nuevo post.\nCrea un subdirectorio dentro de tu directorio posts/: Para mantenerme organizado, suelo nombrar el mío YYYY-MM-DD-describe_post. Este nombre de carpeta también se convertirá en la parte identificativa única de una dirección web (normalmente al final de la URL) de tu post publicado.\nDentro de tu nuevo subdirectorio, crea un archivo index.qmd. El nombre es importante. Debe llamarse index.qmd. La ruta del archivo debe ser similar a la siguiente: …/posts/2023-11-12-crear_un_post/index.qmd. Este archivo es la entrada de tu blog. Escribe todo el contenido aquí. Configure su entrada de blog: Puedes añadir diferentes opciones a la sección YAML de index.qmd.\n\nrunif(1,0,100)\n\n[1] 28.83341\n\n\n\n\n\nCitationBibTeX citation:@online{chiquito valencia2023,\n  author = {Chiquito Valencia, Cristian},\n  title = {¿Cómo Crear Un Post?},\n  date = {2023-11-12},\n  url = {https://cchiquitovalencia.github.io/posts/2023-11-12-crear_un_post/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nChiquito Valencia, Cristian. 2023. “¿Cómo Crear Un Post?”\nNovember 12, 2023. https://cchiquitovalencia.github.io/posts/2023-11-12-crear_un_post/."
  },
  {
    "objectID": "posts/2023-11-13-random_search_algorithm/index.html",
    "href": "posts/2023-11-13-random_search_algorithm/index.html",
    "title": "Random Search",
    "section": "",
    "text": "Random Search pertenece a los campos de la Optimización Estocástica y la Optimización Global. Es un método de búsqueda directa, no requiere derivadas para buscar en un dominio continuo. Este enfoque está relacionado con técnicas que proporcionan pequeñas mejoras, como la Directed Random Search y la Adaptative Random Search."
  },
  {
    "objectID": "posts/2023-11-13-random_search_algorithm/index.html#taxonomía",
    "href": "posts/2023-11-13-random_search_algorithm/index.html#taxonomía",
    "title": "Random Search",
    "section": "",
    "text": "Random Search pertenece a los campos de la Optimización Estocástica y la Optimización Global. Es un método de búsqueda directa, no requiere derivadas para buscar en un dominio continuo. Este enfoque está relacionado con técnicas que proporcionan pequeñas mejoras, como la Directed Random Search y la Adaptative Random Search."
  },
  {
    "objectID": "posts/2023-11-13-random_search_algorithm/index.html#estrategia",
    "href": "posts/2023-11-13-random_search_algorithm/index.html#estrategia",
    "title": "Random Search",
    "section": "Estrategia",
    "text": "Estrategia\nLa estrategia de Random Search consiste en muestrear soluciones de todo el espacio de búsqueda utilizando una distribución de probabilidad uniforme. Cada muestra futura es independiente de las anteriores."
  },
  {
    "objectID": "posts/2023-11-13-random_search_algorithm/index.html#procedimiento",
    "href": "posts/2023-11-13-random_search_algorithm/index.html#procedimiento",
    "title": "Random Search",
    "section": "Procedimiento",
    "text": "Procedimiento\n\n\n\nPseudocódigo Random Search"
  },
  {
    "objectID": "posts/2023-11-13-random_search_algorithm/index.html#heurística",
    "href": "posts/2023-11-13-random_search_algorithm/index.html#heurística",
    "title": "Random Search",
    "section": "Heurística",
    "text": "Heurística\nRandom Search es minimalista en el sentido de que sólo requiere una rutina de construcción de soluciones candidatas y una rutina de evaluación de soluciones candidatas, ambas pueden calibrarse con el enfoque.\nEn el peor de los casos, el rendimiento de Random Search para localizar el óptimo es peor que una Enumeración del dominio de búsqueda, dado que Random Search no tiene memoria y puede remuestrear a ciegas.\nRandom Search puede devolver una aproximación razonable de la solución óptima en un tiempo razonable con problemas de baja dimensionalidad, aunque el enfoque no se escala bien con tamaño del problema (como el número de dimensiones).\nHay que tener cuidado con algunos dominios de problemas para garantizar que la construcción aleatoria de soluciones candidatas no esté sesgada.\nLos resultados de una Random Search pueden utilizarse para sembrar otra técnica de búsqueda, como una técnica de búsqueda local (como el algoritmo Hill Climbing) que se puede utilizar para localizar la mejor solución en la vecindad de la “buena” solución candidata."
  },
  {
    "objectID": "posts/2023-11-13-random_search_algorithm/index.html#código",
    "href": "posts/2023-11-13-random_search_algorithm/index.html#código",
    "title": "Random Search",
    "section": "Código",
    "text": "Código\nEl problema de ejemplo es un caso de optimización continua que busca:\n\\(min f(x)\\) donde \\(f = ∑_{i=1}^n X_i^2\\), \\(-5.0&lt;=x_i&lt;=5.0\\) y \\(n=2\\).\nLa solución óptima para esta función es \\((v_0,…,v_{n-1})=0.0\\)\n\n# Definir la función objetivo\nobjective_function &lt;- function(vector) {\n    return(sum(vector^2))\n}\n\n# Generar un vector aleatorio\nrandom_vector &lt;- function(minmax) {\n    return(runif(length(minmax), min = minmax[,1], max = minmax[,2]))\n}\n\n# Realizar la bósqueda aleatoria\nsearch &lt;- function(search_space, max_iter) {\n    best &lt;- NULL\n    costs &lt;- c()  # Vector para almacenar los costos\n    for (iter in 1:max_iter) {\n        candidate &lt;- list()\n        candidate$vector &lt;- random_vector(search_space)\n        candidate$cost &lt;- objective_function(candidate$vector)\n        costs &lt;- c(costs, candidate$cost)  # Almacenar el costo de la iteraciÃ³n actual\n        if (is.null(best) || candidate$cost &lt; best$cost) {\n            best &lt;- candidate\n        }\n    }\n    return(list(best = best, costs = costs))  # Devolver el mejor resultado y los costos\n}\n\n# Configuración del problema\nproblem_size &lt;- 2\nsearch_space &lt;- matrix(c(-5, 5), nrow = problem_size, ncol = 2, byrow = TRUE)\n\n# Configuración del algoritmo\nmax_iter &lt;- 1000\n\n# Ejecutar el algoritmo\nresult &lt;- search(search_space, max_iter)\nbest &lt;- result$best\ncosts &lt;- result$costs\n\nRevisamemos el comportamiento del algoritmo para encontrar la solución óptima:\n\nlibrary(ggplot2)\n\n# Crear un dataframe con los costos\ndf &lt;- data.frame(\n    Iteration = 1:length(costs),\n    Cost = costs\n)\n\n# Crear modificaciones al plot\ncrear_tema &lt;- function() {\n    theme_minimal() +\n        theme(\n            plot.background = element_rect(fill = \"white\", color = NA), \n            panel.grid.major = element_line(color = \"white\", size = 0.2), \n            panel.grid.minor = element_line(color = \"white\", size = 0.2), \n            panel.background = element_rect(fill = \"white\", color = NA), \n            plot.title = element_text(face = \"bold\", size = 14, color = \"#4d6080\"),\n            axis.title = element_text(face = \"bold\", size = 12, color = \"#4d6080\"),\n            axis.text = element_text(size = 10, color = \"#4d6080\"),\n            axis.line = element_line(size = 1.5, colour = \"#de6f41\"), \n            legend.background = element_rect(fill = \"#4d6080\", color = NA), \n            legend.key = element_rect(fill = \"grey90\", color = NA),\n            axis.ticks.x = element_line(color = \"#de6f41\", size = 1),\n            axis.ticks.y = element_line(color = \"#de6f41\", size = 1)\n        )\n}\n\nggplot(df, aes(x = Iteration, y = Cost)) +\n    geom_line(colour = \"#4d6080\", size = 1) +\n    labs(\n        title = \"Progreso de la función objetivo\",\n        x = \"Iteración\",\n        y = \"Costo\"\n    ) +\n    crear_tema()\n\n\n\n\nLa solución óptima es entonces:\n\nresult$best$vector\n\n[1]  0.14119307  1.06820860 -0.02988087 -0.25322848"
  },
  {
    "objectID": "posts/2023-11-13-adaptative_random_search/index.html",
    "href": "posts/2023-11-13-adaptative_random_search/index.html",
    "title": "Adaptative Random Search",
    "section": "",
    "text": "El algoritmo Adaptative Random Search pertenece al conjunto general de enfoques conocidos como Optimización Estocástica y Optimización Global.\nEs un método de búsqueda directa, en el sentido de que no requiere derivadas para para navegar por el espacio de búsqueda. Adaptative Random Search es una extensión de los algoritmos Random Search."
  },
  {
    "objectID": "posts/2023-11-13-adaptative_random_search/index.html#taxonomía",
    "href": "posts/2023-11-13-adaptative_random_search/index.html#taxonomía",
    "title": "Adaptative Random Search",
    "section": "",
    "text": "El algoritmo Adaptative Random Search pertenece al conjunto general de enfoques conocidos como Optimización Estocástica y Optimización Global.\nEs un método de búsqueda directa, en el sentido de que no requiere derivadas para para navegar por el espacio de búsqueda. Adaptative Random Search es una extensión de los algoritmos Random Search."
  },
  {
    "objectID": "posts/2023-11-13-adaptative_random_search/index.html#estrategia",
    "href": "posts/2023-11-13-adaptative_random_search/index.html#estrategia",
    "title": "Adaptative Random Search",
    "section": "Estrategia",
    "text": "Estrategia\nEl algoritmo Adaptative Random Search fue diseñado para abordar las limitaciones del tamaño de paso fijo en el algoritmo de Localized Random Search.\nLa estrategia de la Adaptative Random Search consiste en realizar paso óptimo necesario para alcanzar el óptimo global en el espacio de búsqueda. Esto se consigue probando y adoptando tamaños de paso menores o mayores sólo si mejoran el rendimiento de la búsqueda.\nLa estrategia del algoritmo Adaptive Step Size Random Search (la técnica específica revisada) consiste en probar un paso mayor en cada iteración y adoptarlo si mejora el resultado. Los pasos muy grandes se prueban de la misma manera, aunque con una frecuencia mucho menor. Esta estrategia de preferir movimientos grandes tiene por objeto permitir que la técnica escape a los óptimos locales. Los pasos más pequeños se adoptan si no se produce ninguna mejora durante un periodo prolongado."
  },
  {
    "objectID": "posts/2023-11-13-adaptative_random_search/index.html#procedimiento",
    "href": "posts/2023-11-13-adaptative_random_search/index.html#procedimiento",
    "title": "Adaptative Random Search",
    "section": "Procedimiento",
    "text": "Procedimiento\n\n\n\nPseudocódigo Random Search"
  },
  {
    "objectID": "posts/2023-11-13-adaptative_random_search/index.html#heurística",
    "href": "posts/2023-11-13-adaptative_random_search/index.html#heurística",
    "title": "Adaptative Random Search",
    "section": "Heurística",
    "text": "Heurística\nAdaptative Random Search fue diseñado para dominios de problemas de optimización de funciones continuas.\nLos candidatos con igual costo deben considerarse mejoras para permitir que el algoritmo progrese a través de mesetas en la superficie de respuesta.\nAdaptative Random Search puede adaptar la dirección de búsqueda además del tamaño del paso.\nEl tamaño del paso puede adaptarse para todos los parámetros o para cada parámetro individualmente."
  },
  {
    "objectID": "posts/2023-11-13-adaptative_random_search/index.html#código",
    "href": "posts/2023-11-13-adaptative_random_search/index.html#código",
    "title": "Adaptative Random Search",
    "section": "Código",
    "text": "Código\nEn el ejemplo, el algoritmo se ejecuta durante un número fijo de iteraciones y devuelve la mejor solución candidata descubierta. El problema del ejemplo es un caso de optimización de una función continua que busca\n\\(min f(x)\\) donde \\(f = ∑_{i=1}^n X_i^2\\), \\(-5.0&lt;=x_i&lt;=5.0\\) y \\(n=2\\).\nLa solución óptima para esta función es \\((v_0,...,v_{n-1})=0.0\\)\n\n# Definir la función objetivo\nobjective_function &lt;- function(vector) {\n    return(sum(vector^2))\n}\n\n# Generar un número aleatorio en el intervalo [min, max]\nrand_in_bounds &lt;- function(min, max) {\n    return(min + ((max-min) * runif(1)))\n}\n\n# Generar un vector aleatorio en el espacio de búsqueda\nrandom_vector &lt;- function(minmax) {\n    #minmax &lt;- matrix(bounds,nrow = problem_size, ncol = problem_size, byrow = FALSE)\n    return(runif(length(minmax), min = minmax[,1], max = minmax[,2]))\n}\n\n# Dar un paso en una dirección aleatoria\ntake_step &lt;- function(minmax, current, step_size) {\n    position &lt;- numeric(length(current))\n    for (i in 1:(length(current)/problem_size)) {\n        min &lt;- max(minmax[i,1], current[i]-step_size)\n        max &lt;- min(minmax[i,2], current[i]+step_size)\n        position[i] &lt;- rand_in_bounds(min, max)\n    }\n    return(position)\n}\n\n# Dar un paso grande en una dirección aleatoria\nlarge_step_size &lt;- function(iter, step_size, s_factor, l_factor, iter_mult) {\n    if (iter &gt; 0 && iter %% iter_mult == 0) {\n        return(step_size * l_factor)\n    } else {\n        return(step_size * s_factor)\n    }\n}\n\n# Dar un paso y un gran paso en direcciones aleatorias\ntake_steps &lt;- function(bounds, current, step_size, big_stepsize) {\n    step &lt;- list()\n    big_step &lt;- list()\n    step$vector &lt;- take_step(bounds, current$vector, step_size)\n    step$cost &lt;- objective_function(step$vector)\n    big_step$vector &lt;- take_step(bounds, current$vector, big_stepsize)\n    big_step$cost &lt;- objective_function(big_step$vector)\n    return(list(step, big_step))\n}\n\n# Inicializar un dataframe para almacenar los resultados\nresults &lt;- data.frame(iteration = integer(), cost = numeric())\n\n# Realizar la búsqueda aleatoria adaptativa\nsearch &lt;- function(max_iter, bounds, init_factor, s_factor, l_factor, iter_mult, max_no_impr) {\n    step_size &lt;- (bounds[1,2]-bounds[1,1]) * init_factor\n    current &lt;- list()\n    current$vector &lt;- random_vector(bounds)\n    current$cost &lt;- objective_function(current$vector)\n    count &lt;- 0\n    for (iter in 1:max_iter) {\n        big_stepsize &lt;- large_step_size(iter, step_size, s_factor, l_factor, iter_mult)\n        steps &lt;- take_steps(bounds, current, step_size, big_stepsize)\n        if (steps[[1]]$cost &lt;= current$cost || steps[[2]]$cost &lt;= current$cost) {\n            if (steps[[2]]$cost &lt;= steps[[1]]$cost) {\n                step_size &lt;- big_stepsize\n                current &lt;- steps[[2]]\n            } else {\n                current &lt;- steps[[1]]\n            }\n            count &lt;- 0\n        } else {\n            count &lt;- count + 1\n            if (count &gt;= max_no_impr) {\n                step_size &lt;- step_size / s_factor\n                count &lt;- 0\n            }\n        }\n        # Almacenar los resultados en el dataframe\n        results &lt;&lt;- rbind(results, data.frame(iteration = iter, cost = current$cost))\n    }\n    return(current)\n}\n\n# Configuración del problema\nproblem_size &lt;- 2\nbounds &lt;- matrix(c(-5, 5), nrow = problem_size, ncol = 2, byrow = TRUE)\n\n# Configuración del algoritmo\nmax_iter &lt;- 100\ninit_factor &lt;- 0.05\ns_factor &lt;- 1.3\nl_factor &lt;- 3.0\niter_mult &lt;- 10\nmax_no_impr &lt;- 30\n\n# Ejecutar el algoritmo\nbest &lt;- search(max_iter, bounds, init_factor, s_factor, l_factor, iter_mult, max_no_impr)\n\nRevisamemos el comportamiento del algoritmo para encontrar la solución óptima:\n\nlibrary(ggplot2)\n\n# Crear modificaciones al plot\ncrear_tema &lt;- function() {\n    theme_minimal() +\n        theme(\n            plot.background = element_rect(fill = \"white\", color = NA), \n            panel.grid.major = element_line(color = \"white\", size = 0.2), \n            panel.grid.minor = element_line(color = \"white\", size = 0.2), \n            panel.background = element_rect(fill = \"white\", color = NA), \n            plot.title = element_text(face = \"bold\", size = 14, color = \"#4d6080\"),\n            axis.title = element_text(face = \"bold\", size = 12, color = \"#4d6080\"),\n            axis.text = element_text(size = 10, color = \"#4d6080\"),\n            axis.line = element_line(size = 1.5, colour = \"#de6f41\"), \n            legend.background = element_rect(fill = \"#4d6080\", color = NA), \n            legend.key = element_rect(fill = \"grey90\", color = NA),\n            axis.ticks.x = element_line(color = \"#de6f41\", size = 1),\n            axis.ticks.y = element_line(color = \"#de6f41\", size = 1)\n        )\n}\n\nggplot(results, aes(x = iteration, y = cost)) +\n    geom_line() +\n    labs(title = \"Progreso de la función objetivo\", \n         x = \"Iteración\", y = \"Costo\")+\n    crear_tema()\n\n\n\n\nLa solución óptima es entonces:\n\nbest$vector\n\n[1] -0.11150437  0.02282235  0.00000000  0.00000000"
  },
  {
    "objectID": "posts/2023-11-13-stochastic_hill_climbing/index.html",
    "href": "posts/2023-11-13-stochastic_hill_climbing/index.html",
    "title": "Stochastic Hill Climbing",
    "section": "",
    "text": "El algoritmo Stochastic Hill Climbing es un algoritmo de Optimización Estocástica y es un algoritmo de Optimización Local (a diferencia de la Optimización Global). Es una técnica de búsqueda directa, ya que no requiere derivadas del espacio de búsqueda. Stochastic Hill Climbing es una extensión de los algoritmos deterministas como el Simple Hill Climbing (primer mejor vecino), Steepest-Ascent Hill Climbing (mejor vecino), y un padre de enfoques como Parallel Hill Climbing y Random-Restart Hill Climbing."
  },
  {
    "objectID": "posts/2023-11-13-stochastic_hill_climbing/index.html#taxonomía",
    "href": "posts/2023-11-13-stochastic_hill_climbing/index.html#taxonomía",
    "title": "Stochastic Hill Climbing",
    "section": "",
    "text": "El algoritmo Stochastic Hill Climbing es un algoritmo de Optimización Estocástica y es un algoritmo de Optimización Local (a diferencia de la Optimización Global). Es una técnica de búsqueda directa, ya que no requiere derivadas del espacio de búsqueda. Stochastic Hill Climbing es una extensión de los algoritmos deterministas como el Simple Hill Climbing (primer mejor vecino), Steepest-Ascent Hill Climbing (mejor vecino), y un padre de enfoques como Parallel Hill Climbing y Random-Restart Hill Climbing."
  },
  {
    "objectID": "posts/2023-11-13-stochastic_hill_climbing/index.html#estrategia",
    "href": "posts/2023-11-13-stochastic_hill_climbing/index.html#estrategia",
    "title": "Stochastic Hill Climbing",
    "section": "Estrategia",
    "text": "Estrategia\nLa estrategia del Stochastic Hill Climbing consiste en iterar el proceso de selección aleatoria de un vecino para una solución candidata y aceptarla sólo si da lugar a una mejora. La estrategia se propuso para hacer frente a las limitaciones de las técnicas de ascenso determinista que se atascaban en óptimos locales debido a su avariciosa aceptación de movimientos vecinos."
  },
  {
    "objectID": "posts/2023-11-13-stochastic_hill_climbing/index.html#procedimiento",
    "href": "posts/2023-11-13-stochastic_hill_climbing/index.html#procedimiento",
    "title": "Stochastic Hill Climbing",
    "section": "Procedimiento",
    "text": "Procedimiento\n\n\n\nPseudocódigo Stochastic Hill Climbing"
  },
  {
    "objectID": "posts/2023-11-13-stochastic_hill_climbing/index.html#heurística",
    "href": "posts/2023-11-13-stochastic_hill_climbing/index.html#heurística",
    "title": "Stochastic Hill Climbing",
    "section": "Heurística",
    "text": "Heurística\nStochastic Hill Climbing fue diseñado para ser utilizado en dominios discretos con vecinos explícitos, como la optimización combinatoria (en comparación con la optimización de funciones continuas).\nLa estrategia del algoritmo puede aplicarse a dominios continuos haciendo uso de un tamaño de paso para definir los vecinos de la solución candidata (como la Localized Random Search y la Fixed Step-Size Random Search).\nStochastic Hill Climbing es una técnica de búsqueda local (en comparación a la búsqueda global) y puede utilizarse para refinar un resultado tras la ejecución de un algoritmo de búsqueda global.\nAunque la técnica utiliza un proceso estocástico, aún puede atascarse en óptimos locales.\nLos vecinos con mejor o igual costo deben ser aceptados, lo que permite a la técnica navegar a través de mesetas en la superficie de respuesta.\nEl algoritmo puede reiniciarse y repetirse una serie de veces veces después de que converja para obtener un resultado mejorado (lo que se denomina Multiple Restart Hill Climbing).\nEl procedimiento puede aplicarse a varias soluciones candidatas simultáneamente, lo que permite ejecutar varios algoritmos al mismo tiempo (llamado Parallel Hill Climbing)."
  },
  {
    "objectID": "posts/2023-11-13-stochastic_hill_climbing/index.html#código",
    "href": "posts/2023-11-13-stochastic_hill_climbing/index.html#código",
    "title": "Stochastic Hill Climbing",
    "section": "Código",
    "text": "Código\nEl algoritmo se ejecuta durante un número fijo de iteraciones y se aplica a un problema de optimización de cadena binaria denominado ‘One Max’. El objetivo de este problema de maximización es preparar una cadena con todos los bits ‘1’, donde la función de costo sólo informa del número de bits en una cadena dada.\n\n# Función para calcular la suma de los unos en un vector\nonemax &lt;- function(vector) {\n    return(sum(vector == \"1\"))\n}\n\n# Función para generar una cadena de bits aleatorios\nrandom_bitstring &lt;- function(num_bits) {\n    return(sample(c(\"0\", \"1\"), num_bits, replace = TRUE))\n}\n\n# Función para generar un vecino aleatorio cambiando un bit\nrandom_neighbor &lt;- function(bitstring) {\n    mutant &lt;- bitstring\n    pos &lt;- sample(seq_along(bitstring), 1)\n    mutant[pos] &lt;- ifelse(mutant[pos] == \"1\", \"0\", \"1\")\n    return(mutant)\n}\n\n# Función de búsqueda principal\nsearch &lt;- function(max_iterations, num_bits) {\n    # Inicializar el candidato con un vector aleatorio y calcular su costo\n    candidate &lt;- list()\n    candidate$vector &lt;- random_bitstring(num_bits)\n    candidate$cost &lt;- onemax(candidate$vector)\n    costs &lt;- c()  # Vector para almacenar los costos\n    # Iterar hasta el número máximo de iteraciones\n    for (iter in seq_len(max_iterations)) {\n        # Generar un vecino y calcular su costo\n        neighbor &lt;- list()\n        neighbor$vector &lt;- random_neighbor(candidate$vector)\n        neighbor$cost &lt;- onemax(neighbor$vector)\n        costs &lt;- c(costs, candidate$cost)  # Almacenar el costo de la iteración actual\n        # Si el vecino es mejor o igual, actualizar el candidato\n        if (neighbor$cost &gt;= candidate$cost) {\n            candidate &lt;- neighbor\n        }\n        # Si se encuentra la solución óptima, terminar\n        if (candidate$cost == num_bits) {\n            break\n        }\n    }\n    # Devolver el mejor candidato encontrado y los costos\n    return(list(best = candidate, costs = costs))\n}\n\n# Configuración del problema\nnum_bits &lt;- 64\n\n# Configuración del algoritmo\nmax_iterations &lt;- 1000\n\n# Ejecutar el algoritmo\nresult &lt;- search(max_iterations, num_bits)\nbest &lt;- result$best\ncosts &lt;- result$costs\n\nRevisamemos el comportamiento del algoritmo para encontrar la solución óptima:\n\nlibrary(ggplot2)\n# Crear un gráfico del progreso de la función objetivo\ndf &lt;- data.frame(\n  Iteration = 1:length(costs),\n  Cost = costs\n)\n\n# Crear modificaciones al plot\ncrear_tema &lt;- function() {\n    theme_minimal() +\n        theme(\n            plot.background = element_rect(fill = \"white\", color = NA), \n            panel.grid.major = element_line(color = \"white\", size = 0.2), \n            panel.grid.minor = element_line(color = \"white\", size = 0.2), \n            panel.background = element_rect(fill = \"white\", color = NA), \n            plot.title = element_text(face = \"bold\", size = 14, color = \"#4d6080\"),\n            axis.title = element_text(face = \"bold\", size = 12, color = \"#4d6080\"),\n            axis.text = element_text(size = 10, color = \"#4d6080\"),\n            axis.line = element_line(size = 1.5, colour = \"#de6f41\"), \n            legend.background = element_rect(fill = \"#4d6080\", color = NA), \n            legend.key = element_rect(fill = \"grey90\", color = NA),\n            axis.ticks.x = element_line(color = \"#de6f41\", size = 1),\n            axis.ticks.y = element_line(color = \"#de6f41\", size = 1)\n        )\n}\n\nggplot(df, aes(x = Iteration, y = Cost)) +\n  geom_line(colour = \"steelblue\", size = 1) +\n  labs(\n    title = \"Progreso de la función objetivo\",\n    subtitle = \"Visualización del costo a lo largo de las iteraciones\",\n    x = \"Iteración\",\n    y = \"Costo\"\n  ) +\n  crear_tema()\n\n\n\n\nLa solución óptima es entonces:\n\nresult$best$vector\n\n [1] \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\"\n[20] \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\"\n[39] \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\"\n[58] \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\""
  },
  {
    "objectID": "posts/2023-11-18-iterated_local_search/index.html",
    "href": "posts/2023-11-18-iterated_local_search/index.html",
    "title": "Iterated Local serach",
    "section": "",
    "text": "Iterated Local Search es una Metaheurística y una técnica de Optimización Global. Es una extensión de Multi-Restar Search y puede considerarse la base de muchos enfoques de búsqueda en dos fases, como el procedimiento de Greedy Randomized Adaptive Search Procedure y Variable Neighborhood Search."
  },
  {
    "objectID": "posts/2023-11-18-iterated_local_search/index.html#taxonomía",
    "href": "posts/2023-11-18-iterated_local_search/index.html#taxonomía",
    "title": "Iterated Local serach",
    "section": "",
    "text": "Iterated Local Search es una Metaheurística y una técnica de Optimización Global. Es una extensión de Multi-Restar Search y puede considerarse la base de muchos enfoques de búsqueda en dos fases, como el procedimiento de Greedy Randomized Adaptive Search Procedure y Variable Neighborhood Search."
  },
  {
    "objectID": "posts/2023-11-18-iterated_local_search/index.html#estrategia",
    "href": "posts/2023-11-18-iterated_local_search/index.html#estrategia",
    "title": "Iterated Local serach",
    "section": "Estrategia",
    "text": "Estrategia\nEl objetivo de Iterated Local Search es mejorar la Multi-Restar Search mediante el muestreo en la vecindad más amplia de soluciones candidatas y el uso de una técnica de Local Search para reﬁnar las soluciones a sus óptimos locales. Iterated Local Search explora una secuencia de soluciones creadas como perturbaciones de la mejor solución actual, cuyo resultado se reﬁna mediante una heurística integrada."
  },
  {
    "objectID": "posts/2023-11-18-iterated_local_search/index.html#procedimiento",
    "href": "posts/2023-11-18-iterated_local_search/index.html#procedimiento",
    "title": "Iterated Local serach",
    "section": "Procedimiento",
    "text": "Procedimiento\n\n\n\nPseudocódigo Stochastic Hill Climbing"
  },
  {
    "objectID": "posts/2023-11-18-iterated_local_search/index.html#heurística",
    "href": "posts/2023-11-18-iterated_local_search/index.html#heurística",
    "title": "Iterated Local serach",
    "section": "Heurística",
    "text": "Heurística\nIterated Local Search se diseñó para, y se ha aplicado, predominantemente a dominios discretos, como los problemas de optimización combinatoria.\nLa perturbación de la mejor solución actual debe estar en un vecindario más allá del alcance de la heurística incorporada y no debe deshacerse fácilmente.\nLas perturbaciones demasiado pequeñas hacen que el algoritmo sea demasiado codicioso, mientras que las perturbaciones demasiado grandes hacen que el algoritmo sea demasiado estocástico.\nLa heurística incrustada suele ser una técnica de búsqueda local específica del problema.\nEl punto de partida de la búsqueda puede ser una solución candidata construida aleatoriamente o mediante una heurística específica del problema (como el vecino más próximo).\nLas perturbaciones pueden hacerse de forma determinista, aunque las más comunes son las estocásticas y probabilísticas (adaptativas basadas en el historial).\nEl procedimiento puede almacenar tanto o tan poco historial como sea necesario para utilizarlo durante la perturbación y los criterios de aceptación. La ausencia de historial representa un paseo aleatorio en un vecindario más amplio de la mejor solución y es la aplicación más común del enfoque.\nEl criterio de aceptación más simple y común es una mejora en el costo de las soluciones candidatas construidas."
  },
  {
    "objectID": "posts/2023-11-18-iterated_local_search/index.html#código",
    "href": "posts/2023-11-18-iterated_local_search/index.html#código",
    "title": "Iterated Local serach",
    "section": "Código",
    "text": "Código\nEl algoritmo se aplica a la instancia Berlin52 del Traveling Saleman Problem (TSP), tomada de la TSPLIB. El problema busca una permutación del orden de visita de las ciudades (llamada recorrido) que minimice la distancia total recorrida. La distancia óptima del recorrido para el caso Berlín52 es de 7.542 unidades.\nIterated Local Search se ejecuta durante un número fijo de iteraciones. La implementación se basa en un algoritmo común conﬁguración para el TSP, donde un 'double-bridge move' (4-opt) se utiliza como la técnica de perturbación, y un 2-opt estocástico se utiliza como la heurística de búsqueda local incrustada. El doube-bridge move consiste en dividir una permutación en 4 partes (a,b,c,d) y volver a unirlas en un orden específico y desordenado (a,d,c,b).\n\n# Función para calcular la distancia euclidiana entre dos puntos\neuc_2d &lt;- function(c1, c2) {\n    return(round(sqrt((c1[1] - c2[1])^2 + (c1[2] - c2[2])^2)))\n}\n\n# Función para calcular el costo de una permutación de ciudades\ncost &lt;- function(permutation, cities) {\n    distance &lt;- 0\n    for (i in seq_along(permutation)) {\n        c1 &lt;- permutation[i]\n        c2 &lt;- if (i == length(permutation)) permutation[1] else permutation[i + 1]\n        distance &lt;- distance + euc_2d(cities[c1, ], cities[c2, ])\n    }\n    return(distance)\n}\n\n# Función para generar una permutación aleatoria de las ciudades\nrandom_permutation &lt;- function(cities) {\n    return(sample(nrow(cities)))\n}\n\n# Función para realizar una operación de dos-opt estocástica en una permutación\nstochastic_two_opt &lt;- function(permutation) {\n    perm &lt;- permutation\n    c1 &lt;- sample(length(perm), 1)\n    exclude &lt;- c(c1, if (c1 == 1) length(perm) else c1 - 1, if (c1 == length(perm)) 1 else c1 + 1)\n    c2 &lt;- sample(length(perm), 1)\n    while (c2 %in% exclude) {\n        c2 &lt;- sample(length(perm), 1)\n    }\n    if (c2 &lt; c1) {\n        c1 &lt;- c2\n        c2 &lt;- c1\n    }\n    perm[c1:c2] &lt;- rev(perm[c1:c2])\n    return(perm)\n}\n\n# Función para realizar una búsqueda local en el espacio de las permutaciones\nlocal_search &lt;- function(best, cities, max_no_improv) {\n    count &lt;- 0\n    repeat {\n        candidate &lt;- list()\n        candidate$vector &lt;- stochastic_two_opt(best$vector)\n        candidate$cost &lt;- cost(candidate$vector, cities)\n        if (candidate$cost &lt; best$cost) {\n            count &lt;- 0\n            best &lt;- candidate\n        } else {\n            count &lt;- count + 1\n        }\n        if (count &gt;= max_no_improv) break\n    }\n    return(best)\n}\n\n# Función para realizar un movimiento de doble puente en una permutación\ndouble_bridge_move &lt;- function(perm) {\n    pos1 &lt;- 1 + sample(floor(length(perm) / 4), 1)\n    pos2 &lt;- pos1 + 1 + sample(floor(length(perm) / 4), 1)\n    pos3 &lt;- pos2 + 1 + sample(floor(length(perm) / 4), 1)\n    return(c(perm[1:pos1], perm[(pos3 + 1):length(perm)], perm[(pos2 + 1):pos3], perm[(pos1 + 1):pos2]))\n}\n\n# Función para perturbar la mejor solución encontrada hasta ahora\nperturbation &lt;- function(cities, best) {\n    candidate &lt;- list()\n    candidate$vector &lt;- double_bridge_move(best$vector)\n    candidate$cost &lt;- cost(candidate$vector, cities)\n    return(candidate)\n}\n\n# Función de búsqueda principal\nsearch &lt;- function(cities, max_iterations, max_no_improv) {\n    best &lt;- list()\n    best$vector &lt;- random_permutation(cities)\n    best$cost &lt;- cost(best$vector, cities)\n    best &lt;- local_search(best, cities, max_no_improv)\n    # Creamos un vector para almacenar el costo del mejor vector en cada iteración\n    best_costs &lt;- numeric(max_iterations)\n    for (iter in seq_len(max_iterations)) {\n        candidate &lt;- perturbation(cities, best)\n        candidate &lt;- local_search(candidate, cities, max_no_improv)\n        if (candidate$cost &lt; best$cost) {\n            best &lt;- candidate\n        }\n        # Almacenamos el costo del mejor vector en la iteración actual\n        best_costs[iter] &lt;- best$cost\n        #print(paste(\" &gt; iteration\", iter, \", best=\", best$cost))\n    }\n    return(list(best = best, best_costs = best_costs))\n}\n\n# Configuración del problema\nberlin52 &lt;- matrix(c(565,575,25,185,345,750,945,685,845,655,\n                     880,660,25,230,525,1000,580,1175,650,1130,\n                     1605,620,1220,580,1465,200,1530,5,845,680,\n                     725,370,145,665,415,635,510,875,560,365,300,\n                     465,520,585,480,415,835,625,975,580,1215,245,\n                     1320,315,1250,400,660,180,410,250,420,555,575,\n                     665,1150,1160,700,580,685,595,685,610,770,610,\n                     795,645,720,635,760,650,475,960,95,260,875,920,\n                     700,500,555,815,830,485,1170,65,830,610,605,625,\n                     595,360,1340,725,1740,245), ncol = 2, byrow = TRUE)\n\n# Configuración del algoritmo\nmax_iterations &lt;- 100\nmax_no_improv &lt;- 50\n\n# Ejecutar el algoritmo\nresult &lt;- search(berlin52, max_iterations, max_no_improv)\n\nRevisamemos el comportamiento del algoritmo para encontrar la solución óptima:\n\n# Crear un gráfico del progreso de la función objetivo\nlibrary(ggplot2)\n\ndf &lt;- data.frame(iteration = 1:max_iterations, cost = result$best_costs)\n\n# Crear modificaciones al plot\ncrear_tema &lt;- function() {\n    theme_minimal() +\n        theme(\n            plot.background = element_rect(fill = \"white\", color = NA), \n            panel.grid.major = element_line(color = \"white\", size = 0.2), \n            panel.grid.minor = element_line(color = \"white\", size = 0.2), \n            panel.background = element_rect(fill = \"white\", color = NA), \n            plot.title = element_text(face = \"bold\", size = 14, color = \"#4d6080\"),\n            axis.title = element_text(face = \"bold\", size = 12, color = \"#4d6080\"),\n            axis.text = element_text(size = 10, color = \"#4d6080\"),\n            axis.line = element_line(size = 1.5, colour = \"#de6f41\"), \n            legend.background = element_rect(fill = \"#4d6080\", color = NA), \n            legend.key = element_rect(fill = \"grey90\", color = NA),\n            axis.ticks.x = element_line(color = \"#de6f41\", size = 1),\n            axis.ticks.y = element_line(color = \"#de6f41\", size = 1)\n        )\n}\n\n\nggplot(df, aes(x = iteration, y = cost)) +\n    geom_line() +\n    labs(title = \"Progreso del costo a lo largo de las iteraciones\", x = \"Iteración\", y = \"Costo\")+\n    crear_tema()\n\n\n\n\nLa solución óptima (con las iteraciones establecidas) es entonces:\n\nresult$best$vector\n\n [1] 26 12 25 24 45 19 41  8  9 10 43 39 35 18  3 17 31 22  1 49 32 36 40 37 38\n[26] 34 48 44 29 20 23 42 21  2  7 30 50 16 46 28  4  6 15  5 33 51 11 13 52 27\n[51] 14 47"
  }
]