[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Cristian Chiquito Valencia",
    "section": "",
    "text": "AWS Cloud Solutions Architect (December 2024)\nData Science: Foundations using R Specialization (April 2022)\nLogistics, Specialist | Universidad del Valle (September 2019)\nIndustrial Engineer, B.S. | Universidad Icesi (February 2015)\n\n\n\nMaintenance Planner @ Grupo Integrado de Transporte Masivo S.A. (_Jul 2024 - Sep 2024)\n- Propose to the Maintenance Department improvement, recovery, and maintenance projects for the fleet, with technical information by component and system of the buses. - Plan maintenance for the fleet according to the established wear strategy, operational standards, considering the criticality of equipment, fleet age, and manufacturer manuals. - Generate monthly and annual budget information for the Maintenance area based on the maintenance plan and kilometer execution within the information system. - Plan resources required for the maintenance plan for the fleet (spare parts, labor, tools, vehicle availability, and pending activities) based on the approved monthly and annual budget. - Manage maintenance indicators (maintainability, reliability, fuel efficiency, fleet condition index, and maintenance cost per kilometer). - Ensure that daily, monthly, quarterly, and annual management reports are prepared and delivered to the Maintenance Department and General Management. - Adjust the maintenance plan according to the fleet’s state and age. - Manage compliance with contractual commitments with Metro Cali S.A. and other entities. - Configure, administer, and manage the maintenance software used by the company. - Verify and control information from the support platforms for the Maintenance area. - Verify and evaluate daily the information provided by the lubrication and fuel engineer on the fleet’s mileage and consumption, and the results of oil sample analyses, adjusting the maintenance system’s parametrization. - Track and control information on non-compliances reported by Metro Cali S.A. vs. fines and maintenance indicators. - Track and control the response to PQRS and OTRS by Metro Cali, which are related to the Maintenance area.\nMaintenance Controller @ Grupo Integrado de Transporte Masivo S.A. (_Jan 2024 - Jul 2024)\n- Develop, control, and track the annual maintenance budget, performing monthly reconciliations with the finance and procurement areas. - Model maintenance costs over the life of the fleet and the concession contract with the Managing Entity. - Support the procurement process in evaluating, selecting, and developing suppliers. - Make projections of critical and sensitive spare part consumption to ensure fleet availability. - Conduct failure analysis, lead strategic planning meetings to design action plans for fleet intervention focused on reliability and contractual compliance. - Control and track the mileage and energy and fuel consumption of the fleet. - Generate annual, semi-annual, and monthly maintenance schedules for the fleet. - Control costs and track all activities in the maintenance process. - Track and control information on non-compliances reported by Metro Cali S.A vs. fines and maintenance indicators.\nMaintenance Manager @ Grupo Integrado de Transporte Masivo S.A. (_August 2022 - Jan 2024)\n- Ensure compliance with the clauses of the current concession contract and its respective others that correspond to the Maintenance area for the provision of the public mass passenger transportation service within the integrated mass transportation system of Santiago de Cali of the Managing Entity. - Implement, standardize and improve the management of your process in order to guarantee compliance with the company’s objectives and the Integrated Management System. - Guarantee compliance with contractual commitments with the Managing Entity, guaranteeing the availability and reliability of the fleet as well as its preventive maintenance. - Develop strategies to increase the productivity levels of the process taking into account the associated resources available by the organization. - Coordinate and provide the necessary resources for the management carried out by the maintenance area collaborators. - Guarantee compliance with commitments with the integrated management system defined by the organization and establish improvement plans when necessary. - Develop knowledge management projects within the maintenance area through process automation and productivity improvement, as well as identify training and qualification needs of the collaborators in charge. - Synergistically ensure with the Operations Department the availability and reliability of the fleet. - Establish and supervise the execution of service agreements agreed upon with suppliers associated with the maintenance area, evaluating and reevaluating the management developed by them. - Plan the implementation, creation and development of projects, plans, activities and/or acquisition of new suppliers that aim to improve the Maintenance process.\nLeader of operational services plan and data analysis @ Grupo Integrado de Transporte Masivo S.A. (_February 2019 - July 2022)\n- Plan, propose and implement process improvement projects through the use of descriptive and inferential statistics. - Apply engineering techniques to achieve cost reduction in production management through resource optimization. - Analyze and evaluate the profitability of resources dedicated to production for decision making. - Presentation of reports, analysis and statistics on a regular basis. - Actively participate in the planning and programming of the distribution of kilometers. - Pose and establish process optimization models through the statistical analysis of distribution and programming data. - Schedule route trips in accordance with the designed offer defined in the Operation Services Plan. - Adjust opening and closing trips that guarantee service coverage to the user up to the times defined in the designed offer. - Determine necessary fleet by type of vehicle according to the designed service offer. - Prepare information to export data to the control center, vehicles and dispatches with part of the fleet operation support system. - Generate preliminary reports, input for optimizing operator shifts.\nProduction Engineer @ Grupo Integrado de Transporte Masivo S.A. (_March 2015 - February 2019)\n- Planning, control and administration of the vehicle fleet. - Programming of yard operators for different activities related to the production area. - Responsible for supervising and controlling operators and technicians, track inspectors and operation controllers. - Coordinate and evaluate operation processes in other yards. Analyze causes of non-compliance with company objectives. - Monitoring and control of corrective and preventive maintenance times.\n\n\n\nDevelopment and implementation of a methodology for detecting atypical trips through the use of control charts for transportation times in the city of Cali.\nCreation and administration of a linear programming model in R language to optimize the distribution of kilometers in service, guaranteeing the expected income and minimizing the cost per empty kilometers and the number of operator-hours."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "What’s inside?",
    "section": "",
    "text": "Want to learn how to use linear programming to optimize your processes and improve your results? Are you interested in learning about the benefits of using R and BI languages for data analysis? Do you want to know how statistics can help you make better decisions in your business? If the answer is yes, this blog is for you.\nIn this blog, I’ll teach you everything you need to know about statistics, data, linear programming, R and BI languages, and process improvement. I’ll show you how to apply these tools and techniques in real-world and practical cases, so you can solve complex problems, reduce costs, increase profits, improve quality and customer satisfaction.\nStatistics is the science of collecting, organizing, analyzing, and interpreting numerical data to extract conclusions and make inferences about a population or phenomenon of interest. Statistics is fundamental for designing experiments, testing hypotheses, estimating parameters, predicting trends, etc.\nLinear programming is a mathematical technique used to optimize the performance or efficiency of a system. It’s based on the idea of maximizing or minimizing a linear function subject to a set of linear constraints. In other words, it’s about finding the best way to assign limited resources to achieve a specific goal.\nR and BI languages are two of the most popular and powerful for data analysis. R is a programming language and software environment that allows you to perform all types of statistical operations, graphics, and modeling. BI (Business Intelligence) is a set of tools and methodologies that enable you to transform data into useful and relevant information for decision-making.\nProcess improvement is a management strategy that aims to increase the effectiveness and efficiency of an organization’s processes by identifying, analyzing, measuring, controlling, and continuously improving them. Process improvement is based on the use of methodologies, tools, and techniques such as the PDCA cycle, Ishikawa diagram, Pareto analysis, Six Sigma, Lean, etc.\nIf you want to learn more about these topics and see how you can apply them to your business, I invite you to keep reading this blog and subscribe to my newsletter (coming soon), where I’ll send you exclusive content, tips, resources, and special offers. You can also leave a comment, question, or suggestion, and I’ll be happy to respond. Thank you for your attention, and see you soon.”"
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Cristian Chiquito Valencia",
    "section": "",
    "text": "AWS Cloud Solutions Architect (December 2024)\nData Science: Foundations using R Specialization (April 2022)\nLogistics, Specialist | Universidad del Valle (September 2019)\nIndustrial Engineer, B.S. | Universidad Icesi (February 2015)\n\n\n\nMaintenance Planner @ Grupo Integrado de Transporte Masivo S.A. (_Jul 2024 - Sep 2024)\n- Propose to the Maintenance Department improvement, recovery, and maintenance projects for the fleet, with technical information by component and system of the buses. - Plan maintenance for the fleet according to the established wear strategy, operational standards, considering the criticality of equipment, fleet age, and manufacturer manuals. - Generate monthly and annual budget information for the Maintenance area based on the maintenance plan and kilometer execution within the information system. - Plan resources required for the maintenance plan for the fleet (spare parts, labor, tools, vehicle availability, and pending activities) based on the approved monthly and annual budget. - Manage maintenance indicators (maintainability, reliability, fuel efficiency, fleet condition index, and maintenance cost per kilometer). - Ensure that daily, monthly, quarterly, and annual management reports are prepared and delivered to the Maintenance Department and General Management. - Adjust the maintenance plan according to the fleet’s state and age. - Manage compliance with contractual commitments with Metro Cali S.A. and other entities. - Configure, administer, and manage the maintenance software used by the company. - Verify and control information from the support platforms for the Maintenance area. - Verify and evaluate daily the information provided by the lubrication and fuel engineer on the fleet’s mileage and consumption, and the results of oil sample analyses, adjusting the maintenance system’s parametrization. - Track and control information on non-compliances reported by Metro Cali S.A. vs. fines and maintenance indicators. - Track and control the response to PQRS and OTRS by Metro Cali, which are related to the Maintenance area.\nMaintenance Controller @ Grupo Integrado de Transporte Masivo S.A. (_Jan 2024 - Jul 2024)\n- Develop, control, and track the annual maintenance budget, performing monthly reconciliations with the finance and procurement areas. - Model maintenance costs over the life of the fleet and the concession contract with the Managing Entity. - Support the procurement process in evaluating, selecting, and developing suppliers. - Make projections of critical and sensitive spare part consumption to ensure fleet availability. - Conduct failure analysis, lead strategic planning meetings to design action plans for fleet intervention focused on reliability and contractual compliance. - Control and track the mileage and energy and fuel consumption of the fleet. - Generate annual, semi-annual, and monthly maintenance schedules for the fleet. - Control costs and track all activities in the maintenance process. - Track and control information on non-compliances reported by Metro Cali S.A vs. fines and maintenance indicators.\nMaintenance Manager @ Grupo Integrado de Transporte Masivo S.A. (_August 2022 - Jan 2024)\n- Ensure compliance with the clauses of the current concession contract and its respective others that correspond to the Maintenance area for the provision of the public mass passenger transportation service within the integrated mass transportation system of Santiago de Cali of the Managing Entity. - Implement, standardize and improve the management of your process in order to guarantee compliance with the company’s objectives and the Integrated Management System. - Guarantee compliance with contractual commitments with the Managing Entity, guaranteeing the availability and reliability of the fleet as well as its preventive maintenance. - Develop strategies to increase the productivity levels of the process taking into account the associated resources available by the organization. - Coordinate and provide the necessary resources for the management carried out by the maintenance area collaborators. - Guarantee compliance with commitments with the integrated management system defined by the organization and establish improvement plans when necessary. - Develop knowledge management projects within the maintenance area through process automation and productivity improvement, as well as identify training and qualification needs of the collaborators in charge. - Synergistically ensure with the Operations Department the availability and reliability of the fleet. - Establish and supervise the execution of service agreements agreed upon with suppliers associated with the maintenance area, evaluating and reevaluating the management developed by them. - Plan the implementation, creation and development of projects, plans, activities and/or acquisition of new suppliers that aim to improve the Maintenance process.\nLeader of operational services plan and data analysis @ Grupo Integrado de Transporte Masivo S.A. (_February 2019 - July 2022)\n- Plan, propose and implement process improvement projects through the use of descriptive and inferential statistics. - Apply engineering techniques to achieve cost reduction in production management through resource optimization. - Analyze and evaluate the profitability of resources dedicated to production for decision making. - Presentation of reports, analysis and statistics on a regular basis. - Actively participate in the planning and programming of the distribution of kilometers. - Pose and establish process optimization models through the statistical analysis of distribution and programming data. - Schedule route trips in accordance with the designed offer defined in the Operation Services Plan. - Adjust opening and closing trips that guarantee service coverage to the user up to the times defined in the designed offer. - Determine necessary fleet by type of vehicle according to the designed service offer. - Prepare information to export data to the control center, vehicles and dispatches with part of the fleet operation support system. - Generate preliminary reports, input for optimizing operator shifts.\nProduction Engineer @ Grupo Integrado de Transporte Masivo S.A. (_March 2015 - February 2019)\n- Planning, control and administration of the vehicle fleet. - Programming of yard operators for different activities related to the production area. - Responsible for supervising and controlling operators and technicians, track inspectors and operation controllers. - Coordinate and evaluate operation processes in other yards. Analyze causes of non-compliance with company objectives. - Monitoring and control of corrective and preventive maintenance times.\n\n\n\nDevelopment and implementation of a methodology for detecting atypical trips through the use of control charts for transportation times in the city of Cali.\nCreation and administration of a linear programming model in R language to optimize the distribution of kilometers in service, guaranteeing the expected income and minimizing the cost per empty kilometers and the number of operator-hours."
  },
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Resources",
    "section": "",
    "text": "Here are the branches of creations."
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Aquí mi Blog",
    "section": "",
    "text": "Toma mejores decisiones\n\n\n\nInventarios\n\n\nSupply Chain\n\n\nEvaluación de Proyectos\n\n\n\nINVENTARIOS Serie - Parte 11\n\n\n\nCristian Chiquito Valencia\n\n\nMar 3, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAplicaciones prácticas\n\n\n\nInventarios\n\n\nSupply Chain\n\n\nEvaluación de Proyectos\n\n\n\nINVENTARIOS Serie - Parte 10\n\n\n\nCristian Chiquito Valencia\n\n\nFeb 28, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCostos totales de mantener el inventario antes de impuestos\n\n\n\nInventarios\n\n\nSupply Chain\n\n\nEvaluación de Proyectos\n\n\n\nINVENTARIOS Serie - Parte 9\n\n\n\nCristian Chiquito Valencia\n\n\nFeb 27, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQué pasa con una tasa de inversión?\n\n\n\nInventarios\n\n\nSupply Chain\n\n\nEvaluación de Proyectos\n\n\n\nINVENTARIOS Serie - Parte 8\n\n\n\nCristian Chiquito Valencia\n\n\nFeb 26, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPor qué no usar una tasa de préstamo?\n\n\n\nInventarios\n\n\nSupply Chain\n\n\nLogística\n\n\n\nINVENTARIOS Serie - Parte 7\n\n\n\nCristian Chiquito Valencia\n\n\nFeb 25, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPor qué usar el WACC como costo de mantener inventario?\n\n\n\nInventarios\n\n\nSupply Chain\n\n\nEvaluación de Proyectos\n\n\n\nINVENTARIOS Serie - Parte 6\n\n\n\nCristian Chiquito Valencia\n\n\nFeb 24, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnálisis de las razones financieras\n\n\n\nInventarios\n\n\nSupply Chain\n\n\nLogística\n\n\nFinanzas\n\n\n\nINVENTARIOS Serie - Parte 5\n\n\n\nCristian Chiquito Valencia\n\n\nFeb 21, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUsa el costo de capital promedio ponderado\n\n\n\nInventarios\n\n\nSupply Chain\n\n\nLogística\n\n\n\nINVENTARIOS Serie - Parte 4\n\n\n\nCristian Chiquito Valencia\n\n\nFeb 20, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAhora la carga de capital de inventario\n\n\n\nInventarios\n\n\nSupply Chain\n\n\nLogística\n\n\n\nINVENTARIOS Serie - Parte 3\n\n\n\nCristian Chiquito Valencia\n\n\nFeb 19, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCuáles son los costos no capitalizados de mantener los inventarios?\n\n\n\nInventarios\n\n\nSupply Chain\n\n\nLogística\n\n\n\nINVENTARIOS Serie - Parte 2\n\n\n\nCristian Chiquito Valencia\n\n\nFeb 18, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEl impacto de los inventarios\n\n\n\nInventarios\n\n\nSupply Chain\n\n\nLogística\n\n\n\nINVENTARIOS Serie - Parte 1\n\n\n\nCristian Chiquito Valencia\n\n\nFeb 17, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntroducción al Machine Learning\n\n\n\nMachine Learning\n\n\nArtificial Intelligence\n\n\nData Science\n\n\nDeep Learning\n\n\n\nPrincipios en ingeniería\n\n\n\nCristian Chiquito Valencia\n\n\nFeb 5, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUna aplicación robusta para Mantenimiento\n\n\n\nScheduling\n\n\nMantenimiento\n\n\nMILP\n\n\nOptimización\n\n\n\nMTTO Serie - Parte 7\n\n\n\nCristian Chiquito Valencia\n\n\nFeb 4, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIndispensable crear el PLAN\n\n\n\nScheduling\n\n\nMaintenance\n\n\n\nMTTO Serie - Parte 6\n\n\n\nCristian Chiquito Valencia\n\n\nFeb 3, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDesplegar Shiny App\n\n\n\nGithub\n\n\nShiny App\n\n\nShiny Server\n\n\nAWS\n\n\nEC2\n\n\n\nMTTO Serie - Parte 5\n\n\n\nCristian Chiquito Valencia\n\n\nJan 30, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCrear Shiny App\n\n\n\nGithub\n\n\nShiny App\n\n\n\nMTTO Serie - Parte 4\n\n\n\nCristian Chiquito Valencia\n\n\nJan 29, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCrear Shiny Server en AWS\n\n\n\nCloud\n\n\nAWS\n\n\nEC2\n\n\nShiny Server\n\n\nShiny App\n\n\n\nMTTO Serie - Parte 3\n\n\n\nCristian Chiquito Valencia\n\n\nJan 28, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGestión de sistemas de mantenimiento\n\n\n\nMantenimiento\n\n\nSoftware\n\n\nProgramación Lineal Entera Mixta\n\n\nMILP\n\n\nOptimización\n\n\n\nMTTO Serie - Parte 2\n\n\n\nCristian Chiquito Valencia\n\n\nJan 27, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntroducción a los sistemas de mantenimiento\n\n\n\nMantenimiento\n\n\nPreventivo\n\n\nFallas\n\n\n\nMTTO Serie - Parte 1\n\n\n\nCristian Chiquito Valencia\n\n\nJan 27, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShopify scraping con R\n\n\n\nR\n\n\nWeb Scraping\n\n\nShopify\n\n\nselenider\n\n\n\nCartlow website\n\n\n\nCristian Chiquito Valencia\n\n\nDec 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeb scraping con R\n\n\n\nR\n\n\nWeb Scraping\n\n\nselenider\n\n\n\nUsando selenider\n\n\n\nCristian Chiquito Valencia\n\n\nNov 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEl secreto para organizar a tu familia\n\n\n\nR\n\n\nprogramació lineal\n\n\nompr\n\n\noptimización\n\n\n\nAsignar dormitorios\n\n\n\nCristian Chiquito Valencia\n\n\nNov 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRetomando labores\n\n\n\nGit\n\n\nGithub\n\n\n\nClonando repositorio a local\n\n\n\nCristian Chiquito Valencia\n\n\nNov 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntroducción a Git\n\n\n\nGit\n\n\n\nFundamental para Data Science\n\n\n\nCristian Chiquito Valencia\n\n\nNov 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntroducción a Github\n\n\n\nGithub\n\n\n\nColaboración para Data Science\n\n\n\nCristian Chiquito Valencia\n\n\nNov 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGreedy Randomized Adaptative Search\n\n\n\nR\n\n\noptimización\n\n\n\nBúsqueda Adaptativa Aleatoria y Codiciosa\n\n\n\nCristian Chiquito Valencia\n\n\nDec 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable Neighborhood Search\n\n\n\nR\n\n\noptimización\n\n\n\nBúsqueda de Vencindario Variable\n\n\n\nCristian Chiquito Valencia\n\n\nDec 3, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGuided Local serach\n\n\n\nR\n\n\noptimización\n\n\n\nBúsqueda Local Guiada\n\n\n\nCristian Chiquito Valencia\n\n\nNov 19, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIterated Local serach\n\n\n\nR\n\n\noptimización\n\n\n\nBúsqueda Local Iterada\n\n\n\nCristian Chiquito Valencia\n\n\nNov 18, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRandom Search\n\n\n\nR\n\n\noptimización\n\n\n\nBúsqueda aleatoria\n\n\n\nCristian Chiquito Valencia\n\n\nNov 13, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStochastic Hill Climbing\n\n\n\nR\n\n\noptimización\n\n\n\nEscalada estocástica\n\n\n\nCristian Chiquito Valencia\n\n\nNov 13, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdaptative Random Search\n\n\n\nR\n\n\noptimización\n\n\n\nBúsqueda aleatoria adaptativa\n\n\n\nCristian Chiquito Valencia\n\n\nNov 13, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n¿Cómo crear un post?\n\n\n\nQuarto\n\n\nR\n\n\n\nParece ser una buena manera de conservar un buen flujo de trabajo\n\n\n\nCristian Chiquito Valencia\n\n\nNov 12, 2023\n\n\n\n\n\n\n\n\nNo hay resultados"
  },
  {
    "objectID": "posts/2023-11-12-crear_un_post/index.html",
    "href": "posts/2023-11-12-crear_un_post/index.html",
    "title": "¿Cómo crear un post?",
    "section": "",
    "text": "Ahora que ya tienes tu página configurada, puedes empezar a llenarla con entradas de blog. Repite los siguientes pasos cada vez que desees añadir un nuevo post.\nCrea un subdirectorio dentro de tu directorio posts/: Para mantenerme organizado, suelo nombrar el mío YYYY-MM-DD-describe_post. Este nombre de carpeta también se convertirá en la parte identificativa única de una dirección web (normalmente al final de la URL) de tu post publicado.\nDentro de tu nuevo subdirectorio, crea un archivo index.qmd. El nombre es importante. Debe llamarse index.qmd. La ruta del archivo debe ser similar a la siguiente: …/posts/2023-11-12-crear_un_post/index.qmd. Este archivo es la entrada de tu blog. Escribe todo el contenido aquí. Configure su entrada de blog: Puedes añadir diferentes opciones a la sección YAML de index.qmd.\n\nrunif(1,0,100)\n\n[1] 1.481772\n\n\n\n\n\nCitationBibTeX citation:@online{chiquito_valencia2023,\n  author = {Chiquito Valencia, Cristian},\n  title = {¿Cómo Crear Un Post?},\n  date = {2023-11-12},\n  url = {https://cchiquitovalencia.github.io/posts/2023-11-12-crear_un_post/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nChiquito Valencia, Cristian. 2023. “¿Cómo Crear Un Post?”\nNovember 12, 2023. https://cchiquitovalencia.github.io/posts/2023-11-12-crear_un_post/."
  },
  {
    "objectID": "posts/2023-11-13-random_search_algorithm/index.html",
    "href": "posts/2023-11-13-random_search_algorithm/index.html",
    "title": "Random Search",
    "section": "",
    "text": "Random Search pertenece a los campos de la Optimización Estocástica y la Optimización Global. Es un método de búsqueda directa, no requiere derivadas para buscar en un dominio continuo. Este enfoque está relacionado con técnicas que proporcionan pequeñas mejoras, como la Directed Random Search y la Adaptative Random Search."
  },
  {
    "objectID": "posts/2023-11-13-random_search_algorithm/index.html#taxonomía",
    "href": "posts/2023-11-13-random_search_algorithm/index.html#taxonomía",
    "title": "Random Search",
    "section": "",
    "text": "Random Search pertenece a los campos de la Optimización Estocástica y la Optimización Global. Es un método de búsqueda directa, no requiere derivadas para buscar en un dominio continuo. Este enfoque está relacionado con técnicas que proporcionan pequeñas mejoras, como la Directed Random Search y la Adaptative Random Search."
  },
  {
    "objectID": "posts/2023-11-13-random_search_algorithm/index.html#estrategia",
    "href": "posts/2023-11-13-random_search_algorithm/index.html#estrategia",
    "title": "Random Search",
    "section": "Estrategia",
    "text": "Estrategia\nLa estrategia de Random Search consiste en muestrear soluciones de todo el espacio de búsqueda utilizando una distribución de probabilidad uniforme. Cada muestra futura es independiente de las anteriores."
  },
  {
    "objectID": "posts/2023-11-13-random_search_algorithm/index.html#procedimiento",
    "href": "posts/2023-11-13-random_search_algorithm/index.html#procedimiento",
    "title": "Random Search",
    "section": "Procedimiento",
    "text": "Procedimiento\n\n\n\nPseudocódigo Random Search"
  },
  {
    "objectID": "posts/2023-11-13-random_search_algorithm/index.html#heurística",
    "href": "posts/2023-11-13-random_search_algorithm/index.html#heurística",
    "title": "Random Search",
    "section": "Heurística",
    "text": "Heurística\nRandom Search es minimalista en el sentido de que sólo requiere una rutina de construcción de soluciones candidatas y una rutina de evaluación de soluciones candidatas, ambas pueden calibrarse con el enfoque.\nEn el peor de los casos, el rendimiento de Random Search para localizar el óptimo es peor que una Enumeración del dominio de búsqueda, dado que Random Search no tiene memoria y puede remuestrear a ciegas.\nRandom Search puede devolver una aproximación razonable de la solución óptima en un tiempo razonable con problemas de baja dimensionalidad, aunque el enfoque no se escala bien con tamaño del problema (como el número de dimensiones).\nHay que tener cuidado con algunos dominios de problemas para garantizar que la construcción aleatoria de soluciones candidatas no esté sesgada.\nLos resultados de una Random Search pueden utilizarse para sembrar otra técnica de búsqueda, como una técnica de búsqueda local (como el algoritmo Hill Climbing) que se puede utilizar para localizar la mejor solución en la vecindad de la “buena” solución candidata."
  },
  {
    "objectID": "posts/2023-11-13-random_search_algorithm/index.html#código",
    "href": "posts/2023-11-13-random_search_algorithm/index.html#código",
    "title": "Random Search",
    "section": "Código",
    "text": "Código\nEl problema de ejemplo es un caso de optimización continua que busca:\n\\(min f(x)\\) donde \\(f = ∑_{i=1}^n X_i^2\\), \\(-5.0&lt;=x_i&lt;=5.0\\) y \\(n=2\\).\nLa solución óptima para esta función es \\((v_0,…,v_{n-1})=0.0\\)\n\n# Definir la función objetivo\nobjective_function &lt;- function(vector) {\n    return(sum(vector^2))\n}\n\n# Generar un vector aleatorio\nrandom_vector &lt;- function(minmax) {\n    return(runif(length(minmax), min = minmax[,1], max = minmax[,2]))\n}\n\n# Realizar la bósqueda aleatoria\nsearch &lt;- function(search_space, max_iter) {\n    best &lt;- NULL\n    costs &lt;- c()  # Vector para almacenar los costos\n    for (iter in 1:max_iter) {\n        candidate &lt;- list()\n        candidate$vector &lt;- random_vector(search_space)\n        candidate$cost &lt;- objective_function(candidate$vector)\n        costs &lt;- c(costs, candidate$cost)  # Almacenar el costo de la iteraciÃ³n actual\n        if (is.null(best) || candidate$cost &lt; best$cost) {\n            best &lt;- candidate\n        }\n    }\n    return(list(best = best, costs = costs))  # Devolver el mejor resultado y los costos\n}\n\n# Configuración del problema\nproblem_size &lt;- 2\nsearch_space &lt;- matrix(c(-5, 5), nrow = problem_size, ncol = 2, byrow = TRUE)\n\n# Configuración del algoritmo\nmax_iter &lt;- 1000\n\n# Ejecutar el algoritmo\nresult &lt;- search(search_space, max_iter)\nbest &lt;- result$best\ncosts &lt;- result$costs\n\nRevisamemos el comportamiento del algoritmo para encontrar la solución óptima:\n\nlibrary(ggplot2)\n\n# Crear un dataframe con los costos\ndf &lt;- data.frame(\n    Iteration = 1:length(costs),\n    Cost = costs\n)\n\n# Crear modificaciones al plot\ncrear_tema &lt;- function() {\n    theme_minimal() +\n        theme(\n            plot.background = element_rect(fill = \"white\", color = NA), \n            panel.grid.major = element_line(color = \"white\", size = 0.2), \n            panel.grid.minor = element_line(color = \"white\", size = 0.2), \n            panel.background = element_rect(fill = \"white\", color = NA), \n            plot.title = element_text(face = \"bold\", size = 14, color = \"#4d6080\"),\n            axis.title = element_text(face = \"bold\", size = 12, color = \"#4d6080\"),\n            axis.text = element_text(size = 10, color = \"#4d6080\"),\n            axis.line = element_line(size = 1.5, colour = \"#de6f41\"), \n            legend.background = element_rect(fill = \"#4d6080\", color = NA), \n            legend.key = element_rect(fill = \"grey90\", color = NA),\n            axis.ticks.x = element_line(color = \"#de6f41\", size = 1),\n            axis.ticks.y = element_line(color = \"#de6f41\", size = 1)\n        )\n}\n\nggplot(df, aes(x = Iteration, y = Cost)) +\n    geom_line(colour = \"#4d6080\", size = 1) +\n    labs(\n        title = \"Progreso de la función objetivo\",\n        x = \"Iteración\",\n        y = \"Costo\"\n    ) +\n    crear_tema()\n\n\n\n\n\n\n\n\nLa solución óptima es entonces:\n\nresult$best$vector\n\n[1]  0.3349870 -0.6764305  0.2794488  0.4845480"
  },
  {
    "objectID": "posts/2023-11-13-adaptative_random_search/index.html",
    "href": "posts/2023-11-13-adaptative_random_search/index.html",
    "title": "Adaptative Random Search",
    "section": "",
    "text": "El algoritmo Adaptative Random Search pertenece al conjunto general de enfoques conocidos como Optimización Estocástica y Optimización Global.\nEs un método de búsqueda directa, en el sentido de que no requiere derivadas para para navegar por el espacio de búsqueda. Adaptative Random Search es una extensión de los algoritmos Random Search."
  },
  {
    "objectID": "posts/2023-11-13-adaptative_random_search/index.html#taxonomía",
    "href": "posts/2023-11-13-adaptative_random_search/index.html#taxonomía",
    "title": "Adaptative Random Search",
    "section": "",
    "text": "El algoritmo Adaptative Random Search pertenece al conjunto general de enfoques conocidos como Optimización Estocástica y Optimización Global.\nEs un método de búsqueda directa, en el sentido de que no requiere derivadas para para navegar por el espacio de búsqueda. Adaptative Random Search es una extensión de los algoritmos Random Search."
  },
  {
    "objectID": "posts/2023-11-13-adaptative_random_search/index.html#estrategia",
    "href": "posts/2023-11-13-adaptative_random_search/index.html#estrategia",
    "title": "Adaptative Random Search",
    "section": "Estrategia",
    "text": "Estrategia\nEl algoritmo Adaptative Random Search fue diseñado para abordar las limitaciones del tamaño de paso fijo en el algoritmo de Localized Random Search.\nLa estrategia de la Adaptative Random Search consiste en realizar paso óptimo necesario para alcanzar el óptimo global en el espacio de búsqueda. Esto se consigue probando y adoptando tamaños de paso menores o mayores sólo si mejoran el rendimiento de la búsqueda.\nLa estrategia del algoritmo Adaptive Step Size Random Search (la técnica específica revisada) consiste en probar un paso mayor en cada iteración y adoptarlo si mejora el resultado. Los pasos muy grandes se prueban de la misma manera, aunque con una frecuencia mucho menor. Esta estrategia de preferir movimientos grandes tiene por objeto permitir que la técnica escape a los óptimos locales. Los pasos más pequeños se adoptan si no se produce ninguna mejora durante un periodo prolongado."
  },
  {
    "objectID": "posts/2023-11-13-adaptative_random_search/index.html#procedimiento",
    "href": "posts/2023-11-13-adaptative_random_search/index.html#procedimiento",
    "title": "Adaptative Random Search",
    "section": "Procedimiento",
    "text": "Procedimiento\n\n\n\nPseudocódigo Random Search"
  },
  {
    "objectID": "posts/2023-11-13-adaptative_random_search/index.html#heurística",
    "href": "posts/2023-11-13-adaptative_random_search/index.html#heurística",
    "title": "Adaptative Random Search",
    "section": "Heurística",
    "text": "Heurística\nAdaptative Random Search fue diseñado para dominios de problemas de optimización de funciones continuas.\nLos candidatos con igual costo deben considerarse mejoras para permitir que el algoritmo progrese a través de mesetas en la superficie de respuesta.\nAdaptative Random Search puede adaptar la dirección de búsqueda además del tamaño del paso.\nEl tamaño del paso puede adaptarse para todos los parámetros o para cada parámetro individualmente."
  },
  {
    "objectID": "posts/2023-11-13-adaptative_random_search/index.html#código",
    "href": "posts/2023-11-13-adaptative_random_search/index.html#código",
    "title": "Adaptative Random Search",
    "section": "Código",
    "text": "Código\nEn el ejemplo, el algoritmo se ejecuta durante un número fijo de iteraciones y devuelve la mejor solución candidata descubierta. El problema del ejemplo es un caso de optimización de una función continua que busca\n\\(min f(x)\\) donde \\(f = ∑_{i=1}^n X_i^2\\), \\(-5.0&lt;=x_i&lt;=5.0\\) y \\(n=2\\).\nLa solución óptima para esta función es \\((v_0,...,v_{n-1})=0.0\\)\n\n# Definir la función objetivo\nobjective_function &lt;- function(vector) {\n    return(sum(vector^2))\n}\n\n# Generar un número aleatorio en el intervalo [min, max]\nrand_in_bounds &lt;- function(min, max) {\n    return(min + ((max-min) * runif(1)))\n}\n\n# Generar un vector aleatorio en el espacio de búsqueda\nrandom_vector &lt;- function(minmax) {\n    #minmax &lt;- matrix(bounds,nrow = problem_size, ncol = problem_size, byrow = FALSE)\n    return(runif(length(minmax), min = minmax[,1], max = minmax[,2]))\n}\n\n# Dar un paso en una dirección aleatoria\ntake_step &lt;- function(minmax, current, step_size) {\n    position &lt;- numeric(length(current))\n    for (i in 1:(length(current)/problem_size)) {\n        min &lt;- max(minmax[i,1], current[i]-step_size)\n        max &lt;- min(minmax[i,2], current[i]+step_size)\n        position[i] &lt;- rand_in_bounds(min, max)\n    }\n    return(position)\n}\n\n# Dar un paso grande en una dirección aleatoria\nlarge_step_size &lt;- function(iter, step_size, s_factor, l_factor, iter_mult) {\n    if (iter &gt; 0 && iter %% iter_mult == 0) {\n        return(step_size * l_factor)\n    } else {\n        return(step_size * s_factor)\n    }\n}\n\n# Dar un paso y un gran paso en direcciones aleatorias\ntake_steps &lt;- function(bounds, current, step_size, big_stepsize) {\n    step &lt;- list()\n    big_step &lt;- list()\n    step$vector &lt;- take_step(bounds, current$vector, step_size)\n    step$cost &lt;- objective_function(step$vector)\n    big_step$vector &lt;- take_step(bounds, current$vector, big_stepsize)\n    big_step$cost &lt;- objective_function(big_step$vector)\n    return(list(step, big_step))\n}\n\n# Inicializar un dataframe para almacenar los resultados\nresults &lt;- data.frame(iteration = integer(), cost = numeric())\n\n# Realizar la búsqueda aleatoria adaptativa\nsearch &lt;- function(max_iter, bounds, init_factor, s_factor, l_factor, iter_mult, max_no_impr) {\n    step_size &lt;- (bounds[1,2]-bounds[1,1]) * init_factor\n    current &lt;- list()\n    current$vector &lt;- random_vector(bounds)\n    current$cost &lt;- objective_function(current$vector)\n    count &lt;- 0\n    for (iter in 1:max_iter) {\n        big_stepsize &lt;- large_step_size(iter, step_size, s_factor, l_factor, iter_mult)\n        steps &lt;- take_steps(bounds, current, step_size, big_stepsize)\n        if (steps[[1]]$cost &lt;= current$cost || steps[[2]]$cost &lt;= current$cost) {\n            if (steps[[2]]$cost &lt;= steps[[1]]$cost) {\n                step_size &lt;- big_stepsize\n                current &lt;- steps[[2]]\n            } else {\n                current &lt;- steps[[1]]\n            }\n            count &lt;- 0\n        } else {\n            count &lt;- count + 1\n            if (count &gt;= max_no_impr) {\n                step_size &lt;- step_size / s_factor\n                count &lt;- 0\n            }\n        }\n        # Almacenar los resultados en el dataframe\n        results &lt;&lt;- rbind(results, data.frame(iteration = iter, cost = current$cost))\n    }\n    return(current)\n}\n\n# Configuración del problema\nproblem_size &lt;- 2\nbounds &lt;- matrix(c(-5, 5), nrow = problem_size, ncol = 2, byrow = TRUE)\n\n# Configuración del algoritmo\nmax_iter &lt;- 100\ninit_factor &lt;- 0.05\ns_factor &lt;- 1.3\nl_factor &lt;- 3.0\niter_mult &lt;- 10\nmax_no_impr &lt;- 30\n\n# Ejecutar el algoritmo\nbest &lt;- search(max_iter, bounds, init_factor, s_factor, l_factor, iter_mult, max_no_impr)\n\nRevisamemos el comportamiento del algoritmo para encontrar la solución óptima:\n\nlibrary(ggplot2)\n\n# Crear modificaciones al plot\ncrear_tema &lt;- function() {\n    theme_minimal() +\n        theme(\n            plot.background = element_rect(fill = \"white\", color = NA), \n            panel.grid.major = element_line(color = \"white\", size = 0.2), \n            panel.grid.minor = element_line(color = \"white\", size = 0.2), \n            panel.background = element_rect(fill = \"white\", color = NA), \n            plot.title = element_text(face = \"bold\", size = 14, color = \"#4d6080\"),\n            axis.title = element_text(face = \"bold\", size = 12, color = \"#4d6080\"),\n            axis.text = element_text(size = 10, color = \"#4d6080\"),\n            axis.line = element_line(size = 1.5, colour = \"#de6f41\"), \n            legend.background = element_rect(fill = \"#4d6080\", color = NA), \n            legend.key = element_rect(fill = \"grey90\", color = NA),\n            axis.ticks.x = element_line(color = \"#de6f41\", size = 1),\n            axis.ticks.y = element_line(color = \"#de6f41\", size = 1)\n        )\n}\n\nggplot(results, aes(x = iteration, y = cost)) +\n    geom_line() +\n    labs(title = \"Progreso de la función objetivo\", \n         x = \"Iteración\", y = \"Costo\")+\n    crear_tema()\n\n\n\n\n\n\n\n\nLa solución óptima es entonces:\n\nbest$vector\n\n[1]  0.1144359 -0.1796417  0.0000000  0.0000000"
  },
  {
    "objectID": "posts/2023-11-13-stochastic_hill_climbing/index.html",
    "href": "posts/2023-11-13-stochastic_hill_climbing/index.html",
    "title": "Stochastic Hill Climbing",
    "section": "",
    "text": "El algoritmo Stochastic Hill Climbing es un algoritmo de Optimización Estocástica y es un algoritmo de Optimización Local (a diferencia de la Optimización Global). Es una técnica de búsqueda directa, ya que no requiere derivadas del espacio de búsqueda. Stochastic Hill Climbing es una extensión de los algoritmos deterministas como el Simple Hill Climbing (primer mejor vecino), Steepest-Ascent Hill Climbing (mejor vecino), y un padre de enfoques como Parallel Hill Climbing y Random-Restart Hill Climbing."
  },
  {
    "objectID": "posts/2023-11-13-stochastic_hill_climbing/index.html#taxonomía",
    "href": "posts/2023-11-13-stochastic_hill_climbing/index.html#taxonomía",
    "title": "Stochastic Hill Climbing",
    "section": "",
    "text": "El algoritmo Stochastic Hill Climbing es un algoritmo de Optimización Estocástica y es un algoritmo de Optimización Local (a diferencia de la Optimización Global). Es una técnica de búsqueda directa, ya que no requiere derivadas del espacio de búsqueda. Stochastic Hill Climbing es una extensión de los algoritmos deterministas como el Simple Hill Climbing (primer mejor vecino), Steepest-Ascent Hill Climbing (mejor vecino), y un padre de enfoques como Parallel Hill Climbing y Random-Restart Hill Climbing."
  },
  {
    "objectID": "posts/2023-11-13-stochastic_hill_climbing/index.html#estrategia",
    "href": "posts/2023-11-13-stochastic_hill_climbing/index.html#estrategia",
    "title": "Stochastic Hill Climbing",
    "section": "Estrategia",
    "text": "Estrategia\nLa estrategia del Stochastic Hill Climbing consiste en iterar el proceso de selección aleatoria de un vecino para una solución candidata y aceptarla sólo si da lugar a una mejora. La estrategia se propuso para hacer frente a las limitaciones de las técnicas de ascenso determinista que se atascaban en óptimos locales debido a su avariciosa aceptación de movimientos vecinos."
  },
  {
    "objectID": "posts/2023-11-13-stochastic_hill_climbing/index.html#procedimiento",
    "href": "posts/2023-11-13-stochastic_hill_climbing/index.html#procedimiento",
    "title": "Stochastic Hill Climbing",
    "section": "Procedimiento",
    "text": "Procedimiento\n\n\n\nPseudocódigo Stochastic Hill Climbing"
  },
  {
    "objectID": "posts/2023-11-13-stochastic_hill_climbing/index.html#heurística",
    "href": "posts/2023-11-13-stochastic_hill_climbing/index.html#heurística",
    "title": "Stochastic Hill Climbing",
    "section": "Heurística",
    "text": "Heurística\nStochastic Hill Climbing fue diseñado para ser utilizado en dominios discretos con vecinos explícitos, como la optimización combinatoria (en comparación con la optimización de funciones continuas).\nLa estrategia del algoritmo puede aplicarse a dominios continuos haciendo uso de un tamaño de paso para definir los vecinos de la solución candidata (como la Localized Random Search y la Fixed Step-Size Random Search).\nStochastic Hill Climbing es una técnica de búsqueda local (en comparación a la búsqueda global) y puede utilizarse para refinar un resultado tras la ejecución de un algoritmo de búsqueda global.\nAunque la técnica utiliza un proceso estocástico, aún puede atascarse en óptimos locales.\nLos vecinos con mejor o igual costo deben ser aceptados, lo que permite a la técnica navegar a través de mesetas en la superficie de respuesta.\nEl algoritmo puede reiniciarse y repetirse una serie de veces veces después de que converja para obtener un resultado mejorado (lo que se denomina Multiple Restart Hill Climbing).\nEl procedimiento puede aplicarse a varias soluciones candidatas simultáneamente, lo que permite ejecutar varios algoritmos al mismo tiempo (llamado Parallel Hill Climbing)."
  },
  {
    "objectID": "posts/2023-11-13-stochastic_hill_climbing/index.html#código",
    "href": "posts/2023-11-13-stochastic_hill_climbing/index.html#código",
    "title": "Stochastic Hill Climbing",
    "section": "Código",
    "text": "Código\nEl algoritmo se ejecuta durante un número fijo de iteraciones y se aplica a un problema de optimización de cadena binaria denominado ‘One Max’. El objetivo de este problema de maximización es preparar una cadena con todos los bits ‘1’, donde la función de costo sólo informa del número de bits en una cadena dada.\n\n# Función para calcular la suma de los unos en un vector\nonemax &lt;- function(vector) {\n    return(sum(vector == \"1\"))\n}\n\n# Función para generar una cadena de bits aleatorios\nrandom_bitstring &lt;- function(num_bits) {\n    return(sample(c(\"0\", \"1\"), num_bits, replace = TRUE))\n}\n\n# Función para generar un vecino aleatorio cambiando un bit\nrandom_neighbor &lt;- function(bitstring) {\n    mutant &lt;- bitstring\n    pos &lt;- sample(seq_along(bitstring), 1)\n    mutant[pos] &lt;- ifelse(mutant[pos] == \"1\", \"0\", \"1\")\n    return(mutant)\n}\n\n# Función de búsqueda principal\nsearch &lt;- function(max_iterations, num_bits) {\n    # Inicializar el candidato con un vector aleatorio y calcular su costo\n    candidate &lt;- list()\n    candidate$vector &lt;- random_bitstring(num_bits)\n    candidate$cost &lt;- onemax(candidate$vector)\n    costs &lt;- c()  # Vector para almacenar los costos\n    # Iterar hasta el número máximo de iteraciones\n    for (iter in seq_len(max_iterations)) {\n        # Generar un vecino y calcular su costo\n        neighbor &lt;- list()\n        neighbor$vector &lt;- random_neighbor(candidate$vector)\n        neighbor$cost &lt;- onemax(neighbor$vector)\n        costs &lt;- c(costs, candidate$cost)  # Almacenar el costo de la iteración actual\n        # Si el vecino es mejor o igual, actualizar el candidato\n        if (neighbor$cost &gt;= candidate$cost) {\n            candidate &lt;- neighbor\n        }\n        # Si se encuentra la solución óptima, terminar\n        if (candidate$cost == num_bits) {\n            break\n        }\n    }\n    # Devolver el mejor candidato encontrado y los costos\n    return(list(best = candidate, costs = costs))\n}\n\n# Configuración del problema\nnum_bits &lt;- 64\n\n# Configuración del algoritmo\nmax_iterations &lt;- 1000\n\n# Ejecutar el algoritmo\nresult &lt;- search(max_iterations, num_bits)\nbest &lt;- result$best\ncosts &lt;- result$costs\n\nRevisamemos el comportamiento del algoritmo para encontrar la solución óptima:\n\nlibrary(ggplot2)\n# Crear un gráfico del progreso de la función objetivo\ndf &lt;- data.frame(\n  Iteration = 1:length(costs),\n  Cost = costs\n)\n\n# Crear modificaciones al plot\ncrear_tema &lt;- function() {\n    theme_minimal() +\n        theme(\n            plot.background = element_rect(fill = \"white\", color = NA), \n            panel.grid.major = element_line(color = \"white\", size = 0.2), \n            panel.grid.minor = element_line(color = \"white\", size = 0.2), \n            panel.background = element_rect(fill = \"white\", color = NA), \n            plot.title = element_text(face = \"bold\", size = 14, color = \"#4d6080\"),\n            axis.title = element_text(face = \"bold\", size = 12, color = \"#4d6080\"),\n            axis.text = element_text(size = 10, color = \"#4d6080\"),\n            axis.line = element_line(size = 1.5, colour = \"#de6f41\"), \n            legend.background = element_rect(fill = \"#4d6080\", color = NA), \n            legend.key = element_rect(fill = \"grey90\", color = NA),\n            axis.ticks.x = element_line(color = \"#de6f41\", size = 1),\n            axis.ticks.y = element_line(color = \"#de6f41\", size = 1)\n        )\n}\n\nggplot(df, aes(x = Iteration, y = Cost)) +\n  geom_line(colour = \"steelblue\", size = 1) +\n  labs(\n    title = \"Progreso de la función objetivo\",\n    subtitle = \"Visualización del costo a lo largo de las iteraciones\",\n    x = \"Iteración\",\n    y = \"Costo\"\n  ) +\n  crear_tema()\n\n\n\n\n\n\n\n\nLa solución óptima es entonces:\n\nresult$best$vector\n\n [1] \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\"\n[20] \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\"\n[39] \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\"\n[58] \"1\" \"1\" \"1\" \"1\" \"1\" \"1\" \"1\""
  },
  {
    "objectID": "posts/2023-11-18-iterated_local_search/index.html",
    "href": "posts/2023-11-18-iterated_local_search/index.html",
    "title": "Iterated Local serach",
    "section": "",
    "text": "Iterated Local Search es una Metaheurística y una técnica de Optimización Global. Es una extensión de Multi-Restar Search y puede considerarse la base de muchos enfoques de búsqueda en dos fases, como el procedimiento de Greedy Randomized Adaptive Search Procedure y Variable Neighborhood Search."
  },
  {
    "objectID": "posts/2023-11-18-iterated_local_search/index.html#taxonomía",
    "href": "posts/2023-11-18-iterated_local_search/index.html#taxonomía",
    "title": "Iterated Local serach",
    "section": "",
    "text": "Iterated Local Search es una Metaheurística y una técnica de Optimización Global. Es una extensión de Multi-Restar Search y puede considerarse la base de muchos enfoques de búsqueda en dos fases, como el procedimiento de Greedy Randomized Adaptive Search Procedure y Variable Neighborhood Search."
  },
  {
    "objectID": "posts/2023-11-18-iterated_local_search/index.html#estrategia",
    "href": "posts/2023-11-18-iterated_local_search/index.html#estrategia",
    "title": "Iterated Local serach",
    "section": "Estrategia",
    "text": "Estrategia\nEl objetivo de Iterated Local Search es mejorar la Multi-Restar Search mediante el muestreo en la vecindad más amplia de soluciones candidatas y el uso de una técnica de Local Search para reﬁnar las soluciones a sus óptimos locales. Iterated Local Search explora una secuencia de soluciones creadas como perturbaciones de la mejor solución actual, cuyo resultado se reﬁna mediante una heurística integrada."
  },
  {
    "objectID": "posts/2023-11-18-iterated_local_search/index.html#procedimiento",
    "href": "posts/2023-11-18-iterated_local_search/index.html#procedimiento",
    "title": "Iterated Local serach",
    "section": "Procedimiento",
    "text": "Procedimiento\n\n\n\nPseudocódigo Iterated Local Search"
  },
  {
    "objectID": "posts/2023-11-18-iterated_local_search/index.html#heurística",
    "href": "posts/2023-11-18-iterated_local_search/index.html#heurística",
    "title": "Iterated Local serach",
    "section": "Heurística",
    "text": "Heurística\nIterated Local Search se diseñó para, y se ha aplicado, predominantemente a dominios discretos, como los problemas de optimización combinatoria.\nLa perturbación de la mejor solución actual debe estar en un vecindario más allá del alcance de la heurística incorporada y no debe deshacerse fácilmente.\nLas perturbaciones demasiado pequeñas hacen que el algoritmo sea demasiado codicioso, mientras que las perturbaciones demasiado grandes hacen que el algoritmo sea demasiado estocástico.\nLa heurística incrustada suele ser una técnica de búsqueda local específica del problema.\nEl punto de partida de la búsqueda puede ser una solución candidata construida aleatoriamente o mediante una heurística específica del problema (como el vecino más próximo).\nLas perturbaciones pueden hacerse de forma determinista, aunque las más comunes son las estocásticas y probabilísticas (adaptativas basadas en el historial).\nEl procedimiento puede almacenar tanto o tan poco historial como sea necesario para utilizarlo durante la perturbación y los criterios de aceptación. La ausencia de historial representa un paseo aleatorio en un vecindario más amplio de la mejor solución y es la aplicación más común del enfoque.\nEl criterio de aceptación más simple y común es una mejora en el costo de las soluciones candidatas construidas."
  },
  {
    "objectID": "posts/2023-11-18-iterated_local_search/index.html#código",
    "href": "posts/2023-11-18-iterated_local_search/index.html#código",
    "title": "Iterated Local serach",
    "section": "Código",
    "text": "Código\nEl algoritmo se aplica a la instancia Berlin52 del Traveling Saleman Problem (TSP), tomada de la TSPLIB. El problema busca una permutación del orden de visita de las ciudades (llamada recorrido) que minimice la distancia total recorrida. La distancia óptima del recorrido para el caso Berlín52 es de 7.542 unidades.\nIterated Local Search se ejecuta durante un número fijo de iteraciones. La implementación se basa en un algoritmo común conﬁguración para el TSP, donde un 'double-bridge move' (4-opt) se utiliza como la técnica de perturbación, y un 2-opt estocástico se utiliza como la heurística de búsqueda local incrustada. El doube-bridge move consiste en dividir una permutación en 4 partes (a,b,c,d) y volver a unirlas en un orden específico y desordenado (a,d,c,b).\n\n# Función para calcular la distancia euclidiana entre dos puntos\neuc_2d &lt;- function(c1, c2) {\n    return(round(sqrt((c1[1] - c2[1])^2 + (c1[2] - c2[2])^2)))\n}\n\n# Función para calcular el costo de una permutación de ciudades\ncost &lt;- function(permutation, cities) {\n    distance &lt;- 0\n    for (i in seq_along(permutation)) {\n        c1 &lt;- permutation[i]\n        c2 &lt;- if (i == length(permutation)) permutation[1] else permutation[i + 1]\n        distance &lt;- distance + euc_2d(cities[c1, ], cities[c2, ])\n    }\n    return(distance)\n}\n\n# Función para generar una permutación aleatoria de las ciudades\nrandom_permutation &lt;- function(cities) {\n    return(sample(nrow(cities)))\n}\n\n# Función para realizar una operación de dos-opt estocástica en una permutación\nstochastic_two_opt &lt;- function(permutation) {\n    perm &lt;- permutation\n    c1 &lt;- sample(length(perm), 1)\n    exclude &lt;- c(c1, if (c1 == 1) length(perm) else c1 - 1, if (c1 == length(perm)) 1 else c1 + 1)\n    c2 &lt;- sample(length(perm), 1)\n    while (c2 %in% exclude) {\n        c2 &lt;- sample(length(perm), 1)\n    }\n    if (c2 &lt; c1) {\n        c1 &lt;- c2\n        c2 &lt;- c1\n    }\n    perm[c1:c2] &lt;- rev(perm[c1:c2])\n    return(perm)\n}\n\n# Función para realizar una búsqueda local en el espacio de las permutaciones\nlocal_search &lt;- function(best, cities, max_no_improv) {\n    count &lt;- 0\n    repeat {\n        candidate &lt;- list()\n        candidate$vector &lt;- stochastic_two_opt(best$vector)\n        candidate$cost &lt;- cost(candidate$vector, cities)\n        if (candidate$cost &lt; best$cost) {\n            count &lt;- 0\n            best &lt;- candidate\n        } else {\n            count &lt;- count + 1\n        }\n        if (count &gt;= max_no_improv) break\n    }\n    return(best)\n}\n\n# Función para realizar un movimiento de doble puente en una permutación\ndouble_bridge_move &lt;- function(perm) {\n    pos1 &lt;- 1 + sample(floor(length(perm) / 4), 1)\n    pos2 &lt;- pos1 + 1 + sample(floor(length(perm) / 4), 1)\n    pos3 &lt;- pos2 + 1 + sample(floor(length(perm) / 4), 1)\n    return(c(perm[1:pos1], perm[(pos3 + 1):length(perm)], perm[(pos2 + 1):pos3], perm[(pos1 + 1):pos2]))\n}\n\n# Función para perturbar la mejor solución encontrada hasta ahora\nperturbation &lt;- function(cities, best) {\n    candidate &lt;- list()\n    candidate$vector &lt;- double_bridge_move(best$vector)\n    candidate$cost &lt;- cost(candidate$vector, cities)\n    return(candidate)\n}\n\n# Función de búsqueda principal\nsearch &lt;- function(cities, max_iterations, max_no_improv) {\n    best &lt;- list()\n    best$vector &lt;- random_permutation(cities)\n    best$cost &lt;- cost(best$vector, cities)\n    best &lt;- local_search(best, cities, max_no_improv)\n    # Creamos un vector para almacenar el costo del mejor vector en cada iteración\n    best_costs &lt;- numeric(max_iterations)\n    for (iter in seq_len(max_iterations)) {\n        candidate &lt;- perturbation(cities, best)\n        candidate &lt;- local_search(candidate, cities, max_no_improv)\n        if (candidate$cost &lt; best$cost) {\n            best &lt;- candidate\n        }\n        # Almacenamos el costo del mejor vector en la iteración actual\n        best_costs[iter] &lt;- best$cost\n        #print(paste(\" &gt; iteration\", iter, \", best=\", best$cost))\n    }\n    return(list(best = best, best_costs = best_costs))\n}\n\n# Configuración del problema\nberlin52 &lt;- matrix(c(565,575,25,185,345,750,945,685,845,655,\n                     880,660,25,230,525,1000,580,1175,650,1130,\n                     1605,620,1220,580,1465,200,1530,5,845,680,\n                     725,370,145,665,415,635,510,875,560,365,300,\n                     465,520,585,480,415,835,625,975,580,1215,245,\n                     1320,315,1250,400,660,180,410,250,420,555,575,\n                     665,1150,1160,700,580,685,595,685,610,770,610,\n                     795,645,720,635,760,650,475,960,95,260,875,920,\n                     700,500,555,815,830,485,1170,65,830,610,605,625,\n                     595,360,1340,725,1740,245), ncol = 2, byrow = TRUE)\n\n# Configuración del algoritmo\nmax_iterations &lt;- 100\nmax_no_improv &lt;- 50\n\n# Ejecutar el algoritmo\nresult &lt;- search(berlin52, max_iterations, max_no_improv)\n\nRevisamemos el comportamiento del algoritmo para encontrar la solución óptima:\n\n# Crear un gráfico del progreso de la función objetivo\nlibrary(ggplot2)\n\ndf &lt;- data.frame(iteration = 1:max_iterations, cost = result$best_costs)\n\n# Crear modificaciones al plot\ncrear_tema &lt;- function() {\n    theme_minimal() +\n        theme(\n            plot.background = element_rect(fill = \"white\", color = NA), \n            panel.grid.major = element_line(color = \"white\", size = 0.2), \n            panel.grid.minor = element_line(color = \"white\", size = 0.2), \n            panel.background = element_rect(fill = \"white\", color = NA), \n            plot.title = element_text(face = \"bold\", size = 14, color = \"#4d6080\"),\n            axis.title = element_text(face = \"bold\", size = 12, color = \"#4d6080\"),\n            axis.text = element_text(size = 10, color = \"#4d6080\"),\n            axis.line = element_line(size = 1.5, colour = \"#de6f41\"), \n            legend.background = element_rect(fill = \"#4d6080\", color = NA), \n            legend.key = element_rect(fill = \"grey90\", color = NA),\n            axis.ticks.x = element_line(color = \"#de6f41\", size = 1),\n            axis.ticks.y = element_line(color = \"#de6f41\", size = 1)\n        )\n}\n\n\nggplot(df, aes(x = iteration, y = cost)) +\n    geom_line() +\n    labs(title = \"Progreso del costo a lo largo de las iteraciones\", x = \"Iteración\", y = \"Costo\")+\n    crear_tema()\n\n\n\n\n\n\n\n\nLa solución óptima (con las iteraciones establecidas) es entonces:\n\nresult$best$vector\n\n [1] 48 47 26 13 52 14 27 28 12 11 51 43 33  9 10 41  8 45 25 46  5 24  6  4 15\n[26] 19  3 31 23 21  7  2 17 42 30 20 50 29 16 44 37 38 49 35 34 40 39 36 32 18\n[51] 22  1"
  },
  {
    "objectID": "posts/2023-11-19-guided_local_search/index.html",
    "href": "posts/2023-11-19-guided_local_search/index.html",
    "title": "Guided Local serach",
    "section": "",
    "text": "El algoritmo de Guided Local Search es una Metaheurística y un algoritmo de Optimización Global que hace uso de un algoritmo de Local Search embebido. Se trata de una extensión de los algoritmos de búsqueda local como Hill Climbing y es similar en estrategia al algoritmo de Tabu Search y al algoritmo de Iterated Local Search."
  },
  {
    "objectID": "posts/2023-11-19-guided_local_search/index.html#taxonomía",
    "href": "posts/2023-11-19-guided_local_search/index.html#taxonomía",
    "title": "Guided Local serach",
    "section": "",
    "text": "El algoritmo de Guided Local Search es una Metaheurística y un algoritmo de Optimización Global que hace uso de un algoritmo de Local Search embebido. Se trata de una extensión de los algoritmos de búsqueda local como Hill Climbing y es similar en estrategia al algoritmo de Tabu Search y al algoritmo de Iterated Local Search."
  },
  {
    "objectID": "posts/2023-11-19-guided_local_search/index.html#estrategia",
    "href": "posts/2023-11-19-guided_local_search/index.html#estrategia",
    "title": "Guided Local serach",
    "section": "Estrategia",
    "text": "Estrategia\nLa estrategia del algoritmo Guided Local Search consiste en utilizar penalizaciones para animar a una técnica de Local Search a escapar de los óptimos locales y descubrir el óptimo global. Un algoritmo de Local Search se ejecuta hasta que se queda atascado en un óptimo local. Las características de los óptimos locales se evalúan y se penalizan, sus resultados se utilizan en una función de costo aumentada empleada por el procedimiento de Local Search, que se repite varias veces utilizando los últimos óptimos locales descubiertos y la función de costo aumentada que guía la exploración lejos de las soluciones con características presentes en los óptimos locales descubiertos."
  },
  {
    "objectID": "posts/2023-11-19-guided_local_search/index.html#procedimiento",
    "href": "posts/2023-11-19-guided_local_search/index.html#procedimiento",
    "title": "Guided Local serach",
    "section": "Procedimiento",
    "text": "Procedimiento\nEl algoritmo de Local Search utilizado por el algoritmo de Guided Local Search utiliza una función de costo aumentada de la forma \\(h(s) = g(s)+ 𝞴*∑_{i=1}^Mf_i\\), donde \\(h(s)\\) es la función de costo aumentada, \\(g(s)\\) es la función de costo del problema, es el `parámetro de regularización’ (un coeficiente para escalar las penalizaciones), \\(s\\) es una solución localmente óptima de \\(M\\) características, y \\(f_i\\) es la \\(i\\)-ésima característica en la solución localmente óptima. La función de costos aumentada sólo la utiliza el procedimiento de Local Search, mientras que el algoritmo Guided Local Search utiliza la función de costos específica del problema sin aumento.\nLas penalizaciones sólo se actualizan para aquellas características en una solución localmente óptima que maximizan la utilidad, actualizadas añadiendo 1 a la penalización para el futuro (un contador). La utilidad de una característica se calcula como \\(U_{feature} = C_{feature} / (1+P_{feaure})\\) , donde \\(U_{feaure}\\) es la utilidad de penalizar una característica (maximizar), \\(C_{feaure}\\) es el costo de la característica y \\(P_{feature}\\) es la penalización actual para la característica.\n\n\n\nPseudocódigo Guided Local Search"
  },
  {
    "objectID": "posts/2023-11-19-guided_local_search/index.html#heurística",
    "href": "posts/2023-11-19-guided_local_search/index.html#heurística",
    "title": "Guided Local serach",
    "section": "Heurística",
    "text": "Heurística\nEl procedimiento de Guided Local Search es independiente del procedimiento de Local Search integrado en él. Debe identificarse y emplearse un procedimiento de búsqueda específico del dominio.\nEl procedimiento de Guided Local Search puede tener que ejecutarse durante miles a cientos de miles de iteraciones, cada iteración supone una ejecución de un algoritmo de Local Search hasta la convergencia.\nEl algoritmo se diseñó para problemas de optimización discretos en los que una solución se compone de “características” evaluables independientemente como la Optimización Combinatoria, aunque se ha aplicado a la optimización de funciones continuas modeladas como cadenas binarias.\nEl parámetro \\(𝞴\\) es un factor de escala para la penalización de características que debe estar en la misma proporción que los costos de la solución candidata del problema específico al que se aplica el algoritmo. Como tal, el valor para \\(𝞴\\) debe ser significativo cuando se utiliza dentro de la función de costo aumentada (como cuando se añade a un costo de una solución candidata en la minimización y se resta de un en el caso de un problema de maximización)."
  },
  {
    "objectID": "posts/2023-11-19-guided_local_search/index.html#código",
    "href": "posts/2023-11-19-guided_local_search/index.html#código",
    "title": "Guided Local serach",
    "section": "Código",
    "text": "Código\nEl algoritmo se aplica a la instancia Berlin52 de Travling Salesman Problem (TSP), tomada de la TSPLIB. El problema busca una permutación del orden de visita de las ciudades (llamada tour o recorrido) que minimice la distancia total recorrida. La distancia óptima del recorrido para el caso Berlín52 es de 7.542 unidades. Se utiliza un algoritmo de Local Search 2-opt que selecciona dos puntos en una permutación y reconecta el tour, potencialmente desenrollando el tour en los puntos seleccionados. La condición de parada para 2-opt es un número fijo de movimientos no mejorables.\nLa ecuación para ajustar \\(𝞴\\) para instancias de TSP es \\(𝞴 = ⍺ * costo(optima)/N\\) , donde \\(N\\) es el número de ciudades, \\(costo(optima)\\) es el costo de un óptimo local encontrado mediante una búsqueda local, y \\(⍺ ∈ (0,1]\\) (alrededor de 0,3 para TSP y 2-opt). El costo de un óptimo local se fijó en el valor aproximado de 15.000 para el TSP de Berlín52. La función de utilidad para las características (aristas) en el TSP es \\(U_{edge} = D_{edge}/(1+P_{edge})\\) donde \\(U_{edge}\\) es la utilidad de penalizar una arista (maximizar), \\(D_{edge}\\) es el coste de la arista (distancia entre ciudades) y \\(P_{edge}\\) es la penalización actual de la arista.\n\n# Función para calcular la distancia euclidiana entre dos puntos\neuc_2d &lt;- function(c1, c2) {\n    return(round(sqrt((c1[1] - c2[1])^2 + (c1[2] - c2[2])^2)))\n}\n\n# Función para generar una permutación aleatoria de las ciudades\nrandom_permutation &lt;- function(cities) {\n    return(sample(nrow(cities)))\n}\n\n# Función para realizar una operación de dos-opt estocástica en una permutación\nstochastic_two_opt &lt;- function(permutation) {\n    perm &lt;- permutation\n    c1 &lt;- sample(length(perm), 1)\n    exclude &lt;- c(c1, if (c1 == 1) length(perm) else c1 - 1, if (c1 == length(perm)) 1 else c1 + 1)\n    c2 &lt;- sample(length(perm), 1)\n    while (c2 %in% exclude) {\n        c2 &lt;- sample(length(perm), 1)\n    }\n    if (c2 &lt; c1) {\n        temp &lt;- c1\n        c1 &lt;- c2\n        c2 &lt;- temp\n    }\n    perm[c1:c2] &lt;- rev(perm[c1:c2])\n    return(perm)\n}\n\n# Función para calcular el costo y el costo aumentado de una permutación\naugmented_cost &lt;- function(permutation, penalties, cities, lambda) {\n    distance &lt;- 0\n    augmented &lt;- 0\n    for (i in seq_along(permutation)) {\n        c1 &lt;- permutation[i]\n        c2 &lt;- if (i == length(permutation)) permutation[1] else permutation[i + 1]\n        if (c2 &lt; c1) {\n            temp &lt;- c1\n            c1 &lt;- c2\n            c2 &lt;- temp\n        }\n        d &lt;- euc_2d(cities[c1, ], cities[c2, ])\n        distance &lt;- distance + d\n        augmented &lt;- augmented + d + (lambda * penalties[c1, c2])\n    }\n    return(c(distance, augmented))\n}\n\n# Función para calcular el costo de un candidato\ncost &lt;- function(cand, penalties, cities, lambda) {\n    costs &lt;- augmented_cost(cand$vector, penalties, cities, lambda)\n    cand$cost &lt;- costs[1]\n    cand$aug_cost &lt;- costs[2]\n    return(cand)\n}\n\n# Función para realizar una búsqueda local en el espacio de las permutaciones\nlocal_search &lt;- function(current, cities, penalties, max_no_improv, lambda) {\n    current &lt;- cost(current, penalties, cities, lambda)\n    count &lt;- 0\n    repeat {\n        candidate &lt;- list()\n        candidate$vector &lt;- stochastic_two_opt(current$vector)\n        candidate &lt;- cost(candidate, penalties, cities, lambda)\n        if (candidate$aug_cost &lt; current$aug_cost) {\n            count &lt;- 0\n            current &lt;- candidate\n        } else {\n            count &lt;- count + 1\n        }\n        if (count &gt;= max_no_improv) break\n    }\n    return(current)\n}\n\n# Función para calcular las utilidades de las características\ncalculate_feature_utilities &lt;- function(penal, cities, permutation) {\n    utilities &lt;- numeric(length(permutation))\n    for (i in seq_along(permutation)) {\n        c1 &lt;- permutation[i]\n        c2 &lt;- if (i == length(permutation)) permutation[1] else permutation[i + 1]\n        if (c2 &lt; c1) {\n            temp &lt;- c1\n            c1 &lt;- c2\n            c2 &lt;- temp\n        }\n        utilities[i] &lt;- euc_2d(cities[c1, ], cities[c2, ]) / (1.0 + penal[c1, c2])\n    }\n    return(utilities)\n}\n\n# Función para actualizar las penalizaciones\nupdate_penalties &lt;- function(penalties, cities, permutation, utilities) {\n    max_utility &lt;- max(utilities)\n    for (i in seq_along(permutation)) {\n        c1 &lt;- permutation[i]\n        c2 &lt;- ifelse(i == length(permutation), permutation[1], permutation[i + 1])\n        if (c2 &lt; c1) {\n            temp &lt;- c1\n            c1 &lt;- c2\n            c2 &lt;- temp\n        }\n        penalties[c1, c2] &lt;- ifelse(utilities[i] == max_utility, penalties[c1, c2] + 1, penalties[c1, c2])\n    }\n    return(penalties)\n}\n\n# Función de búsqueda principal\nsearch &lt;- function(max_iterations, cities, max_no_improv, lambda) {\n    current &lt;- list()\n    current$vector &lt;- random_permutation(cities)\n    best &lt;- NULL\n    penalties &lt;- matrix(0, nrow = nrow(cities), ncol = nrow(cities))\n    cost_progress &lt;- data.frame(iteration=integer(), cost=numeric()) # Para llevar el seguimiento del progreso del costo\n    for (iter in seq_len(max_iterations)) {\n        current &lt;- local_search(current, cities, penalties, max_no_improv, lambda)\n        utilities &lt;- calculate_feature_utilities(penalties, cities, current$vector)\n        penalties &lt;- update_penalties(penalties, cities, current$vector, utilities)\n        if (is.null(best) || current$cost &lt; best$cost) {\n            best &lt;- current\n        }\n        cost_progress &lt;- rbind(cost_progress, data.frame(iteration=iter, cost=best$cost)) # Registrar el costo en cada iteración\n        #print(paste(\" &gt; iter =\", iter + 1, \", best =\", best$cost, \", aug =\", best$aug_cost))\n    }\n    return(list(best=best, cost_progress=cost_progress)) # Devolver tanto la mejor solución como el progreso del costo\n}\n\n\n# Configuración del problema\nberlin52 &lt;- matrix(c(565,575,25,185,345,750,945,685,845,655,\n                     880,660,25,230,525,1000,580,1175,650,1130,\n                     1605,620,1220,580,1465,200,1530,5,845,680,\n                     725,370,145,665,415,635,510,875,560,365,\n                     300,465,520,585,480,415,835,625,975,580,\n                     1215,245,1320,315,1250,400,660,180,410,250,\n                     420,555,575,665,1150,1160,700,580,685,595,\n                     685,610,770,610,795,645,720,635,760,650,\n                     475,960,95,260,875,920,700,500,555,815,\n                     830,485,1170,65,830,610,605,625,595,360,1340,725,1740,245), ncol = 2, byrow = TRUE)\n\n# Configuración del algoritmo\nmax_iterations &lt;- 150\nmax_no_improv &lt;- 20\nalpha &lt;- 0.3\nlocal_search_optima &lt;- 12000.0\nlambda &lt;- alpha * (local_search_optima / nrow(berlin52))\n\n# Ejecutar el algoritmo\nresult &lt;- search(max_iterations, berlin52, max_no_improv, lambda)\n\nRevisamemos el comportamiento del algoritmo para encontrar la solución óptima:\n\nlibrary(ggplot2)\n\ncrear_tema &lt;- function() {\n    theme_minimal() +\n        theme(\n            plot.background = element_rect(fill = \"white\", color = NA), \n            panel.grid.major = element_line(color = \"white\", size = 0.2), \n            panel.grid.minor = element_line(color = \"white\", size = 0.2), \n            panel.background = element_rect(fill = \"white\", color = NA), \n            plot.title = element_text(face = \"bold\", size = 14, color = \"#4d6080\"),\n            axis.title = element_text(face = \"bold\", size = 12, color = \"#4d6080\"),\n            axis.text = element_text(size = 10, color = \"#4d6080\"),\n            axis.line = element_line(size = 1.5, colour = \"#de6f41\"), \n            legend.background = element_rect(fill = \"#4d6080\", color = NA), \n            legend.key = element_rect(fill = \"grey90\", color = NA),\n            axis.ticks.x = element_line(color = \"#de6f41\", size = 1),\n            axis.ticks.y = element_line(color = \"#de6f41\", size = 1)\n        )\n}\n\nggplot(result$cost_progress, aes(x=iteration, y=cost)) +\n    geom_line() +\n    labs(title=\"Progreso del costo a lo largo de las iteraciones\", x=\"Iteración\", y=\"Costo\")+\n    crear_tema()\n\n\n\n\n\n\n\n\nLa solución óptima (con las iteraciones establecidas) es entonces:\n\nresult$best$vector\n\n [1]  1 22 32 49 36 35 34 44 46 37 40 39 38 24 48  5 15  6  4 25 12 28 26 27 47\n[26] 13 14 52 11 51 43 33 10  9 41  8 19 45  3 18 31  7  2 30 42 17 21 20 29 16\n[51] 50 23"
  },
  {
    "objectID": "posts/2023-12-03-variable_neighborhood_search/index.html",
    "href": "posts/2023-12-03-variable_neighborhood_search/index.html",
    "title": "Variable Neighborhood Search",
    "section": "",
    "text": "Variable Neighborhood Search es una Metaheurística y una técnica de Optimización Global que administra una técnica de Local Search. Está relacionada con el algoritmo de Iterated Local Search."
  },
  {
    "objectID": "posts/2023-12-03-variable_neighborhood_search/index.html#taxonomía",
    "href": "posts/2023-12-03-variable_neighborhood_search/index.html#taxonomía",
    "title": "Variable Neighborhood Search",
    "section": "",
    "text": "Variable Neighborhood Search es una Metaheurística y una técnica de Optimización Global que administra una técnica de Local Search. Está relacionada con el algoritmo de Iterated Local Search."
  },
  {
    "objectID": "posts/2023-12-03-variable_neighborhood_search/index.html#estrategia",
    "href": "posts/2023-12-03-variable_neighborhood_search/index.html#estrategia",
    "title": "Variable Neighborhood Search",
    "section": "Estrategia",
    "text": "Estrategia\nLa estrategia para Variable Neighborhood Search implica la exploración iterativa de vecindarios cada vez más grandes para un óptimo local dado hasta que se localiza una mejora, tras lo cual se repite la búsqueda a través de vecindarios en expansión. La estrategia está motivada por tres principios 1) un mínimo local para una estructura de vecindad puede no ser un mínimo local para una estructura de vecindad diferente, 2) un mínimo global es un mínimo local para todas las estructuras de vecindad posibles, y 3) los mínimos locales están relativamente cerca de los mínimos globales en muchas clases de problemas."
  },
  {
    "objectID": "posts/2023-12-03-variable_neighborhood_search/index.html#procedimiento",
    "href": "posts/2023-12-03-variable_neighborhood_search/index.html#procedimiento",
    "title": "Variable Neighborhood Search",
    "section": "Procedimiento",
    "text": "Procedimiento\nEl pseudocódigo muestra que la búsqueda sistemática de vecindarios en expansión para un óptimo local se abandona cuando se alcanza una mejora global (mostrada con el salto Break).\n\n\n\nPseudocódigo Variable Neighborhood Search"
  },
  {
    "objectID": "posts/2023-12-03-variable_neighborhood_search/index.html#heurística",
    "href": "posts/2023-12-03-variable_neighborhood_search/index.html#heurística",
    "title": "Variable Neighborhood Search",
    "section": "Heurística",
    "text": "Heurística\nSe sugiere el uso de métodos de aproximación (como Stochastic Hill Climbing) como procedimiento de Local Search para instancias de problemas grandes con el fin de reducir el tiempo de ejecución.\nVariable Neighborhood Search se ha aplicado a una amplia gama de problemas de optimización combinatoria, así como a problemas de agrupación (clustering) y optimización de funciones continuas.\nLa técnica de Local Search incrustada debe especializarse según el tipo de problema y la instancia a la que se aplica la técnica.\nVariable Neighborhood Descent (VND) se puede incrustar en Variable Neighborhood Search como un procedimiento de Local Search y ha demostrado ser el más eficaz."
  },
  {
    "objectID": "posts/2023-12-03-variable_neighborhood_search/index.html#código",
    "href": "posts/2023-12-03-variable_neighborhood_search/index.html#código",
    "title": "Variable Neighborhood Search",
    "section": "Código",
    "text": "Código\nEl algoritmo se aplica a la instancia Berlin52 de Travling Salesman Problem (TSP), tomada de la TSPLIB. El problema busca una permutación del orden de visita de las ciudades (llamada tour o recorrido) que minimice la distancia total recorrida. La distancia óptima del recorrido para el caso Berlín52 es de 7.542 unidades.\nVariable Neighborhood Search utiliza un procedimiento estocástico 2-opt como Local Serach incrustada. El procedimiento elimina dos aristas e invierte la secuencia entre las aristas eliminadas, eliminando potencialmente “giros” en el recorrido. La estructura de vecindad utilizada en la búsqueda es el número de veces que se realiza el procedimiento 2-opt en una permutación, entre 1 y 20 veces. La condición de parada para el procedimiento de Local Search es un número máximo de iteraciones sin mejora.\nLa misma condición de parada es empleada por el procedimiento de orden superior Variable Neighborhood Search aunque con un límite inferior en el número de iteraciones sin mejora.\n\n# Función para calcular la distancia euclidiana entre dos puntos\neuc_2d &lt;- function(c1, c2) {\n    return(round(sqrt((c1[1] - c2[1])^2 + (c1[2] - c2[2])^2)))\n}\n\n# Función para calcular el costo de una permutación de ciudades\ncost &lt;- function(perm, cities) {\n    distance &lt;- 0\n    for (i in seq_along(perm)) {\n        c1 &lt;- perm[i]\n        c2 &lt;- if (i == length(perm)) perm[1] else perm[i + 1]\n        distance &lt;- distance + euc_2d(cities[c1, ], cities[c2, ])\n    }\n    return(distance)\n}\n\n# Función para generar una permutación aleatoria de las ciudades\nrandom_permutation &lt;- function(cities) {\n    return(sample(nrow(cities)))\n}\n\n# Función para realizar una operación de dos-opt estocástica en una permutación\nstochastic_two_opt &lt;- function(perm) {\n    c1 &lt;- sample(length(perm), 1)\n    exclude &lt;- c(c1, if (c1 == 1) length(perm) else c1 - 1, if (c1 == length(perm)) 1 else c1 + 1)\n    c2 &lt;- sample(length(perm), 1)\n    while (c2 %in% exclude) {\n        c2 &lt;- sample(length(perm), 1)\n    }\n    if (c2 &lt; c1) {\n        temp &lt;- c1\n        c1 &lt;- c2\n        c2 &lt;- temp\n    }\n    perm[c1:c2] &lt;- rev(perm[c1:c2])\n    return(perm)\n}\n\n# Función para realizar una búsqueda local en el espacio de las permutaciones\nlocal_search &lt;- function(best, cities, max_no_improv, neighborhood) {\n    count &lt;- 0\n    repeat {\n        candidate &lt;- list()\n        candidate$vector &lt;- stochastic_two_opt(best$vector)\n        candidate$cost &lt;- cost(candidate$vector, cities)\n        if (candidate$cost &lt; best$cost) {\n            count &lt;- 0\n            best &lt;- candidate\n        } else {\n            count &lt;- count + 1\n        }\n        if (count &gt;= max_no_improv) break\n    }\n    return(best)\n}\n\n# Función de búsqueda principal\nsearch &lt;- function(cities, neighborhoods, max_no_improv, max_no_improv_ls) {\n    best &lt;- list()\n    best$vector &lt;- random_permutation(cities)\n    best$cost &lt;- cost(best$vector, cities)\n    iter &lt;- 0\n    count &lt;- 0\n    stop_loop &lt;- FALSE\n    # Creamos un dataframe para guardar las soluciones\n    solutions &lt;- data.frame(iteration=integer(), cost=double())\n    for (neigh in neighborhoods) {\n        if (stop_loop) {\n            break\n        }\n        candidate &lt;- list()\n        candidate$vector &lt;- best$vector\n        for (i in seq_len(neigh)) {\n            candidate$vector &lt;- stochastic_two_opt(candidate$vector)\n        }\n        candidate$cost &lt;- cost(candidate$vector, cities)\n        candidate &lt;- local_search(candidate, cities, max_no_improv_ls, neigh)\n        cat(\" &gt; iteration\", iter + 1, \", neigh=\", neigh, \", best=\", best$cost, \"\\n\")\n        iter &lt;- iter + 1\n        # Guardamos la solución en el dataframe\n        solutions &lt;- rbind(solutions, data.frame(iteration=iter, cost=best$cost))\n        if (candidate$cost &lt; best$cost) {\n            best &lt;- candidate\n            count &lt;- 0\n            cat(\"New best, restarting neighborhood search.\\n\")\n        } else {\n            count &lt;- count + 1\n        }\n        if (count &gt;= max_no_improv) {\n            stop_loop &lt;- TRUE\n        }\n    }\n    return(solutions)\n}\n\n# Configuración del problema\nberlin52 &lt;- matrix(c(565,575,25,185,345,750,945,685,845,655,\n                     880,660,25,230,525,1000,580,1175,650,1130,\n                     1605,620,1220,580,1465,200,1530,5,845,680,\n                     725,370,145,665,415,635,510,875,560,365,\n                     300,465,520,585,480,415,835,625,975,580,\n                     1215,245,1320,315,1250,400,660,180,410,250,\n                     420,555,575,665,1150,1160,700,580,685,595,\n                     685,610,770,610,795,645,720,635,760,650,475,\n                     960,95,260,875,920,700,500,555,815,830,485,\n                     1170,65,830,610,605,625,595,360,1340,725,1740,245), ncol = 2, byrow = TRUE)\n\n# Configuración del algoritmo\nmax_no_improv &lt;- 50\nmax_no_improv_ls &lt;- 70\nneighborhoods &lt;- 1:20\n\n# Ejecutar el algoritmo\nbest &lt;- search(berlin52, neighborhoods, max_no_improv, max_no_improv_ls)\n\n &gt; iteration 1 , neigh= 1 , best= 30828 \nNew best, restarting neighborhood search.\n &gt; iteration 2 , neigh= 2 , best= 12474 \n &gt; iteration 3 , neigh= 3 , best= 12474 \nNew best, restarting neighborhood search.\n &gt; iteration 4 , neigh= 4 , best= 10586 \n &gt; iteration 5 , neigh= 5 , best= 10586 \n &gt; iteration 6 , neigh= 6 , best= 10586 \n &gt; iteration 7 , neigh= 7 , best= 10586 \n &gt; iteration 8 , neigh= 8 , best= 10586 \nNew best, restarting neighborhood search.\n &gt; iteration 9 , neigh= 9 , best= 9873 \n &gt; iteration 10 , neigh= 10 , best= 9873 \n &gt; iteration 11 , neigh= 11 , best= 9873 \n &gt; iteration 12 , neigh= 12 , best= 9873 \n &gt; iteration 13 , neigh= 13 , best= 9873 \n &gt; iteration 14 , neigh= 14 , best= 9873 \n &gt; iteration 15 , neigh= 15 , best= 9873 \n &gt; iteration 16 , neigh= 16 , best= 9873 \n &gt; iteration 17 , neigh= 17 , best= 9873 \n &gt; iteration 18 , neigh= 18 , best= 9873 \n &gt; iteration 19 , neigh= 19 , best= 9873 \n &gt; iteration 20 , neigh= 20 , best= 9873 \n\n\nRevisamemos el comportamiento del algoritmo para encontrar la solución óptima:\n\nlibrary(ggplot2)\n\ncrear_tema &lt;- function() {\n    theme_minimal() +\n        theme(\n            plot.background = element_rect(fill = \"white\", color = NA), \n            panel.grid.major = element_line(color = \"white\", size = 0.2), \n            panel.grid.minor = element_line(color = \"white\", size = 0.2), \n            panel.background = element_rect(fill = \"white\", color = NA), \n            plot.title = element_text(face = \"bold\", size = 14, color = \"#4d6080\"),\n            axis.title = element_text(face = \"bold\", size = 12, color = \"#4d6080\"),\n            axis.text = element_text(size = 10, color = \"#4d6080\"),\n            axis.line = element_line(size = 1.5, colour = \"#de6f41\"), \n            legend.background = element_rect(fill = \"#4d6080\", color = NA), \n            legend.key = element_rect(fill = \"grey90\", color = NA),\n            axis.ticks.x = element_line(color = \"#de6f41\", size = 1),\n            axis.ticks.y = element_line(color = \"#de6f41\", size = 1)\n        )\n}\n\nggplot(best, aes(x=iteration, y=cost)) +\n    geom_line() +\n    labs(title=\"Progreso del costo a lo largo de las iteraciones\", x=\"Iteración\", y=\"Costo\")+\n    crear_tema()"
  },
  {
    "objectID": "posts/2023-12-08-greedy_randomized_adaptative_search/index.html",
    "href": "posts/2023-12-08-greedy_randomized_adaptative_search/index.html",
    "title": "Greedy Randomized Adaptative Search",
    "section": "",
    "text": "El Procedimiento de Greedy Randomized Adaptative Search es un algoritmo Metaheurístico y de Optimización Global, originalmente propuesto para los practicantes de la Investigación de Operaciones. La aplicación iterativa de una técnica de Local Search incrustada relaciona el enfoque con Iterated Local Search y las técnicas de Multi-Start."
  },
  {
    "objectID": "posts/2023-12-08-greedy_randomized_adaptative_search/index.html#taxonomía",
    "href": "posts/2023-12-08-greedy_randomized_adaptative_search/index.html#taxonomía",
    "title": "Greedy Randomized Adaptative Search",
    "section": "",
    "text": "El Procedimiento de Greedy Randomized Adaptative Search es un algoritmo Metaheurístico y de Optimización Global, originalmente propuesto para los practicantes de la Investigación de Operaciones. La aplicación iterativa de una técnica de Local Search incrustada relaciona el enfoque con Iterated Local Search y las técnicas de Multi-Start."
  },
  {
    "objectID": "posts/2023-12-08-greedy_randomized_adaptative_search/index.html#estrategia",
    "href": "posts/2023-12-08-greedy_randomized_adaptative_search/index.html#estrategia",
    "title": "Greedy Randomized Adaptative Search",
    "section": "Estrategia",
    "text": "Estrategia\nEl objetivo del Greedy Randomized Adaptative Search es muestrear repetidamente soluciones codiciosas y, a continuación, utilizar un procedimiento de Local Search para refinarlas hasta alcanzar un óptimo local. La estrategia del procedimiento se centra en el mecanismo de construcción por pasos estocásticos y codiciosos que restringe la selección y el orden de inclusión de los componentes de una solución en función del valor que se espera que aporten."
  },
  {
    "objectID": "posts/2023-12-08-greedy_randomized_adaptative_search/index.html#procedimiento",
    "href": "posts/2023-12-08-greedy_randomized_adaptative_search/index.html#procedimiento",
    "title": "Greedy Randomized Adaptative Search",
    "section": "Procedimiento",
    "text": "Procedimiento\nSe presenta un pseudocódigo del Greedy Randomized Adaptative Search para minimizar una función de costo.\n\n\n\nPseudocódigo Greedy Randomized Adaptative Search\n\n\nAdemás, el pseudocódigo de la función de construcción aleatoria codiciosa. La función consiste en la construcción paso a paso de una solución candidata utilizando un proceso de construcción estocástico. La función trabaja construyendo una Lista Restringida de Candidatos (RCL por sus siglas en inglés) que restringe los componentes de una solución (características) que pueden seleccionarse en cada ciclo. La RCL puede limitarse mediante un tamaño explícito o utilizando un umbral \\((⍺ ∈ [0,1])\\) en el costo de añadir cada característica a la solución candidata actual.\n\n\n\nPseudocódigo Función de Construcción"
  },
  {
    "objectID": "posts/2023-12-08-greedy_randomized_adaptative_search/index.html#heurística",
    "href": "posts/2023-12-08-greedy_randomized_adaptative_search/index.html#heurística",
    "title": "Greedy Randomized Adaptative Search",
    "section": "Heurística",
    "text": "Heurística\nEl umbral \\(⍺\\) define el grado de avaricia del mecanismo de construcción, donde valores cercanos a 0 pueden ser demasiado codiciosos, y valores cercanos a 1 pueden ser demasiado generalizados.\nComo alternativa al uso del umbral \\(⍺\\), el RCL se puede puede limitarse al top \\(n%\\) de las características candidatas que pueden seleccionarse en cada ciclo de construcción.\nLa técnica se diseñó para clases de problemas discretos, como los problemas de optimización combinatoria."
  },
  {
    "objectID": "posts/2023-12-08-greedy_randomized_adaptative_search/index.html#código",
    "href": "posts/2023-12-08-greedy_randomized_adaptative_search/index.html#código",
    "title": "Greedy Randomized Adaptative Search",
    "section": "Código",
    "text": "Código\nEl algoritmo se aplica a la instancia Berlin52 de Travling Salesman Problem (TSP), tomada de la TSPLIB. El problema busca una permutación del orden de visita de las ciudades (llamada tour o recorrido) que minimice la distancia total recorrida. La distancia óptima del recorrido para el caso Berlín52 es de 7.542 unidades.\nLa construcción estocástica y codiciosa por pasos de un recorrido implica la evaluación de las ciudades candidatas por el costo que aportan por ser la siguiente ciudad del recorrido. El algoritmo utiliza un procedimiento estocástico 2-opt para Local Search con un número fijo de iteraciones no mejoradas como como condición de parada.\n\n# Función para calcular la distancia euclidiana entre dos puntos\neuc_2d &lt;- function(c1, c2) {\n    return(round(sqrt((c1[1] - c2[1])^2 + (c1[2] - c2[2])^2)))\n}\n\n# Función para calcular el costo de una permutación de ciudades\ncost &lt;- function(perm, cities) {\n    distance &lt;- 0\n    for (i in seq_along(perm)) {\n        c1 &lt;- perm[i]\n        c2 &lt;- if (i == length(perm)) perm[1] else perm[i + 1]\n        distance &lt;- distance + euc_2d(cities[c1, ], cities[c2, ])\n    }\n    return(distance)\n}\n\n# Función para realizar una operación de dos-opt estocástica en una permutación\nstochastic_two_opt &lt;- function(permutation) {\n    perm &lt;- permutation\n    c1 &lt;- sample(length(perm), 1)\n    exclude &lt;- c(c1, if (c1 == 1) length(perm) else c1 - 1, if (c1 == length(perm)) 1 else c1 + 1)\n    c2 &lt;- sample(length(perm), 1)\n    while (c2 %in% exclude) {\n        c2 &lt;- sample(length(perm), 1)\n    }\n    if (c2 &lt; c1) {\n        temp &lt;- c1\n        c1 &lt;- c2\n        c2 &lt;- temp\n    }\n    perm[c1:c2] &lt;- rev(perm[c1:c2])\n    return(perm)\n}\n\n# Función para realizar una búsqueda local en el espacio de las permutaciones\nlocal_search &lt;- function(best, cities, max_no_improv) {\n    count &lt;- 0\n    repeat {\n        candidate &lt;- list()\n        candidate$vector &lt;- stochastic_two_opt(best$vector)\n        candidate$cost &lt;- cost(candidate$vector, cities)\n        if (candidate$cost &lt; best$cost) {\n            count &lt;- 0\n            best &lt;- candidate\n        } else {\n            count &lt;- count + 1\n        }\n        if (count &gt;= max_no_improv) break\n    }\n    return(best)\n}\n\n# Función para construir una solución codiciosa aleatorizada\nconstruct_randomized_greedy_solution &lt;- function(cities, alpha) {\n    candidate &lt;- list()\n    candidate$vector &lt;- sample(1:nrow(cities), 1)\n    allCities &lt;- 1:nrow(cities)\n    while (length(candidate$vector) &lt; nrow(cities)) {\n        candidates &lt;- setdiff(allCities, candidate$vector)\n        costs &lt;- sapply(candidates, function(i) euc_2d(cities[candidate$vector[length(candidate$vector)], ], cities[i, ]))\n        rcl &lt;- candidates[which(costs &lt;= min(costs) + alpha * (max(costs) - min(costs)))]\n        candidate$vector &lt;- c(candidate$vector, sample(rcl, 1))\n    }\n    candidate$cost &lt;- cost(candidate$vector, cities)\n    return(candidate)\n}\n\n# Función de búsqueda principal\nsearch &lt;- function(cities, max_iter, max_no_improv, alpha) {\n    best &lt;- NULL\n    cost_progress &lt;- list()  # Lista para registrar el progreso del costo\n    for (iter in seq_len(max_iter)) {\n        candidate &lt;- construct_randomized_greedy_solution(cities, alpha)\n        candidate &lt;- local_search(candidate, cities, max_no_improv)\n        if (is.null(best) || candidate$cost &lt; best$cost) {\n            best &lt;- candidate\n        }\n        cost_progress[[iter]] &lt;- best$cost  # Registrar el costo en la lista\n        cat(\" &gt; iteration\", iter, \", best=\", best$cost, \"\\n\")\n    }\n    return(list(best = best, cost_progress = cost_progress))  # Devolver la mejor solución y el progreso del costo\n}\n\n# Configuración del problema\nberlin52 &lt;- matrix(c(565,575,25,185,345,750,945,685,845,655,\n                     880,660,25,230,525,1000,580,1175,650,1130,\n                     1605,620,1220,580,1465,200,1530,5,845,680,\n                     725,370,145,665,415,635,510,875,560,365,300,\n                     465,520,585,480,415,835,625,975,580,1215,245,\n                     1320,315,1250,400,660,180,410,250,420,555,575,\n                     665,1150,1160,700,580,685,595,685,610,770,610,\n                     795,645,720,635,760,650,475,960,95,260,875,920,\n                     700,500,555,815,830,485,1170,65,830,610,605,625,\n                     595,360,1340,725,1740,245), ncol = 2, byrow = TRUE)\n\n# Configuración del algoritmo\nmax_iter &lt;- 50\nmax_no_improv &lt;- 50\ngreediness_factor &lt;- 0.3\n\n# Ejecutar el algoritmo\nresult &lt;- search(berlin52, max_iter, max_no_improv, greediness_factor)\n\n &gt; iteration 1 , best= 11976 \n &gt; iteration 2 , best= 11434 \n &gt; iteration 3 , best= 9936 \n &gt; iteration 4 , best= 9936 \n &gt; iteration 5 , best= 9936 \n &gt; iteration 6 , best= 9461 \n &gt; iteration 7 , best= 9461 \n &gt; iteration 8 , best= 9461 \n &gt; iteration 9 , best= 9461 \n &gt; iteration 10 , best= 9461 \n &gt; iteration 11 , best= 9461 \n &gt; iteration 12 , best= 9461 \n &gt; iteration 13 , best= 9461 \n &gt; iteration 14 , best= 9461 \n &gt; iteration 15 , best= 9461 \n &gt; iteration 16 , best= 9461 \n &gt; iteration 17 , best= 9461 \n &gt; iteration 18 , best= 9461 \n &gt; iteration 19 , best= 9461 \n &gt; iteration 20 , best= 9461 \n &gt; iteration 21 , best= 9461 \n &gt; iteration 22 , best= 9461 \n &gt; iteration 23 , best= 9461 \n &gt; iteration 24 , best= 9461 \n &gt; iteration 25 , best= 9461 \n &gt; iteration 26 , best= 9461 \n &gt; iteration 27 , best= 9461 \n &gt; iteration 28 , best= 9461 \n &gt; iteration 29 , best= 9461 \n &gt; iteration 30 , best= 9461 \n &gt; iteration 31 , best= 9461 \n &gt; iteration 32 , best= 9461 \n &gt; iteration 33 , best= 9461 \n &gt; iteration 34 , best= 9461 \n &gt; iteration 35 , best= 9461 \n &gt; iteration 36 , best= 9461 \n &gt; iteration 37 , best= 9461 \n &gt; iteration 38 , best= 9461 \n &gt; iteration 39 , best= 9461 \n &gt; iteration 40 , best= 9461 \n &gt; iteration 41 , best= 9461 \n &gt; iteration 42 , best= 9461 \n &gt; iteration 43 , best= 9461 \n &gt; iteration 44 , best= 9461 \n &gt; iteration 45 , best= 9461 \n &gt; iteration 46 , best= 9461 \n &gt; iteration 47 , best= 9461 \n &gt; iteration 48 , best= 9461 \n &gt; iteration 49 , best= 9461 \n &gt; iteration 50 , best= 9461 \n\nbest &lt;- result$best\ncost_progress &lt;- result$cost_progress\n\nRevisamemos el comportamiento del algoritmo para encontrar la solución óptima:\n\nlibrary(ggplot2)\n\ncrear_tema &lt;- function() {\n    theme_minimal() +\n        theme(\n            plot.background = element_rect(fill = \"white\", color = NA), \n            panel.grid.major = element_line(color = \"white\", size = 0.2), \n            panel.grid.minor = element_line(color = \"white\", size = 0.2), \n            panel.background = element_rect(fill = \"white\", color = NA), \n            plot.title = element_text(face = \"bold\", size = 14, color = \"#4d6080\"),\n            axis.title = element_text(face = \"bold\", size = 12, color = \"#4d6080\"),\n            axis.text = element_text(size = 10, color = \"#4d6080\"),\n            axis.line = element_line(size = 1.5, colour = \"#de6f41\"), \n            legend.background = element_rect(fill = \"#4d6080\", color = NA), \n            legend.key = element_rect(fill = \"grey90\", color = NA),\n            axis.ticks.x = element_line(color = \"#de6f41\", size = 1),\n            axis.ticks.y = element_line(color = \"#de6f41\", size = 1)\n        )\n}\n\ndf &lt;- data.frame(iteration = 1:max_iter, cost = unlist(cost_progress))\nggplot(df, aes(x = iteration, y = cost)) +\n    geom_line() +\n    labs(title = \"Progreso del costo a lo largo de las iteraciones\",\n         x = \"Iteración\",\n         y = \"Costo\")+\n    crear_tema()"
  },
  {
    "objectID": "posts/2024-11-18-intro_git/index.html",
    "href": "posts/2024-11-18-intro_git/index.html",
    "title": "Introducción a Git",
    "section": "",
    "text": "En este módulo, obtendrás una introducción al control de versiones, y a Git. Git puede parecer un poco críptico al principio, e incluso puede ser frustrante a veces. Pero si lo aprendes paso a paso, descubrirás que hay una razón por la que Git se está convirtiendo rápidamente en el sistema de control de versiones más popular del mundo, no sólo para desarrolladores de software, sino también para equipos que escriben documentación y colaboran en otros trabajos."
  },
  {
    "objectID": "posts/2024-11-18-intro_git/index.html#introducción",
    "href": "posts/2024-11-18-intro_git/index.html#introducción",
    "title": "Introducción a Git",
    "section": "",
    "text": "En este módulo, obtendrás una introducción al control de versiones, y a Git. Git puede parecer un poco críptico al principio, e incluso puede ser frustrante a veces. Pero si lo aprendes paso a paso, descubrirás que hay una razón por la que Git se está convirtiendo rápidamente en el sistema de control de versiones más popular del mundo, no sólo para desarrolladores de software, sino también para equipos que escriben documentación y colaboran en otros trabajos."
  },
  {
    "objectID": "posts/2024-11-18-intro_git/index.html#objetivos-de-aprendizaje",
    "href": "posts/2024-11-18-intro_git/index.html#objetivos-de-aprendizaje",
    "title": "Introducción a Git",
    "section": "Objetivos de aprendizaje",
    "text": "Objetivos de aprendizaje\nEn este módulo:\n\nAprenderás qué es el control de versiones.\nEntender los sistemas de control de versiones distribuidos, como Git.\nReconocer las diferencias entre Git y GitHub y las funciones que desempeñan en el ciclo de vida de desarrollo de software."
  },
  {
    "objectID": "posts/2024-11-18-intro_git/index.html#qué-es-el-control-de-versiones",
    "href": "posts/2024-11-18-intro_git/index.html#qué-es-el-control-de-versiones",
    "title": "Introducción a Git",
    "section": "¿Qué es el control de versiones?",
    "text": "¿Qué es el control de versiones?\nUn sistema de control de versiones (VCS) es un programa o conjunto de programas que rastrea los cambios realizados en una colección de archivos. Uno de los objetivos de un VCS es recuperar fácilmente versiones anteriores de archivos individuales o de todo el proyecto. Otro objetivo es permitir que varios miembros de un equipo trabajen en un proyecto, incluso en los mismos archivos, al mismo tiempo sin afectar al trabajo de los demás.\nOtro nombre para un VCS es sistema de gestión de configuración de software (SCM). De hecho, la documentación oficial de Git se encuentra en git-scm.com. Técnicamente, el control de versiones es sólo una de las prácticas implicadas en la SCM. Un VCS puede utilizarse para proyectos distintos del software, incluidos libros y tutoriales en línea.\nCon un VCS, puedes:\n\nVer todos los cambios realizados en tu proyecto, cuándo se hicieron y quién los hizo.\nIncluir un mensaje con cada cambio para explicar los motivos del mismo.\nRecuperar versiones anteriores de todo el proyecto o de archivos individuales.\nCrear ramas, donde se pueden realizar cambios de forma experimental. Esta función permite trabajar en varios conjuntos diferentes de cambios (por ejemplo, características o correcciones de errores) al mismo tiempo, posiblemente por diferentes personas, sin afectar a la rama principal. Más tarde, puedes fusionar los cambios que quieras conservar en la rama principal.\nAdjunta una etiqueta a una versión, por ejemplo, para marcar una nueva versión.\n\nGit es un VCS rápido, versátil, altamente escalable, gratuito y de código abierto. Su principal autor es Linus Torvalds, el creador de Linux."
  },
  {
    "objectID": "posts/2024-11-18-intro_git/index.html#control-de-versiones-distribuido",
    "href": "posts/2024-11-18-intro_git/index.html#control-de-versiones-distribuido",
    "title": "Introducción a Git",
    "section": "Control de versiones distribuido",
    "text": "Control de versiones distribuido\nLos primeros VCS, como CVS, Subversion (SVN) y Perforce, utilizaban un servidor centralizado para almacenar el historial de un proyecto. Esta centralización significaba que el único servidor era también potencialmente un único punto de fallo.\nGit es distribuido, lo que significa que el historial completo de un proyecto se almacena tanto en el cliente como en el servidor. Puedes editar archivos sin conexión a la red, comprobarlos localmente y sincronizarlos con el servidor cuando haya una conexión disponible. Si un servidor se cae, sigues teniendo una copia local del proyecto. Técnicamente, ni siquiera hace falta tener un servidor. Los cambios pueden ser enviados por correo electrónico o compartidos mediante el uso de medios extraíbles, pero nadie utiliza Git de esta manera en la práctica."
  },
  {
    "objectID": "posts/2024-11-18-intro_git/index.html#terminología-de-git",
    "href": "posts/2024-11-18-intro_git/index.html#terminología-de-git",
    "title": "Introducción a Git",
    "section": "Terminología de Git",
    "text": "Terminología de Git\nPara entender Git, tienes que entender su terminología. Aquí tienes una pequeña lista de términos que los usuarios de Git utilizan con frecuencia. No te preocupes por los detalles por ahora; todos estos términos te resultarán familiares a medida que vayas avanzando en los ejercicios de este módulo.\n\nÁrbol de trabajo: El conjunto de directorios y archivos anidados que contienen el proyecto en el que se está trabajando.\nRepositorio (repo): El directorio, situado en el nivel superior de un árbol de trabajo, donde Git guarda toda la historia y metadatos de un proyecto. Los repositorios casi siempre se denominan repos. Un repositorio vacío es aquel que no forma parte de un árbol de trabajo; se utiliza para compartir o hacer copias de seguridad. Un repositorio vacío es normalmente un directorio con un nombre que termina en .git-por ejemplo, proyecto.git.\nHash: Un número producido por una función hash que representa el contenido de un archivo u otro objeto como un número fijo de dígitos. Git utiliza hashes de 160 bits de longitud. Una ventaja de usar hashes es que Git puede saber si un archivo ha cambiado haciendo un hash de su contenido y comparando el resultado con el hash anterior. Si la fecha y hora del archivo cambia, pero el hash del archivo no, Git sabe que el contenido del archivo no ha cambiado.\nObjetos: Un repositorio Git contiene cuatro tipos de objetos, cada uno identificado de forma única por un hash SHA-1. Un objeto blob contiene un archivo ordinario. Un objeto tree representa un directorio; contiene nombres, hashes y permisos. Un objeto commit representa una versión específica del árbol de trabajo. Una etiqueta es un nombre asociado a una confirmación.\nCommit: Cuando se utiliza como verbo, commit significa crear un objeto commit. Esta acción toma su nombre de las confirmaciones a una base de datos. Significa que estás confirmando los cambios que has hecho para que otros también puedan verlos.\nRama: Una rama es una serie de confirmaciones enlazadas. El commit más reciente de una rama se denomina head. La rama por defecto, que se crea cuando inicializas un repositorio, se llama main, a menudo llamada master en Git. La cabecera de la rama actual se llama HEAD. Las ramas son una característica increíblemente útil de Git porque permiten a los desarrolladores trabajar independientemente (o juntos) en ramas y más tarde fusionar sus cambios en la rama por defecto.\nRemoto: Un remoto es una referencia con nombre a otro repositorio Git. Cuando creas un repositorio, Git crea un remoto llamado origen, que es el remoto por defecto para las operaciones push y pull.\nComandos, subcomandos y opciones: Las operaciones de Git se realizan usando comandos como git push y git pull. git es el comando, y push o pull es el subcomando. El subcomando especifica la operación que quieres que Git realice. Los comandos suelen ir acompañados de opciones, que utilizan guiones (-) o guiones dobles (–). Por ejemplo, git reset --hard.\n\nEstos términos y otros, como «empujar» y « tirar», tendrán más sentido en breve. Pero tienes que empezar por algún sitio, y puede que te resulte útil volver y revisar este glosario de términos cuando termines el módulo."
  },
  {
    "objectID": "posts/2024-11-18-intro_git/index.html#la-línea-de-comandos-de-git",
    "href": "posts/2024-11-18-intro_git/index.html#la-línea-de-comandos-de-git",
    "title": "Introducción a Git",
    "section": "La línea de comandos de Git",
    "text": "La línea de comandos de Git\nExisten diferentes interfaces gráficas para Git, incluyendo GitHub Desktop. Muchos editores de programación, como Microsoft Visual Studio Code, también tienen una interfaz para Git. Todos funcionan de forma diferente y tienen distintas limitaciones. Ninguno de ellos implementa todas las funcionalidades de Git.\nLos ejercicios de este módulo utilizan la línea de comandos de Git, en concreto, comandos de Git ejecutados en Azure Cloud Shell. Sin embargo, la interfaz de línea de comandos de Git funciona igual, independientemente del sistema operativo que estés utilizando. Además, la línea de comandos te permite aprovechar toda la funcionalidad de Git. Los desarrolladores que sólo ven Git a través de una interfaz gráfica de usuario a veces se encuentran con mensajes de error que no pueden resolver, y tienen que recurrir a la línea de comandos para ponerse en marcha de nuevo."
  },
  {
    "objectID": "posts/2024-11-18-intro_git/index.html#git-y-github",
    "href": "posts/2024-11-18-intro_git/index.html#git-y-github",
    "title": "Introducción a Git",
    "section": "Git y GitHub",
    "text": "Git y GitHub\nA medida que trabajas con Git, puede que te preguntes sobre las diferencias entre las funciones que ofrece y las que ofrece GitHub.\nComo se mencionó anteriormente, Git es un sistema de control de versiones distribuido (DVCS) que múltiples desarrolladores y otros colaboradores pueden utilizar para trabajar en un proyecto. Proporciona una manera de trabajar con una o más ramas locales y luego enviarlas a un repositorio remoto.\nGitHub es una plataforma en la nube que utiliza Git como tecnología central. GitHub simplifica el proceso de colaboración en proyectos y proporciona un sitio web, más herramientas de línea de comandos y un flujo general que los desarrolladores y usuarios pueden utilizar para trabajar juntos. GitHub actúa como el repositorio remoto mencionado anteriormente.\nEntre las principales características que ofrece GitHub se incluyen:\n\nTemas\nDebates\nPull requests\nNotificaciones\nEtiquetas\nAcciones\nForks\nProyectos\n\nPara obtener más información sobre GitHub, consulta el módulo Introducción a GitHub de Microsoft Learn o la documentación de ayuda Introducción a GitHub.\nEl siguiente paso es probar Git por ti mismo."
  },
  {
    "objectID": "posts/2024-11-18-intro_git/index.html#ejercicio---prueba-git",
    "href": "posts/2024-11-18-intro_git/index.html#ejercicio---prueba-git",
    "title": "Introducción a Git",
    "section": "Ejercicio - Prueba Git",
    "text": "Ejercicio - Prueba Git\nAntes de que puedas crear tu primer repositorio, debes asegurarte de que Git está instalado y configurado. Git viene preinstalado con Azure Cloud Shell, por lo que podemos utilizar Git en Cloud Shell a la derecha.\n\nConfigurar Git\n\nEn Cloud Shell, para comprobar que Git está instalado, escribe git --version:\n\n\n\nBash\n\ngit --version\n\n\n\n\n\n\n\nTip\n\n\n\nPuede utilizar el botón Copiar para copiar comandos en el portapapeles. Para pegar, haga clic con el botón derecho en una nueva línea del terminal de Cloud Shell y seleccione Pegar, o utilice el atajo de teclado Mayús+Insertar (⌘+V en macOS).\n\n\n\nDebería ver una salida parecida a la de este ejemplo:\n\n\n\nOutput\n\ngit version 2.22.0\n\n\nPara configurar Git, debes definir algunas variables globales: user.name y user.email. Ambas son necesarias para que puedas hacer commits.\nEstablezca su nombre en Cloud Shell con el siguiente comando. Sustituya &lt;NOMBRE_USUARIO&gt; por el nombre de usuario que desee utilizar.\n\n\n\nBash\n\ngit config --global user.name \"&lt;NOMBRE_USUARIO&gt;\"\n\n\nAhora, utilice este comando para crear una variable de configuración user.email, sustituyendo &lt;USER_EMAIL&gt; por su dirección de correo electrónico:\n\n\n\nBash\n\ngit config --global user.email \"&lt;USER_EMAIL&gt;\"\n\n\nEjecute el siguiente comando para comprobar que sus cambios han funcionado:\n\n\n\nBash\n\ngit config --list\n\n\nCompruebe que la salida incluye dos líneas similares a las del ejemplo siguiente. Su nombre y dirección de correo electrónico serán diferentes de los que se muestran en el ejemplo.\n\n\n\nOutput\n\nuser.name=MIUSUARIO\nuser.email=miusuario@protonmail.com"
  },
  {
    "objectID": "posts/2024-11-18-intro_git/index.html#configura-tu-repositorio-git",
    "href": "posts/2024-11-18-intro_git/index.html#configura-tu-repositorio-git",
    "title": "Introducción a Git",
    "section": "Configura tu repositorio Git",
    "text": "Configura tu repositorio Git\nGit funciona comprobando los cambios en los archivos dentro de una carpeta determinada. Crearemos una carpeta para que sirva como nuestro árbol de trabajo (directorio del proyecto) y dejaremos que Git lo sepa, para que pueda empezar a seguir los cambios. Le diremos a Git que empiece a seguir los cambios inicializando un repositorio Git en esa carpeta.\nEmpieza creando una carpeta vacía para tu proyecto, y luego inicializa un repositorio Git dentro de ella.\n\nCrea una carpeta llamada Gatos. Esta carpeta será el directorio del proyecto, también llamado árbol de trabajo. El directorio del proyecto es donde se almacenan todos los archivos relacionados con tu proyecto. En este ejercicio, es donde se almacenan tu sitio web y los archivos que crean el sitio web y su contenido.\n\n\n\nBash\n\nmkdir Cats\n\n\nCambie al directorio del proyecto utilizando el comando cd:\n\n\n\nBash\n\ncd Cats\n\n\nAhora, inicialice su nuevo repositorio y establezca el nombre de la rama por defecto a main:\n\n\n\nBash\n\ngit init --initial-branch=main\n\nO utilice el siguiente comando:\n\n\nBash\n\ngit init -b main\n\nPara versiones anteriores de Git, utiliza estos comandos:\n\n\nBash\n\ngit init\ngit checkout -b main\n\nDespués de ejecutar el comando initialize, deberías ver una salida similar a la de este ejemplo:\n\n\nBash\n\nInitialized empty Git repository in /home/&lt;user&gt;/Cats/.git/\n\nSwitched to a new branch 'main'\n\n\nAhora, usa el comando git status para mostrar el estado del árbol de trabajo:\n\n\n\nBash\n\ngit status\n\nGit responde con esta salida, que indica que main es la rama actual. (También es la única rama.) Hasta aquí, todo bien.\n\n\nBash\n\nOn branch main\n\nNo commits yet\n\nnothing to commit (create/copy files and use \"git add\" to track)        \n\n\nUtilice un comando ls para mostrar el contenido del árbol de trabajo:\n\n\n\nBash\n\nls -a\n\nConfirme que el directorio contiene un subdirectorio llamado .git. (Usar la opción -a con ls es importante porque Linux normalmente oculta los nombres de archivos y directorios que empiezan con un punto). Esta carpeta es el repositorio deGit -el directorio en el que Git almacena los metadatos y el historial del árbol de trabajo. Normalmente no haces nada con el directorio .git directamente. Git actualiza los metadatos allí a medida que cambia el estado del árbol de trabajo para mantener un registro de lo que ha cambiado en tus archivos. Este directorio no tiene nada que ver contigo, pero es increíblemente importante para Git."
  },
  {
    "objectID": "posts/2024-11-18-intro_git/index.html#obtén-ayuda-de-git",
    "href": "posts/2024-11-18-intro_git/index.html#obtén-ayuda-de-git",
    "title": "Introducción a Git",
    "section": "Obtén ayuda de Git",
    "text": "Obtén ayuda de Git\nGit, como la mayoría de las herramientas de línea de comandos, tiene una función de ayuda integrada que puedes utilizar para buscar comandos y palabras clave.\n\nEscribe el siguiente comando para obtener ayuda sobre lo que puedes hacer con Git:\n\n\nBash\n\ngit -help\n\nEl comando muestra la siguiente salida:\n\n\nOutput\n\nusage: git [--version] [--help] [-C &lt;path&gt;] [-c name=value]\n       [--exec-path[=&lt;path&gt;]] [--html-path] [--man-path] [--info-path]\n       [-p | --paginate | --no-pager] [--no-replace-objects] [--bare]\n       [--git-dir=&lt;path&gt;] [--work-tree=&lt;path&gt;] [--namespace=&lt;name&gt;]\n       &lt;command&gt; [&lt;args&gt;]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone      Clone a repository into a new directory\n   init       Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add        Add file contents to the index\n   mv         Move or rename a file, a directory, or a symlink\n   reset      Reset current HEAD to the specified state\n   rm         Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect     Use binary search to find the commit that introduced a bug\n   grep       Print lines matching a pattern\n   log        Show commit logs\n   show       Show various types of objects\n   status     Show the working tree status\n\ngrow, mark and tweak your common history\n   branch     List, create, or delete branches\n   checkout   Switch branches or restore working tree files\n   commit     Record changes to the repository\n   diff       Show changes between commits, commit and working tree, etc\n   merge      Join two or more development histories together\n   rebase     Forward-port local commits to the updated upstream head\n   tag        Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch      Download objects and refs from another repository\n   pull       Fetch from and integrate with another repository or a local branch\n   push       Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help &lt;command&gt;' or 'git help &lt;concept&gt;'\nto read about a specific subcommand or concept."
  },
  {
    "objectID": "posts/2024-11-18-intro_git/index.html#comandos-básicos-de-git",
    "href": "posts/2024-11-18-intro_git/index.html#comandos-básicos-de-git",
    "title": "Introducción a Git",
    "section": "Comandos básicos de Git",
    "text": "Comandos básicos de Git\nGit funciona recordando los cambios en tus archivos como si estuviera tomando instantáneas de tu sistema de archivos.\nCubriremos algunos comandos básicos para comenzar a rastrear archivos en su repositorio. Luego, guardaremos nuestra primera «instantánea» para que Git la compare.\n\ngit status\nEl primer comando de Git, y el más utilizado, es git status . Ya lo usaste una vez, en el ejercicio anterior, para comprobar que habías inicializado tu repositorio de Git correctamente.\ngit status muestra el estado del árbol de trabajo (y del área de preparación-pronto hablaremos más sobre el área de preparación). Te permite ver qué cambios están siendo seguidos actualmente por Git, para que puedas decidir si quieres pedir a Git que tome otra instantánea.\n\n\ngit add\ngit add es el comando que usas para decirle a Git que empiece a registrar los cambios en ciertos archivos.\nEl término técnico es preparar estos cambios. Usarás git add para preparar los cambios para una confirmación. Todos los cambios en los archivos que han sido añadidos pero aún no confirmados se almacenan en el área de preparación.\n\n\ngit commit\nDespués de haber preparado algunos cambios para su confirmación, puedes guardar tu trabajo en una instantánea invocando el comando git commit.\nCommit es tanto un verbo como un sustantivo. Tiene esencialmente el mismo significado que cuando confirmas un plan o un cambio en una base de datos. Como verbo, confirmar cambios significa que pones una copia (del archivo, directorio u otra «cosa») en el repositorio como una nueva versión. Como sustantivo, una confirmación es el pequeño fragmento de datos que da una identidad única a los cambios que has confirmado. Los datos que se guardan en una confirmación incluyen el nombre y la dirección de correo electrónico del autor, la fecha, comentarios sobre lo que has hecho (y por qué), una firma digital opcional y el identificador único de la confirmación anterior.\n\n\ngit log\nEl comando git log te permite ver información sobre confirmaciones anteriores. Cada confirmación tiene un mensaje adjunto (un mensaje de confirmación), y el comando git log imprime información sobre las confirmaciones más recientes, como su marca de tiempo, el autor y un mensaje de confirmación. Este comando te ayuda a hacer un seguimiento de lo que has estado haciendo y de los cambios que se han guardado.\n\n\ngit help\nYa has probado el comando git help, pero merece la pena recordártelo. Usa este comando para obtener fácilmente información sobre todos los comandos que has aprendido hasta ahora, y más.\nRecuerda que cada comando tiene su propia página de ayuda. Puedes encontrar estas páginas de ayuda escribiendo git &lt;comando&gt; --help. Por ejemplo, git commit --help muestra una página que te informa sobre el comando git commit y cómo usarlo."
  },
  {
    "objectID": "posts/2024-11-18-intro_git/index.html#resumen",
    "href": "posts/2024-11-18-intro_git/index.html#resumen",
    "title": "Introducción a Git",
    "section": "Resumen",
    "text": "Resumen\n¡Enhorabuena! En este módulo, aprendiste los conceptos básicos del uso de Git.\nAprendiste:\n\nUna visión general de los Sistemas de Control de Versiones (VCS).\nTerminología importante de Git.\nLas diferencias entre Git y GitHub.\nCómo configurar Git.\nAlgunos comandos básicos de Git.\n\nLlegados a este punto, ya sabes lo suficiente sobre Git como para utilizar el control de versiones por ti mismo en un proyecto básico. La colaboración con otros desarrolladores es donde brilla el control de versiones. Echa un vistazo a los otros módulos de esta ruta de aprendizaje para obtener más información sobre el uso de Git con otros."
  },
  {
    "objectID": "actualizado.html",
    "href": "actualizado.html",
    "title": "Primera actualizacion",
    "section": "",
    "text": "Este archivo es para realizar el primer commit luego de clonar el repositorio desde Github a mi equipo local."
  },
  {
    "objectID": "posts/2024-11-18-intro_github/index.html",
    "href": "posts/2024-11-18-intro_github/index.html",
    "title": "Introducción a Github",
    "section": "",
    "text": "GitHub proporciona una plataforma para desarrolladores impulsada por IA para crear, escalar y entregar software seguro. Ya sea para planificar nuevas características, corregir errores o colaborar en los cambios, GitHub es el lugar donde más de 100 millones de desarrolladores de todo el mundo se reúnen para crear cosas y hacerlas aún mejor.\nEn este módulo, aprenderás los conceptos básicos de GitHub y obtendrás una mejor comprensión de sus características fundamentales con un ejercicio práctico, todo dentro de un repositorio de GitHub.\n\n\nEn este módulo:\n\nIdentificar las características fundamentales de GitHub.\nAprenderás sobre la gestión de repositorios.\nComprender el flujo de GitHub, incluyendo ramas, commits y pull requests.\nExplorar las características de colaboración de GitHub mediante la revisión de problemas y discusiones.\nReconocer cómo gestionar tus notificaciones y suscripciones de GitHub."
  },
  {
    "objectID": "posts/2024-11-18-intro_github/index.html#introduccion",
    "href": "posts/2024-11-18-intro_github/index.html#introduccion",
    "title": "Introducción a Github",
    "section": "",
    "text": "GitHub proporciona una plataforma para desarrolladores impulsada por IA para crear, escalar y entregar software seguro. Ya sea para planificar nuevas características, corregir errores o colaborar en los cambios, GitHub es el lugar donde más de 100 millones de desarrolladores de todo el mundo se reúnen para crear cosas y hacerlas aún mejor.\nEn este módulo, aprenderás los conceptos básicos de GitHub y obtendrás una mejor comprensión de sus características fundamentales con un ejercicio práctico, todo dentro de un repositorio de GitHub.\n\n\nEn este módulo:\n\nIdentificar las características fundamentales de GitHub.\nAprenderás sobre la gestión de repositorios.\nComprender el flujo de GitHub, incluyendo ramas, commits y pull requests.\nExplorar las características de colaboración de GitHub mediante la revisión de problemas y discusiones.\nReconocer cómo gestionar tus notificaciones y suscripciones de GitHub."
  },
  {
    "objectID": "posts/2024-11-18-intro_github/index.html#qué-es-github",
    "href": "posts/2024-11-18-intro_github/index.html#qué-es-github",
    "title": "Introducción a Github",
    "section": "¿Qué es GitHub?",
    "text": "¿Qué es GitHub?\nEn esta unidad, revisamos los siguientes objetivos de aprendizaje:\n\nBreve descripción de la plataforma empresarial GitHub.\nCómo crear un repositorio.\nCómo añadir archivos a un repositorio.\nCómo buscar repositorios.\nIntroducción a gists y wikis.\n\n\nGitHub\nEs una plataforma basada en la nube que utiliza Git, un sistema de control de versiones distribuido, en su núcleo. La plataforma GitHub simplifica el proceso de colaboración en proyectos y proporciona un sitio web, herramientas de línea de comandos y un flujo general que permite a los desarrolladores y usuarios trabajar juntos.\nComo hemos aprendido antes, GitHub proporciona una plataforma para desarrolladores impulsada por IA para construir, escalar y entregar software seguro. Vamos a desglosar cada uno de los pilares fundamentales de la plataforma GitHub Enterprise, IA, Colaboración, Productividad, Seguridad y Escala.\n\n\nIA\nLa IA generativa está transformando drásticamente el desarrollo de software en estos momentos. La plataforma GitHub Enterprise está mejorando la colaboración a través de pull requests y issues impulsados por IA, la productividad a través de Copilot, y la seguridad automatizando las comprobaciones de seguridad con mayor rapidez.\n\n\nColaboración\nLa colaboración es el núcleo de todo lo que hace GitHub. Sabemos que una colaboración ineficiente supone una pérdida de tiempo y dinero. Contrarrestamos esto con un conjunto de herramientas que permiten la colaboración sin esfuerzo.\nRepositorios, Issues, Pull Requests y otras herramientas ayudan a que desarrolladores, jefes de proyecto, líderes de operaciones y otras personas de la misma empresa puedan colaborar. Esto les permite trabajar juntos más rápido, reducir los tiempos de aprobación y realizar los envíos con mayor celeridad.\n\n\nProductividad\nLa productividad se acelera con la automatización que proporciona la Plataforma Empresarial GitHub. Con herramientas CI/CD (Integración Continua y Entrega Continua) integradas directamente en el flujo de trabajo, la plataforma ofrece a los usuarios la posibilidad de establecer tareas y olvidarse de ellas, ocupándose de la administración rutinaria y acelerando el trabajo diario. De este modo, los desarrolladores disponen de más tiempo para centrarse en lo más importante: crear soluciones innovadoras.\n\n\nSeguridad\nGitHub se centra en integrar la seguridad directamente en el proceso de desarrollo desde el principio. La plataforma GitHub Enterprise incluye funciones de seguridad nativas y propias que minimizan el riesgo de seguridad con una solución de seguridad integrada. Además, tu código permanece privado dentro de tu organización. Al mismo tiempo, puedes aprovechar la visión general de la seguridad y Dependabot.\nGitHub ha seguido invirtiendo para garantizar que nuestras funciones estén preparadas para la empresa. Microsoft y las industrias altamente reguladas confían en GitHub, y cumplimos con los requisitos de cumplimiento global.\n\n\nEscala\nGitHub es la mayor comunidad de desarrolladores de su clase, con datos en tiempo real sobre más de 100 millones de desarrolladores, más de 330 millones de repositorios e innumerables despliegues. Hemos sido capaces de entender las necesidades cambiantes de los desarrolladores y hacer cambios en nuestro producto para que coincida.\nEsto se ha traducido en una escala increíble que no tiene parangón ni comparación con ninguna otra empresa del planeta. Cada día obtenemos más información de esta impresionante comunidad y hacemos evolucionar la plataforma para satisfacer sus necesidades.\nEn esencia, la Plataforma Empresarial GitHub se centra en la experiencia del desarrollador. Tiene la escala para proporcionar conocimientos que cambian la industria, capacidades de colaboración para la eficiencia transformadora, las herramientas para aumentar la productividad, la seguridad en cada paso, y AI para impulsar todo a nuevas alturas en una sola plataforma integrada.\nAhora vamos a entrar en la columna vertebral de GitHub, los repositorios.\n\n\nIntroducción a los repositorios\nHagamos primero un repaso:\n\n¿Qué es un repositorio?\nCómo crear un repositorio\nAñadir ficheros a un repositorio\nCómo buscar repositorios\nIntroducción a gists, wikis y páginas de GitHub\n\n\n¿Qué es un repositorio?\nUn repositorio contiene todos los archivos de tu proyecto y el historial de revisiones de cada archivo. Es una de las partes esenciales que te ayuda a colaborar con la gente. Puedes utilizar repositorios para gestionar tu trabajo, realizar un seguimiento de los cambios, almacenar el historial de revisiones y trabajar con otras personas. Antes de profundizar demasiado, empecemos por cómo crear un repositorio.\n\n\n¿Cómo crear un repositorio?\nPuedes crear un nuevo repositorio en tu cuenta personal o en cualquier organización donde tengas permisos suficientes.\nVamos a abordar la creación de un repositorio desde github.com.\n\nEn la esquina superior derecha de cualquier página, utilice el menú desplegable y seleccione New repository.\n\n\n\n\nUtilice el menú desplegable Owner para seleccionar la cuenta que desea que sea la propietaria del repositorio.\n\n\n\n\nEscriba un nombre para su repositorio y una descripción opcional.Escriba un nombre para su repositorio y una descripción opcional.\n\n\n\n\nElija una visibilidad de repositorio.\n\nLos repositorios públicos son accesibles a todo el mundo en Internet.\nLos repositorios privados sólo son accesibles para ti, para las personas con las que compartes explícitamente el acceso y, para los repositorios de organizaciones, para ciertos miembros de la organización.\n\nSeleccione Crear repositorio y ¡enhorabuena! ¡Acaba de crear un repositorio!\n\n\nA continuación, vamos a ver cómo añadir ficheros a tu repositorio.\n\n\n¿Cómo añadir un archivo a tu repositorio?\nLos archivos en GitHub pueden hacer un puñado de cosas, pero el propósito principal de los archivos es almacenar datos e información sobre tu proyecto. Vale la pena saber que para añadir un archivo a un repositorio primero debes tener un acceso mínimo de Escritura dentro del repositorio al que quieres añadir un archivo.\nRepasemos cómo añadir un archivo a tu repositorio.\n\nEn GitHub.com, navega a la página principal del repositorio.\nEn tu repositorio, navega hasta la carpeta donde quieres crear un archivo seleccionando el enlace crear un nuevo archivo o subiendo un archivo existente.\n\nEn el campo de nombre de archivo, escriba el nombre y la extensión del archivo. Para crear subdirectorios, escriba el separador de directorios /.\n\nEn el cuadro de texto Contenido del archivo, escriba el contenido del archivo.\n\nPara revisar el nuevo contenido, encima del contenido del archivo, seleccione Vista previa.\nSeleccione Confirmar cambios.\n\nEn el campo Mensaje de confirmación, escriba un mensaje de confirmación breve y significativo que describa el cambio realizado en el archivo. Puedes atribuir la confirmación a más de un autor en el mensaje de confirmación.\n\nAsi se puede ver luego de realizar commit:\n\nVamos a crear otro archivo.\n\nDebajo de los campos de mensaje de confirmación, decida si desea añadir su confirmación a la rama actual o a una nueva rama. Si su rama actual es la rama por defecto, debe elegir crear una nueva rama para su confirmación y, a continuación, crear una solicitud de extracción.\n\n\n\n\nSeleccione Confirmar cambios o Proponer cambios.\n\n\nEnhorabuena, ¡acaba de crear un nuevo fichero en su repositorio! También has creado una nueva rama y hecho un commit.\nAntes de revisar ramas y commits en la siguiente unidad, vamos a revisar rápidamente gists, wikis y páginas de GitHub porque son similares a los repositorios.\n\n\n¿Qué son las gists?\nAhora que ya conocemos bien los repositorios, podemos revisar las gists. Al igual que los repositorios, las gists son una forma simplificada de compartir fragmentos de código con los demás.\nCada gist es un repositorio Git, que puedes bifurcar y clonar y que puede ser público o privado. Las gists públicas se muestran públicamente y la gente puede consultar las nuevas a medida que se crean. En las gists públicas también se pueden realizar búsquedas. Por el contrario, las gists privadas no permiten búsquedas, pero no son totalmente privadas. Si envías la URL de una lista secreta a un amigo, éste podrá verla.\nPara obtener más información sobre gists, consulte el artículo vinculado en nuestra sección de Recursos al final de este módulo titulado Creación de Gists.\n\n\n¿Qué son las wikis?\nCada repositorio en GitHub.com viene equipado con una sección para alojar documentación, llamada wiki. Puedes utilizar el wiki de tu repositorio para compartir contenido extenso sobre tu proyecto, como por ejemplo ¿cómo utilizarlo?, ¿cómo lo diseñaste?, o sus principios básicos. Mientras que un archivo README dice rápidamente lo que su proyecto puede hacer, puede utilizar un wiki para proporcionar documentación adicional.\nVale la pena recordar que si su repositorio es privado, sólo las personas que tienen al menos acceso de lectura a su repositorio tendrán acceso a su wiki."
  },
  {
    "objectID": "posts/2024-11-18-intro_github/index.html#componentes-del-flujo-de-github",
    "href": "posts/2024-11-18-intro_github/index.html#componentes-del-flujo-de-github",
    "title": "Introducción a Github",
    "section": "Componentes del flujo de GitHub",
    "text": "Componentes del flujo de GitHub\nEn esta unidad, revisaremos los siguientes componentes del flujo de GitHub:\n\nRamas\nCommits\nSolicitudes de Pull\nEl flujo de GitHub\n\n\n¿Qué son las ramas?\nEn la última sección, hemos creado un nuevo archivo y una nueva rama en tus repositorios.\nLas ramas son una parte esencial de la experiencia GitHub, ya que son donde podemos hacer cambios sin afectar a todo el proyecto en el que estamos trabajando.\nTu rama es un lugar seguro para experimentar con nuevas características o correcciones. Si cometes un error, puedes revertir tus cambios o empujar más cambios para corregir el error. Tus cambios no se actualizarán en la rama por defecto hasta que fusiones tu rama.\n\nNota\nAlternativamente, puedes crear una nueva rama y comprobarla usando git en un terminal. El comando sería git checkout -b nombreNuevaRama\n\n\n\n¿Qué son los commits?\nEn la unidad anterior, añadiste un nuevo archivo al repositorio enviando una confirmación. Repasemos brevemente qué son las confirmaciones.\nUna confirmación es un cambio en uno o más ficheros de una rama. Cada vez que se crea una confirmación, se le asigna un ID único y se realiza un seguimiento junto con la hora y el contribuidor. Los commits proporcionan una pista de auditoría clara para cualquiera que revise el historial de un archivo o elemento vinculado, como una incidencia (issue) o pull request.\n\nDentro de un repositorio de Git, un archivo puede existir en varios estados válidos a medida que pasa por el proceso de control de versiones. Los estados primarios de un archivo en un repositorio de Git son No rastreado y Rastreado.\nNo rastreado: El estado inicial de un archivo cuando no forma parte aún del repositorio de Git. Git no está al tanto de su existencia.\nRastreado: Un archivo rastreado es uno que Git está monitoreando activamente. Puede estar en uno de los siguientes subestados:\n\nNo modificado: El archivo es rastreado, pero no ha sido modificado desde el último commit.\nModificado: El archivo ha sido cambiado desde el último commit, pero estos cambios no están aún en la área de staging para el próximo commit.\nStaged: El archivo ha sido modificado y los cambios han sido agregados al área de staging (también conocida como el índice). Estos cambios están listos para ser comprometidos.\nCommited: El archivo se encuentra en la base de datos del repositorio. Representa la versión más reciente comprometida del archivo.\n\nEstos estados y subestados son importantes para colaborar con tu equipo y saber dónde se encuentra cada y cada commit en el proceso de tu proyecto. Ahora, pasemos a las solicitudes de extracción.\n\n\n¿Qué son las solicitudes de extracción?\nLa solicitud de extracción es el mecanismo utilizado para indicar que los commits de una rama están listos para ser fusionados en otra rama.\nEl miembro del equipo que envía la solicitud de extracción pide a uno o más revisores que verifiquen el código y aprueben la fusión. Estos revisores tienen la oportunidad de comentar sobre los cambios, agregar sus propios o utilizar la solicitud de extracción misma para discusiones adicionales.\nUna vez aprobados los cambios (si es necesario), la rama de origen (rama de comparación) se fusiona en la rama base.\n\nLuego de oprimir Crear pull request nos queda la siguiente pantalla:\n\nQuiere decir que alguien (para este caso nosotros mismos) quiere fusionar a la rama principal (main) un commit que proviene de la rama cchiquitovalencia-patch-1.\n\nNos solicita confirmacion de la siguiente forma:\n\nFinalmente llegamos a:\n\nEn este punto, luego de haber realizado los cambios en la rama que creamos (no la principal “main”) y confirmado que queremos actualizarlos dentro de la rama original, Github nos dice que es seguro eliminar esa rama, ya cumplio con su cometido.\nAntes de hacerlo vamos a nuestro repositorio para ver el estado:\n\nAqui esta la historia de lo que hemos realizado en cuanto a los commits:\n\nAhora que conocemos todos los ingredientes, revisemos el flujo de GitHub.\n\n\nEl flujo de GitHub\n\nEl flujo de GitHub se puede definir como un flujo de trabajo ligero que permite experimentar de manera segura. Puedes probar nuevas ideas y colaborar con tu equipo utilizando ramas, solicitudes de extracción y fusión.\nAhora que conocemos los fundamentos de GitHub, podemos recorrer el flujo de GitHub y sus componentes.\nComienza creando una rama para que los cambios, características y correcciones que creas no afecten la rama principal. A continuación, haz tus cambios. Recomendamos desplegar cambios en tu rama de características antes de fusionar en la rama principal. Al hacerlo, aseguras que los cambios sean válidos en un entorno de producción. Ahora, crea una solicitud de extracción para pedir retroalimentación a tus colaboradores. La revisión de solicitudes de extracción es tan valiosa que algunos repositorios requieren una revisión aprobatoria antes de que las solicitudes de extracción puedan ser fusionadas. Luego, revisa y aplica la retroalimentación de tus colaboradores. Una vez que te sientas satisfecho con tus cambios, es hora de obtener aprobación para tu solicitud de extracción y fusionarla en la rama principal. Finalmente, puedes eliminar tu rama. Eliminar tu rama indica que tu trabajo en la rama está completo y previene que tú o otros utilicen ramas antiguas por error.\n¡Eso es todo! Has completado un ciclo de flujo de GitHub.\nVamos a pasar al siguiente apartado, donde cubriremos las diferencias entre problemas (issues) y discusiones (discussions)."
  },
  {
    "objectID": "posts/2024-11-18-intro_github/index.html#github-es-una-plataforma-colaborativa",
    "href": "posts/2024-11-18-intro_github/index.html#github-es-una-plataforma-colaborativa",
    "title": "Introducción a Github",
    "section": "GitHub es una plataforma colaborativa",
    "text": "GitHub es una plataforma colaborativa\nLa colaboración está en el núcleo de todo lo que hace GitHub. En el primer unidad del módulo, aprendimos que los repositorios ayudan a organizar tu proyecto y sus archivos. En la última unidad, aprendimos sobre solicitudes de extracción, que es una forma de seguir el progreso de los cambios realizados en tu proyecto.\nEn este unidad, estamos aprendiendo sobre problemas y discusiones. Estos son dos piezas más que contribuyen a la naturaleza colaborativa de la plataforma de GitHub Enterprise.\n\nProblemas (issues)\nLos problemas de GitHub se crearon para rastrear ideas, retroalimentación, tareas o bugs para el trabajo en GitHub. Los problemas pueden crearse de varias maneras, por lo que puedes elegir el método más conveniente para tu flujo de trabajo.\nPara este recorrido, vamos a cubrir cómo crear un problema desde un repositorio. Pero los problemas también pueden crearse desde:\n\nUn elemento en una lista de tareas.\nUna nota en un proyecto.\nUn comentario en un problema o solicitud de extracción.\nUna línea específica de código.\nUna consulta URL.\n\n\n\nCrear un problema desde un repositorio\n\nEn GitHub.com, navega hasta la página principal del repositorio.\nDebajo de tu nombre de repositorio, selecciona Problemas.\n\n\n\nSelecciona Nuevo problema.\nSi tu repositorio utiliza plantillas de problemas, a continuación de la tipo de problema que deseas abrir, selecciona Iniciar. Si el tipo de problema que deseas abrir no se incluye en las opciones disponibles, selecciona Abrir un problema en blanco. Si no se utiliza plantillas, omita este paso.\nEn el campo Agregar un título, ingresa un título para tu problema.\nEn el campo Agregar una descripción, escribe una descripción de tu problema.\n\nSi eres un mantenedor del proyecto, puedes asignar el problema a alguien, agregarlo a una pizarra de proyecto, asociarlo con un hito o aplicar una etiqueta.\nCuando estés listo, selecciona Enviar nuevo problema.\n\n\nAlgunas conversaciones son más adecuadas para GitHub Discusiones. Puedes utilizar GitHub Discusiones para preguntar y responder preguntas, compartir información, hacer anuncios y conducir o participar en conversaciones sobre un proyecto.\nEn la próxima sección, revisaremos Discusiones y cómo utilizar mejor el recurso.\n\n\nDiscusiones\nLas discusiones son para conversaciones que necesitan ser accesibles para todos y no están relacionadas con el código. Las discusiones permiten conversaciones fluidas y abiertas en un foro público.\nEn esta sección, vamos a cubrir:\n\nHabilitar una discusión en tu repositorio.\nCrear una nueva discusión y categorías de discusión.\n\nVamos a profundizar en habilitar una discusión en tu repositorio.\n\n\nHabilitar una discusión en tu repositorio\nLos propietarios de repositorios y las personas con acceso de escritura pueden habilitar GitHub Discusiones para una comunidad en sus repositorios públicos y privados. La visibilidad de una discusión se hereda del repositorio en el que se crea la discusión.\nCuando habilitas GitHub Discusiones por primera vez, te invitan a configurar un post de bienvenida.\n\nEn GitHub.com, navega hasta la página principal del repositorio.\nDebajo de tu nombre de repositorio, selecciona Configuración.\n\nDesplaza el cursor hacia abajo hasta la sección Características y selecciona Configurar discusiones.\n\nEn Iniciar una nueva discusión, edita el plantilla para alinear con los recursos y el tono que deseas establecer para tu comunidad.\n\nSelecciona Iniciar discusión.\n\nAhora estás listo para crear una nueva discusión.\n\n\n\n\n\nCrear una nueva discusión\nCualquier usuario autenticado que pueda ver el repositorio puede crear una discusión en ese repositorio. De manera similar, ya que las discusiones de organización se basan en un repositorio fuente, cualquier usuario autenticado que pueda ver el repositorio fuente puede crear una discusión en esa organización.\n\nEn GitHub.com, navega hasta la página principal del repositorio o rganización donde deseas iniciar una discusión.\nDebajo de tu nombre de repositorio o organización, selecciona Discusiones.\nEn el lado derecho de la página, selecciona Nueva discusión.\nSelecciona una categoría de discusión al seleccionar Get started. Todos los problemas deben crearse en una categoría. Para las discusiones de repositorios, los mantenidos o administradores del repositorio definen las categorías de discusiones en ese repositorio.\n\n\nCada categoría debe tener un nombre único, emparejamiento de emojis y una descripción detallada que explique su propósito. Las categorías ayudan a los mantenidos a organizar cómo se archivan las conversaciones. Están personalizables para ayudar a distinguir categorías que son Q&A o conversaciones más abiertas.\n\nLa siguiente tabla muestra las categorías predeterminadas para discusiones y su propósito.\n\nEso cubre un poco sobre cómo GitHub inspira la colaboración. Ahora, vamos a movernos a cómo puedes administrar notificaciones, suscribirte a hilo y empezar con GitHub Pages."
  },
  {
    "objectID": "posts/2024-11-18-intro_github/index.html#gestión-de-la-plataforma-de-github",
    "href": "posts/2024-11-18-intro_github/index.html#gestión-de-la-plataforma-de-github",
    "title": "Introducción a Github",
    "section": "Gestión de la plataforma de GitHub",
    "text": "Gestión de la plataforma de GitHub\nAhora que conoces los fundamentos de la plataforma de GitHub, vamos a explorar algunas estrategias de gestión de la plataforma.\nEn esta unidad, cubriremos:\n\nAdministrar notificaciones y suscripciones.\nSuscribirte a hilos y encontrar hilos donde te mencionan.\nPublicar tu proyecto o organización en GitHub Pages.\n\n\nGestión de notificaciones y suscripciones\nPuedes elegir recibir actualizaciones continuas sobre actividad específica en GitHub.com a través de una suscripción. Las notificaciones son las actualizaciones que recibes sobre actividad específica a la que te has suscrito.\n\nOpciones de suscripción\nPuedes elegir suscribirte a notificaciones para:\n\nUna conversación en un problema específico, solicitud de extracción o gist.\nActividad de CI, como el estado de flujos de trabajo en repositorios configurados con GitHub Actions.\nProblemas, solicitudes de extracción, lanzamientos, alertas de seguridad o discusiones (si se habilitan) en un repositorio.\nTodas las actividades en un repositorio.\n\nEn algunos casos, te suscribirás automáticamente a conversaciones en GitHub. Ejemplos incluyen abrir una solicitud de extracción o problema, comentar en un hilo o ser asignado a un problema o solicitud de extracción.\nSi ya no estás interesado en una conversación, puedes desuscribirte, desatender o personalizar los tipos de notificaciones que recibirás en el futuro.\nSi alguna vez estás interesado en problemas que mencionan a un usuario específico, puedes utilizar menciones: como el cuadro para encontrar esos problemas específicos.\n\n\n\n¿Qué son GitHub Pages?\nPara completar nuestro viaje por GitHub, vamos a abordar GitHub Pages. Puedes utilizar GitHub Pages para publicar y alojar un sitio web sobre ti mismo, tu organización o tu proyecto directamente desde un repositorio en GitHub.com.\nGitHub Pages es un servicio de alojamiento de sitios web estáticos que toma archivos HTML, CSS y JavaScript directamente desde un repositorio en GitHub. Opcionalmente, puedes ejecutar los archivos a través de un proceso de compilación y publicar un sitio web. Edita y envía tus cambios, y tu proyecto estará disponible para el público de manera organizada visualmente."
  },
  {
    "objectID": "posts/2024-11-18-ejemplo_usarGithub/index.html",
    "href": "posts/2024-11-18-ejemplo_usarGithub/index.html",
    "title": "Retomando labores",
    "section": "",
    "text": "Tengo una página en Github, la había creado en el 2023 en un equipo diferente al que ahora estoy usando, la última vez que actualicé la página fue en octubre 2024:\n\nEstaba entusiasmado por retomar con las publicaciones de lo que puedo compartir de mis experiencias en programación (claramente no soy un experto) para optimizar los procesos. Pero todo lo había creado en un computador que ahora no es mio.\nPor cosas de la vida ahora estoy usando un computador muy antiguo, ni siquiera soportaba Windows 7, asi que, leyendo un poco, ahora esta corriendo Linux Mint. Aquí las especificaciones:\n\n\nBash\n\nArchitecture:                       x86_64\nCPU op-mode(s):                     32-bit, 64-bit\nByte Order:                         Little Endian\nAddress sizes:                      36 bits physical, 48 bits virtual\nCPU(s):                             2\nOn-line CPU(s) list:                0,1\nThread(s) per core:                 1\nCore(s) per socket:                 2\nSocket(s):                          1\nNUMA node(s):                       1\nVendor ID:                          AuthenticAMD\nCPU family:                         20\nModel:                              1\nModel name:                         AMD E-350 Processor\nStepping:                           0\nCPU MHz:                            1595.989\nCPU max MHz:                        1600,0000\nCPU min MHz:                        800,0000\nBogoMIPS:                           3191.98\nVirtualization:                     AMD-V\nL1d cache:                          64 KiB\nL1i cache:                          64 KiB\nL2 cache:                           1 MiB\nNUMA node0 CPU(s):                  0,1\n\nComo ven, antiguo. Pero funciona!\nMi tarea ahora es lograr configurar el flujo de trabajo que tenía en ese entonces en mi “nuevo” equipo.\nVoy a la carpeta Documents, creo una nueva llamada repo_cchiquitovalencia.\nPasos:\n\nEn GitHub, navegué hasta la página principal del repositorio.\nEncima de la lista de archivos, hice clic en Código.\n\nCopié la dirección URL del repositorio. Para clonar el repositorio con HTTPS, en “HTTPS”, hice clic en el ícono.\nAbrí una Terminal.\nCambié el directorio de trabajo actual a la ubicación en donde quería clonar el directorio. En mi caso:\n\n\nBash\n\ncd Documents/repo_cchiquitovalencia\n\nEscribí git clone y pegué la dirección URL que he copiado antes.\n\n\nBash\n\ngit clone https://github.com/cchiquitovalencia/cchiquitovalencia.github.io.git\n\nPresioné Entrar para crear el clon local.\n\n\nBash\n\nClonando en 'cchiquitovalencia.github.io'...\nremote: Enumerating objects: 406, done.\nremote: Counting objects: 100% (406/406), done.\nremote: Compressing objects: 100% (249/249), done.\nremote: Total 406 (delta 210), reused 304 (delta 116), pack-reused 0 (from 0)\nRecibiendo objetos: 100% (406/406), 2.75 MiB | 3.32 MiB/s, listo.\nResolviendo deltas: 100% (210/210), listo.\n\n\nListo! En este momento los archivos estan en mi equipo local. Pero eso es todo, no estan en seguimiento. Entonces:\n\n\nBash\n\n~/Documents/repo_cchiquitovalencia$ git init\n\n\n\nOutput\n\nInicializado repositorio Git vacío en /home/cchvcpcj/Documents/repo_cchiquitovalencia/.git/\n\nRevisemos el estado:\n\n\nBash\n\n~/Documents/repo_cchiquitovalencia$ git status\n\n\n\nOutput\n\nEn la rama master\n\nNo hay commits todavía\n\nArchivos sin seguimiento:\n  (usa \"git add &lt;archivo&gt;...\" para incluirlo a lo que se será confirmado)\n\n    cchiquitovalencia.github.io/\n\nno hay nada agregado al commit pero hay archivos sin seguimiento presentes (usa \"git add\" para hacerles seguimiento)\n\nHago lo que me dice:\n\n\nBash\n\n~/Documents/repo_cchiquitovalencia$ git add cchiquitovalencia.github.io/\n\n\n\nOutput\n\nEn la rama master\n\nNo hay commits todavía\n\nCambios a ser confirmados:\n  (usa \"git rm --cached &lt;archivo&gt;...\" para sacar del área de stage)\n\n    nuevo archivo:  cchiquitovalencia.github.io/.gitignore\n    nuevo archivo:  cchiquitovalencia.github.io/.nojekyll\n...\n    nuevo archivo:  cchiquitovalencia.github.io/posts/_metadata.yml\n    nuevo archivo:  cchiquitovalencia.github.io/resources.qmd\n    nuevo archivo:  cchiquitovalencia.github.io/styles.css\n    nuevo archivo:  cchiquitovalencia.github.io/styles.scss\n\nAhora, mientras escribo este post en un documento de Quarto dentro de una sesion de Rstudio, puedo abrir otra para revisar que todo este en orden: poder hacer commits y push desde local a Github.\n\nBueno, aquí mi primer problema:\n\nEl formato ssh no tiene soporte? Como siempre, cuando hay problemas, vamos a stack overflow: “push git unsupported gpg.format ssh”, unos blogs más tarde, la respuesta fue:\n\nEn este momento, me acordé que en la manana estaba trabajando en otro post sobre Git, y revise la version:\n\nEntonces le hice caso a Martin Thoma. Miremos lo que tengo:\n\n\nBash\n\ngit config --list\n\n\n\nOutput\n\ncredential.helper=cache\ncredential.helper=\ncredential.helper=/usr/local/share/gcm-core/git-credential-manager-core\ncredential.credentialstore=gpg\nuser.name=cchiquitovalencia\nuser.email=cchiquito.valencia@pm.me\nuser.signingkey=/home/cchvcpcj/.ssh/id_ed25519.pub\ncredential.https://dev.azure.com.usehttppath=true\ncommit.gpgsign=false\ngpg.format=ssh\n\nLuego de modificar el .gitconfig\n\nAhora, PUSH!: y me solicita un PASSPHRASE.\n\nClaro que algo falló, no me acuerdo del passphrase! Luego de investigar un poco sobre como recuperar mi passphrase: puedes revisar en donde esta disponible tu llave y puedes crear el certificado de revocacion de tu llave publica, pero necesitas acordarte del passphrase!\nY luego segui revisando otro poco mas, y como no entendi nada aqui, pues me asegure de no olvidar nunca mas el passphrase.\nAl final lo unico que entendi fue que debia generar otra llave:\n\nDescargué e instalé las herramientas de línea de comandos GPG para mi sistema operativo.\nPuedes confirmar si tienes una version instalada:\n\n\nBash\n\ngpg --version\n\n\n\nOutput\n\ngpg (GnuPG) 2.2.19\nlibgcrypt 1.8.5\nCopyright (C) 2019 Free Software Foundation, Inc.\nLicense GPLv3+: GNU GPL version 3 or later &lt;https://gnu.org/licenses/gpl.html&gt;\nThis is free software: you are free to change and redistribute it.\nThere is NO WARRANTY, to the extent permitted by law.\n\nHome: /home/cchvcpcj/.gnupg\nSupported algorithms:\nPubkey: RSA, ELG, DSA, ECDH, ECDSA, EDDSA\nCipher: IDEA, 3DES, CAST5, BLOWFISH, AES, AES192, AES256, TWOFISH,\n        CAMELLIA128, CAMELLIA192, CAMELLIA256\nHash: SHA1, RIPEMD160, SHA256, SHA384, SHA512, SHA224\nCompression: Uncompressed, ZIP, ZLIB, BZIP2\n\nAbrí una Terminal.\nGeneré un par de claves GPG. Dado que existen varias versiones de GPG, es posible que debas consultar la página de manual correspondiente para encontrar el comando de generación de claves adecuado.\n\n\nBash\n\ngpg --full-generate-key\n\n\n\nOutput\n\ngpg (GnuPG) 2.2.19; Copyright (C) 2019 Free Software Foundation, Inc.\nThis is free software: you are free to change and redistribute it.\nThere is NO WARRANTY, to the extent permitted by law.\n\nPlease select what kind of key you want:\n   (1) RSA and RSA (default)\n   (2) DSA and Elgamal\n   (3) DSA (sign only)\n   (4) RSA (sign only)\n  (14) Existing key from card\nYour selection? 1\n\nRSA keys may be between 1024 and 4096 bits long.\nWhat keysize do you want? (3072) 4096\n\nPlease specify how long the key should be valid.\n         0 = key does not expire\n      &lt;n&gt;  = key expires in n days\n      &lt;n&gt;w = key expires in n weeks\n      &lt;n&gt;m = key expires in n months\n      &lt;n&gt;y = key expires in n years\nKey is valid for? (0) 0\nKey does not expire at all\nIs this correct? (y/N) y\n\n\nFinalmente genero otra llave más porque la que tenia había expirado. Qué tal que hubiera buscado maneras de aligerar la búsqueda de mi llave?, será que al final tendría que haber buscado la manera de ponerla a funcionar luego de expirar?\n\n\nOutput\n\nsec   rsa4096/BE0A7004D70A24F0 2022-03-23 [SC]\n      8D8EDF6C11646AB64D276070BE0A7004D70A24F0\nuid                 [ultimate] cchiquitovalencia (Key to) &lt;cchiquito.valencia@pm.me&gt;\n\nsec   rsa4096/D0A5DB1B2962C681 2024-11-15 [SC]\n      6DA68EDA9FE612269D802528D0A5DB1B2962C681\nuid                 [ultimate] cchiquitovalencia (Acceso para Github) &lt;cchiquito.valencia@pm.me&gt;\nssb   rsa4096/F4AE44B3682F30AE 2024-11-15 [E]\n\nEs necesario registrar la llave en Github, vamos a Configuración:\n\nLa zona de acceso\n\ny nueva llave:\n\nY digitamos título y PUBLIC KEY BLOCK:\n\nPara obtener la llave completa que debemos registrar, ejecutar en la Terminal:\n\n\nBash\n\ngpg --armor --export D0A5DB1B2962C681\n\nCambiando el Key ID para cada llave generada. Ahora tengo esto:\n\nAhora si, ya:\n\nCloné el repositorio que se encuentra alojado en Github a mi equipo local.\nInicié el seguimiento con Git en mi control de versiones al proyecto local.\nActualicé mi version de Git para tener acceso son SSH.\nCreé una llave pública nueva, porque no recordaba que la anterior expiró.\nRegistré la llave nueva a Github para realizar PUSH desde lo local.\n\nEntonces creo un archivo para realizar la prueba, se llama “actualizado.qmd” y contiene lo siguiente.\n\nFinalmente guardo el archivo y le doy commit:\n\nAhora, la hora de la verdad: PUSH! No sin antes decirle a Git que cambie la llave porque al principio teniamos: user.signingkey=/home/cchvcpcj/.ssh/id_ed25519.pub\nEn la Terminal:\n\n\nBash\n\ngit config --global user.signingkey D0A5DB1B2962C681\n\nPUSH!!!!\nPues nada pasó a Github. De alguna manera me pide el usuario, y le digo cchiquitovalencia, luego me pide clave, pero de un correo que no tengo registado en Github. Solo tengo registrado cchiquito.valencia@pm.me, entonces pienso que algo tiene que ver con el “credential.manager”:\n\n\nBash\n\ngit-credential-manager configure\n\n\n\nOutput\n\nbash: git-credential-manager: command not found\n\nPues a instalarlo se dijo:\n\nY así:\n\n\nBash\n\nsudo dpkg -i /home/cchvcpcj/Downloads/gcm-linux_amd64.2.6.0.deb\n\n\n\nOutput\n\nSeleccionando el paquete gcm previamente no seleccionado.\n(Leyendo la base de datos ... 419408 ficheros o directorios instalados actualmente.)\nPreparando para desempaquetar .../gcm-linux_amd64.2.6.0.deb ...\nDesempaquetando gcm (2.6.0) ...\nConfigurando gcm (2.6.0) ...\n\nAhora sí:\n\n\nBash\n\ngit-credential-manager configure\n\n\n\nOutput\n\nConfiguring component 'Git Credential Manager'...\nConfiguring component 'Azure Repos provider'...\n\nReviso la configuracion:\n\n\nBash\n\ngit config --list\n\n\n\nOutput\n\ncredential.helper=cache\ncredential.helper=\ncredential.helper=/usr/local/share/gcm-core/git-credential-manager-core\ncredential.credentialstore=gpg\ncredential.cacheoptions=--timeout 300\ncredential.helper=\ncredential.helper=/usr/local/bin/git-credential-manager\nuser.name=cchiquitovalencia\nuser.email=cchiquito.valencia@pm.me\nuser.signingkey=D0A5DB1B2962C681\ncredential.https://dev.azure.com.usehttppath=true\ncommit.gpgsign=true\n\nAlgunas verificaciones mas tarde, un passphrase muy bien recordado (no lo olvidaré, y me aseguré muy bien de no volver a hacerlo) y finalmente:\n\ny PUSH!!!!!!!!!!\n\n“De nuevo en el negocio.”\n\n\n\nCitationBibTeX citation:@online{chiquito_valencia2024,\n  author = {Chiquito Valencia, Cristian},\n  title = {Retomando Labores},\n  date = {2024-11-18},\n  url = {https://cchiquitovalencia.github.io/posts/2028-11-18-ejemplo_usarGithub/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nChiquito Valencia, Cristian. 2024. “Retomando Labores.”\nNovember 18, 2024. https://cchiquitovalencia.github.io/posts/2028-11-18-ejemplo_usarGithub/."
  },
  {
    "objectID": "posts/2024-11-18-ejemplo_usarGithub/ejemplo_usarGithub.html",
    "href": "posts/2024-11-18-ejemplo_usarGithub/ejemplo_usarGithub.html",
    "title": "Retomando labores",
    "section": "",
    "text": "Tengo una página en Github, la había creado en el 2023 en un equipo diferente al que ahora estoy usando, la ultima vez que actualice la pagina fue en octubre 2024:\n\nEstaba entusiasmado por retomar con las publicaciones de lo que puedo compartir de mis experiencias en programación (claramente no soy un experto) para optimizar los procesos. Pero todo lo había creado en un computador que ahora no es mio.\nPor cosas de la vida ahora estoy usando un computador muy antiguo, ni siquiera soportaba Windows 7, asi que, leyendo un poco, ahora esta corriendo Linux Mint. Aqui las especificaciones:\n\n\nBash\n\nArchitecture:                       x86_64\nCPU op-mode(s):                     32-bit, 64-bit\nByte Order:                         Little Endian\nAddress sizes:                      36 bits physical, 48 bits virtual\nCPU(s):                             2\nOn-line CPU(s) list:                0,1\nThread(s) per core:                 1\nCore(s) per socket:                 2\nSocket(s):                          1\nNUMA node(s):                       1\nVendor ID:                          AuthenticAMD\nCPU family:                         20\nModel:                              1\nModel name:                         AMD E-350 Processor\nStepping:                           0\nCPU MHz:                            1595.989\nCPU max MHz:                        1600,0000\nCPU min MHz:                        800,0000\nBogoMIPS:                           3191.98\nVirtualization:                     AMD-V\nL1d cache:                          64 KiB\nL1i cache:                          64 KiB\nL2 cache:                           1 MiB\nNUMA node0 CPU(s):                  0,1\n\nComo ven, antiguo. Pero funciona!\nMi tarea ahora es lograr configurar el flujo de trabajo que tenia en ese entonces en mi “nuevo” equipo.\nVoy a la carpeta Documentos, creo una nueva llamada repo_cchiquitovalencia.\nPasos:\n\nEn GitHub, navegué hasta la página principal del repositorio.\nEncima de la lista de archivos, hice clic en Código.\n\nCopié la dirección URL del repositorio. Para clonar el repositorio con HTTPS, en “HTTPS”, hice clic en el ícono.\nAbrí una Terminal.\nCambié el directorio de trabajo actual a la ubicación en donde quería clonar el directorio. En mi caso:\n\n\nBash\n\ncd Documents/repo_cchiquitovalencia\n\nEscribí git clone y pegué la dirección URL que he copiado antes.\n\n\nBash\n\ngit clone https://github.com/cchiquitovalencia/cchiquitovalencia.github.io.git\n\nPresioné Entrar para crear el clon local.\n\n\nBash\n\nClonando en 'cchiquitovalencia.github.io'...\nremote: Enumerating objects: 406, done.\nremote: Counting objects: 100% (406/406), done.\nremote: Compressing objects: 100% (249/249), done.\nremote: Total 406 (delta 210), reused 304 (delta 116), pack-reused 0 (from 0)\nRecibiendo objetos: 100% (406/406), 2.75 MiB | 3.32 MiB/s, listo.\nResolviendo deltas: 100% (210/210), listo.\n\n\nListo! En este momento los archivos estan en mi equipo local. Pero eso es todo, no estan en seguimiento. Entonces:\n\n\nBash\n\n~/Documents/repo_cchiquitovalencia$ git init\n\n\n\nOutput\n\nInicializado repositorio Git vacío en /home/cchvcpcj/Documents/repo_cchiquitovalencia/.git/\n\nRevisemos el estado:\n\n\nBash\n\n~/Documents/repo_cchiquitovalencia$ git status\n\n\n\nOutput\n\nEn la rama master\n\nNo hay commits todavía\n\nArchivos sin seguimiento:\n  (usa \"git add &lt;archivo&gt;...\" para incluirlo a lo que se será confirmado)\n\n    cchiquitovalencia.github.io/\n\nno hay nada agregado al commit pero hay archivos sin seguimiento presentes (usa \"git add\" para hacerles seguimiento)\n\nHago lo que me dice:\n\n\nBash\n\n~/Documents/repo_cchiquitovalencia$ git add cchiquitovalencia.github.io/\n\n\n\nOutput\n\nEn la rama master\n\nNo hay commits todavía\n\nCambios a ser confirmados:\n  (usa \"git rm --cached &lt;archivo&gt;...\" para sacar del área de stage)\n\n    nuevo archivo:  cchiquitovalencia.github.io/.gitignore\n    nuevo archivo:  cchiquitovalencia.github.io/.nojekyll\n...\n    nuevo archivo:  cchiquitovalencia.github.io/posts/_metadata.yml\n    nuevo archivo:  cchiquitovalencia.github.io/resources.qmd\n    nuevo archivo:  cchiquitovalencia.github.io/styles.css\n    nuevo archivo:  cchiquitovalencia.github.io/styles.scss\n\nAhora, mientras escribo este post en un documento de Quarto dentro de una sesion de Rstudio, puedo abrir otra para revisar que todo este en orden: poder hacer commits y push desde local a Github.\n\nBueno, aquí mi primer problema:\n\nEl formato ssh no tiene soporte? Como siempre, cuando hay problemas, vamos a stack overflow: “push git unsupported gpg.format ssh”, unos blogs más tarde, la respuesta fue:\n\nEn este momento, me acordé que en la manana estaba trabajando en otro post sobre Git, y revise la version:\n\nEntonces le hice caso a Martin Thoma. Miremos lo que tengo:\n\n\nBash\n\ngit config --list\n\n\n\nOutput\n\ncredential.helper=cache\ncredential.helper=\ncredential.helper=/usr/local/share/gcm-core/git-credential-manager-core\ncredential.credentialstore=gpg\nuser.name=cchiquitovalencia\nuser.email=cchiquito.valencia@pm.me\nuser.signingkey=/home/cchvcpcj/.ssh/id_ed25519.pub\ncredential.https://dev.azure.com.usehttppath=true\ncommit.gpgsign=false\ngpg.format=ssh\n\nLuego de modificar el .gitconfig\n\nAhora, PUSH!: y me solicita un PASSPHRASE.\n\nClaro que algo falló, no me acuerdo del passphrase! Luego de investigar un poco sobre como recuperar mi passphrase: puedes revisar en donde esta disponible tu llave y puedes crear el certificado de revocacion de tu llave publica, pero necesitas acordarte del passphrase!\nY luego segui revisando otro poco mas, y como no entendi nada aqui, pues me asegure de no olvidar nunca mas el passphrase.\nAl final lo unico que entendi fue que debia generar otra llave:\n\nDescargué e instalé las herramientas de línea de comandos GPG para mi sistema operativo.\nPuedes confirmar si tienes una version instalada:\n\n\nBash\n\ngpg --version\n\n\n\nOutput\n\ngpg (GnuPG) 2.2.19\nlibgcrypt 1.8.5\nCopyright (C) 2019 Free Software Foundation, Inc.\nLicense GPLv3+: GNU GPL version 3 or later &lt;https://gnu.org/licenses/gpl.html&gt;\nThis is free software: you are free to change and redistribute it.\nThere is NO WARRANTY, to the extent permitted by law.\n\nHome: /home/cchvcpcj/.gnupg\nSupported algorithms:\nPubkey: RSA, ELG, DSA, ECDH, ECDSA, EDDSA\nCipher: IDEA, 3DES, CAST5, BLOWFISH, AES, AES192, AES256, TWOFISH,\n        CAMELLIA128, CAMELLIA192, CAMELLIA256\nHash: SHA1, RIPEMD160, SHA256, SHA384, SHA512, SHA224\nCompression: Uncompressed, ZIP, ZLIB, BZIP2\n\nAbrí una Terminal.\nGeneré un par de claves GPG. Dado que existen varias versiones de GPG, es posible que debas consultar la página de manual correspondiente para encontrar el comando de generación de claves adecuado.\n\n\nBash\n\ngpg --full-generate-key\n\n\n\nOutput\n\ngpg (GnuPG) 2.2.19; Copyright (C) 2019 Free Software Foundation, Inc.\nThis is free software: you are free to change and redistribute it.\nThere is NO WARRANTY, to the extent permitted by law.\n\nPlease select what kind of key you want:\n   (1) RSA and RSA (default)\n   (2) DSA and Elgamal\n   (3) DSA (sign only)\n   (4) RSA (sign only)\n  (14) Existing key from card\nYour selection? 1\n\nRSA keys may be between 1024 and 4096 bits long.\nWhat keysize do you want? (3072) 4096\n\nPlease specify how long the key should be valid.\n         0 = key does not expire\n      &lt;n&gt;  = key expires in n days\n      &lt;n&gt;w = key expires in n weeks\n      &lt;n&gt;m = key expires in n months\n      &lt;n&gt;y = key expires in n years\nKey is valid for? (0) 0\nKey does not expire at all\nIs this correct? (y/N) y\n\n\nFinalmente genero otra llave más porque la que tenia había expirado. Qué tal que hubiera buscado maneras de aligerar la búsqueda de mi llave?, será que al final tendría que haber buscado la manera de ponerla a funcionar luego de expirar?\n\n\nOutput\n\nsec   rsa4096/BE0A7004D70A24F0 2022-03-23 [SC]\n      8D8EDF6C11646AB64D276070BE0A7004D70A24F0\nuid                 [ultimate] cchiquitovalencia (Key to) &lt;cchiquito.valencia@pm.me&gt;\n\nsec   rsa4096/D0A5DB1B2962C681 2024-11-15 [SC]\n      6DA68EDA9FE612269D802528D0A5DB1B2962C681\nuid                 [ultimate] cchiquitovalencia (Acceso para Github) &lt;cchiquito.valencia@pm.me&gt;\nssb   rsa4096/F4AE44B3682F30AE 2024-11-15 [E]\n\nEs necesario registrar la llave en Github, vamos a Configuración:\n\nLa zona de acceso\n\ny nueva llave:\n\nY digitamos título y PUBLIC KEY BLOCK:\n\nPara obtener la llave completa que debemos registrar, ejecutar en la Terminal:\n\n\nBash\n\ngpg --armor --export D0A5DB1B2962C681\n\nCambiando el Key ID para cada llave generada. Ahora tengo esto:\n\nAhora si, ya:\n\nCloné el repositorio que se encuentra alojado en Github a mi equipo local.\nInicié el seguimiento con Git en mi control de versiones al proyecto local.\nActualicé mi version de Git para tener acceso son SSH.\nCreé una llave pública nueva, porque no recordaba que la anterior expiró.\nRegistré la llave nueva a Github para realizar PUSH desde lo local.\n\nEntonces creo un archivo para realizar la prueba, se llama “actualizado.qmd” y contiene lo siguiente.\n\nFinalmente guardo el archivo y le doy commit:\n\nAhora, la hora de la verdad: PUSH! No sin antes decirle a Git que cambie la llave porque al principio teniamos: user.signingkey=/home/cchvcpcj/.ssh/id_ed25519.pub\nEn la Terminal:\n\n\nBash\n\ngit config --global user.signingkey D0A5DB1B2962C681\n\nPUSH!!!!\nPues nada pasó a Github. De alguna manera me pide el usuario, y le digo cchiquitovalencia, luego me pide clave, pero de un correo que no tengo registado en Github. Solo tengo registrado cchiquito.valencia@pm.me, entonces pienso que algo tiene que ver con el “credential.manager”:\n\n\nBash\n\ngit-credential-manager configure\n\n\n\nOutput\n\nbash: git-credential-manager: command not found\n\nPues a instalarlo se dijo:\n\nY así:\n\n\nBash\n\nsudo dpkg -i /home/cchvcpcj/Downloads/gcm-linux_amd64.2.6.0.deb\n\n\n\nOutput\n\nSeleccionando el paquete gcm previamente no seleccionado.\n(Leyendo la base de datos ... 419408 ficheros o directorios instalados actualmente.)\nPreparando para desempaquetar .../gcm-linux_amd64.2.6.0.deb ...\nDesempaquetando gcm (2.6.0) ...\nConfigurando gcm (2.6.0) ...\n\nAhora sí:\n\n\nBash\n\ngit-credential-manager configure\n\n\n\nOutput\n\nConfiguring component 'Git Credential Manager'...\nConfiguring component 'Azure Repos provider'...\n\nReviso la configuracion:\n\n\nBash\n\ngit config --list\n\n\n\nOutput\n\ncredential.helper=cache\ncredential.helper=\ncredential.helper=/usr/local/share/gcm-core/git-credential-manager-core\ncredential.credentialstore=gpg\ncredential.cacheoptions=--timeout 300\ncredential.helper=\ncredential.helper=/usr/local/bin/git-credential-manager\nuser.name=cchiquitovalencia\nuser.email=cchiquito.valencia@pm.me\nuser.signingkey=D0A5DB1B2962C681\ncredential.https://dev.azure.com.usehttppath=true\ncommit.gpgsign=true\n\nAlgunas verificaciones mas tarde, un passphrase muy bien recordado (no lo olvidaré, y me aseguré muy bien de no volver a hacerlo) y finalmente:\n\ny PUSH!!!!!!!!!!\n\n“De nuevo en el negocio.”"
  },
  {
    "objectID": "posts/2024-11-20-ejemplo_usarGithub/index.html",
    "href": "posts/2024-11-20-ejemplo_usarGithub/index.html",
    "title": "Retomando labores",
    "section": "",
    "text": "Tengo una página en Github, la había creado en el 2023 en un equipo diferente al que ahora estoy usando, la última vez que actualicé la página fue en octubre 2024:\n\nEstaba entusiasmado por retomar las publicaciones de lo que puedo compartir de mis experiencias en programación (claramente no soy un experto) para optimizar los procesos. Pero todo lo había creado en un computador que ahora no es mio.\nPor cosas de la vida ahora estoy usando un computador muy antiguo, ni siquiera soportaba Windows 7, asi que, leyendo un poco, ahora esta corriendo Linux Mint. AquÍ las especificaciones:\n\n\nBash\n\nArchitecture:                       x86_64\nCPU op-mode(s):                     32-bit, 64-bit\nByte Order:                         Little Endian\nAddress sizes:                      36 bits physical, 48 bits virtual\nCPU(s):                             2\nOn-line CPU(s) list:                0,1\nThread(s) per core:                 1\nCore(s) per socket:                 2\nSocket(s):                          1\nNUMA node(s):                       1\nVendor ID:                          AuthenticAMD\nCPU family:                         20\nModel:                              1\nModel name:                         AMD E-350 Processor\nStepping:                           0\nCPU MHz:                            1595.989\nCPU max MHz:                        1600,0000\nCPU min MHz:                        800,0000\nBogoMIPS:                           3191.98\nVirtualization:                     AMD-V\nL1d cache:                          64 KiB\nL1i cache:                          64 KiB\nL2 cache:                           1 MiB\nNUMA node0 CPU(s):                  0,1\n\nComo ven, antiguo. Pero funciona!\nMi tarea ahora es lograr configurar el flujo de trabajo que tenia en ese entonces en mi “nuevo” equipo.\nVoy a la carpeta Documentos, creo una nueva llamada repo_cchiquitovalencia donde alojaré lo que ya había subido a Github.\nLo que hice:\n\nEn GitHub, navegué hasta la página principal del repositorio.\nEncima de la lista de archivos, hice clic en Código.\n\nCopié la dirección URL del repositorio. Para clonar el repositorio con HTTPS, en “HTTPS”, hice clic en el ícono.\nAbrí una Terminal.\nCambié el directorio de trabajo actual a la ubicación en donde quería clonar el directorio. En mi caso:\n\n\nBash\n\ncd Documents/repo_cchiquitovalencia\n\nEscribí git clone y pegué la dirección URL que he copiado antes.\n\n\nBash\n\ngit clone https://github.com/cchiquitovalencia/cchiquitovalencia.github.io.git\n\nPresioné Enter para crear el clon local.\n\n\nBash\n\nClonando en 'cchiquitovalencia.github.io'...\nremote: Enumerating objects: 406, done.\nremote: Counting objects: 100% (406/406), done.\nremote: Compressing objects: 100% (249/249), done.\nremote: Total 406 (delta 210), reused 304 (delta 116), pack-reused 0 (from 0)\nRecibiendo objetos: 100% (406/406), 2.75 MiB | 3.32 MiB/s, listo.\nResolviendo deltas: 100% (210/210), listo.\n\n\nListo! En este momento los archivos están en mi equipo local. Pero eso es todo, no están en seguimiento. Entonces:\n\n\nBash\n\n~/Documents/repo_cchiquitovalencia$ git init\n\n\n\nOutput\n\nInicializado repositorio Git vacío en /home/cchvcpcj/Documents/repo_cchiquitovalencia/.git/\n\nRevisemos el estado:\n\n\nBash\n\n~/Documents/repo_cchiquitovalencia$ git status\n\n\n\nOutput\n\nEn la rama master\n\nNo hay commits todavía\n\nArchivos sin seguimiento:\n  (usa \"git add &lt;archivo&gt;...\" para incluirlo a lo que se será confirmado)\n\n    cchiquitovalencia.github.io/\n\nno hay nada agregado al commit pero hay archivos sin seguimiento presentes (usa \"git add\" para hacerles seguimiento)\n\nHago lo que me dice, agrego:\n\n\nBash\n\n~/Documents/repo_cchiquitovalencia$ git add cchiquitovalencia.github.io/\n\n\n\nOutput\n\nEn la rama master\n\nNo hay commits todavía\n\nCambios a ser confirmados:\n  (usa \"git rm --cached &lt;archivo&gt;...\" para sacar del área de stage)\n\n    nuevo archivo:  cchiquitovalencia.github.io/.gitignore\n    nuevo archivo:  cchiquitovalencia.github.io/.nojekyll\n... # varias líneas de código después\n    nuevo archivo:  cchiquitovalencia.github.io/posts/_metadata.yml\n    nuevo archivo:  cchiquitovalencia.github.io/resources.qmd\n    nuevo archivo:  cchiquitovalencia.github.io/styles.css\n    nuevo archivo:  cchiquitovalencia.github.io/styles.scss\n\nAhora, mientras escribo este post en un documento de Quarto dentro de una sesion de Rstudio, puedo abrir otra para revisar que todo esté en orden: poder hacer commits y push desde local a Github. Con el comando htop puedo ver la carga de mis dos súper procesadores:\n\nBueno, aquí mi primer problema:\n\nEl formato ssh no tiene soporte? Como siempre, cuando hay problemas, vamos a stackoverflow: “push git unsupported gpg.format ssh”, unos blogs más tarde, la respuesta fue:\n\nEn este momento, me acordé que hace poco estaba trabajando en otro post sobre Git, y revisé la versión:\n\nEntonces le hice caso a Martin Thoma. Miremos lo que tengo:\n\n\nBash\n\ngit config --list\n\n\n\nOutput\n\ncredential.helper=cache\ncredential.helper=\ncredential.helper=/usr/local/share/gcm-core/git-credential-manager-core\ncredential.credentialstore=gpg\nuser.name=cchiquitovalencia\nuser.email=cchiquito.valencia@pm.me\nuser.signingkey=/home/cchvcpcj/.ssh/id_ed25519.pub\ncredential.https://dev.azure.com.usehttppath=true\ncommit.gpgsign=false\ngpg.format=ssh\n\nLuego de modificar el .gitconfig (gpgsign = true)\n\nAhora, PUSH!: y me solicita un PASSPHRASE.\n\nClaro que algo falló, no me acuerdo del passphrase! Luego de investigar un poco sobre como recuperar mi passphrase: puedes revisar en donde esta disponible tu llave y puedes crear el certificado de revocacion de tu llave publica, pero necesitas acordarte del passphrase!\nY luego seguí revisando otro poco más, y como no entendí nada aquí, pues me aseguré de no olvidar nunca más el passphrase.\nAl final lo único que entendí fue que debía generar otra llave:\n\nDescargué e instalé las herramientas de línea de comandos GPG para mi sistema operativo.\nPuedes confirmar si tienes una versión instalada:\n\n\nBash\n\ngpg --version\n\n\n\nOutput\n\ngpg (GnuPG) 2.2.19\nlibgcrypt 1.8.5\nCopyright (C) 2019 Free Software Foundation, Inc.\nLicense GPLv3+: GNU GPL version 3 or later &lt;https://gnu.org/licenses/gpl.html&gt;\nThis is free software: you are free to change and redistribute it.\nThere is NO WARRANTY, to the extent permitted by law.\n\nHome: /home/cchvcpcj/.gnupg\nSupported algorithms:\nPubkey: RSA, ELG, DSA, ECDH, ECDSA, EDDSA\nCipher: IDEA, 3DES, CAST5, BLOWFISH, AES, AES192, AES256, TWOFISH,\n        CAMELLIA128, CAMELLIA192, CAMELLIA256\nHash: SHA1, RIPEMD160, SHA256, SHA384, SHA512, SHA224\nCompression: Uncompressed, ZIP, ZLIB, BZIP2\n\nAbrí una Terminal.\nGeneré un par de claves GPG. Dado que existen varias versiones de GPG, es posible que debas consultar la página de manual correspondiente para encontrar el comando de generación de claves adecuado.\n\n\nBash\n\ngpg --full-generate-key\n\n\n\nOutput\n\ngpg (GnuPG) 2.2.19; Copyright (C) 2019 Free Software Foundation, Inc.\nThis is free software: you are free to change and redistribute it.\nThere is NO WARRANTY, to the extent permitted by law.\n\nPlease select what kind of key you want:\n   (1) RSA and RSA (default)\n   (2) DSA and Elgamal\n   (3) DSA (sign only)\n   (4) RSA (sign only)\n  (14) Existing key from card\nYour selection? 1\n\nRSA keys may be between 1024 and 4096 bits long.\nWhat keysize do you want? (3072) 4096\n\nPlease specify how long the key should be valid.\n         0 = key does not expire\n      &lt;n&gt;  = key expires in n days\n      &lt;n&gt;w = key expires in n weeks\n      &lt;n&gt;m = key expires in n months\n      &lt;n&gt;y = key expires in n years\nKey is valid for? (0) 0\nKey does not expire at all\nIs this correct? (y/N) y\n\n\nFinalmente genero otra llave más porque la que tenia había expirado. Qué tal que hubiera buscado maneras de aligerar la búsqueda de mi llave?, será que al final tendría que haber buscado la manera de ponerla a funcionar luego de expirar?\n\n\nOutput\n\nsec   rsa4096/BE0A7004D70A24F0 2022-03-23 [SC]\n      8D8EDF6C11646AB64D276070BE0A7004D70A24F0\nuid                 [ultimate] cchiquitovalencia (Key to) &lt;cchiquito.valencia@pm.me&gt;\n\nsec   rsa4096/D0A5DB1B2962C681 2024-11-15 [SC]\n      6DA68EDA9FE612269D802528D0A5DB1B2962C681\nuid                 [ultimate] cchiquitovalencia (Acceso para Github) &lt;cchiquito.valencia@pm.me&gt;\nssb   rsa4096/F4AE44B3682F30AE 2024-11-15 [E]\n\nEs necesario registrar la llave en Github, vamos a Configuración:\n\nLa zona de acceso\n\ny nueva llave:\n\nY digitamos título y PUBLIC KEY BLOCK:\n\nPara obtener la llave completa que debemos registrar, ejecutar en la Terminal:\n\n\nBash\n\ngpg --armor --export D0A5DB1B2962C681\n\nCambiando el Key ID para cada llave generada. Ahora tengo esto:\n\nAhora si, ya:\n\nCloné el repositorio que se encuentra alojado en Github a mi equipo local.\nInicié el seguimiento con Git en mi control de versiones al proyecto local.\nActualicé mi version de Git para tener acceso son SSH.\nCreé una llave pública nueva, porque no recordaba que la anterior expiró.\nRegistré la llave nueva a Github para realizar PUSH desde lo local.\n\nEntonces creo un archivo para realizar la prueba, se llama “actualizado.qmd” y contiene lo siguiente.\n\nFinalmente guardo el archivo y le doy commit:\n\nAhora, la hora de la verdad: PUSH! No sin antes decirle a Git que cambie la llave porque al principio teniamos: user.signingkey=/home/cchvcpcj/.ssh/id_ed25519.pub\nEn la Terminal:\n\n\nBash\n\ngit config --global user.signingkey D0A5DB1B2962C681\n\nPUSH!!!!\nPues nada pasó a Github. De alguna manera me pide el usuario, y le digo cchiquitovalencia, luego me pide clave, pero de un correo que no tengo registado en Github. Solo tengo registrado cchiquito.valencia@pm.me, entonces pienso que algo tiene que ver con el “credential.manager”:\n\n\nBash\n\ngit-credential-manager configure\n\n\n\nOutput\n\nbash: git-credential-manager: command not found\n\nPues a instalarlo se dijo:\n\nY así:\n\n\nBash\n\nsudo dpkg -i /home/cchvcpcj/Downloads/gcm-linux_amd64.2.6.0.deb\n\n\n\nOutput\n\nSeleccionando el paquete gcm previamente no seleccionado.\n(Leyendo la base de datos ... 419408 ficheros o directorios instalados actualmente.)\nPreparando para desempaquetar .../gcm-linux_amd64.2.6.0.deb ...\nDesempaquetando gcm (2.6.0) ...\nConfigurando gcm (2.6.0) ...\n\nAhora sí:\n\n\nBash\n\ngit-credential-manager configure\n\n\n\nOutput\n\nConfiguring component 'Git Credential Manager'...\nConfiguring component 'Azure Repos provider'...\n\nReviso la configuracion:\n\n\nBash\n\ngit config --list\n\n\n\nOutput\n\ncredential.helper=cache\ncredential.helper=\ncredential.helper=/usr/local/share/gcm-core/git-credential-manager-core\ncredential.credentialstore=gpg\ncredential.cacheoptions=--timeout 300\ncredential.helper=\ncredential.helper=/usr/local/bin/git-credential-manager\nuser.name=cchiquitovalencia\nuser.email=cchiquito.valencia@pm.me\nuser.signingkey=D0A5DB1B2962C681\ncredential.https://dev.azure.com.usehttppath=true\ncommit.gpgsign=true\n\nAlgunas verificaciones mas tarde, un passphrase muy bien recordado (no lo olvidaré, y me aseguré muy bien de no volver a hacerlo) y finalmente:\n\ny PUSH!!!!!!!!!!\n\n“De nuevo en el negocio.”\n\n\n\nCómo citarBibTeX@online{chiquito_valencia2024,\n  author = {Chiquito Valencia, Cristian},\n  title = {Retomando Labores},\n  date = {2024-11-20},\n  url = {https://cchiquitovalencia.github.io/posts/2024-11-20-ejemplo_usarGithub/},\n  langid = {en}\n}\nPor favor, cita este trabajo como:\nChiquito Valencia, Cristian. 2024. “Retomando Labores.”\nNovember 20, 2024. https://cchiquitovalencia.github.io/posts/2024-11-20-ejemplo_usarGithub/."
  },
  {
    "objectID": "posts/2024-11-26-organizar_a_tu_familia/index.html",
    "href": "posts/2024-11-26-organizar_a_tu_familia/index.html",
    "title": "El secreto para organizar a tu familia",
    "section": "",
    "text": "Desde hace varios años mi esposa y yo habíamos querido organizar unas vacaciones familiares. Estoy hablando de vacaciones familiares en grande! Logramos reservar un espacio con la capacidad suficiente y una ubicación central para los diferentes planes en la region. Ahora el lío era cuadrar dónde iba a dormir cada uno.\nLas personas confirmadas fueron:\n\nlistado &lt;- read.csv(\"./listado.csv\")\n\nlistado\n\n      persona edad grupo\n1       Nelsy   75     1\n2    Hernando   74     2\n3      Ofelia   63     3\n4     Liliana   63     4\n5  John Jairo   61     4\n6       Jimmy   45     5\n7        Luis   42     6\n8       Linda   41     6\n9    Mercedes   40     5\n10     Sandra   35     3\n11  Estefania   33     7\n12       Juan   31     7\n13   Cristian   32     8\n14    Claudia   31     8\n15    Daniela   30     4\n16     Felipe   17     6\n17    Nicolas   11     5\n18   Emiliano    8     7\n19    Gabriel    4     5\n20       Emma    2     7\n\n\nEn el lugar habían 3 tipos de cama: sencilla, doble y camarote. Las camas estaban distribuidas en 8 dormitorios. Solo 3 dormitorios contaban con baño privado.\n\ndormitorios &lt;- read.csv(\"./dormitorios.csv\")\n\ndormitorios\n\n  dormitorio sencilla doble camarote wc\n1          1        1     0        2  0\n2          2        1     0        2  0\n3          3        1     0        2  0\n4          4        1     0        1  1\n5          5        4     0        0  0\n6          6        0     1        0  1\n7          7        1     0        2  0\n8          8        1     0        2  1\n9       sala        1     0        0  0\n\n\nAquí realmente en la sala habia un sofa cama, pero sirve como un espacio para dormir una persona. Los camarotes, cada uno cuenta con 2 espacios para dormir."
  },
  {
    "objectID": "posts/2024-11-26-organizar_a_tu_familia/index.html#introducción",
    "href": "posts/2024-11-26-organizar_a_tu_familia/index.html#introducción",
    "title": "El secreto para organizar a tu familia",
    "section": "",
    "text": "Desde hace varios años mi esposa y yo habíamos querido organizar unas vacaciones familiares. Estoy hablando de vacaciones familiares en grande! Logramos reservar un espacio con la capacidad suficiente y una ubicación central para los diferentes planes en la region. Ahora el lío era cuadrar dónde iba a dormir cada uno.\nLas personas confirmadas fueron:\n\nlistado &lt;- read.csv(\"./listado.csv\")\n\nlistado\n\n      persona edad grupo\n1       Nelsy   75     1\n2    Hernando   74     2\n3      Ofelia   63     3\n4     Liliana   63     4\n5  John Jairo   61     4\n6       Jimmy   45     5\n7        Luis   42     6\n8       Linda   41     6\n9    Mercedes   40     5\n10     Sandra   35     3\n11  Estefania   33     7\n12       Juan   31     7\n13   Cristian   32     8\n14    Claudia   31     8\n15    Daniela   30     4\n16     Felipe   17     6\n17    Nicolas   11     5\n18   Emiliano    8     7\n19    Gabriel    4     5\n20       Emma    2     7\n\n\nEn el lugar habían 3 tipos de cama: sencilla, doble y camarote. Las camas estaban distribuidas en 8 dormitorios. Solo 3 dormitorios contaban con baño privado.\n\ndormitorios &lt;- read.csv(\"./dormitorios.csv\")\n\ndormitorios\n\n  dormitorio sencilla doble camarote wc\n1          1        1     0        2  0\n2          2        1     0        2  0\n3          3        1     0        2  0\n4          4        1     0        1  1\n5          5        4     0        0  0\n6          6        0     1        0  1\n7          7        1     0        2  0\n8          8        1     0        2  1\n9       sala        1     0        0  0\n\n\nAquí realmente en la sala habia un sofa cama, pero sirve como un espacio para dormir una persona. Los camarotes, cada uno cuenta con 2 espacios para dormir."
  },
  {
    "objectID": "posts/2024-11-26-organizar_a_tu_familia/index.html#nuestro-reto-acomodar",
    "href": "posts/2024-11-26-organizar_a_tu_familia/index.html#nuestro-reto-acomodar",
    "title": "El secreto para organizar a tu familia",
    "section": "Nuestro reto: acomodar",
    "text": "Nuestro reto: acomodar\nComo reglas básicas pensamos:\n\nLos grupos familiares no se deben mezclar entre sí.\nLos matrimonios necesitan dormir en el mismo dormitorio.\nLos niños menores, en caso de ser necesario, pueden mezclarse.\nPor condiciones de salud, Ofelia y John Jairo deben dormir en un dormitorio con baño."
  },
  {
    "objectID": "posts/2024-11-26-organizar_a_tu_familia/index.html#modelo-de-asignación",
    "href": "posts/2024-11-26-organizar_a_tu_familia/index.html#modelo-de-asignación",
    "title": "El secreto para organizar a tu familia",
    "section": "Modelo de asignación",
    "text": "Modelo de asignación\nLa idea es introducir una variable binaria \\(x_{i,j}\\) que sea \\(1\\) si una persona \\(i\\) es asignada al dormitorio \\(j\\). Como un objetivo (y puede ser el caso ajustarse a cualquier otro) podemos tratar de garantizar las reglas otorgando un peso. Aqui claramente la capacidad del lugar es suficiente para la cantidad de personas en la familia.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(ompr)\nlibrary(ompr.roi)\n\n\ndormitorios &lt;- dormitorios %&gt;% \n        mutate(capacidad = sencilla * 1 + doble * 2 + camarote * 2)\n\ndormitorios\n\n  dormitorio sencilla doble camarote wc capacidad\n1          1        1     0        2  0         5\n2          2        1     0        2  0         5\n3          3        1     0        2  0         5\n4          4        1     0        1  1         3\n5          5        4     0        0  0         4\n6          6        0     1        0  1         2\n7          7        1     0        2  0         5\n8          8        1     0        2  1         5\n9       sala        1     0        0  0         1\n\n\nVamos a establecer, como administradores, las reglas basicas en cuanto a preferencias. A cada uno de los integrantes vamos a definirle 3 dormitorios que cumplan con nuestras reglas.\n\n# Definir el orden de las preferencias por persona\ndatos_preferencias &lt;- setNames(\nlist(c(2,3,4), # Nelsy no tiene problema\n     c(2,3,4), # Hernando no tiene problema\n     c(4,6,8), # Ofelia requiere un baño\n     c(4,8,6), # Liliana va con su esposo en dormitorio con baño\n     c(4,6,8), # John requiere un baño\n     c(3,7,8), # Jimmy quiere dormir con toda su familia\n     c(2,3,7), # Luis quiere dormir con su padre e hijo también\n     c(2,3,7), # Linda quiere dormir con su esposo\n     c(3,7,8), # Mercedes quiere dormir con toda su familia\n     c(4,6,8), # Sandra quiere dormir con la madre\n     c(3,7,8), # Estefania quiere dormir con toda su familia\n     c(3,7,8), # Juan quiere dormir con toda su familia\n     c(2,4,6), # Cristian quiere dormir con su esposa\n     c(2,4,6), # Claudia quiere dormir con su esposo\n     c(4,8,5), # Daniela quiere dormir sola o con sus padres\n     c(4,8,5), # Felipe quiere dormir solo o con sus padres\n     c(5,7,8), # Nicolas no quiere dormir solo o con sus padres\n     c(5,7,8), # Emiliano no quiere dormir solo o con sus padres\n     c(3,7,8), # Gabriel quiere dormir con sus padres\n     c(3,7,8) # Emma quiere dormir con sus padres\n     )\n,\nlistado$personas\n)\n\n# Definir funcion para extraer vector de preferencia por persona\nbuscar_preferencia &lt;- function(persona) datos_preferencias[[persona]]\n\n# Entregar prefencia con el par persona-dormitorio(hab)\npreferencias &lt;- function(persona, hab) {\n        p &lt;- which(as.numeric(hab) == buscar_preferencia(as.numeric(persona)))\n        as.integer(if (length(p) == 0) {\n                -100000\n        } else {\n                p\n        })\n}\n\nPodríamos haber definido 4 o 5 opciones, pero el punto es entender que, para éste ejemplo, lo que hemos hecho es establecer nosotros, administradores, las prioridades. Podríamos haber hecho una encuesta, enviarle un link a cada participante, para recolectar los datos y de esa forma obtener otros valores. Seguramente la solución del modelo no apuntaría a las reglas básicas que establecimos con mi esposa, y eso esta bien, es una solución mas, otra forma de resolver el problema de asignación.\n\\[\nmaximixar ∑_{i=1}^{n}∑_{j=1}^{m}preferencias_{i,j} · x_{i,j}\n\\]\n\\[\nsujeto ∑_{i=1}^{n}x_{i,j}≤capacidad_{j}, j=1,...,m\n\\]\n\\[\n∑_{j=1}^{m}x_{i,j}=1, i=1,...,n\n\\]\n\\[\nx_{i,j}∈❴0,1❵,i=1,...,nj=1,...,m\n\\]\nEn R seria:\n\npersonas &lt;- length(listado$persona)\nhab &lt;- length(dormitorios$dormitorio)\n\nmodelo &lt;- MIPModel() %&gt;% \n        \n        # 1 si la persona i se asigna al dormitorio j\n        add_variable(x[i,j], i = 1:personas, j = 1:hab, type = \"binary\") %&gt;% \n        \n        # maximixar las preferencias\n        set_objective(sum_over(preferencias(i,j) * x[i,j], i = 1:personas, j = 1:hab), sense = c(\"max\")) %&gt;% \n        \n        # no podemos exceder la capacidad de algun dormitorio\n        add_constraint(sum_over(x[i,j], i = 1:personas) &lt;= dormitorios$capacidad[j], j = 1:hab) %&gt;% \n        \n        # cada persona debe asignarse a un dormitorio\n        add_constraint(sum_over(x[i,j], j = 1:hab) == 1, i = 1:personas) %&gt;% \n        \n        # los matrimonios no pueden dormir separados\n        add_constraint(x[4,j] == x[5,j], j = 1:hab) %&gt;% \n        add_constraint(x[6,j] == x[9,j], j = 1:hab) %&gt;% \n        add_constraint(x[7,j] == x[8,j], j = 1:hab) %&gt;% \n        add_constraint(x[11,j] == x[12,j], j = 1:hab) %&gt;% \n        add_constraint(x[13,j] == x[14,j], j = 1:hab) \n\nmodelo\n\nMixed integer linear optimization problem\nVariables:\n  Continuous: 0 \n  Integer: 0 \n  Binary: 180 \nModel sense: maximize \nConstraints: 74 \n\n\n\nSolución\nUsamos GLPK y Symphony para resolver el modelo:\n\nSolver GLPKSolver Symphony\n\n\n\nlibrary(ROI.plugin.glpk)\n\nresultado_glpk &lt;- solve_model(modelo, with_ROI(solver = \"glpk\", verbose = TRUE))\n\n&lt;SOLVER MSG&gt;  ----\nGLPK Simplex Optimizer, v4.65\n74 rows, 180 columns, 450 non-zeros\n      0: obj =  -0.000000000e+00 inf =   2.000e+01 (20)\n     24: obj =  -1.499995000e+06 inf =   0.000e+00 (0)\n*    92: obj =   4.900000000e+01 inf =   0.000e+00 (0)\nOPTIMAL LP SOLUTION FOUND\nGLPK Integer Optimizer, v4.65\n74 rows, 180 columns, 450 non-zeros\n180 integer variables, all of which are binary\nInteger optimization begins...\nLong-step dual simplex will be used\n+    92: mip =     not found yet &lt;=              +inf        (1; 0)\n+   105: &gt;&gt;&gt;&gt;&gt;   4.900000000e+01 &lt;=   4.900000000e+01   0.0% (6; 0)\n+   105: mip =   4.900000000e+01 &lt;=     tree is empty   0.0% (0; 11)\nINTEGER OPTIMAL SOLUTION FOUND\n&lt;!SOLVER MSG&gt; ----\n\n\n\n\nlibrary(ROI.plugin.symphony)\n\nresultado_symphony &lt;- solve_model(modelo, with_ROI(solver = \"symphony\", verbosity = 1))\n\n\n\n\n# Define funcion para extraer datos de solucion\nentrega_hab &lt;- function(solucion){\n        solucion %&gt;% \n                get_solution(x[i,j]) %&gt;%\n                filter(value &gt; .9) %&gt;%  \n                select(i, j) %&gt;% \n                rowwise() %&gt;% \n                mutate(ranking_preferencia = preferencias(as.numeric(i), as.numeric(j)), \n                       eleccion_administrador = paste0(buscar_preferencia(as.numeric(i)), collapse = \",\")) %&gt;% \n                ungroup %&gt;% \n                rename(persona = i,\n                       dormitorio = j)\n}\n\n# Guardamos la informacion por modelo\nopcion_glpk &lt;- entrega_hab(resultado_glpk) \nopcion_symphony &lt;- entrega_hab(resultado_symphony) \n\n\nResultados con solver GLPKResultados con solver Symphony\n\n\n\nopcion_glpk\n\n# A tibble: 20 × 4\n   persona dormitorio ranking_preferencia eleccion_administrador\n     &lt;int&gt;      &lt;int&gt;               &lt;int&gt; &lt;chr&gt;                 \n 1       1          3                   2 2,3,4                 \n 2       7          3                   2 2,3,7                 \n 3       8          3                   2 2,3,7                 \n 4       2          4                   3 2,3,4                 \n 5      13          4                   2 2,4,6                 \n 6      14          4                   2 2,4,6                 \n 7      15          5                   3 4,8,5                 \n 8      16          5                   3 4,8,5                 \n 9       4          6                   3 4,8,6                 \n10       5          6                   2 4,6,8                 \n11       6          7                   2 3,7,8                 \n12       9          7                   2 3,7,8                 \n13      11          7                   2 3,7,8                 \n14      12          7                   2 3,7,8                 \n15      20          7                   2 3,7,8                 \n16       3          8                   3 4,6,8                 \n17      10          8                   3 4,6,8                 \n18      17          8                   3 5,7,8                 \n19      18          8                   3 5,7,8                 \n20      19          8                   3 3,7,8                 \n\n\n\n\n\nopcion_symphony\n\n# A tibble: 20 × 4\n   persona dormitorio ranking_preferencia eleccion_administrador\n     &lt;int&gt;      &lt;int&gt;               &lt;int&gt; &lt;chr&gt;                 \n 1       2          3                   2 2,3,4                 \n 2       7          3                   2 2,3,7                 \n 3       8          3                   2 2,3,7                 \n 4       1          4                   3 2,3,4                 \n 5      13          4                   2 2,4,6                 \n 6      14          4                   2 2,4,6                 \n 7      15          5                   3 4,8,5                 \n 8      16          5                   3 4,8,5                 \n 9       4          6                   3 4,8,6                 \n10       5          6                   2 4,6,8                 \n11      11          7                   2 3,7,8                 \n12      12          7                   2 3,7,8                 \n13      17          7                   2 5,7,8                 \n14      19          7                   2 3,7,8                 \n15      20          7                   2 3,7,8                 \n16       3          8                   3 4,6,8                 \n17       6          8                   3 3,7,8                 \n18       9          8                   3 3,7,8                 \n19      10          8                   3 4,6,8                 \n20      18          8                   3 5,7,8                 \n\n\n\n\n\n\n# Define funcion para crear graficas\ngraficar_solucion &lt;- function(opcion){\n        merge(listado %&gt;% rowid_to_column(),\n              opcion,\n              by.x = \"rowid\",\n              by.y = \"persona\")  %&gt;% \n                ggplot(aes(rowid, dormitorio, label = persona))+\n                geom_point(size = 3, aes(colour = factor(grupo)))+\n                facet_wrap(~ ranking_preferencia)+\n                ggrepel::geom_text_repel()+\n                theme(legend.position = \"top\")+\n                labs(x = \"ID de persona\")+\n                guides(col = guide_legend(title = \"grupo\"))+\n                scale_color_brewer(palette = \"Accent\")\n}\n\n\nObserva GLPKObserva Symphony\n\n\n\ngraficar_solucion(opcion_glpk)\n\n\n\n\n\n\n\n\n\n\n\ngraficar_solucion(opcion_symphony)\n\n\n\n\n\n\n\n\n\n\n\nLas asignaciones de dormitorios para las personas son diferentes para cada modelo, aún cuando ambos arrojaron la solución óptima.\n\nresultado_glpk\n\nStatus: success\nObjective value: 49\n\n\n\nresultado_symphony\n\nStatus: success\nObjective value: 49\n\n\nComo esas dos soluciones óptimas, podrian existir muchas mas, después de todo éste es un problema de optimización combinatorio."
  },
  {
    "objectID": "posts/2024-11-26-organizar_a_tu_familia/index.html#conclusiones",
    "href": "posts/2024-11-26-organizar_a_tu_familia/index.html#conclusiones",
    "title": "El secreto para organizar a tu familia",
    "section": "Conclusiones",
    "text": "Conclusiones\nVoy a ir con las dos soluciones a planteárselas a mi familia para nuestras vacaciones. Seguramente el plan no va a ejecutarse al pie de la letra, siguiendo los resultados de la solución obtenida, pero será un punto de partida interesante para organizar la solución definitiva, pues tenemos un problema con 180 variables binarias para jugar.\nAdemás, tenemos en ambas soluciones, tenemos dos dormitorios sin usar. esto sucede porque:\n\nDentro de las preferencias establecidas no se eligen todos los dormitorios, dejamos de listar el dormitorio # 1.\nLas restricciones declaradas en el código son suficientes para resolver la maximización de esas preferencias, entonces pueden quedar dormitorios libres.\n\nPodría ser que la función objetivo establecida no se realmente útil para nuestro problema. Sin embargo, existen formas de equilibrar y contrastar problemas de optimización lineal con varios objetivos al tiempo."
  },
  {
    "objectID": "posts/2024-11-26-web_scraping_with_R/index.html",
    "href": "posts/2024-11-26-web_scraping_with_R/index.html",
    "title": "Web scraping con R",
    "section": "",
    "text": "Hace poco revisé una de las muchas opciones de trabajo remoto que existen para obtener ingresos en plataformas. Apareció una que me llamó mucho la atención en Upwork:"
  },
  {
    "objectID": "posts/2024-11-26-web_scraping_with_R/index.html#la-descripción-del-trabajo-web-scraping-expert---in-r",
    "href": "posts/2024-11-26-web_scraping_with_R/index.html#la-descripción-del-trabajo-web-scraping-expert---in-r",
    "title": "Web scraping con R",
    "section": "La descripción del trabajo: Web Scraping expert - in R",
    "text": "La descripción del trabajo: Web Scraping expert - in R\n\nI am looking for someone to help me scrape data from a website using R.\nI am trying to scrape information from lawsuits on the website of the Superior Court of São Paulo (https://esaj.tjsp.jus.br/cjpg/). I wrote the attached R code using Rvest and it works partially. I have successfully extracted some of the data I need (see the attached output). However:\n\nMy code only extracts the information for one keyword. When I add more search terms, I get an error. I’ve tried using a for loop to generate different URLs, but I keep getting an error. I would like to change the code so that I can extract data for different keywords.\nThe second problem is that my sample code only extracts information from the results that are on the first page, but not for the next pages. This happens because I am using Rvest which does not work on javascript, in this sense I would like to have this code adapted to R selenium or other R package so that I can extract the data for all page results.\n\nI would like to have as outputs the R script and the final dataset\n\nDecidí intentarlo con selenider porque: la persona lo sugierió, y permite hacer clic en un elemento HTML, ya sea simulando un clic del mouse o activando el evento “clic” del elemento.\nEste es un pantallazo de la estructura de la página que queremos, donde estoy buscando la palabra clave “Teruel”:\n\nObserven que tenemos 21 resultados (es posible que para la fecha en que tú consultes la página cambie el dato, depende si eliminan o agregan entradas):\n\nEl primer problema que enfrenta la persona es la búsqueda de varios términos o palabras, así que vamos a intentarlo manualmente. Usamos el botón dispuesto “OU” y clic en Consultar:\n\nReviso el cambio en la URL, comparo el resultado de la búsqueda de “Teruel” versus el resultado de la búsqueda de “Teruel OU abr”. Para efectos de lectura fácil, omitiré cierto trozo del string:\n\nPrimera búsqueda\nhttps://esaj.tjsp.jus.br/cjpg/pesquisar.do?conversationId=&dadosConsulta.pesquisaLivre=Teruel&tipoNumero=UNIFICADO&numeroDigitoAnoUnificado=&foroNumeroUnificado=&dadosConsulta.nuProcesso=&dadosConsulta.nuProcessoAntigo=&classeTreeSelection.values=&classeTreeSelection.text=&assuntoTreeSelection.values=10467&assuntoTreeSelection.text=Despesas+Condominiais&agenteSelectedEntitiesList=&contadoragente=0&contadorMaioragente=0&cdAgente=&nmAgente=&dadosConsulta.dtInicio=&dadosConsulta.dtFim=14%2F11%2F2024&&varasTreeSelection.text=122+Registros+selecionados&dadosConsulta.ordenacao=DESC\n\n\nSegunda búsqueda\nhttps://esaj.tjsp.jus.br/cjpg/pesquisar.do?conversationId=&dadosConsulta.pesquisaLivre=Teruel+OU+abr&tipoNumero=UNIFICADO&numeroDigitoAnoUnificado=&foroNumeroUnificado=&dadosConsulta.nuProcesso=&dadosConsulta.nuProcessoAntigo=&classeTreeSelection.values=&classeTreeSelection.text=&assuntoTreeSelection.values=10467&assuntoTreeSelection.text=Despesas+Condominiais&agenteSelectedEntitiesList=&contadoragente=0&contadorMaioragente=0&cdAgente=&nmAgente=&dadosConsulta.dtInicio=&dadosConsulta.dtFim=14%2F11%2F2024&&varasTreeSelection.text=122+Registros+selecionados&dadosConsulta.ordenacao=DESC\nEl cambio radica en: dadosConsulta.pesquisaLivre.\n\n# Cargar librerías\nlibrary(selenider)\n\n# Términos a buscar\nwords &lt;- c(\"Teruel\", \"abr\")\n\n# string completo de los términos de interés\nsearch_term &lt;- paste0(words, collapse = \"+OU+\")\n\n# Defining the url\nurl &lt;- paste0(\n  \"http://esaj.tjsp.jus.br/cjpg/pesquisar.do?\",\n  \"dadosConsulta.pesquisaLivre=\", URLencode(search_term),\n  \"&tipoNumero=UNIFICADO&numeroDigitoAnoUnificado=&foroNumeroUnificado=&dadosConsulta.nuProcesso=&dadosConsulta.nuProcessoAntigo=&classeTreeSelection.values=&classeTreeSelection.text=&assuntoTreeSelection.values=10467&assuntoTreeSelection.text=Despesas+Condominiais&agenteSelectedEntitiesList=&contadoragente=0&contadorMaioragente=0&cdAgente=&nmAgente=&dadosConsulta.dtInicio=&dadosConsulta.dtFim=14%2F11%2F2024&varasTreeSelection.values=2-2723%2C2-6843%2C2-997%2C2-203%2C2-6874%2C2-7386%2C2-3772%2C2-9%2C2-2894%2C2-501%2C2-2%2C2-5221%2C2-3820%2C2-6873%2C2-998%2C2-3127%2C2-6844%2C2-3710%2C2-1001%2C2-103%2C2-6875%2C2-7385%2C2-3534%2C2-204%2C2-2602%2C2-6865%2C2-502%2C2-5490%2C2-3979%2C2-8%2C2-5689%2C2-6350%2C2-7387%2C2-7388%2C2-102%2C2-5610%2C2-5717%2C2-6845%2C2-999%2C2-13%2C2-6872%2C2-6841%2C2-321%2C2-4%2C2-5442%2C2-6883%2C2-3868%2C2-202%2C2-5757%2C2-2005%2C2-4864%2C2-2003%2C2-5569%2C2-3026%2C2-601%2C2-6881%2C2-6890%2C2-3469%2C2-5323%2C2-15%2C2-6870%2C2-11%2C2-6888%2C2-1848%2C2-2004%2C2-6878%2C2-5742%2C2-604%2C2-603%2C2-3389%2C2-4367%2C2-5099%2C2-1673%2C2-901%2C2-5633%2C2-101%2C2-6312%2C2-7221%2C2-505%2C2-4684%2C2-6889%2C2-6879%2C2-10%2C2-3589%2C2-6867%2C2-6866%2C2-5%2C2-5649%2C2-6%2C2-7%2C2-6868%2C2-504%2C2-6876%2C2-503%2C2-6887%2C2-4499%2C2-201%2C2-3634%2C2-205%2C2-3853%2C2-6886%2C2-602%2C2-3952%2C2-3199%2C2-3%2C2-6869%2C2-506%2C2-6862%2C2-2109%2C2-900%2C2-12%2C2-5528%2C2-3676%2C2-14%2C2-1900%2C2-6840%2C2-6871%2C2-1%2C2-3280%2C2-703%2C2-3910%2C2-1697&varasTreeSelection.text=122+Registros+selecionados&dadosConsulta.ordenacao=DESC\")\n\n# Vamos a permitir 15 segundos de espera\nsession &lt;- selenider_session(\n    \"selenium\",\n    #options = selenium_options(server_options = NULL),\n    \"firefox\",\n    timeout = 15\n)\n\nPara el segundo problema debemos revisar con F12 la estructura de la página, buscamos la flecha que gestiona el cambio entre páginas de los resultados. Queremos hacer clic en esa flecha:\n\nCuando ya lo tenemos identificado, nuestra labor se centrará en “raspar” los datos:\n\nCon esto en mente iniciamos nuestro código:\n\nAbrimos la página.\nCreamos una función para extraer los datos.\nDeterminamos el número de páginas que tiene nuestra consulta. Esto para sabe cuántas veces debemos “dar clic” a las flechas.\nGeneramos un for loop para leer toda la información y guardarla en un data.frame.\n\n\n# Abrir página web\nopen_url(url)\n\n\n# Función para extraer datos de una página\nconsolidar_resultados &lt;- function(pagina) {\n  cat(\"INICIO DE LECTURA DE PÁGINA\", \"\\n\")\n  \n  obtener_texto &lt;- function(elemento, idx, replace_pattern = NULL) {\n    texto &lt;- elemento[[idx]] |&gt; \n      find_element(\"td\") |&gt; \n      elem_text() |&gt; \n      stringr::str_squish()\n    if (!is.null(replace_pattern)) {\n      texto &lt;- gsub(pattern = replace_pattern[1], replacement = replace_pattern[2], texto)\n    }\n    return(texto)\n  }\n  \n  articulos &lt;- pagina |&gt; \n    lapply(\\(x) x |&gt; find_elements(xpath = \"./td/table/tbody/tr\"))\n  \n  cat(\"Leyendo título\", \"\\n\")\n  columna_1 &lt;- articulos |&gt; lapply(\\(x) x[[1]] |&gt; find_element(\"span\") |&gt; elem_text())\n  cat(\"Leyendo Classe\", \"\\n\")\n  columna_2 &lt;- articulos |&gt; lapply(\\(x) obtener_texto(x, 2, c(\"Classe: \", \"\")))\n  cat(\"Leyendo Assunto\", \"\\n\")\n  columna_3 &lt;- articulos |&gt; lapply(\\(x) obtener_texto(x, 3, c(\"Assunto: \", \"\")))\n  cat(\"Leyendo Magistrado\", \"\\n\")\n  columna_4 &lt;- articulos |&gt; lapply(\\(x) obtener_texto(x, 4, c(\"Magistrado: \", \"\")))\n  cat(\"Leyendo Comarca\", \"\\n\")\n  columna_5 &lt;- articulos |&gt; lapply(\\(x) obtener_texto(x, 5, c(\"Comarca: \", \"\")))\n  cat(\"Leyendo Foro\", \"\\n\")\n  columna_6 &lt;- articulos |&gt; lapply(\\(x) obtener_texto(x, 6, c(\"Foro: \", \"\")))\n  cat(\"Leyendo Vara\", \"\\n\")\n  columna_7 &lt;- articulos |&gt; lapply(\\(x) obtener_texto(x, 7, c(\"Vara: \", \"\")))\n  cat(\"Leyendo Data_de_Disponibilização\", \"\\n\")\n  columna_8 &lt;- articulos |&gt; lapply(\\(x) obtener_texto(x, 8, c(\"Data de Disponibilização: \", \"\")))\n  cat(\"Leyendo Decision\", \"\\n\")\n  columna_9 &lt;- articulos |&gt; lapply(\\(x) x[[9]] |&gt; find_element(\"span\") |&gt; elem_text() |&gt; stringr::str_squish())\n  \n  cat(\"FIN DE LECTURA DE PÁGINA\", \"\\n\")\n  \n  return(list(\n    titulo = columna_1,\n    Classe = columna_2,\n    Assunto = columna_3,\n    Magistrado = columna_4,\n    Comarca = columna_5,\n    Foro = columna_6,\n    Vara = columna_7,\n    Data_de_Disponibilização = columna_8,\n    Decision = columna_9\n  ))\n}\n\n\n# Contar cantidad de páginas por resultado\npags &lt;- s(\".trocaDePagina\") |&gt; \n  find_elements(\"a\") |&gt; \n  as.list() |&gt; \n  length() # la última es la flecha (la usaremos más adelante)\n\nifelse(pags[1] == -1, pags[1] &lt;- 1, pags[1] &lt;- pags[1])\n\n[1] 3\n\ndata_completo &lt;- unname(data.frame())\n\nfor (pagina in 1:pags) {\n  \n  cat(paste0(\"Estamos en la página: \", pagina, \"\\n\"))\n  \n  recolectar &lt;- s(\"#divDadosResultado\") |&gt; \n    find_elements(xpath = \"./table/tbody/tr\") |&gt; \n    as.list() \n  \n  resultados &lt;- consolidar_resultados(recolectar)\n  \n  temporal &lt;- resultados |&gt; \n    purrr::map(~ do.call(rbind, .x) |&gt; \n                 unlist()) |&gt; \n    data.frame()\n  \n  data_completo &lt;- rbind(data_completo, temporal)\n  \n  temporal &lt;- unname(data.frame())\n  \n  if (pagina == pags) {\n    \n    break()\n    \n  } else {\n    \n    ir_a &lt;- as.numeric(pagina) + 1\n    \n    cat(\"\\n\",\"\\n\",\"____PASANDO PÁGINA____\", \"\\n\",\"\\n\")\n    \n    s(\".trocaDePagina\") |&gt; \n      find_element(name = as.character(ir_a)) |&gt; \n      elem_click()\n    \n    Sys.sleep(10)\n  }\n}\n\nEstamos en la página: 1\nINICIO DE LECTURA DE PÁGINA \nLeyendo título \nLeyendo Classe \nLeyendo Assunto \nLeyendo Magistrado \nLeyendo Comarca \nLeyendo Foro \nLeyendo Vara \nLeyendo Data_de_Disponibilização \nLeyendo Decision \nFIN DE LECTURA DE PÁGINA \n\n \n ____PASANDO PÁGINA____ \n \nEstamos en la página: 2\nINICIO DE LECTURA DE PÁGINA \nLeyendo título \nLeyendo Classe \nLeyendo Assunto \nLeyendo Magistrado \nLeyendo Comarca \nLeyendo Foro \nLeyendo Vara \nLeyendo Data_de_Disponibilização \nLeyendo Decision \nFIN DE LECTURA DE PÁGINA \n\n \n ____PASANDO PÁGINA____ \n \nEstamos en la página: 3\nINICIO DE LECTURA DE PÁGINA \nLeyendo título \nLeyendo Classe \nLeyendo Assunto \nLeyendo Magistrado \nLeyendo Comarca \nLeyendo Foro \nLeyendo Vara \nLeyendo Data_de_Disponibilização \nLeyendo Decision \nFIN DE LECTURA DE PÁGINA \n\n\n\n\nExtracción final\nAhora nuestra información organizada:\n\ndata_completo\n\n                      titulo                           Classe\n1  1051229-39.2024.8.26.0002 Execução de Título Extrajudicial\n2  1005876-78.2021.8.26.0002 Execução de Título Extrajudicial\n3  1005870-71.2021.8.26.0002 Execução de Título Extrajudicial\n4  1005878-48.2021.8.26.0002 Execução de Título Extrajudicial\n5  1017042-05.2024.8.26.0002 Execução de Título Extrajudicial\n6  1051406-03.2024.8.26.0002 Execução de Título Extrajudicial\n7  1005664-57.2021.8.26.0002 Execução de Título Extrajudicial\n8  1005872-41.2021.8.26.0002 Execução de Título Extrajudicial\n9  1005872-41.2021.8.26.0002 Execução de Título Extrajudicial\n10 1005656-80.2021.8.26.0002 Execução de Título Extrajudicial\n11 1005653-28.2021.8.26.0002 Execução de Título Extrajudicial\n12 1005656-80.2021.8.26.0002 Execução de Título Extrajudicial\n13 1005879-33.2021.8.26.0002 Execução de Título Extrajudicial\n14 1014990-41.2021.8.26.0002 Execução de Título Extrajudicial\n15 1014990-41.2021.8.26.0002 Execução de Título Extrajudicial\n16 1014990-41.2021.8.26.0002 Execução de Título Extrajudicial\n17 1005653-28.2021.8.26.0002 Execução de Título Extrajudicial\n18 1005656-80.2021.8.26.0002 Execução de Título Extrajudicial\n19 1005680-11.2021.8.26.0002 Execução de Título Extrajudicial\n20 1005675-86.2021.8.26.0002 Execução de Título Extrajudicial\n21 1005877-63.2021.8.26.0002 Execução de Título Extrajudicial\n22 0083447-94.2011.8.26.0002         Procedimento Comum Cível\n23 1019510-54.2015.8.26.0002         Procedimento Comum Cível\n24 0011321-80.2010.8.26.0002         Procedimento Comum Cível\n                 Assunto                                   Magistrado   Comarca\n1  Despesas Condominiais                         Théo Assuar Gragnano SÃO PAULO\n2  Despesas Condominiais               Marina Balester Mello de Godoy SÃO PAULO\n3  Despesas Condominiais                        Emanuel Brandão Filho SÃO PAULO\n4  Despesas Condominiais                  Eurico Leonel Peixoto Filho SÃO PAULO\n5  Despesas Condominiais                         Théo Assuar Gragnano SÃO PAULO\n6  Despesas Condominiais           LUIZ RAPHAEL NARDY LENCIONI VALDEZ SÃO PAULO\n7  Despesas Condominiais                       ANDERSON CORTEZ MENDES SÃO PAULO\n8  Despesas Condominiais                               ROGE NAIM TENN SÃO PAULO\n9  Despesas Condominiais                                VANESSA SFEIR SÃO PAULO\n10 Despesas Condominiais                                VANESSA SFEIR SÃO PAULO\n11 Despesas Condominiais                      ALEXANDRE BATISTA ALVES SÃO PAULO\n12 Despesas Condominiais                     Fernanda Soares Fialdini SÃO PAULO\n13 Despesas Condominiais                      Guilherme Silva e Souza SÃO PAULO\n14 Despesas Condominiais                             Ricardo Hoffmann SÃO PAULO\n15 Despesas Condominiais                             Ricardo Hoffmann SÃO PAULO\n16 Despesas Condominiais                             Ricardo Hoffmann SÃO PAULO\n17 Despesas Condominiais                      ALEXANDRE BATISTA ALVES SÃO PAULO\n18 Despesas Condominiais                     Fernanda Soares Fialdini SÃO PAULO\n19 Despesas Condominiais                       FABIANA FEHER RECASENS SÃO PAULO\n20 Despesas Condominiais                      Guilherme Duran Depieri SÃO PAULO\n21 Despesas Condominiais                         Théo Assuar Gragnano SÃO PAULO\n22 Despesas Condominiais              Vanessa Miranda Tavares de Lima SÃO PAULO\n23 Despesas Condominiais                Carolina Nabarro Munhoz Rossi SÃO PAULO\n24 Despesas Condominiais Hertha Helena Rollemberg Padilha de Oliveira SÃO PAULO\n                             Foro           Vara Data_de_Disponibilização\n1  Foro Regional II - Santo Amaro 12ª Vara Cível               31/10/2024\n2  Foro Regional II - Santo Amaro 14ª Vara Cível               01/10/2024\n3  Foro Regional II - Santo Amaro  6ª Vara Cível               26/09/2024\n4  Foro Regional II - Santo Amaro  5ª Vara Cível               16/09/2024\n5  Foro Regional II - Santo Amaro 12ª Vara Cível               13/09/2024\n6  Foro Regional II - Santo Amaro  7ª Vara Cível               23/08/2024\n7  Foro Regional II - Santo Amaro  9ª Vara Cível               15/03/2024\n8  Foro Regional II - Santo Amaro 13ª Vara Cível               19/01/2024\n9  Foro Regional II - Santo Amaro 13ª Vara Cível               08/08/2023\n10 Foro Regional II - Santo Amaro 13ª Vara Cível               07/07/2023\n11 Foro Regional II - Santo Amaro 14ª Vara Cível               24/05/2023\n12 Foro Regional II - Santo Amaro 13ª Vara Cível               19/04/2023\n13 Foro Regional II - Santo Amaro  1ª Vara Cível               23/02/2023\n14 Foro Regional II - Santo Amaro 11ª Vara Cível               19/01/2023\n15 Foro Regional II - Santo Amaro 11ª Vara Cível               11/01/2023\n16 Foro Regional II - Santo Amaro 11ª Vara Cível               01/09/2022\n17 Foro Regional II - Santo Amaro 14ª Vara Cível               26/04/2022\n18 Foro Regional II - Santo Amaro 13ª Vara Cível               08/02/2022\n19 Foro Regional II - Santo Amaro  1ª Vara Cível               17/12/2021\n20 Foro Regional II - Santo Amaro 10ª Vara Cível               25/10/2021\n21 Foro Regional II - Santo Amaro 12ª Vara Cível               30/07/2021\n22 Foro Regional II - Santo Amaro  4ª Vara Cível               31/10/2016\n23 Foro Regional II - Santo Amaro  1ª Vara Cível               28/06/2016\n24 Foro Regional II - Santo Amaro  2ª Vara Cível               09/10/2015\n                                                                                                                                                                                                                                                                                                                                                                                          Decision\n1            ... Residencial Teruel Executado: Ramiles Santana Cruz Justiça Gratuita Juiz(a) de Direito: Dr(a). Théo Assuar Gragnano Vistos. Satisfeito o crédito, promovo a extinção da execução, com fundamento no art. 924, II, do Código de Processo Civil. Oportunamente, certifique-se o trânsito em julgado e arquivem-se os autos, observando a Secretaria, previamente, o disposto no ...\n2              ... Residencial Teruel Executado: Maria Damiana de Souza Justiça Gratuita Juiz(a) de Direito: Dr(a). Marina Balester Mello de Godoy Vistos. HOMOLOGO o acordo de fls. 179/181 e SUSPENDO a execução, para que a parte executada cumpra voluntariamente as obrigações assumidas, nos termos do artigo 922, caput, do Código de Processo Civil. Cabe à parte credora comunicar os ...\n3         ... Residencial Teruel Executado: Kelly Carolina Pereira Mota C O N C L U S Ã O Em 26 de setembro de 2024, faço estes autos conclusos ao(à) MM(a). Juiz(Juíza) de Direito da 6ª Vara Cível Foro Regional de Santo Amaro, Dr(a). Emanuel Brandão Filho. Eu, (DYK), escr., digitei. Vistos. Fls. 240/253 e 254: 1- Regularizada a representação processual do exequente, expeça-se MLE ...\n4                 ... Residencial Teruel Executado: Nathália Rodrigues Bazolli CONCLUSÃO Aos 13 de setembro de 2024, faço estes autos conclusos ao(à) MM(a). Juiz(a) de Direito: Dr(a). Eurico Leonel Peixoto Filho. Letícia Minari Biaggioni, Escrevente Técnico Judiciário, M378130. Vistos. Conjunto Residencial Teruel propôs ação de Execução de Título Extrajudicial em face de Nathália ...\n5                                ... Residencial Teruel Executado: Tatiane Silva de Oliveira Justiça Gratuita Juiz(a) de Direito: Dr(a). Théo Assuar Gragnano Vistos. Ante o acordo firmado entre as partes, suspenda-se o feito, nos termos do art. 922 do Código de Processo Civil. Aguarde-se no arquivo. Intime-se. São Paulo, 13 de setembro de 2024. DOCUMENTO ASSINADO DIGITALMENTE NOS ...\n6                         ... Residencial Teruel Executado: Cacilda Andre da Silva e outro Vistos HOMOLOGO os termos do acordo entabulado pelas partes, com suspensão da execução nos termos do art. 922 do CPC. Aguarde-se, em arquivo provisório, o cumprimento do acordo. Eventual descumprimento, incumbirá à parte exequente provocar o prosseguimento da execução. Int. São Paulo, 11 de ...\n7       ... Residencial Teruel Executado: Dercílio Edimar Rodrigues Vistos, Diante da satisfação da parte exequente, JULGO EXTINTO O PROCESSO, com fundamento no artigo 924, inciso II, do Código de Processo Civil. Inexistindo interesse recursal, certifique a Serventia, desde logo, o trânsito em julgado. LIBERE-SE o montante bloqueado em favor da parte executada. Assim, expeça-se o ...\n8            ... Residencial Teruel Executado: Vera Lúcia de Oliveira Em 12 de janeiro de 2024 faço estes autos conclusos ao MM. Juiz de Direito da 1ª Vara Cível de São Roque/SP, Dr. ROGE NAIM TENN. Eu____, Escr. Subscrevi. Vistos. Considerando que houve a quitação da dívida, JULGO EXTINTO o processo, nos termos do artigo 924, inciso II, do Código de Processo Civil. Transitada em ...\n9                 ... Residencial Teruel Executado: Vera Lúcia de Oliveira Juiz(a) de Direito: Dr(a). VANESSA SFEIR Vistos. 1. Dou por regularizada a representação processual do exequente. 2. Homologo o acordo celebrado pelas partes às fls. 148/149, para que produza seus jurídicos e legais efeitos. 3. Declaro suspenso o processo, com fulcro no artigo 922 do CPC. 4. Arquivem-se os ...\n10                         ... Residencial Teruel Executado: Cintia Sousa Nascimento Justiça Gratuita Juiz(a) de Direito: Dr(a). VANESSA SFEIR Vistos. Regularizada a representação processual da exequente (fls. 184 e 189/194). HOMOLOGO o acordo celebrado entre as partes (fls. 166/169) e SUSPENDO a execução até seu integral cumprimento, nos moldes do art. 922, do Código de Processo ...\n11                       ... Residencial Teruel Executado: Aurizene Santos Bonfim Justiça Gratuita Juiz(a) de Direito: Dr(a). ALEXANDRE BATISTA ALVES Vistos. Conjunto Residencial Teruel propôs esta ação de Execução de Título Extrajudicial em face de Aurizene Santos Bonfim. A parte exequente informa a quitação integral do acordo pela executada. Em razão do exposto, JULGO EXTINTO o ...\n12            ... Residencial Teruel Executado: Cintia Sousa Nascimento Justiça Gratuita Juiz(a) de Direito: Dr(a). Fernanda Soares Fialdini Vistos. 1. Ante a concordância do exequente (fl. ), proceda a serventia ao desbloqueio dos valores encontrados em contas da executada (fls. 160/161), via Sisbajud. 2. Homologo o acordo celebrado pelas partes às fls. 153/156, para que produza ...\n13                       ... Residencial Teruel Executado: Paula de Oliveira Costa Justiça Gratuita CONCLUSÃO Em 23 de fevereiro de 2023, faço estes autos conclusos a MM Juiz de Direito, Dra. Guilherme Silva e Souza. Eu, _______(Vithoria Hilinsky, E52052932), Estagiário Nível Superior, subscrevi. Vistos. À vista da petição de fls. 132, considero adimplida a obrigação por parte da ...\n14      ... Residencial Teruel Executado: Manelito Fonseca dos Santos- Espólio Justiça Gratuita CONCLUSÃO Em 19 de janeiro, faço estes autos conclusos ao Exmo. Sr. Dr., MM Juiz de Direito abaixo designado na 11º Vara Cível do Foro Regional II - Santo Amaro. Eu ________________, (escr.) subscr. Juiz(a) de Direito: Dr(a). Ricardo Hoffmann Vistos. Com fundamento no artigo 924, II do ...\n15                 ... Residencial Teruel Executado: Manelito Fonseca dos Santos- Espólio Justiça Gratuita Em 10 de janeiro de 2023�, faço estes autos conclusos ao Exmo. Sr. Dr., MM. Juiz de Direito abaixo designado da 11ª Vara Cível do Foro Regional II - Santo Amaro. Eu, Érica Regina Kunigami, assistente judiciário, subscr. Juiz de Direito: Dr. Ricardo Hoffmann Vistos. As partes ...\n16           ... Residencial Teruel Executado: Manelito Fonseca dos Santos Justiça Gratuita CONCLUSÃO Em 01 de setembro, faço estes autos conclusos ao Exmo. Sr. Dr., MM Juiz de Direito abaixo designado na 11º Vara Cível do Foro Regional II - Santo Amaro. Eu ________________, (escr.) subscr. Juiz de Direito: Dr. Ricardo Hoffmann Vistos. Homologo o acordo firmado entre as partes em ...\n17                 ... Residencial Teruel Executado: Aurizene Santos Bonfim Justiça Gratuita Juiz(a) de Direito: Dr(a). ALEXANDRE BATISTA ALVES Vistos. Homologo o acordo e suspendo, nos termos do CPC, art. 922, o curso da execução para seu cumprimento. Cabe ao credor comunicar os órgãos de proteção ao crédito ou fornecer documento para providências do devedor. Ao término do prazo ...\n18                ... Residencial Teruel Executado: Cintia Sousa Nascimento Justiça Gratuita Juiz(a) de Direito: Dr(a). Fernanda Soares Fialdini Vistos. 1. Autos desarquivados, independentemente do recolhimento de custas, em vista da gratuidade concedida ao exequente. 2. Homologo o acordo celebrado pelas partes às fls. 142/144, para que produza seus jurídicos e legais efeitos. 3. ...\n19         ... Santos BonfimConjunto Residencial Teruel Executado(s): Izabete Santos Bonfim Juíza de Direito: Drª FABIANA FEHER RECASENS Vistos, Tendo em vista a notícia do bloqueio integral do débito, bem com a inércia da executada e a concordância, implícita, do exequente , JULGO EXTINTA a presente ação de EXECUÇÃO, com fundamento no artigo 924, inciso II, do Código de Processo ...\n20            ... Residencial Teruel Executado: Iranildes Elias Teixeira Justiça Gratuita Juiz(a) de Direito: Dr(a). Guilherme Duran Depieri Vistos. Homologo a transação de fls. 134/137, para que surtam os devidos efeitos de direito, nos termos do art. 922 do CPC. Aguarde-se integral cumprimento do acordo, no arquivo, o qual deverá ser informado pela parte exequente para extinção ...\n21            ... Residencial Teruel Executado: Maria de Lourdes Ferreira de Oliveira Justiça Gratuita Juiz(a) de Direito: Théo Assuar Gragnano Vistos. 1. Fls 81/84: Satisfeito o crédito, promovo a extinção da execução, com fundamento no art. 924, II, do Código de Processo Civil. 2. Tendo o pagamento sido ultimado extrajudicialmente e antes mesmo da citação, não incidem as custas ...\n22 ... 453) até o limite de R$ 372.089,46 (abr/2015). O exequente apresentou cálculo do valor de R$ 7.837,62 como valor devido pelas taxas condominiais até a imissão a posse pelo arrematante. DECIDO. Este processo alcançou sua finalidade. Julgo EXTINTA a presente execução, nos termos do art. 924, II, do CPC. Esta decisão servirá como mandado para fins de cancelamento de eventuais ...\n23    ... cobrado sob a rubrica \"investimentos abr/2015\", no total de R$500,18 e \"compl condomínio\" set/2014 e abr/2015, impugnados pelos réus, sem que o autor tenha trazido qualquer documento que comprovasse a legitimidade destas cobranças, não juntando aos autos convenção condominial ou assembleia que as tenha aprovado, não tendo o relatório juntado a força probante pretendida, ...\n24         ... referentes aos meses de Jul/08, set/08, abr/09 e mai/09, já estariam pagas, e portanto, além de serem excluídas da cobrança, faria jus ao recebimento do dobro do valor cobrado indevidamente. A ré apresenta comprovante de pagamento das despesas condominiais relativas aos meses de Jul/08, set/08, abr/09 e mai/09. Apresenta os recibos da administradora do condomínio e ..."
  },
  {
    "objectID": "posts/2024-12-19-cartlow_scraping/index.html",
    "href": "posts/2024-12-19-cartlow_scraping/index.html",
    "title": "Shopify scraping con R",
    "section": "",
    "text": "Aquí tenemos otro trabajo de Web Scraping:\n\nDescripción del trabajo:\n\nEsta vez tenemos un poco más de complejidad. A medida que vamos desarrollando el código vamos a ir descubriendo ciertos problemas a considerar.\nMiremos la página:\n\n\n\nEstrategia:\nVamos a:\n\nIdentificar la cantidad de páginas que contiene la web.\n\nPara cada página vamos a almacenar las URL de los productos.\nEntraremos a cada URL para identificar la cantidad de variantes que tiene el producto. Hay 3 categorias: condición, color y tamaño.\n\nElegimos cada uno de los botones y extraemos la información solicitada.\nTomaremos el tiempo que tarda cada consulta para estimar un requerido de horas.\n\n\n\nCódigo:\n\n# Cargamos librería\nlibrary(selenider)\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter()    masks stats::filter()\n✖ tibble::has_name() masks selenider::has_name()\n✖ dplyr::lag()       masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(RSelenium)\n\n# Definimos la página para extraer los datos\nurl &lt;- \"https://www.cartlow.com/uae/en/q\"\n\nwithr::deferred_clear()\n\n# En nuestra sesión permitiremos 30 segundos\n# session &lt;- selenider_session(\n#         \"selenium\",\n#         browser = \"firefox\",\n#         timeout = 30,\n#         .env = rlang::caller_env(),\n#         view = FALSE,\n#         quiet = TRUE\n# )\n\nDefinimos las funciones que nos ayudarán para el scraping:\n\n\nCode\nextraer_botones &lt;- function(boton){\n        \n        desc_botones &lt;- boton |&gt; \n                purrr::map(~ .x |&gt; \n                                   purrr::map(~ .x$class)) |&gt; \n                unlist()\n        \n        desc_botones &lt;- gsub(\"active\", \"\", desc_botones)\n        \n        return(list(iter_botones = desc_botones))\n        \n}\n\nextrae_imagenes &lt;- function(producto){\n        \n        mostrando &lt;- s(\".cz-thumblist-holder.sm-scrollbar\") |&gt; \n                find_elements(\"a\") |&gt; \n                as.list() |&gt; \n                lapply(\\(x) x |&gt; elem_attrs())\n        \n        elegir_activos &lt;- mostrando |&gt; \n                purrr::map(~ .x$class) \n        \n        escondidos &lt;- elegir_activos |&gt; \n                purrr::map(~ stringr::str_detect(.x, \"hidden\")) |&gt; \n                unlist()\n        \n        show_block &lt;- elegir_activos |&gt; \n                purrr::map(~ stringr::str_detect(.x, \"show_block\")) |&gt; \n                unlist()\n        \n        real_mostrar &lt;- escondidos & show_block\n        \n        # Si la suma es cero implica que no hay otras variantes\n        # Las imagenes todas son de esa variante\n        if (sum(escondidos) == 0) {\n                \n                filtrando &lt;- rep(TRUE, length(escondidos)) |&gt; \n                        purrr::map(~ list(.x) |&gt; unlist())\n                \n        } else {\n                \n                filtrando &lt;- real_mostrar\n                \n        }\n        \n        #filtrando &lt;- elegir_activos |&gt; \n        #       purrr::map(~ stringr::str_detect(.x, \"show_block\"))\n        \n        mostrando[which(filtrando == TRUE)] |&gt; \n                purrr::map(~ .x$`data-fullsizeimgsrc`) |&gt; \n                unlist()\n        \n}\n\nextraer_info_variante &lt;- function(producto){\n        \n        #- Title                xxx\n        titulo &lt;- s(\".cart-info.text-left\") |&gt; \n                find_element(\"h1\") |&gt; \n                elem_text()\n        \n        # Variants\n        variante &lt;- ss(\".mr-md-3.mr-sm-1\") |&gt; \n                lapply(\\(x) x  |&gt; \n                               elem_text())\n        # Images\n        imagenes_url &lt;- extrae_imagenes() \n        \n        # Price\n        precio_final &lt;- s(\".cart-info.text-left\") |&gt; \n                find_element(\"#var_price\") |&gt; \n                elem_text()\n        \n        precio_anterior &lt;- s(\".cart-info.text-left\") |&gt; \n                find_element(\"#var_market_price\") |&gt; \n                elem_text()\n        \n        # Encuentra la descripcion\n        descripcion &lt;- s(\".des-pro-sec\") |&gt; \n                find_elements(\"li\") |&gt; \n                lapply(\\(x) x |&gt;  with(elem_text(x)))\n        \n        # Encuentra la categoria\n        categoria &lt;- s(\".container.npdp-design\") |&gt; \n                find_element(\".breadcrumb-custom\") |&gt; \n                find_elements(\"a\") |&gt; \n                lapply(\\(x) x |&gt; elem_attr(\"href\"))\n        \n        return(list(titulo = titulo,\n                    imagenes_url = imagenes_url,\n                    variante = variante,\n                    precio_final = precio_final,\n                    precio_anterior = precio_anterior,\n                    descripcion = descripcion,\n                    categoria = categoria))\n}\n\n# Consolida todas las URL de la pagina mostrada\nleer_direcciones &lt;- function(){\n        \n        s(\".products-grid\") |&gt; \n                find_elements(\".productImage\") |&gt; \n                lapply(\\(x) x |&gt; \n                               find_element(\"a\") |&gt; \n                               elem_attr(\"href\"))\n        \n}\n\npasar_pagina &lt;- function(){\n        \n        paginacion &lt;- s(\".pagination\") |&gt; \n                find_elements(\"li\") |&gt;\n                as.list() |&gt; \n                lapply(\\(x) x |&gt; elem_attrs()) |&gt; \n                purrr::map(~ .x$class) |&gt; \n                unlist()\n        \n        s(paste0(\".\", gsub(\"\\\\..$\", \"\", gsub(\" \", \".\", paginacion[length(paginacion)])))) |&gt; \n                elem_click()\n        \n}\n\nconvertir_string &lt;- function(button){\n        \n        sub(\"[.]$\",\"\",gsub(\"\\\\..$\", \"\", gsub(\" \", \".\", button)))\n        \n}\n\nmi_funcion &lt;- function(listado_botones_new){\n        \n        cat(paste0(\"Aquí: \", length(listado_botones_new$iter_botones), \" a leer\\n\"))\n        \n        for (btn in 1:length(listado_botones_new$iter_botones)) {\n                \n                skip_next_loop &lt;- FALSE\n                cat(paste0(\"___Iniciando lectura del boton: \", btn, \"\\n\"))\n                tryCatch(\n                        expr = {\n                                # ss(paste0(\".\", convertir_string(listado_botones$iter_botones[btn]))) |&gt; \n                                #         as.list() |&gt; \n                                #         lapply(\\(x) x |&gt; elem_click())\n                                \n                                ss(\"button\") |&gt; #elem_filter(is_enabled) |&gt;  str()\n                                        elem_filter(has_exact_text(listado_botones_new$iter_botones[btn])) |&gt; \n                                        lapply(\\(x) x |&gt; \n                                                       elem_click())\n                                \n                                Sys.sleep(0.5)\n                                \n                                #cat(paste0(\"\", \"\\n\"))\n                                guardar_info &lt;- extraer_info_variante()\n                                \n                                cat(paste0(\"___Terminamos lectura de variantes\", \"\\n\"))\n                                info_producto[[btn]] &lt;- guardar_info\n                        },\n                        error = function(e) {\n                                # Manejar el error aquí\n                                print(paste(\"Error en la iteración\", btn, \": \", e$message))\n                                # Continuar con el bucle for\n                                skip_next_loop &lt;- TRUE\n                        }\n                )\n                if (skip_next_loop) {\n                        next\n                }\n        }\n        \n        return(info_producto)\n}\n\notra_funcion &lt;- function(consolidar_direcciones) {\n        ejecutar &lt;- list()\n        timings &lt;- list()\n        \n        for (product in 1:length(consolidar_direcciones)) {\n                tryCatch(\n                        {\n                                tictoc::tic(product)\n                                cat(\"Iniciamos scraping del producto: \", product, \"\\n\")\n                                \n                                open_url(paste0(\"https://www.cartlow.com/\", consolidar_direcciones[[product]]))\n                                \n                                Sys.sleep(1)\n                                \n                                texto_botones &lt;- s(\".cart-info.text-left\") |&gt; \n                                        find_elements(\".prd-condition.mb-3\") |&gt; \n                                        as.list() |&gt; \n                                        lapply(\\(x) x |&gt; find_elements(\".btn\") |&gt; \n                                                       lapply(\\(x) x |&gt; elem_text()))\n                                \n                                listado_botones_new &lt;- list(iter_botones = unlist(texto_botones))\n                                \n                                info_producto &lt;- vector(\"list\", length(listado_botones_new$iter_botones))\n                                guardar_info &lt;- list()\n                                \n                                ejecutar[[product]] &lt;- mi_funcion(listado_botones_new)\n                                \n                                cat(\"Terminamos scraping del producto: \", product, \"\\n\\n\")\n                                tictoc::toc(log = TRUE, quiet = TRUE)\n                                \n                        },\n                        error = function(e) {\n                                cat(\"Error occurred while processing product\", product, \"\\n\")\n                                # You can log the error, send an email, or do something else\n                                # For example, you can log the error to a file:\n                                sink(\"error.log\")\n                                cat(\"Error: \", str(e), \"\\n\")\n                                sink()\n                        }\n                )\n        }\n        \n        log.txt &lt;- tictoc::tic.log(format = TRUE)\n        log.lst &lt;- tictoc::tic.log(format = FALSE)\n        \n        tictoc::tic.clearlog()\n        \n        timings &lt;- unlist(lapply(log.lst, function(x) x$toc - x$tic))\n        \n        return(list(ejecutar = ejecutar, tiempos = timings))\n}\n\ncalcula_cantidad_variante &lt;- function(bd){\n        \n        bd$ejecutar |&gt; \n                lapply(\\(x) x |&gt; \n                               purrr::map(~ (unlist(.x$variante)))) |&gt; \n                lapply(\\(x) length(x)) |&gt; \n                unlist()\n        \n}\n\norganizar_tiempos &lt;- function(tabla, bd){\n        \n        entregar &lt;- tabla |&gt; \n                dplyr::mutate(cantidad = calcula_cantidad_variante(bd)[1:length(tabla[,1])]) \n        \n        names(entregar) &lt;- c(\"tiempos\", \"cantidad\")\n        \n        entregar\n}\n\n\nDeclaradas las funciones que vamos a usar, empecemos a ejecutar:\n\n# Abrir la página\nopen_url(url)\n\nSys.sleep(2)\n\n# Identificar cantidad de paginas\npaginas &lt;- s(\".pagination\") |&gt; \n        find_elements(\"li\") |&gt;\n        lapply(\\(x) x |&gt; \n                       elem_text())\n\npaginas &lt;- as.numeric(paginas[[length(paginas)-1]])\n\n\nconsolidar_direcciones &lt;- list()\n\n# Obtener URL de cada producto\nfor (pagina in 1:3) {\n        \n        cat(paste0(\"Estamos en la página: \", pagina, \"\\n\"))\n        \n        # Leer las URL de las imagenes\n        direcciones &lt;- leer_direcciones()\n        \n        # Agregar las URL\n        consolidar_direcciones &lt;- append(consolidar_direcciones,\n                                         direcciones)\n        \n        # Pasar a la siguiente página\n        pasar_pagina()\n        \n        cat(paste0(\"...pasando a la siguiente página\", \"\\n\"))\n        \n        Sys.sleep(1)\n        \n}\n\nPor ahora solo vamos a explorar el tiempo que tarda la lectura de datos en las primeras 3 páginas.\n\nbd_info &lt;- list()\nbd_info &lt;- otra_funcion(consolidar_direcciones)\n\nAquí deberás hacer un salto de fe y creerme que la siguiente información no la inventé, sino que son los resultados del código ejecutado de manera local. Guardé los datos en 3 archivos diferentes adjuntos. Habrás notado que los dos anteriores chunks estaban programados para no ejecutarse:\n\nbd_info &lt;- readRDS(file = \"./DBcartlowNOJS.RDS\")\nbd_info1 &lt;- readRDS(file = \"./DBcartlow1120.RDS\")\nbd_info2 &lt;- readRDS(file = \"./DBcartlow2150.RDS\")\n    \ntbl_tiempos &lt;- list(bd_info, bd_info1, bd_info2) |&gt; \n        purrr::map(~ organizar_tiempos(.x$tiempos |&gt; as.data.frame(),\n                                       .x)) |&gt; \n        dplyr::bind_rows() |&gt; \n        dplyr::mutate(media = tiempos / cantidad) |&gt; \n        dplyr::filter(cantidad != 0)\n\nRevisamos gráficamente la distribución de tiempos de extracción por la cantidad de variantes que contenga el producto:\n\ntbl_tiempos |&gt; \n        ggplot2::ggplot(ggplot2::aes(factor(cantidad), as.numeric(tiempos/60)))+\n        ggplot2::geom_boxplot()+\n        hrbrthemes::theme_ipsum()+\n        ggplot2::scale_y_continuous(breaks = c(seq(0, 90, by = 3)))+\n        ggplot2::labs(x = \"Cantidad de variantes\",\n                      y = \"Tiempo de búsqueda (min)\")\n\n\n\n\n\n\n\n\nCalculamos una variable para estimar el total:\n\ndist_variantes &lt;- tbl_tiempos |&gt; \n        dplyr::group_by(cantidad) |&gt; \n        dplyr::summarise(cuenta = dplyr::n(),\n                         media = round(mean(media), 2)) |&gt; \n        dplyr::mutate(prop = round(100 * cuenta / sum(cuenta),2))\n\ndist_variantes |&gt; \n    gt::gt()\n\n\n\n\n\n\n\ncantidad\ncuenta\nmedia\nprop\n\n\n\n\n1\n23\n97.16\n47.92\n\n\n2\n7\n46.38\n14.58\n\n\n3\n7\n55.80\n14.58\n\n\n4\n5\n50.33\n10.42\n\n\n5\n1\n62.30\n2.08\n\n\n6\n2\n36.38\n4.17\n\n\n8\n2\n109.35\n4.17\n\n\n11\n1\n212.98\n2.08\n\n\n\n\n\n\n\nLuego de revisar la cantidad de productos por página (30) y la cantidad de páginas promedio (920) podemos hacer una estimación de la cantidad de horas que podríamos tardar haciendo el ejercicio.\n\ndatos &lt;- sample(dist_variantes$cantidad,\n       size = 920*30,\n       replace = TRUE,\n       prob = dist_variantes$prop)\n\ntable(datos) |&gt; \n        data.frame() |&gt; \n        cbind(media = dist_variantes$media) |&gt; \n        dplyr::mutate(total = Freq * media * as.numeric(datos)) |&gt; \n        dplyr::summarise(total = sum(total)/(3600))\n\n     total\n1 1453.796\n\n\n\n\nConsideraciones:\n\nLeer cada página de resultados (aproximadamente entre 915 y 925) toma unos 5 segundos. Por defecto, se muestran 30 productos en cada vista.\nIdentificar el número de opciones por producto (varía entre 1 y 11 según los resultados obtenidos, aunque imagino que es posible encontrar más) toma unos 20 segundos.\nIdentificar los datos de variantes para cada producto (depende de la conexión a Internet y el procesador, estoy trabajando localmente) toma unos 110 segundos.\nDependiendo de lo que estés tratando de lograr con el scraping web, el tiempo de búsqueda puede aumentar significativamente, lo que está influenciado por la cantidad de opciones que tiene cada producto. Si tienes 3 opciones para “Condición”, 5 para “Color” y 3 para “Talla”, seguramente sabes que no son 11 iteraciones para realizar.\nCon los datos que obtuve, se podría estimar un total de 920 páginas * 30 productos por página = 1438 horas. Hay un 47% de probabilidad de que los productos tengan solo 1 variante, un 15% para 2 y un 3%.\nEs probablemente infructífero hacerlo con solo un ordenador. Debes encontrar una forma de hacerlo en paralelo.\nDebes encontrar una forma de garantizar que no se repita la información en la base de datos que uses.\nTen en cuenta que tendrás que desarrollar una idea para manejar la información cuando los productos cambian en la página.\n\n\n\n\n\nCitationBibTeX citation:@online{chiquito_valencia2024,\n  author = {Chiquito Valencia, Cristian},\n  title = {Shopify Scraping Con {R}},\n  date = {2024-12-19},\n  url = {https://cchiquitovalencia.github.io/posts/2024-12-19-cartlow_scraping/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nChiquito Valencia, Cristian. 2024. “Shopify Scraping Con\nR.” December 19, 2024. https://cchiquitovalencia.github.io/posts/2024-12-19-cartlow_scraping/."
  },
  {
    "objectID": "posts/2025-01-27-introduction_maintenance/index.html",
    "href": "posts/2025-01-27-introduction_maintenance/index.html",
    "title": "Introducción a los sistemas de mantenimiento",
    "section": "",
    "text": "El mantenimiento se define como la combinación de actividades mediante las cuales un equipo o un sistema se mantiene en, o se restablece a, un estado en el que puede realizar las funciones designadas. Es un factor importante en la calidad de los productos y puede utilizarse como una estrategia para una competencia exitosa. Las inconsistencias en la operación del equipo de producción dan por resultado una variabilidad excesiva en el producto y, en consecuencia, ocasionan una producción defectuosa. Para producir con un alto nivel de calidad, el equipo de producción debe operar dentro de las especificaciones, las cuales pueden alcanzarse mediante acciones oportunas de mantenimiento.\nUn sistema es un conjunto de componentes que trabajan de manera combinada hacia un objetivo común. El mantenimiento puede ser considerado como un sistema en un conjunto de actividades que se realizan en paralelo con los sistemas de producción.\nLos sistemas de producción generalmente se ocupan de convertir entradas o insumos, como materias primas, mano de obra y procesos, en productos que satisfacen las necesidades de los clientes. La principal salida de un sistema de producción son los productos terminados; una salida secundaria es la falla de un equipo. Esta salida secundaria genera una demanda de mantenimiento. El sistema de mantenimiento toma esto como una entrada y le agrega conocimiento experto, mano de obra y repuestos, y produce un equipo en buenas condiciones que ofrece una capacidad de producción.\nLa principal meta general de un sistema de producción es elevar al máximo las utilidades a partir de las oportunidades disponibles en el mercado, y la meta secundaria tiene que ver con los aspectos económicos y técnicos del proceso de conversión. Los sistemas de mantenienmiento también contribuyen al logro de estas metas al incrementar las utilidades y la satisfacción del cliente. Éstas se logran reduciendo al mínimo el tiempo muerto de la planta, mejorando la calidad, incrementando la productividad y entregando oportunamente los pedidos, o servicios, a los clientes. Los sistemas de producción han sido optimizados como un sistema integral y son estudiados de manera extensa en comparación con los sistemas de mantenimiento. Es claro que resulta necesario adoptar esta tendencia en el mantenimiento.\nDesde hace mucho tiempo se ha tomado en cuenta el papel de los sistemas de mantenimiento en las empresas manufactureras; sin embargo, es claro que las funciones del mantenimiento también son esenciales en las empresas de servicios como hospitales, bancos, instituciones educativas y tiendas.\nUn sistema de mantenimiento puede verse como un modelo sencillo de entrada-salida. Las entradas de dicho modelo son mano de obra, administración, herramientas, repuestos, equipo, etc., y la salida es equipo funcionando, confiable y bien configurado para lograr la operación planeada de la planta. Esto nos permite optimizar los recursos para aumentar al máximo las salidas de un sistema de mantenimiento."
  },
  {
    "objectID": "posts/2025-01-27-introduction_maintenance/index.html#introducción",
    "href": "posts/2025-01-27-introduction_maintenance/index.html#introducción",
    "title": "Introducción a los sistemas de mantenimiento",
    "section": "",
    "text": "El mantenimiento se define como la combinación de actividades mediante las cuales un equipo o un sistema se mantiene en, o se restablece a, un estado en el que puede realizar las funciones designadas. Es un factor importante en la calidad de los productos y puede utilizarse como una estrategia para una competencia exitosa. Las inconsistencias en la operación del equipo de producción dan por resultado una variabilidad excesiva en el producto y, en consecuencia, ocasionan una producción defectuosa. Para producir con un alto nivel de calidad, el equipo de producción debe operar dentro de las especificaciones, las cuales pueden alcanzarse mediante acciones oportunas de mantenimiento.\nUn sistema es un conjunto de componentes que trabajan de manera combinada hacia un objetivo común. El mantenimiento puede ser considerado como un sistema en un conjunto de actividades que se realizan en paralelo con los sistemas de producción.\nLos sistemas de producción generalmente se ocupan de convertir entradas o insumos, como materias primas, mano de obra y procesos, en productos que satisfacen las necesidades de los clientes. La principal salida de un sistema de producción son los productos terminados; una salida secundaria es la falla de un equipo. Esta salida secundaria genera una demanda de mantenimiento. El sistema de mantenimiento toma esto como una entrada y le agrega conocimiento experto, mano de obra y repuestos, y produce un equipo en buenas condiciones que ofrece una capacidad de producción.\nLa principal meta general de un sistema de producción es elevar al máximo las utilidades a partir de las oportunidades disponibles en el mercado, y la meta secundaria tiene que ver con los aspectos económicos y técnicos del proceso de conversión. Los sistemas de mantenienmiento también contribuyen al logro de estas metas al incrementar las utilidades y la satisfacción del cliente. Éstas se logran reduciendo al mínimo el tiempo muerto de la planta, mejorando la calidad, incrementando la productividad y entregando oportunamente los pedidos, o servicios, a los clientes. Los sistemas de producción han sido optimizados como un sistema integral y son estudiados de manera extensa en comparación con los sistemas de mantenimiento. Es claro que resulta necesario adoptar esta tendencia en el mantenimiento.\nDesde hace mucho tiempo se ha tomado en cuenta el papel de los sistemas de mantenimiento en las empresas manufactureras; sin embargo, es claro que las funciones del mantenimiento también son esenciales en las empresas de servicios como hospitales, bancos, instituciones educativas y tiendas.\nUn sistema de mantenimiento puede verse como un modelo sencillo de entrada-salida. Las entradas de dicho modelo son mano de obra, administración, herramientas, repuestos, equipo, etc., y la salida es equipo funcionando, confiable y bien configurado para lograr la operación planeada de la planta. Esto nos permite optimizar los recursos para aumentar al máximo las salidas de un sistema de mantenimiento."
  },
  {
    "objectID": "posts/2025-01-27-introduction_maintenance/index.html#actividades-de-planeación-del-mantenimiento",
    "href": "posts/2025-01-27-introduction_maintenance/index.html#actividades-de-planeación-del-mantenimiento",
    "title": "Introducción a los sistemas de mantenimiento",
    "section": "Actividades de planeación del mantenimiento",
    "text": "Actividades de planeación del mantenimiento\nGeneralmente se incluyen las siguientes:\n\nFilosofía del mantenimiento\nLa filosofía del mantenimiento de una planta es básicamente la de tener un nivel mínimo de personal de mantenimiento que sea consistente con la optimización de la producción y la disponibilidad de la planta sin que se comprometa la seguridad. Para lograr esta filosofía, las siguientes estrategias pueden desempeñar un papel eficaz si se aplican en la combinación y forma correctas:\n\n\n\n\n\n\nFigura 1: Estrategias de mantenimiento.\n\n\n\n\nMantenimiento correctivo o por fallas\nEste tipo de mantenimiento sólo se realiza cuando el equipo es incapaz de seguir operando. No hay elemento de planeación para este tipo de mantenimiento. Éste es el caso que se presenta cuando el costo adicional de otros tipos de mantenimiento no puede justificarse. Este tipo de estrategia a veces se conoce como estrategia de operación-hasta-que-falle. Se aplica principalmente en los componentes electrónicos.\n\n\nMantenimiento preventivo con base en el tiempo o en el uso\nEl mantenimiento preventivo es cualquier mantenimiento planeado que se lleva a cabo para hacer frente a fallas potenciales. Puede realizarse con base en el uso o las condiciones del equipo. El mantenimiento preventivo con base en el uso o en el tiempo se lleva a cabo de acuerdo con las horas de funcionamiento o un calendario establecido. Requiere un alto nivel de planeación. Las rutinas específicas que se realizan son conocidas, así como sus frecuencias. En la determinación de la frecuencia generalmente se necesitan conocimientos acerca de la distribución de las fallas o la confiabilidad del equipo. Aquí lo resalto porque habrá un post sobre cómo optimizar el plan de mantenimiento teniendo en cuenta estas variables.\n\n\nMantenimiento preventivo con base en las condiciones\nEste mantenimiento preventivo se lleva a cabo con base en las condiciones conocidas del equipo. La condición del equipo se determina vigilando los parámetros clave del equipo cuyos valores se ven afectados por la condición de éste. A esta estrategia también se le conoce como mantenimiento predictivo.\n\n\nMantenimiento de oportunidad\nEste tipo de mantenimiento se lleva a cabo cuando surge la oportunidad. Tales oporturnidades pueden presentarse durante los periodos de paros generales programados de un sistema en particular, y pueden utilizarse para efectuar tareas conocidas de mantenimiento.\n\n\nDetección de fallas\nLa detección de fallas es un acto o inspección que se lleva a cabo para evaluar el nivel de presencia inicial de fallas. Un ejemplo de detección de fallas es el de la verificación de la llanta de repuesto de un automóvil antes de emprender un viaje largo.\n\n\nModificación del diseño\nLa modificación del diseño se lleva a cabo para hacer que un equipo alcance una condición que sea aceptable en ese momento. Esta estrategia implica mejoras y, ocasionalmente, expansión de fabricación y capacidad. La modificación del diseño por lo general requiere una coordinación con la función de ingeniería y otros departamentos dentro de la organización.\n\n\nReparación general\nLa reparación general es un examen completo y el restablecimiento de un equipo o sus componentes principales a una condición aceptable. Ésta es generalmente una tarea de gran envergadura.\n\n\nReemplazo\nEsta estrategia implica reemplazar el equipo en lugar de darle mantenimiento. Puede ser un reemplazo planeado o un reemplazo ante una falla.\nCada una de estas estrategias de mantenimiento tiene una función en la operación de la planta. Es la mezcla óptima de estas estrategias la que da por resultado la filosofía de mantenimiento más eficaz. El tamaño de la planta y su nivel de operación planeado, junto con la estrategia de mantenimiento aplicable, pueden ayudar a estimar la carga de mantenimiento o las salidas deseadas de mantenimiento. La Figura 1 resume las estrategias.\n\n\n\nPronóstico de la carga de mantenimiento\nEste pronóstico es el proceso mediante el cual se predice la carga de mantenimiento. La carga de mantenimiento en una platnta dada varía aleatoriamente y, entre otros factores, puede ser una función de la edad del equipo, el nivel de su uso, la calidad del mantenimiento, factores climáticos y las destrezas de los trabajadores de mantenimiento. El pronóstico de la carga de mantenimiento es esencial para alcanzar un nivel deseado de eficacia y uso de los recursos, y sin éste, muchas de las funciones de mantenimiento no pueden realizarse bien.\n\n\nPlaneación de la capacidad de mantenimiento\nLa planeación de la capacidad de mantenimiento determina los recursos necesarios para satisfacer la demanda de trabajos de mantenimiento. Estos recursos incluyen: la mano de obra, materiales, repuestos, equipo y herramientas. Entre los aspectos fundamentales de la capacidad de mantenimiento se incluyen la cantidad de trabajadores de mantenimiento y sus habilidades, las herramientas requeridas para el mantenimiento, etc.\nDebido a que la carga de mantenimiento es una variable aleatoria, no se puede determinar el número exacto de los diversos tipos de técnicos. Por lo tanto, sin pronósticos razonablemente exactos de demanda futura de trabajos de mantenimiento, no sería posible realizar una planeación adecuada de la capacidad a largo plazo.\nPara utilizar mejor sus recursos de mano de obra, las organizaciones tienden a emplear una menor cantidad de técnicos de la que han anticipado, lo cual probablemente dará por resultado una acumulación de trabajos de mantenimiento pendientes. Éstos pueden completarse haciendo que los trabajadores existentes laboren tiempo extra o buscando ayuda exterior de contratistas. Los trabajos pendientes también pueden desahogarse cuando la carga de mantenimiento es menor que la capacidad. Ésta es realmente la principal razón de mantener una reserva de trabajos pendientes. La estimación a largo plazo es una de las áreas críticas de la planeación de la capacidad de mantenimiento, pero que aún no ha sido bien desarrollada.\n\n\nOrganización del mantenimiento\nDependiendo de la carga de mantenimiento, el tamaño de la planta, las destrezas de los trabajadores, etc., el mantenimiento se puede organizar por departamentos, por área o en forma centralizada. Cada tipo de organización tiene sus ventajas y desventajas. En las organizaciones grandes, la descentralización de la función de mantenimiento puede producir un timpo de respuesta más rápido y lograr que los trabajadores se familiaricen más con los problemas de una sección particular de la planta. Sin embargo, la creación de un número de pequeñas unidades tiende a reducir la flexibilidad del sistema de mantenimiento como un todo.\nLa gama de habilidades disponibles se reduce y el uso de la mano de obra es generalmente menor que en una unidad de mantenimiento centralizada. En algunos casos, puede implantarse una solución de compromiso, denominada sistema de cascada. Este sistema permite que las unidades de mantenimiento del área de producción se enlacen con la unidad de mantenimiento central.\n\n\nProgramación del mantenimiento\nLa programación del mantenimiento es el proceso de asignación de recursos y personal para los trabajos que tienen que realizarse en ciertos momentos. Es necesario asegurar que los trabajadores, las piezas y los materiales requeridos estén disponibles antes de poder programar una tarea de mantenimiento. El equipo crítico de una planta se refiere al equipo cuya falla detendrá el proceso de producción o pondrá en riesgo vidas humanas y la seguridad. El trabajo de mantenimiento para estos equipos se maneja bajo prioridades y es atendido antes de emprender cualquier otro trabajo. La ocurrencia de tales trabajos no puede predecirse con certeza, de modo que los programas para el mantenimiento planeado en estos casos tienen que ser revisados.\nEn la eficacia de un sistema de mantenimiento influye mucho el programa de mantenimiento que se haya desarrollado y su capacidad de adaptarse a los cambios. Un alto nivel de eficacia en el programa de mantenimiento es señal de un alto nivel de eficacia en el propio mantenimiento."
  },
  {
    "objectID": "posts/2025-01-28-maintenance_management/index.html",
    "href": "posts/2025-01-28-maintenance_management/index.html",
    "title": "Gestión de sistemas de mantenimiento",
    "section": "",
    "text": "Usar un software de mantenimiento para la gestión de flotas es, sin lugar a dudas, una de las mejores decisiones estratégicas que se pueden asumir en coherencia con la gerencia.\nCualquier software de gestión de mantenimiento debe ser una herramienta valiosa para las empresas que buscan optimizar sus operaciones de mantenimiento. Uno de los beneficios más importantes es la mejora en la planeación y programación. Debes ser capaz de planificar y programar los mantenimientos con anticipación, evitando retrasos y reduciendo los tiempos de inactividad de los vehículos. Esto es especialmente importante en industrias como la logística y el transporte, donde la disponibilidad de los vehículos es crucial para el éxito de la empresa. Además, la planeación y programación efectiva también puede ayudar a reducir costos y mejorar la eficiencia de los procesos.\nOtro beneficio importante es la mejora en la toma de decisiones. El software de gestión de mantenimiento debe proporcionar información detallada sobre los activos y los procesos para que los gerentes puedan tomar decisiones informadas sobre cómo manejar sus activos. Esto puede incluir decisiones sobre cuando reemplazar un componente, cómo asignar recursos y cómo optimizar los procesos. Con esta información, los gerentes pueden identificar oportunidades para reducir costos y mejorar la eficiencia, lo que puede tener un impacto significativo en el éxito de la empresa.\nLa reducción de costos es otro beneficio importante del software de gestión de mantenimiento. Al monitorear el progreso de los mantenimientos y los costos asociados, las empresas pueden identificar oportunidades para reducir gastos y optimizar sus procesos de mantenimiento. Esto puede incluir la identificación de componentes que no son esenciales para el funcionamiento del vehículo, la optimización de los procesos de mantenimiento y la reducción de los costos de repuestos. Además, la reducción de costos también puede ayudar a mejorar la eficiencia y la productividad de los empleados, lo que puede tener un impacto positivo en la cultura de la empresa."
  },
  {
    "objectID": "posts/2025-01-28-maintenance_management/index.html#restricción-de-programación-de-mantenimiento-según-calendario",
    "href": "posts/2025-01-28-maintenance_management/index.html#restricción-de-programación-de-mantenimiento-según-calendario",
    "title": "Gestión de sistemas de mantenimiento",
    "section": "Restricción de programación de mantenimiento según calendario",
    "text": "Restricción de programación de mantenimiento según calendario\nLa Eq.3 controla que el mantenimiento se realice al menos después de \\(U_i\\) periodos de tiempo desde el último mantenimiento. Esta restricción establece que para la suma de \\(y_{i,t}\\) dentro de todos los periodos de tamaño \\(U_i + 1\\), al menos uno de los periodos tiene que tener un evento de mantenimiento planeado con \\(y_{i,t} = 1\\), según el requisito de mantenimiento basado en calendario. Para visualizar las restricciones, se muestra un ejemplo para una unidad \\(j\\) con \\(U_j = 3\\) y \\(H = 8\\).\n\n\n\n\n\n\nFigure 1: Ejemplo de restricción de programación de mantenimiento según calendario."
  },
  {
    "objectID": "posts/2025-01-28-maintenance_management/index.html#restricción-de-programación-de-mantenimiento-según-uso",
    "href": "posts/2025-01-28-maintenance_management/index.html#restricción-de-programación-de-mantenimiento-según-uso",
    "title": "Gestión de sistemas de mantenimiento",
    "section": "Restricción de programación de mantenimiento según uso",
    "text": "Restricción de programación de mantenimiento según uso\nLa restricción Eq.4 se compone de la suma del tiempo de funcionamiento, operación o funcionamiento,\n\\[\n\\sum_{j=t}^{t+u}x_{i,t}, \\quad ∀i, t, u ∈ \\{0,1,...,H-t\\},\n\\] y la suma de eventos de mantenimiento\n\\[\n\\sum_{j=t}^{t+u}y_{i,t}, \\quad ∀i, t, u ∈ \\{0,1,...,H-t\\}\n\\]\nsobre todos los periodos de tiempo continuos de diferentes tamaños. Para cada evento de mantenimiento en el período, se agregan \\(T_i\\) unidades de tiempo dentro del área aceptable de tiempo de funcionamiento. Por lo tanto, la restricción se escribe como: \\[\n\\sum_{j=t}^{t+u}x_{i,t}\\le T_i+T_i \\sum_{j=t}^{t+u}y_{i,t}, \\quad ∀i, t, u ∈ \\{0,1,...,H-t\\},\n\\]\nLos periodos desde \\(t\\) hasta \\(t + u\\) se visualizan en la Figura 2 para una unidad y \\(H = 6\\).\n\n\n\n\n\n\nFigure 2: Ejemplo de restricción de programación de mantenimiento según operación.\n\n\n\nLas ecuaciones de la restricción Eq.4 escritas son:\n\\[\nx_{i,1} \\le T_i+T_iy_{i,1}\n\\]\n\\[\nx_{i,1} + x_{i,2}\\le T_i+T_iy_{i,1} + T_iy_{i,2}\n\\]\n\\[\nx_{i,1} +x_{i,2} +x_{i,3}\\le T_i+T_iy_{i,1} +T_iy_{i,2}+T_iy_{i,3}\n\\]\n\\[\n⠇\n\\]\n\\[\nx_{i,1} +x_{i,2} +...+x_{i,H}\\le T_i+T_iy_{i,1} +T_iy_{i,2}+...+T_iy_{i,H}\n\\]\n\n\n\n$$\n\n\n\n\n$$\n\n\n\n\\[\nx_{i,2} \\le T_i+T_iy_{i,2}\n\\]\n\\[\nx_{i,2} + x_{i,3}\\le T_i+T_iy_{i,2} + T_iy_{i,3}\n\\]\n\\[\nx_{i,2} +x_{i,3} +x_{i,4}\\le T_i+T_iy_{i,2} +T_iy_{i,3}+T_iy_{i,4}\n\\]\n\\[\n⠇\n\\]\n\\[\nx_{i,2} +x_{i,3} +...+x_{i,H}\\le T_i+T_iy_{i,2} +T_iy_{i,3}+...+T_iy_{i,H}\n\\]\n\\[\n⠇\n\\]\n\\[\nx_{i,H-1} \\le T_i+T_iy_{i,H-1}\n\\]\n\\[\nx_{i,H-1} + x_{i,H}\\le T_i+T_iy_{i,H-1} + T_iy_{i,H}\n\\]\n\n\n\n$$\n\n\n\n\n$$\n\n\n\n\\[\nx_{i,H} \\le T_i+T_iy_{i,H}\n\\]\npara cada unidad \\(i\\)."
  },
  {
    "objectID": "posts/2025-01-28-maintenance_management/index.html#ejemplo",
    "href": "posts/2025-01-28-maintenance_management/index.html#ejemplo",
    "title": "Gestión de sistemas de mantenimiento",
    "section": "Ejemplo",
    "text": "Ejemplo\nUn pequeño ejemplo del modelo descrito, con valores de parámetros de entrada listados en la Tabla No.1, se resuelve:\n\nTabla No.1. Valores de entrada para un pequeño ejemplo.\n\n\nParámetro\nValor\n\n\n\n\n\\(m\\)\n2\n\n\n\\(H\\)\n8\n\n\n\\(D\\)\n480\n\n\n\\(U_i\\)\nc(3, 3)\n\n\n\\(T_i\\)\nc(90, 90)\n\n\n\nEn el siguiente link [] podrás encontrar una app en línea que te permitirá ver la solución.\nEl número total de horas de operación para la solución es:\n\\[\n\\sum_{i=1}^{m}\\sum_{t=1}^{H}x_{i,t}^{*}=D,\n\\]\nlas horas máximas de funcionamiento y los periodos de tiempo entre mantenimientos son iguales a \\(T_i\\) y \\(U_i\\) ,respectivamente, y el número de eventos de mantenimiento es:\n\\[\ny_{tot}^{*}=\\sum_{i=1}^{m}\\sum_{t=1}^{H}y_{i,t}^{*}=4\n\\]\nEs claro que el problema planteado aquí es en extremo básico y seguramente no se ajusta a cualquiera que sea tu necesidad. Pero, en mi defensa, mi intención es mostrar que no es imposible crear un servicio en la nube para lograr optimizar los recursos que se encuentran bajo tu dominio."
  },
  {
    "objectID": "posts/2025-01-28-maintenance_management/index.html#proyecto-optimización-de-mantenimiento",
    "href": "posts/2025-01-28-maintenance_management/index.html#proyecto-optimización-de-mantenimiento",
    "title": "Gestión de sistemas de mantenimiento",
    "section": "Proyecto optimización de mantenimiento",
    "text": "Proyecto optimización de mantenimiento\nCrearemos una app que proyecte el calendario de mantenimiento óptimo para una flota de \\(m\\) unidades y \\(H\\) periodos de tiempo. El mantenimiento se refiere a cuándo debe ocurrir y cuántas horas de funcionamiento se planean para cada unidad en cada período de tiempo. Las unidades \\(i\\) y los periodos de tiempo \\(t\\) se representan mediante conjuntos.\n\\[i ∈ \\{1,2,...,m\\}\\]\ny\n\\[\nt ∈ \\{1,2,...,H\\}\n\\]\nEn primer lugar, se utilizan dos variables para definir un calendario. Una variable binaria que almacena el mantenimiento planeado.\n\\[\ny_{i,t}=\\cases{1, \\text{si se realiza mantenimiento de la unidad i en el tiempo t}\\\\0, \\text{de lo contrario}}\n\\]\nY una variable \\(x_{i,t} ≥ 0\\) que representa el número de horas de funcionamiento para la unidad \\(i\\) en el período de tiempo \\(t\\).\nPara encontrar un calendario de mantenimiento óptimo para una flota, se escribe un MILP (Programación Lineal Entera Mixta) donde el objetivo es minimizar el número de ocasiones de mantenimiento planeadas, es decir, minimizar la suma de \\(y_{i,t}\\) sobre cada unidad \\(i\\) y período de tiempo \\(t\\). Para el programa principal, las restricciones incluidas son una demanda de tiempo de funcionamiento para la flota completa de \\(D\\) horas y requisitos de mantenimiento después de al menos \\(U_i\\) tiempo periodos o \\(T_i\\) horas de funcionamiento desde el último mantenimiento, lo que sea lo primero. Esto se puede escribir como:\n\\[\nmin \\sum_{i=1}^{m}\\sum_{t=1}^{H}y_{i,t}\n\\]\n\\[\n\\text{sujeto a } \\sum_{i=1}^{m}\\sum_{t=1}^{H}x_{i,t}\\ge D,\n\\]\n\\[\n\\sum_{j=\\tau}^{\\tau+U_i}y_{i,t} \\ge 1, \\quad ∀i, \\tau ∈ \\{1,2,...,H-U_i\\},\n\\]\n\\[\n\\sum_{j=t}^{t+u}x_{i,t}\\le T_i+T_i \\sum_{j=t}^{t+u}y_{i,t}, \\quad ∀i, t, u ∈ \\{0,1,...,H-t\\},\n\\]\n\\[\nx_{i,t} + x^{max}y_{i,t} \\le x^{max}, \\quad ∀i, t,\n\\]\n\\[\nx_{i,t} \\ge 0, \\quad ∀i, t,\n\\]\n\\[\ny_{i,t} ∈ \\{0,1\\}, \\quad ∀i,t,\n\\]\nDonde Eq.2 garantiza que se cumple la demanda de horas de funcionamiento y Eq.3 y Eq.4 manejan las restricciones de mantenimiento. La restricción Eq.5 garantiza que no se planean operaciones para una unidad que está en mantenimiento, es decir, fuerza la deducción:\n\\[\ny_{i,t}=1 ⟶ x_{i,t}=0, \\quad ∀i, t.\n\\]\nEl parámetro \\(x^{max}\\) es el límite superior de \\(x_{i,t}\\), que se establece en \\(744\\) horas, ya que ese es el máximo número de horas que un mes puede tener."
  },
  {
    "objectID": "posts/2025-01-27-start_EC2_instance/index.html",
    "href": "posts/2025-01-27-start_EC2_instance/index.html",
    "title": "Crear Shiny Server en AWS",
    "section": "",
    "text": "En este post veremos cómo instalar y poner en funcionamiento un Shiny Server en una instancia EC2 de AWS. Este es un primer paso para lograr subir a producción una Shiny app."
  },
  {
    "objectID": "posts/2025-01-27-start_EC2_instance/index.html#acceder-a-la-consola",
    "href": "posts/2025-01-27-start_EC2_instance/index.html#acceder-a-la-consola",
    "title": "Crear Shiny Server en AWS",
    "section": "Acceder a la consola",
    "text": "Acceder a la consola\nLo primero que tienes que hacer es crear una cuenta en AWS. Los pasos no son difícles, te lo puedo asegurar. Así que iniciamos en la pantalla principal que nos muestra inmediatamente luego de creada.\n\n\n\n\n\n\nFigura 1: Pantalla inicial consola AWS\n\n\n\nPosiblemente las únicas diferencias que podrían tener con esta imágen son: el nombre de usuario cchiquitov y la Availability Zone (AZ) que automáticamente se creó en Ohio, useast-2."
  },
  {
    "objectID": "posts/2025-01-27-start_EC2_instance/index.html#crear-servidor-en-ec2-elastic-compute-cloud",
    "href": "posts/2025-01-27-start_EC2_instance/index.html#crear-servidor-en-ec2-elastic-compute-cloud",
    "title": "Crear Shiny Server en AWS",
    "section": "Crear servidor en EC2 (Elastic Compute Cloud)",
    "text": "Crear servidor en EC2 (Elastic Compute Cloud)\nEn el campo Search podemos buscar EC2, o aprovechamos que nos aparece la opción en “Recently visited”\nEs claro que acabo de crear la cuenta porque en los Recursos solamente tenemos un Security group.\n\n\n\n\n\n\nFigura 2: Dashboard de recursos\n\n\n\nIngresamos a Instances:\n\n\n\n\n\n\nFigura 3: Menú desplegable instancias\n\n\n\ny Launch Instances\n\n\n\n\n\n\nFigura 4: Lanzar instancia.\n\n\n\nTe encontrarás en la siguiente pantalla, a ti te aparecerán las opciones expandidas:\n\n\n\n\n\n\nFigura 5: Configuración de instancia\n\n\n\nAquí ya nombré a mi instancia “My first Web Server”, muy astuto.\nPara la AMI (Amazon Machine Image) elijo Ubuntu:\n\n\n\n\n\n\nFigura 6: Configuración del software (sistema operativo, servidor de aplicaciones y aplicaciones)\n\n\n\nPara el tipo de instancia voy con la que me da el Free Tier:\n\n\n\n\n\n\nFigura 7: Tipo de instancia\n\n\n\nContiene una CPU con sólo 1 núcleo, sólo 1 GB de RAM y una conexión a Internet aceptable.\nAhora para lograr una conexión segura debemos crear un key pair.\n\n\n\n\n\n\nFigura 8: Elección de key pair.\n\n\n\nUn key pair, formado por una llave pública y una llave privada, es un conjunto de credenciales de seguridad que utiliza para demostrar tu identidad al conectarse a una instancia de Amazon EC2. En el caso de las instancias de Linux, la llave privada te permite conectarse a tu instancia mediante SSH de forma segura. En el caso de las instancias de Windows, la llave privada se requiere para descifrar la contraseña de administrador, que luego se utiliza para conectarse a la instancia. Amazon EC2 almacena la llave pública en tu instancia, y tu almacenas la llave privada.\n\n\n\n\n\n\nFigura 9: Esquema funcionamiento key pair.\n\n\n\nEs muy importante que guardes tu llave privada en un lugar seguro, ya que cualquiera que posea tu llave privada puede conectarse a tus instancias que utilizan el key pair.\nEntonces, creo mi key pair, para poder seleccionarlo dentro de la lista desplegable, le llamaré “mi-key-pair-useast2”\n\n\n\n\n\n\nFigura 10: Crear un Key Pair\n\n\n\nCuando lo creas, inmediatamente descargas un archivo, la llave privada, que para mi caso es:\n\n\n\n\n\n\nFigura 11: Archivo con llave privada\n\n\n\nContinuamos con la configuración de las redes, donde realmente dejamos lo que viene por defecto.\n\n\n\n\n\n\nFigura 12: Redes de la instancia.\n\n\n\nPara el almacenamiento podríamos cambiar hasta 30Gb sin que debamos pagar (en el primer año) pero lo dejaré por defecto.\n\n\n\n\n\n\nFigura 13: Configura almacenamiento de instancia.\n\n\n\nFinalmente tenemos una instancia así:\n\n\n\n\n\n\nFigura 14: Parámetros de instancia.\n\n\n\ny le damos en “Launch instance”.\nEsperamos pocos minutos mientras surte el proceso:\n\n\n\n\n\n\nFigura 15: Mensaje de espera por lanzamiento.\n\n\n\nAparecerá:\n\n\n\n\n\n\nFigura 16: Creación exitosa de instancia.\n\n\n\nNos devolvemos a Instances para ver qué tenemos ahora:\n\n\n\n\n\n\nFigura 17: Dashboard instancias desactualizado.\n\n\n\nParece que no tuvieramos instancia alguna creada, pero en realidad debemos dar click en\n\n\n\n\n\n\nFigura 18: Actualizar.\n\n\n\npara actualizar el dashboard.\nAhora sí tenemos nuestra instancia llamada “My first Web Server” creada y corriendo.\n\n\n\n\n\n\nFigura 19: Dashboard instancias actualizado."
  },
  {
    "objectID": "posts/2025-01-27-start_EC2_instance/index.html#acceder-al-servidor",
    "href": "posts/2025-01-27-start_EC2_instance/index.html#acceder-al-servidor",
    "title": "Crear Shiny Server en AWS",
    "section": "Acceder al servidor",
    "text": "Acceder al servidor\nDebemos cambiar nuestro directorio de trabajo (working directory) hacia donde tenemos el archivo .pem, yo lo he dejado en Downloads. Así que en la Terminal:\ncd Downloads/\n-rw-rw-r--  1 cchvcpcj cchvcpcj       1678 Jan 22 13:33  mi-key-pair-useast2.pem\nY vamos a cambiar los permisos de este archivo, siendo una llave privada pues debería ser privada realmente:\nchmod 400 mi-key-pair-useast2.pem\n-r--------  1 cchvcpcj cchvcpcj       1678 Jan 22 13:33  mi-key-pair-useast2.pem\nAhora debes ir a la consola de EC2 para revisar la IPv4 de tu instancia, con esto completaremos el siguiente comando para acceder al servidor.\n\n\n\n\n\n\nFigura 20: IPv4 pública de la instancia.\n\n\n\nssh -i \"mi-key-pair-useast2.pem\" ubuntu@ec2-18-117-232-180.us-east-2.compute.amazonaws.com\nThe authenticity of host 'ec2-18-117-232-180.us-east-2.compute.amazonaws.com (18.117.232.180)' can't be established.\nECDSA key fingerprint is SHA256:N55CqCIT1Yyi5tpAY2UDj2Q/1r4aOS4+aTUgXTWfDK8.\nAre you sure you want to continue connecting (yes/no/[fingerprint])?\nDi “yes” y lo lograste. Estas dentro de tu instancia.\nWarning: Permanently added 'ec2-18-117-232-180.us-east-2.compute.amazonaws.com,18.117.232.180' (ECDSA) to the list of known hosts.\nWelcome to Ubuntu 24.04.1 LTS (GNU/Linux 6.8.0-1021-aws x86_64)\n\n * Documentation:  https://help.ubuntu.com\n * Management:     https://landscape.canonical.com\n * Support:        https://ubuntu.com/pro\n\n System information as of Wed Jan 22 19:38:46 UTC 2025\n\n  System load:  0.0               Processes:             106\n  Usage of /:   24.9% of 6.71GB   Users logged in:       0\n  Memory usage: 20%               IPv4 address for enX0: 172.31.5.157\n  Swap usage:   0%\n\n * Ubuntu Pro delivers the most comprehensive open source security and\n   compliance features.\n\n   https://ubuntu.com/aws/pro\n\nExpanded Security Maintenance for Applications is not enabled.\n\n0 updates can be applied immediately.\n\nEnable ESM Apps to receive additional future security updates.\nSee https://ubuntu.com/esm or run: sudo pro status\n\n\nThe list of available updates is more than a week old.\nTo check for new updates run: sudo apt update\n\n\nThe programs included with the Ubuntu system are free software;\nthe exact distribution terms for each program are described in the\nindividual files in /usr/share/doc/*/copyright.\n\nUbuntu comes with ABSOLUTELY NO WARRANTY, to the extent permitted by\napplicable law.\n\nTo run a command as administrator (user \"root\"), use \"sudo &lt;command&gt;\".\nSee \"man sudo_root\" for details.\nPara desconectar puedes usar “exit”."
  },
  {
    "objectID": "posts/2025-01-27-start_EC2_instance/index.html#instalar-r",
    "href": "posts/2025-01-27-start_EC2_instance/index.html#instalar-r",
    "title": "Crear Shiny Server en AWS",
    "section": "Instalar R",
    "text": "Instalar R\nRecuerda que aquí hemos creado la instancia de Ubuntu, por lo que de ahora en adelante aplican comandos para este sistema operativo.\nAhora, antes de R debemos instalar algunas dependencias:\n# Update commands\nsudo apt update\nsudo apt-get update -y\nsudo apt-get dist-upgrade -y\n# Install some system libraries\n$ sudo apt-get -y install \\\nnginx \\\n    gdebi-core \\\n    apache2-utils \\\n    pandoc \\\n    libssl-dev \\\n    libcurl4-gnutls-dev \\\n    libcairo2-dev \\\n    libgsl0-dev \\\n    libgdal-dev \\\n    libgeos-dev \\\n    libproj-dev \\\n    libxml2-dev \\\n    libxt-dev \\\n    libv8-dev \\\n    libhdf5-dev \\\n    git\nPuedes obtener una explicación de qué hace cada expresión:\n\n\n\n\n\n\nFigura 21: Detalle de expresión.\n\n\n\nAhora sí vamos con los comandos para R:\n# Update indices\nsudo apt update -qq\n# Install two helper packages \nsudo apt install --no-install-recommends software-properties-common dirmngr\n# Add the signing key (by Michael Rutter) for these repositories\n# To verify key, run gpg --show-keys /etc/apt/trusted.gpg.d/cran_ubuntu_key.asc \n# Fingerprint: 298A3A825C0D65DFD57CBB651716619E084DAB9\nwget -qO- https://cloud.r-project.org/bin/linux/ubuntu/marutter_pubkey.asc | sudo tee -a /etc/apt/trusted.gpg.d/cran_ubuntu_key.asc\n# Add the R 4.0 repo from CRAN -- adjust 'focal' to 'groovy' or 'bionic' as needed\nsudo add-apt-repository \"deb https://cloud.r-project.org/bin/linux/ubuntu $(lsb_release -cs)-cran40/\"\n# Install recommended packages\nsudo apt install r-base r-base-dev\nRevisamos la versión instalada con:\nR --version\nY deberías obtener algo parecido a esto (es muy probable que exista una versión superior para cuando leas esto).\nR version 4.4.2 (2024-10-31) -- \"Pile of Leaves\"\nCopyright (C) 2024 The R Foundation for Statistical Computing\nPlatform: x86_64-pc-linux-gnu\n\nR is free software and comes with ABSOLUTELY NO WARRANTY.\nYou are welcome to redistribute it under the terms of the\nGNU General Public License versions 2 or 3.\nFor more information about these matters see\nhttps://www.gnu.org/licenses/."
  },
  {
    "objectID": "posts/2025-01-27-start_EC2_instance/index.html#instalar-shiny-server",
    "href": "posts/2025-01-27-start_EC2_instance/index.html#instalar-shiny-server",
    "title": "Crear Shiny Server en AWS",
    "section": "Instalar Shiny Server",
    "text": "Instalar Shiny Server\nDespués de instalar R, pero antes de instalar Shiny Server, debes instalar Shiny. Puedes hacerlo de dos formas:\nLa primera es ejecutando R para abrirlo directamente en la terminal.\nsudo R\n&gt; install.packages(\"shiny\")\nLa otra es “por debajo”:\nsudo su - -c \"R -e \\\"install.packages('shiny', repos='https://cran.rstudio.com/')\\\"\"\nLa instalación de Shiny puede tomar un poco de tiempo en la instancia t2.micro por la cantidad de recursos que establecimos.\nYa podemos instalar Shiny Server:\n# Install Shiny Server\nsudo apt-get install gdebi-core\nwget https://download3.rstudio.org/ubuntu-18.04/x86_64/shiny-server-1.5.22.1017-amd64.deb\nsudo gdebi shiny-server-1.5.22.1017-amd64.deb\nVerificamos la instalación:\nsudo systemctl status shiny-server\n\n\n\n\n\n\nFigura 22: Shiny Server ejecutando.\n\n\n\nPor defecto Shiny Server viene con una Shiny app ejecutandose en tu servidor."
  },
  {
    "objectID": "posts/2025-01-27-start_EC2_instance/index.html#acceder-a-la-shiny-app-por-defecto",
    "href": "posts/2025-01-27-start_EC2_instance/index.html#acceder-a-la-shiny-app-por-defecto",
    "title": "Crear Shiny Server en AWS",
    "section": "Acceder a la Shiny app por defecto",
    "text": "Acceder a la Shiny app por defecto\nCada vez que reinicias la instancia, a no ser que hayas pasado por una Elastic IP, tu IPv4 va a cambiar. Por ahora realizamos de nuevo el ejercicio de arriba para obtener la IP actual.\nPara este momento es:\n\n\n\n\n\n\nFigura 23: IP actual.\n\n\n\ny para acceder a la app debemos ingresar &lt;IP:3838&gt;. Este puerto 3838 corresponde al servicio de Shiny Server. Para mi caso es “3.145.162.7:3838”.\nOjo, si ingresas “https://3.145.162.7:3838” no te va a funcionar. Aquí hay dos problemas por resolver. Uno de ellos es el https, no hemos hecho nada aún. El otro es que debemos habilitar la conexión con un security group:\nSeleccionamos nuestra instancia, vamos a la pestaña Security, y finalmente al link de Security groups:\n\n\n\n\n\n\nFigura 24: Entrar a editar Security group.\n\n\n\nY editamos (Edit inbound rules):\n\n\n\n\n\n\nFigura 25: Editar inbound.\n\n\n\nAñadimos regla:\n\n\n\n\n\n\nFigura 26: Añade regla.\n\n\n\n\nType = Custom TCP\nPort range = 3838\nSource = Custom 0.0.0.0/0\n\n\n\n\n\n\n\nFigura 27: Revisión reglas.\n\n\n\nGuardamos regla:\n\n\n\n\n\n\nFigura 28: Guardar regla.\n\n\n\nSi ves un mensaje emergente como el siguiente, estas listo para ingresar de nuevo &lt;IP:3838&gt;\n\n\n\n\n\n\nFigura 29: Creación exitosa de regla.\n\n\n\nLo que estábamos esperando:\n\n\n\n\n\n\nFigura 30: Shiny app por defecto accesible desde IPv4.\n\n\n\nHasta aquí hemos hecho lo básico para acceder a una Shiny app desde cualquier dispositivo.\nPuedes intentarlo desde tu celular, pues acabamos de dejar expuesto el puerto 3838 donde se encuentra nuestro servicio de Shiny Server en una instancia de AWS que hemos decidido dejar con acceso abierto.\nNo olvides detener tu instancia. Los recursos que te da AWS son gratuitos, pero tienen un límite de uso. Revisa las condiciones del Free Tier.\nEn un próximo post te enseño cómo cambiar la app que viene por defecto en shiny Server."
  },
  {
    "objectID": "posts/2025-01-28-dev_mtto_app/index.html",
    "href": "posts/2025-01-28-dev_mtto_app/index.html",
    "title": "Crear Shiny App",
    "section": "",
    "text": "Vamos a crear una app para nuestro modelo de optimización de mantenimiento que hemos definido aquí."
  },
  {
    "objectID": "posts/2025-01-28-dev_mtto_app/index.html#crear-un-proyecto-local",
    "href": "posts/2025-01-28-dev_mtto_app/index.html#crear-un-proyecto-local",
    "title": "Crear Shiny App",
    "section": "Crear un proyecto local",
    "text": "Crear un proyecto local\nEste repositorio va a contener los archivos necesarios para nuestra app.\nEntramos a nuestra sesión de RStudio:\n\nFile -&gt; New Project\nCon la siguiente ventana emergente:\n\n\n\n\n\n\nFigura 1: Opciones para iniciar nuevo proyecto.\n\n\n\nRealmente voy a comenzar desde cero la aplicación, por lo que\nNew Directory -&gt; Shiny Application\n\n\n\n\n\n\nFigura 2: Configuración del proyecto.\n\n\n\nCreate Project\n\nMi sesión de RStudio queda así:\n\n\n\n\n\n\nFigura 3: Vista inmediata de la creación del proyecto.\n\n\n\n\n.Rproj: es un archivo de configuración para RStudio que contiene información sobre el proyecto, como el directorio de trabajo, los paquetes instalados, las opciones de visualización y los scripts de ejecución.\napp.R: es el archivo principal de un proyecto Shiny que contiene la configuración, la interfaz de usuario y la lógica de negocio de la aplicación.\n.gitignore: es un archivo de configuración para Git que contiene una lista de patrones de archivos y directorios que se deben ignorar por Git.\n\nTen presente que en la esquina superior derecha nos indica el proyecto en el que estamos trabajando dev_shiny_mtto_app.Rproj. En la parte inferior izquierda, en la pestaña de Git, tenemos los cambios que hemos hecho hasta que realicemos un commit."
  },
  {
    "objectID": "posts/2025-01-28-dev_mtto_app/index.html#clonar-el-repositorio-desde-local-a-github.",
    "href": "posts/2025-01-28-dev_mtto_app/index.html#clonar-el-repositorio-desde-local-a-github.",
    "title": "Crear Shiny App",
    "section": "Clonar el repositorio desde local a Github.",
    "text": "Clonar el repositorio desde local a Github.\nPor ahora no voy a modificar el app.R, solo quiero montar la infraestructura para ejecutar el workflow.\nRevisamos qué tenemos en la Terminal dentro de RStudio:\n\n\nBash\n\n~/Documents/shiny_mtto_app/dev_shiny_mtto_app$ git status\n\n\n\nOutput\n\nEn la rama master\n\nNo hay commits todavía\n\nArchivos sin seguimiento:\n  (usa \"git add &lt;archivo&gt;...\" para incluirlo a lo que se será confirmado)\n\n        .gitignore\n        app.R\n        dev_shiny_mtto_app.Rproj\n\nno hay nada agregado al commit pero hay archivos sin seguimiento presentes (usa \"git add\" para hacerles seguimiento)\n\nComo aquí seleccionamos “Create a git repository”, ya hemos iniciado el proceso para subirlo a Github.\nEn este post creamos un repositorio en Github y luego lo clonamos a un repositorio local. Ahora vamos a realizar el proceso al revés, ya creado local vamos a clonarlo a Github.\nPodemos incluir todos nuestros archivos con el comando:\n\n\nBash\n\n~/Documents/shiny_mtto_app/dev_shiny_mtto_app$ git add .\n\n\n\nOutput\n\nEn la rama master\n\nNo hay commits todavía\n\nCambios a ser confirmados:\n  (usa \"git rm --cached &lt;archivo&gt;...\" para sacar del área de stage)\n\n        nuevo archivo:  .gitignore\n        nuevo archivo:  app.R\n        nuevo archivo:  dev_shiny_mtto_app.Rproj\n\nYa están bajo seguimiento. Clic en Commit:\n\n\n\n\n\n\nFigura 4: Clic en Commit.\n\n\n\nInsertamos nuestro comentario “first commit” (buenas prácticas) y obtenemos:\n\n\n\n\n\n\nFigura 5: Resultados commit.\n\n\n\nEn la consola de RStudio ingresamos:\n\n\nConsole\n\nusethis::use_github()\n\n\n\nOutput\n\nℹ Defaulting to \"https\" Git protocol.\n✔ Setting active project to\n  \"~/Documents/shiny_mtto_app/dev_shiny_mtto_app\".\n✔ Creating GitHub repository \"cchiquitovalencia/dev_shiny_mtto_app\".\n✔ Setting remote \"origin\" to\n  \"https://github.com/cchiquitovalencia/dev_shiny_mtto_app.git\".\n✔ Pushing \"master\" branch to GitHub and setting \"origin/master\" as upstream branch.\n✔ Opening URL &lt;https://github.com/cchiquitovalencia/dev_shiny_mtto_app&gt;.\n\nSi en este punto has quedado perdido, puedes revisar este post para guiarte un poco. Entonces ya tenemos establecido en Github nuestro repositorio creado de manera local:\n\n\n\n\n\n\nFigura 6: Repositorio creado local en Github."
  },
  {
    "objectID": "posts/2025-01-28-dev_mtto_app/index.html#desarrollo-de-shiny-app",
    "href": "posts/2025-01-28-dev_mtto_app/index.html#desarrollo-de-shiny-app",
    "title": "Crear Shiny App",
    "section": "Desarrollo de Shiny app",
    "text": "Desarrollo de Shiny app\nCon nuestro modelo de optimización de mantenimiento establecido, vamos a programarlo en una Shiny App en R para poder resolverlo y obtener una solución óptima.\nRecordemos que Shiny es un framework para crear aplicaciones web utilizando código R. Está diseñado principalmente con los científicos de datos en mente, y con ese fin, puede crear aplicaciones Shiny bastante complicadas sin conocimientos de HTML, CSS o JavaScript.\nShiny está diseñado para parecer casi mágicamente fácil cuando se está empezando, y sin embargo, cuanto más se profundiza en su funcionamiento, más se da cuenta de que está construido a partir de principios generales. te das cuenta de que está construido a partir de bloques generales que tienen fuertes principios de ingeniería de software detrás de ellos.\nUna Shiny App se compone de un bloque ui (interfaz del usuario) que define el aspecto de la aplicación, y un bloque server, que define el funcionamiento de la aplicación. Shiny utiliza programación reactiva para actualizar automáticamente las salidas cuando cambian las entradas.\nManos a la obra: reemplazamos todo lo que contiene nuestro archivo app.R con lo siguiente:\n\nlibrary(shiny)\nlibrary(ompr)\nlibrary(ompr.roi)\nlibrary(ROI.plugin.glpk)\nlibrary(ggplot2)\nlibrary(tidyverse)\n\n# Definir UI\nui &lt;- fluidPage(\n        \n        # Título de app\n        titlePanel(\"Planeación de Mantenimiento\"),\n        \n        # Opciones para el modelo\n        fluidPage(\n                sidebarPanel(\n                        numericInput(\"m\", \"Flota\", value = 2, min = 1, max = 5, step = 1),\n                        numericInput(\"H\", \"Periodos\", value = 8, min = 4, max = 12, step = 1),\n                        numericInput(\"D\", \"Demanda\", value = 480, min = 200, max = 1000, step = 20),\n                        numericInput(\"Ui\", \"Periodos entre MTTOs\", value = 3, min = 1, max = 7, step = 1),\n                        numericInput(\"Ti\", \"Horas entre MTTOs\", value = 90, min = 50, max = 200, step = 10),\n                        numericInput(\"xmax\", \"Máximo horas operación\", value = 744, min = 500, max = 1000, step = 66),\n                        actionButton(\"solucionar\", \"Obtener solución!\"),\n                        br(),\n                        actionButton(\"graficar\", \"Graficar solución!\")\n                        , width = 3)\n                ,\n                \n                mainPanel(\n                        h4('Descripción del modelo'),\n                        #verbatimTextOutput(\"periodosMtto\"),\n                        #verbatimTextOutput(\"horasMtto\"),\n                        verbatimTextOutput(\"imprimeModelo\"),\n                        verbatimTextOutput(\"imprimeResultado\"),\n                        plotOutput(\"grafica\")\n                )\n                \n        )\n        \n)\n\n# Definir lógica del servidor para resolver el modelo\nserver &lt;- function(input, output) {\n        \n        # Usado para mostrar variables internas\n        output$periodosMtto &lt;- renderPrint({\n                rep(input$Ui, input$m)\n        })\n        \n        output$horasMtto &lt;- renderPrint({\n                rep(input$Ti, input$m)\n        })\n        \n        # Función para crear modelo planeación\n        crearModelo &lt;- reactive({\n                \n                # Repetir valores ingresados por usuario para Ui y Ti\n                realUi &lt;- rep(input$Ui, input$m)\n                realTi &lt;- rep(input$Ti, input$m)\n                \n                # Definir el modelo con ompr\n                model &lt;- MIPModel() |&gt;\n                        \n                        # Variables\n                        add_variable(y[i, t], i=1:input$m, t=1:input$H, type=\"binary\") |&gt;\n                        add_variable(x[i, t], i=1:input$m, t=1:input$H, type=\"continuous\", lb=0) |&gt;\n                        \n                        # Función objetivo\n                        set_objective(sum_expr(y[i, t], i=1:input$m, t=1:input$H), \"min\") |&gt;\n                        \n                        # Restricciones\n                        add_constraint(sum_expr(x[i, t], i=1:input$m, t=1:input$H) &gt;= input$D) |&gt;\n                        add_constraint(sum_expr(y[i, j], j=tao:(tao+realUi[i])) &gt;= 1, i=1:input$m, tao=1:(input$H-realUi[i])) |&gt;\n                        add_constraint(sum_expr(x[i, j], j=t:(t+u)) &lt;= realTi[i] + realTi[i]*sum_expr(y[i, j], j=t:(t+u)), i=1:input$m, t=1:input$H, u=0:(input$H-t)) |&gt;\n                        add_constraint(x[i, t] + input$xmax*y[i, t] &lt;= input$xmax, i=1:input$m, t=1:input$H)\n                \n                # Devolver el modelo         \n                model\n        })\n        \n        # Función para entregar características del modelo\n        output$imprimeModelo &lt;- renderPrint(crearModelo())\n        \n        # Ejecutar solución del modelo\n        resultado &lt;- eventReactive(\n                input$solucionar, {\n                        \n                        # Activar solver\n                        result &lt;- solve_model(crearModelo(), with_ROI(solver = \"glpk\", verbose = TRUE))\n                        result\n                        \n                })\n        \n        # Función para entregar características de la solución\n        output$imprimeResultado &lt;- renderPrint(resultado())\n        \n        # función para crear gráficas de la solución\n        plotear &lt;- eventReactive(\n                input$graficar, {\n                        \n                        # Graficar solución\n                        gridExtra::grid.arrange(\n                                get_solution(resultado(), y[i,t]) |&gt;\n                                        mutate(Mtto = \"Mant\") |&gt;\n                                        rename(unidad = i, periodo = t) |&gt;\n                                        ggplot()+\n                                        geom_point(aes(periodo, value, color = as.factor(value)), size = 5)+\n                                        facet_grid(unidad~.)+\n                                        hrbrthemes::theme_ipsum()+\n                                        labs(x = \"PERIODO\", y = \"VALOR\", col = \"MTTO\")+\n                                        theme(legend.position = \"top\"),\n\n                                get_solution(resultado(), x[i,t]) |&gt;\n                                        mutate(Horas = \"Opera\") |&gt;\n                                        rename(unidad = i, periodo = t) |&gt;\n                                        ggplot()+\n                                        geom_point(aes(periodo, value, color = as.factor(value)), size = 5)+\n                                        facet_grid(unidad~.)+\n                                        hrbrthemes::theme_ipsum()+\n                                        labs(x = \"PERIODO\", y = \"VALOR\", col = \"OPERA\")+\n                                        theme(legend.position = \"top\"),\n\n                                ncol = 2\n                        )\n                        \n                })\n        \n        output$grafica &lt;- renderPlot(plotear())\n        \n}\n\n# Run the application \nshinyApp(ui = ui, server = server)\n\nHasta aquí, lo que hemos hecho es traducir a una app, que no es la más estilizada (espero no hayas pensado que soy experto en diseño gráfico o en experiencia de usuario) que habíamos modelado matemáticamente en un post anterior.\nShiny es muy amplio en cuanto al desarrollo de aplicaciones se refiere. Si quieres un poco más de contexto puedes revisar el libro Mastering Shiny, donde puedes encontrar la documentación para “llevarte de no saber nada sobre Shiny a ser un desarrollador experto capaz de escribir aplicaciones complejas de gran tamaño que sean mantenibles y tengan un buen rendimiento. Adquirirás un conocimiento profundo del modelo de programación reactiva que subyace en Shiny, además de construir una caja de herramientas de técnicas útiles para resolver los desafíos comunes de las aplicaciones”.\nBásicamente establecemos en la ui los parámetros que podrían cambiar, con algunos rangos que puede modificar (no pueden ser muy amplios porque el problema de optimización es de tipo NP-Hard). Creamos un resumen del tamaño del problema, imprimimos el resultado de la optimización que mostramos cuando el usuario usa un botón, y graficamos la solución con otro botón.\nRealmente nuestra app es muy sencilla (aunque el problema que resuelve no lo sea). Es tan sencilla que podría tener detractores de la cultura DevOps en cualquier punto. Que sea a prueba de balas no es el punto aquí, sino enviar a producción.\nActualizamos nuestro repositorio en Github: commit y push. Tenemos nuestra app lista para clonar desde Github con nuestra instancia en AWS."
  },
  {
    "objectID": "mtto_shiny_app.html",
    "href": "mtto_shiny_app.html",
    "title": "Crear Shiny App",
    "section": "",
    "text": "Con nuestro modelo de optimización de mantenimiento establecido, vamos a programarlo en una Shiny App en R para poder resolverlo y obtener una solución óptima.\n\nlibrary(shiny)\nlibrary(ompr)\nlibrary(ompr.roi)\nlibrary(ROI.plugin.glpk)\nlibrary(ggplot2)\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ lubridate 1.9.3     ✔ tibble    3.2.1\n✔ purrr     1.0.2     ✔ tidyr     1.3.1\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nRecordemos que Shiny es un framework para crear aplicaciones web utilizando código R. Está diseñado principalmente con los científicos de datos en mente, y con ese fin, puede crear aplicaciones Shiny bastante complicadas sin conocimientos de HTML, CSS o JavaScript.\nShiny está diseñado para parecer casi mágicamente fácil cuando se está empezando, y sin embargo, cuanto más se profundiza en su funcionamiento, más se da cuenta de que está construido a partir de principios generales. te das cuenta de que está construido a partir de bloques generales que tienen fuertes principios de ingeniería de software detrás de ellos.\nUna Shiny App se compone de un bloque ui (interfaz del usuario) que define el aspecto de la aplicación, y un bloque server, que define el funcionamiento de la aplicación. Shiny utiliza programación reactiva para actualizar automáticamente las salidas cuando cambian las entradas.\nAquí está nuestro ui:\n\n# Definir UI\nui &lt;- fluidPage(\n        \n        # Título de app\n        titlePanel(\"Planeación de Mantenimiento\"),\n        \n        # Opciones para el modelo\n        fluidPage(\n                sidebarPanel(\n                        numericInput(\"m\", \"Flota\", value = 2, min = 1, max = 5, step = 1),\n                        numericInput(\"H\", \"Periodos\", value = 8, min = 4, max = 12, step = 1),\n                        numericInput(\"D\", \"Demanda\", value = 480, min = 200, max = 1000, step = 20),\n                        numericInput(\"Ui\", \"Periodos entre MTTOs\", value = 3, min = 1, max = 7, step = 1),\n                        numericInput(\"Ti\", \"Horas entre MTTOs\", value = 90, min = 50, max = 200, step = 10),\n                        numericInput(\"xmax\", \"Máximo horas operación\", value = 744, min = 500, max = 1000, step = 66),\n                        actionButton(\"solucionar\", \"Obtener solución!\"),\n                        br(),\n                        actionButton(\"graficar\", \"Graficar solución!\")\n                        , width = 3)\n                ,\n                \n                mainPanel(\n                        h4('Descripción del modelo'),\n                        #verbatimTextOutput(\"periodosMtto\"),\n                        #verbatimTextOutput(\"horasMtto\"),\n                        verbatimTextOutput(\"imprimeModelo\"),\n                        verbatimTextOutput(\"imprimeResultado\"),\n                        plotOutput(\"grafica\")\n                )\n                \n        )\n        \n)\n\nY aquí dejaremos nuestro server:\n\n# Definir lógica del servidor para resolver el modelo\nserver &lt;- function(input, output) {\n        \n        # Usado para mostrar variables internas\n        output$periodosMtto &lt;- renderPrint({\n                rep(input$Ui, input$m)\n        })\n        \n        output$horasMtto &lt;- renderPrint({\n                rep(input$Ti, input$m)\n        })\n        \n        # Función para crear modelo planeación\n        crearModelo &lt;- reactive({\n                \n                # Repetir valores ingresados por usuario para Ui y Ti\n                realUi &lt;- rep(input$Ui, input$m)\n                realTi &lt;- rep(input$Ti, input$m)\n                \n                # Definir el modelo con ompr\n                model &lt;- MIPModel() |&gt;\n                        \n                        # Variables\n                        add_variable(y[i, t], i=1:input$m, t=1:input$H, type=\"binary\") |&gt;\n                        add_variable(x[i, t], i=1:input$m, t=1:input$H, type=\"continuous\", lb=0) |&gt;\n                        \n                        # Función objetivo\n                        set_objective(sum_expr(y[i, t], i=1:input$m, t=1:input$H), \"min\") |&gt;\n                        \n                        # Restricciones\n                        add_constraint(sum_expr(x[i, t], i=1:input$m, t=1:input$H) &gt;= input$D) |&gt;\n                        add_constraint(sum_expr(y[i, j], j=tao:(tao+realUi[i])) &gt;= 1, i=1:input$m, tao=1:(input$H-realUi[i])) |&gt;\n                        add_constraint(sum_expr(x[i, j], j=t:(t+u)) &lt;= realTi[i] + realTi[i]*sum_expr(y[i, j], j=t:(t+u)), i=1:input$m, t=1:input$H, u=0:(input$H-t)) |&gt;\n                        add_constraint(x[i, t] + input$xmax*y[i, t] &lt;= input$xmax, i=1:input$m, t=1:input$H)\n                \n                # Devolver el modelo         \n                model\n        })\n        \n        # Función para entregar características del modelo\n        output$imprimeModelo &lt;- renderPrint(crearModelo())\n        \n        # Ejecutar solución del modelo\n        resultado &lt;- eventReactive(\n                input$solucionar, {\n                        \n                        # Activar solver\n                        result &lt;- solve_model(crearModelo(), with_ROI(solver = \"glpk\", verbose = TRUE))\n                        result\n                        \n                })\n        \n        # Función para entregar características de la solución\n        output$imprimeResultado &lt;- renderPrint(resultado())\n        \n        # función para crear gráficas de la solución\n        plotear &lt;- eventReactive(\n                input$graficar, {\n                        \n                        # Graficar solución\n                        gridExtra::grid.arrange(\n                                get_solution(resultado(), y[i,t]) |&gt;\n                                        mutate(Mtto = \"Mant\") |&gt;\n                                        rename(unidad = i, periodo = t) |&gt;\n                                        ggplot()+\n                                        geom_point(aes(periodo, value, color = as.factor(value)), size = 5)+\n                                        facet_grid(unidad~.)+\n                                        hrbrthemes::theme_ipsum()+\n                                        labs(x = \"PERIODO\", y = \"VALOR\", col = \"MTTO\")+\n                                        theme(legend.position = \"top\"),\n\n                                get_solution(resultado(), x[i,t]) |&gt;\n                                        mutate(Horas = \"Opera\") |&gt;\n                                        rename(unidad = i, periodo = t) |&gt;\n                                        ggplot()+\n                                        geom_point(aes(periodo, value, color = as.factor(value)), size = 5)+\n                                        facet_grid(unidad~.)+\n                                        hrbrthemes::theme_ipsum()+\n                                        labs(x = \"PERIODO\", y = \"VALOR\", col = \"OPERA\")+\n                                        theme(legend.position = \"top\"),\n\n                                ncol = 2\n                        )\n                        \n                })\n        \n        output$grafica &lt;- renderPlot(plotear())\n        \n}\n\nFinalmente, puedes correr la app con:\n\n# Ejecutar la app\nshinyApp(ui = ui, server = server)\n\nShiny applications not supported in static R Markdown documents\n\n\nHasta aquí, lo que hemos hecho es traducir a una app, que no es la más estilizada (espero no hayas pensado que soy experto en diseño gráfico o en experiencia de usuario) que habíamos modelado matemáticamente en un post anterior.\nShiny es muy amplio en cuanto al desarrollo de aplicaciones se refiere. Si quieres un poco más de contexto puedes revisar el libro Mastering Shiny, donde puedes encontrar la documentación para “llevarte de no saber nada sobre Shiny a ser un desarrollador experto capaz de escribir aplicaciones complejas de gran tamaño que sean mantenibles y tengan un buen rendimiento. Adquirirás un conocimiento profundo del modelo de programación reactiva que subyace en Shiny, además de construir una caja de herramientas de técnicas útiles para resolver los desafíos comunes de las aplicaciones”.\nEl próximo paso será:\n\nCrear un nuevo proyecto para alojar el desarrollo de la app.\nClonarlo a Github para control de versiones.\nDocker para inmortalizarlo.\nCambiar la app por defecto."
  },
  {
    "objectID": "posts/2025-01-30-deploy_app_server/index.html",
    "href": "posts/2025-01-30-deploy_app_server/index.html",
    "title": "Desplegar Shiny App",
    "section": "",
    "text": "Ya vimos que en nuestra instancia EC2 tenemos instalado Shiny Server y ahí se encuentra una app que viene por defecto.\nDebemos encontrar dónde se encuentra alojada ese archivo app.R que se está ejecutando para poder modificarlo."
  },
  {
    "objectID": "posts/2025-01-30-deploy_app_server/index.html#iniciar-instancia",
    "href": "posts/2025-01-30-deploy_app_server/index.html#iniciar-instancia",
    "title": "Desplegar Shiny App",
    "section": "Iniciar instancia",
    "text": "Iniciar instancia\nIngresamos a la consola de AWS y seleccionamos la instancia:\n\n\n\n\n\n\nFigura 1: Inicio de instancia.\n\n\n\nEsperamos unos segundos y:\n\n\n\n\n\n\nFigura 2: Inicio exitoso.\n\n\n\nCon nuestro servidor corriendo ahora podemos"
  },
  {
    "objectID": "posts/2025-01-30-deploy_app_server/index.html#explorar-el-servidor",
    "href": "posts/2025-01-30-deploy_app_server/index.html#explorar-el-servidor",
    "title": "Desplegar Shiny App",
    "section": "Explorar el servidor",
    "text": "Explorar el servidor\nPara encontrar el archivo app.R\nAbrimos una terminal y nos conectamos por SSH:\n\n\nOutput\n\nWelcome to Ubuntu 24.04.1 LTS (GNU/Linux 6.8.0-1021-aws x86_64)\n\n * Documentation:  https://help.ubuntu.com\n * Management:     https://landscape.canonical.com\n * Support:        https://ubuntu.com/pro\n\n System information as of Wed Jan 29 00:09:30 UTC 2025\n\n  System load:  0.06              Processes:             107\n  Usage of /:   69.9% of 6.71GB   Users logged in:       0\n  Memory usage: 24%               IPv4 address for enX0: 172.31.5.157\n  Swap usage:   0%\n\n * Ubuntu Pro delivers the most comprehensive open source security and\n   compliance features.\n\n   https://ubuntu.com/aws/pro\n\nExpanded Security Maintenance for Applications is not enabled.\n\n0 updates can be applied immediately.\n\nEnable ESM Apps to receive additional future security updates.\nSee https://ubuntu.com/esm or run: sudo pro status\n\nConectados, ejecutamos el siguiente comando para entrar a la carpeta que contiene los archivos de la app por defecto\n\n\nBash\n\n~$ cd /srv/shiny-server/\n/srv/shiny-server$ ls\n\nResulta: un archivo .html y una carpeta sample-apps:\n\n\nOutput\n\nindex.html  sample-apps\n\nVeamos qué contiene la carpeta:\n\n\nBash\n\n/srv/shiny-server$ ls sample-apps\n\n\n\nOutput\n\nhello  rmd\n\nIngresemos a ver en hello:\n\n\nBash\n\n/srv/shiny-server$ cd sample-apps/hello\n/srv/shiny-server/sample-apps/hello$ ls\n\n\n\nOutput\n\nserver.R  ui.R\n\nEntonces aquí es de donde Shiny Server toma los archivos. Aquí estan el ui y el server, las bases de cualquier app de Shiny."
  },
  {
    "objectID": "posts/2025-01-30-deploy_app_server/index.html#descargar-la-app-desde-github",
    "href": "posts/2025-01-30-deploy_app_server/index.html#descargar-la-app-desde-github",
    "title": "Desplegar Shiny App",
    "section": "Descargar la app desde Github",
    "text": "Descargar la app desde Github\n\nNos devolvemos al home\n\n\nBash\n\ncd\n\nVamos a Github para copiar el link https:\n\n\n\n\n\n\nFigura 3: Copiar HTTPS\n\n\n\n\n\nClonamos el repositorio en nuestro servidor:\n\n\nBash\n\ngit clone https://github.com/cchiquitovalencia/dev_shiny_mtto_app.git\n\n\n\nOutput\n\nCloning into 'dev_shiny_mtto_app'...\nremote: Enumerating objects: 8, done.\nremote: Counting objects: 100% (8/8), done.\nremote: Compressing objects: 100% (7/7), done.\nReceiving objects: 100% (8/8), 4.10 KiB | 840.00 KiB/s, done.\nremote: Total 8 (delta 0), reused 8 (delta 0), pack-reused 0 (from 0)\n\n\n\nCreamos un atajo en /srv/shiny-server/\n\n\nBash\n\ncd /srv/shiny-server\n/srv/shiny-server$ sudo ln -s ~/dev_shiny_mtto_app\n\nRecuerda que puedes ir a https://explainshell.com/ para entender el código:\n\n\n\n\n\n\nFigura 4: Explicación de código.\n\n\n\nConfirmamos que nos queda:\n\n\nOutput\n\ndev_shiny_mtto_app  index.html  sample-apps\n\n\n\nEliminamos el resto con:\n\n\nBash\n\n/srv/shiny-server$ sudo rm index.html\n/srv/shiny-server$ sudo rm -R sample-apps\n\n\n\nPodemos mover los archivos\nSi con las instrucciones del atajo anterior tienes problema, puedes ejecutar:\n\n\nBash\n\ncd /srv/shiny-server # para pararte en la carpeta destino\nsudo mv ~/dev_shiny_mtto_app . # mover todo\n\nAhora que tenemos nuestro archivo app.R en la carpeta donde debe estar podemos ir al explorador e ingresar &lt;IP:3838&gt; (recuerda que la IP de la instancia cambia cada que la reiniciamos en caso de no haber establecido una Elastic IP)\nJusto ahora la IP que AWS me asigna es: 3.141.200.204.\n\n\n\n\n\n\nFigura 5: Conexión a la app.\n\n\n\nEsperaba ver nuestra app funcionando de inmediato, pero bueno. Si das clic:\n\n\n\n\n\n\nFigura 6: Error ejecutar la app.\n\n\n\nParece que debemos"
  },
  {
    "objectID": "posts/2025-01-30-deploy_app_server/index.html#configurar-shiny-server",
    "href": "posts/2025-01-30-deploy_app_server/index.html#configurar-shiny-server",
    "title": "Desplegar Shiny App",
    "section": "Configurar Shiny Server",
    "text": "Configurar Shiny Server\nEl archivo que debemos revisar se encuentra en /etc/shiny-server/shiny-server.conf. Lo abrimos con:\n\n\nBash\n\nsudo nano /etc/shiny-server/shiny-server.conf\n\n\n\nOutput\n\n# Instruct Shiny Server to run applications as the user \"shiny\"\nrun_as shiny;\n\n# Define a server that listens on port 3838\nserver {\n  listen 3838;\n\n  # Define a location at the base URL\n  location / {\n\n    # Host the directory of Shiny Apps stored in this directory\n    site_dir /srv/shiny-server;\n\n    # Log all Shiny output to files in this directory\n    log_dir /var/log/shiny-server;\n\n    # When a user visits the base URL rather than a particular application,\n    # an index of the applications available in this directory will be shown.\n    directory_index on;\n  }\n\n\nrun_as shiny indica el usuario detrás del Shiny Server. Cuando iniciaste sesión a través de ssh, actuaste como usuario ubuntu, el predeterminado. Pero cuando instalamos Shiny Server, creamos un nuevo usuario llamado shiny, y ese es el que ejecuta el Shiny Server.\nlisten 3838. Ese es el puerto. Por eso añadimos :3838 al final de la URL.\nsite_dir /srv/shiny-server te dice dónde tienes que poner los archivos de la aplicación. Efectivamente, ahí es donde hemos creado el acceso directo.\nlog_dir /var/log/shiny-server muestra dónde se almacenan los registros. Eso es súper útil en caso de que algo esté fallando.\ndirectory_index on, permite al servidor mostrar los directorios cuando no hay index.html. Eso es lo que vimos cuando entramos directamente en 3.141.200.204:3838. Para desactivarlo: directory_index off. La razón: no quiero que todo el mundo sepa todas las aplicaciones que tengo.\n\nModificamos un poco para garantizar siempre los registros (logs). Agregamos al inicio preserve_logs true; y sanitize_errors false; y volvemos a cargar el servidor:\n\n\nBash\n\nsudo systemctl reload shiny-server\n\nPreservar logs para obligar a guardar todo comportamiento del servidor (parece que no siempre ocurre), y “estilizar” (on) implica no mostrar al usuario el print de los logs cuando hay errores."
  },
  {
    "objectID": "posts/2025-01-30-deploy_app_server/index.html#depurar-shiny-app-con-logs",
    "href": "posts/2025-01-30-deploy_app_server/index.html#depurar-shiny-app-con-logs",
    "title": "Desplegar Shiny App",
    "section": "Depurar Shiny app con logs",
    "text": "Depurar Shiny app con logs\nPara ver los logs:\n\n\nBash\n\n~$ cd /var/log/shiny-server\n/var/log/shiny-server$ ls\n\n\n\nOutput\n\ndev_shiny_mtto_app-shiny-20250129-003756-35481.log\ndev_shiny_mtto_app-shiny-20250129-012205-43913.log\n\nMiremos uno de ellos:\n\n\nBash\n\nsudo tail dev_shiny_mtto_app-shiny-20250129-012205-43913.log\n\n\n\nOutput\n\nsu: ignoring --preserve-environment, it's mutually exclusive with --login\n-bash: line 1: cd: /srv/shiny-server/dev_shiny_mtto_app: Permission denied\n\nCon este mensaje pasé varias horas revisando internet para depurar cuál había sido el error. Ya ves que el mensaje no dice mucho, pero refiere a permisos.\nVamos a repasar nuestro proceso para desplegar la app:\n\nEstamos accediendo al servidor a través de ssh con el archivo .pem que tengo alojado en mi computador. En este momento mi usuario es ubuntu.\nEl archivo .config del Shiny Server me dice que el usuario es shiny.\n\nPodría modificar el .config para asignar run_as ubuntu;, pero cómo podría diferenciar cuando la app se ejecuta bajo mi nombre y que yo (usuario ubuntu) la ejecute?\nVoy a crear un usuario cchv para no ingresar como root y nos cambiamos al nuevo usuario:\n\n\nBash\n\nadduser cchv\ngpasswd -a cchv sudo\nsu - cchv\n\nCreo un grupo de usuarios llamado shiny-apps y añado los usuarios cchv y shiny. Vamos a hacer que toda la carpeta /srv/shiny-server tenga permisos de lectura+escritura para este grupo:\n\n\nBash\n\nsudo groupadd shiny-apps\nsudo usermod -aG shiny-apps cchv\nsudo usermod -aG shiny-apps shiny\ncd /srv/shiny-server\nsudo chown -R cchv:shiny-apps .\nsudo chmod g+w .\nsudo chmod g+s .\n\nLos pasos que seguí los encontré aquí.\nIngresamos a nuestra app con &lt;IP:3838&gt; y:\n\n\n\n\n\n\nFigura 7: No se encuentran librerías.\n\n\n\nDebemos instalar librerías, y debemos hacerlo con el usuario shiny, que es el que tiene configurado el Shiny Server en el .config.\nNos cambiamos de usario, abrimos R e instalamos lo que necesitamos:\n\n\nBash\n\nsudo su - shiny\nR\n\ninstall.packages(\"pak\") # esta librería nos ayuda con dplyr\ninstall.packages(\"ompr\")\ninstall.packages(\"ompr.roi\")\ninstall.packages(\"ROI.plugin.glpk\") \ninstall.packages(\"ggplot2\")\npak::pkg_install(\"tidyverse/dplyr\")\n\nTen presente que hay un paso adicional que debe ejecutarse antes de la instalacion de ROI.plugin.glpk para que la app funcione.\n\n\n\n\n\n\nFigura 8: Requerimiento adicional para solver.\n\n\n\nPor otro lado, aquí estabamos usando la librería tidyverse, pero los recursos de nuestra instancia son los mínimos (free tier), y no son suficientes para instalarla. Afortunadamente, nuestro código solo requiere funciones de dplyr, y se se logra instalar con ayuda de pak.\nAhora, con todas las librerías al día, ejecutamos nuevamente, y…:"
  },
  {
    "objectID": "posts/2025-01-30-deploy_app_server/index.html#ejecutar-shiny-app",
    "href": "posts/2025-01-30-deploy_app_server/index.html#ejecutar-shiny-app",
    "title": "Desplegar Shiny App",
    "section": "Ejecutar Shiny app",
    "text": "Ejecutar Shiny app\n\n\n\n\n\n\nFigura 9: Aplicación funcionando en la web.\n\n\n\nFinalmente tenemos nuestra Shiny app en línea, accesible y funcionando. El resultado de nuestro modelo se puede ver en:\n\n\n\n\n\n\nFigura 10: Resultado modelo.\n\n\n\nEn el lado izquierdo tienes la planeación de la ejecución de mantenimiento. En el lado derecho tienes el tiempo de operación. En cada fila se registra el vehículo correspondiente.\nDe esta forma tenemos que en el periodo #2, el vehículo #2 tiene mantenimiento (no opera en ese periodo). Además, el vehículo #1 opera 30 horas en el periodo #5 (no tiene mantenimiento)."
  },
  {
    "objectID": "posts/2025-01-30-deploy_app_server/index.html#consideraciones-finales",
    "href": "posts/2025-01-30-deploy_app_server/index.html#consideraciones-finales",
    "title": "Desplegar Shiny App",
    "section": "Consideraciones finales",
    "text": "Consideraciones finales\nPodrías estar pensando que es muy básica la aplicación, y seguro te surgen algunas de las siguientes dudas:\nQué se puede incluir en la aplicación?\n\nSe puede lograr una distribución “uniforme” del tiempo de operación de cada vehiculo. Piensa en esto: el periodo #1 cuenta con \\(90 + 90 = 180\\) horas de operación, pero en el siguiente periodo ninguno de los 2 vehículos se encuentra planeado para operar.\nSe pueden inlcuir restricciones de recursos de mantenimiento, cuánta capacidad tengo para atender, en simultáneo, las rutinas de mantenimiento?\nCada vehículo puede tener unas variables específicas? Por decir algo: el vehículo #1 podría no requerir mínimo 3 periodos entre mantenimiento sino 6 por ser nuevo.\nCuánto es la duración de cada mantenimiento? Será necesario apartar más de un periodo para ejecutar las rutinas?\nQué pasa si la demanda de tiempo de operación es diferente para cada uno de los periodos en el horizonte de tiempo planeado? Tu operación puede ser diferente en fines de semana, o en cada mes del año.\nPuedo determinar “manualmente” cuándo hacer el mantenimiento? Algunos compromisos se deben cumplir, puede ser con agentes externos o clientes internos, que exijan disponibilidad del vehículo en taller en un periodo en particular.\nQué pasa si algunas piezas requieren mantenimiento más seguidas que otras? Consideraríamos “tipos de rutinas” diferentes en este caso.\n\nSi estás interesado en conocer más acerca del modelo y las posibilidades, no dudes en contactarme por correo electrónico, agendamos un espacio y hablamos del desarrollo de la solución.\nTener solo un plan maestro y/o una programación maestra no garantiza el éxito. Al igual que con todos los procesos y herramientas, el plan maestro y/o la programación maestra deben ser administrados. El fracaso a la hora de gestionar el plan maestro y/o la programación maestra conduce a la mala asignación de los recursos de manufactura y abastecimiento de la empresa. Esto, a su vez, puede significar que la empresa no sea capaz de responder a las necesidades de los clientes o sea ineficiente en el uso de sus recursos. En última instancia, la empresa corre el riesgo de perder su posición competitiva.\nAdemás, si el plan maestro y/o la programación maestra no se gestiona correctamente, muchos de los beneficios del proceso de planeación empresarial integrada o planeación de ventas y operaciones se perderán."
  },
  {
    "objectID": "posts/2025-02-04-master_plan/index.html",
    "href": "posts/2025-02-04-master_plan/index.html",
    "title": "Indispensable crear el PLAN",
    "section": "",
    "text": "Hace algunos años me encontraba en la oficina de uno de los ejecutores del Programa de Alimentación Escolar (PAE) realizando una propuesta para implementar un modelo de distribución. Tal vez fueron 3 o 4 encuentros con dos de los principales responsables el Director de Operaciones y el Jefe de Distribución.\nAmbos tenían muy claro el panorama en cuanto a fechas de entrega, formas de almacenar productos en los vehículos, tipos de vehículos disponibles (propios y tercerizados), topología de las rutas de distribución, fechas de caducidad de los alimentos, y otros.\nPor ese entonces estaba yo incursionando en la optimización porque en uno de mis roles me enfrentaba a la tarea de minimizar el costo de operar cerca de 130.000 kilómetros diarios. Entonces mis propuestas se enfocaron en optimizar su red de distribución. Les presenté un modelo que contemplaba principalmente: reducción de kilómetros recorridos (ahorro en combustible), capacidad de almacenamiento por tipo de vehículo, programación de despacho en la semana.\nEstaba seguro que lograría iniciar el proyecto de consultoría con ellos. Lo que había diseñado para su operación encajaba bastante bien con las herramientas que tenían disponibles y la información estaba clara y al alcance de todos.\nAl final, el Jefe de Distribución convenció al Director de Operaciones que el modelo estaba muy bueno, pero que en la realidad existían tantas variables que lo cierto es que no iba a funcionar.\nEn esa época fácilmente dejé llevarme por sus argumentos. Eran ciertos. Todo puede pasar en la operación del día a día y lo que está planeado seguramente no se va a cumplir. Hoy puedo decir que fue un error total: no debí dejarme convencer. Claro que todo puede pasar, pero sino tienes un plan, sino tienes una guía, la hoja de ruta, lo ideal, el deber ser, pues estás bajo las decisiones en caliente. Sin un plan, no vas a lograr más que esforzarte en vano, no tienes una meta.\n\n\n\n\n\n\nEl éxito en los negocios es fácil si haces dos cosas bien: planea tú trabajo y trabaja tú plan.\n\n\n\n\n\n\n\n\n\nCitationBibTeX citation:@online{chiquito_valencia2025,\n  author = {Chiquito Valencia, Cristian},\n  title = {Indispensable Crear El {PLAN}},\n  date = {2025-02-04},\n  url = {https://cchiquitovalencia.github.io/posts/2025-02-04-master_plan/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nChiquito Valencia, Cristian. 2025. “Indispensable Crear El\nPLAN.” February 4, 2025. https://cchiquitovalencia.github.io/posts/2025-02-04-master_plan/."
  },
  {
    "objectID": "posts/2025-02-03-master_plan/index.html",
    "href": "posts/2025-02-03-master_plan/index.html",
    "title": "Indispensable crear el PLAN",
    "section": "",
    "text": "Hace algunos años me encontraba en la oficina de uno de los ejecutores del Programa de Alimentación Escolar (PAE) realizando una propuesta para implementar un modelo de distribución. Tal vez fueron 3 o 4 encuentros con dos de los principales responsables el Director de Operaciones y el Jefe de Distribución.\nAmbos tenían muy claro el panorama en cuanto a fechas de entrega, formas de almacenar productos en los vehículos, tipos de vehículos disponibles (propios y tercerizados), topología de las rutas de distribución, fechas de caducidad de los alimentos, y otros.\nPor ese entonces estaba yo incursionando en la optimización porque en uno de mis roles me enfrentaba a la tarea de minimizar el costo de operar cerca de 130.000 kilómetros diarios con 740 vehículos aproximadamente. Entonces mis propuestas se enfocaron en optimizar su red de distribución. Les presenté un modelo que contemplaba principalmente: reducción de kilómetros recorridos (ahorro en combustible), capacidad de almacenamiento por tipo de vehículo, programación de despachos en los diferentes días de la semana.\nEstaba seguro que lograría iniciar el proyecto de consultoría con ellos. Lo que había diseñado para su operación encajaba bastante bien con las herramientas que tenían disponibles y la información estaba clara y al alcance de todos.\nAl final, el Jefe de Distribución convenció al Director de Operaciones que el modelo estaba muy bueno, pero que en la realidad existían tantas variables que lo cierto es que no iba a funcionar.\nEn esa época fácilmente dejé llevarme por sus argumentos. Eran ciertos. Todo puede pasar en la operación del día a día y lo que está planeado seguramente no se va a cumplir. Hoy puedo decir que fue un error total: no debí dejarme convencer. Claro que todo puede pasar, pero sino tienes un plan, sino tienes una guía, la hoja de ruta, lo ideal, el deber ser, pues estás bajo las decisiones en caliente. Sin un plan, no vas a lograr más que esforzarte en vano, no tienes una meta.\nLa planeación y programación maestros (MPS), junto con la planeación táctica integrada (ITP), es el proceso de gestión de la cadena de suministro (SCM) que traduce los planes de demanda y suministro aprobados por la planeación empresarial integrada (IBP) en planes de demanda y suministro detallados y ejecutables.\nAunque la frase anterior es un poco larga, solo es uno de los objetivos del MPS. Probablemente haya muchos más objetivos pero aquí hay una lista de 20 objetivos más allá.\nEl proceso de planeación y programación maestros se encuentra justo entre el proceso mensual de planeación empresarial integrado de la dirección (incluyendo el apoyo de la gerencia intermedia) y los procesos de producción, logística y contratación de la supervisión (incluyendo a los influenciadores clave y a aquellos que realizan el trabajo)."
  },
  {
    "objectID": "posts/2025-02-03-master_plan/index.html#objetivos-del-mps",
    "href": "posts/2025-02-03-master_plan/index.html#objetivos-del-mps",
    "title": "Indispensable crear el PLAN",
    "section": "Objetivos del MPS:",
    "text": "Objetivos del MPS:\n\nDesagregar los planes de demanda y suministro agregados en planes y horarios detallados\nCrear un plan maestro (abastecimiento) válido y realista a nivel de subfamilia de productos por semanas y meses,\nCrear un horario maestro (abastecimiento) válido y realista a nivel de grupo y/o unidad de almacenamiento por días y semanas,\nAsegurarse de que la capacidad (incluyendo herramientas) esté disponible cuando comience el proceso de producción (operaciones/mantenimiento),\nAsegurarse de que el material esté disponible cuando comience el proceso de producción (operaciones/mantenimiento),\nAlinear los lanzamientos de nuevos productos (también pruebas de producción de nuevos productos) con las necesidades de producción,\nAsegurarse de que las fechas límite de entrega de material sean iguales a las fechas de necesidad de material,\nAsegurarse de que la capacidad planeada sea igual a la capacidad requerida,\nOptimizar la estabilidad del plan maestro (abastecimiento) y el horario maestro (abastecimiento), la creación de órdenes, el reprogramación y el nivelado de carga,\nImplementar acciones sugeridas por mensajes de acción generados por el sistema,\nEquilibrar la demanda del cliente con las capacidades de suministro de la empresa,\nContinuar desafiando y reduciendo los plazos de entrega de los clientes,\nProporcionar información disponible para prometer y registrar órdenes al organización de demanda (ventas y servicio al cliente),\nProbar las capacidades de suministro para satisfacer las necesidades de demanda antes de liberar el plan maestro y/o horario maestro,\nAsegurarse de que los planes de suministro detallados estén sincronizados, alineados y integrados con los planes de suministro agregados,\nIdentificar, negociar y resolver conflictos en las necesidades de demanda y capacidades de suministro,\nCrear un plan maestro y/o horario maestro que satisfaga la demanda del cliente utilizando niveles óptimos de inventario y recursos y mejore las posibilidades de la empresa para hacer dinero y obtener beneficios,\nCrear la hoja de ruta para la planeación detallada de material y capacidad,\nAsistir a la gestión de demanda en la establecimiento de prioridades cuando la demanda supera las capacidades de suministro de la empresa,\nEstablecer una línea de comunicación efectiva con todas las funciones de la empresa.\n\nAsí que la creación de un plan maestro y horario maestro es un proceso fundamental en el mundo de los negocios, ya que permite a las empresas planificar y organizar sus actividades de manera efectiva para satisfacer las necesidades de sus clientes y maximizar sus ganancias. Es importante que las empresas tengan una visión clara de sus objetivos y necesidades para poder crear un plan maestro y horario maestro efectivo, y que identifiquen y resuelvan conflictos en las necesidades de demanda y capacidades de suministro."
  },
  {
    "objectID": "posts/2025-02-03-master_plan/index.html#revisa-el-plan",
    "href": "posts/2025-02-03-master_plan/index.html#revisa-el-plan",
    "title": "Indispensable crear el PLAN",
    "section": "Revisa el plan",
    "text": "Revisa el plan\nCon todo esto en mente, quiero recordarte que aquí creamos una aplicación que optimiza un plan de mantenimiento, para nosotros un buen plan que se diseñó considerando las variables importantes que pensamos podrían modelar nuestro problema. Ese es el plan, ahora nuestro deber es integrarlo con las otras áreas para lograr ejecutarlo."
  },
  {
    "objectID": "posts/2025-02-05-intro_ml/index.html",
    "href": "posts/2025-02-05-intro_ml/index.html",
    "title": "Introducción al Machine Learning",
    "section": "",
    "text": "El aprendizaje automático puede parecer intimidante para aquellos que son nuevos en este campo. Este post tiene como objetivo familiarizar a los lectores con los fundamentos del aprendizaje automático y hacer que se dé cuenta de lo maravilloso que es este tema. Ey, date cuenta! Vamos a explorar los conceptos preliminares del aprendizaje automático y establecer los fundamentos para aprender conceptos avanzados. Primero, los conceptos básicos del aprendizaje automático y algunas perspectivas sobre la inteligencia artificial y el aprendizaje profundo (deep learning). Luego, la evolución gradual del aprendizaje automático a lo largo de la historia, en orden cronológico desde 1940 hasta la actualidad. Después, veremos la motivación, el propósito y la importancia del aprendizaje automático en función de algunas aplicaciones prácticas en la vida real. A continuación, se introduce el conocimiento previo necesario para dominar el aprendizaje automático, para asegurarse de que los lectores sean conscientes qué necesitan saber antes de comenzar su curso sobre aprendizaje automático. Finalmente discutimos los lenguajes de programación y herramientas asociadas necesarias para utilizar el aprendizaje automático. Todo es lo hacemos utilizando R como lenguaje de programación, RStudio como editor de código o compilador, y esta escrito en documento de Quarto (.qmd). Antes de la conclusión, revisamos algunos ejemplos reales de aprendizaje automático que todos los lectores de ingeniería podrán relacionar, lo que despertará su curiosidad para entrar en el mundo del aprendizaje automático."
  },
  {
    "objectID": "posts/2025-02-05-intro_ml/index.html#introducción",
    "href": "posts/2025-02-05-intro_ml/index.html#introducción",
    "title": "Introducción al Machine Learning",
    "section": "",
    "text": "El aprendizaje automático puede parecer intimidante para aquellos que son nuevos en este campo. Este post tiene como objetivo familiarizar a los lectores con los fundamentos del aprendizaje automático y hacer que se dé cuenta de lo maravilloso que es este tema. Ey, date cuenta! Vamos a explorar los conceptos preliminares del aprendizaje automático y establecer los fundamentos para aprender conceptos avanzados. Primero, los conceptos básicos del aprendizaje automático y algunas perspectivas sobre la inteligencia artificial y el aprendizaje profundo (deep learning). Luego, la evolución gradual del aprendizaje automático a lo largo de la historia, en orden cronológico desde 1940 hasta la actualidad. Después, veremos la motivación, el propósito y la importancia del aprendizaje automático en función de algunas aplicaciones prácticas en la vida real. A continuación, se introduce el conocimiento previo necesario para dominar el aprendizaje automático, para asegurarse de que los lectores sean conscientes qué necesitan saber antes de comenzar su curso sobre aprendizaje automático. Finalmente discutimos los lenguajes de programación y herramientas asociadas necesarias para utilizar el aprendizaje automático. Todo es lo hacemos utilizando R como lenguaje de programación, RStudio como editor de código o compilador, y esta escrito en documento de Quarto (.qmd). Antes de la conclusión, revisamos algunos ejemplos reales de aprendizaje automático que todos los lectores de ingeniería podrán relacionar, lo que despertará su curiosidad para entrar en el mundo del aprendizaje automático."
  },
  {
    "objectID": "posts/2025-02-05-intro_ml/index.html#qué-es-machine-learning",
    "href": "posts/2025-02-05-intro_ml/index.html#qué-es-machine-learning",
    "title": "Introducción al Machine Learning",
    "section": "Qué es Machine Learning?",
    "text": "Qué es Machine Learning?\nLa tecnología moderna está mejorando y acelerándose gracias a la investigación, experimentación y desarrollo extensivos y continuos. Por ejemplo, las máquinas están volviéndose inteligentes y realizan tareas de manera mucho más eficiente. El aprendizaje automático ha estado evolucionando a un ritmo sin precedentes, y los resultados son evidentes en nuestros teléfonos y computadoras, que se están convirtiendo en más multifuncionales cada día, los sistemas de automatización están volviéndose omnipresentes, se están construyendo robots inteligentes y así sucesivamente.\nEn 1959, el científico de la computadora y pionero del aprendizaje automático Arthur Samuel definió el aprendizaje automático como el “campo de estudio que le da a los ordenadores la capacidad de aprender sin ser programados explícitamente”. El libro de Tom Mitchell de 1997 sobre aprendizaje automático definió el aprendizaje automático como “el estudio de los algoritmos de computadora que permiten a los programas de computadora mejorar automáticamente a través de la experiencia”. Define el aprendizaje de la siguiente manera: “Un programa de computadora se dice que aprende de la experiencia E con respecto a alguna clase de tareas T y medida de rendimiento P, si su rendimiento en tareas en T, medido por P, mejora con la experiencia E”. El aprendizaje automático (ML) es una rama del aprendizaje artificial (AI) que permite a los ordenadores y máquinas aprender de la información existente y aplicar ese aprendizaje para realizar otras tareas similares. Sin programación explícita, la máquina aprende a partir de los datos que se le proporcionan. La máquina identifica o aprende patrones, tendencias o características esenciales a partir de datos previos y hace una predicción sobre nuevos datos. Un ejemplo de aplicación real del aprendizaje automático es los sistemas de recomendación. Por ejemplo, un sitio de streaming de películas recomendará películas al usuario basadas en su lista de películas vistas previamente.\nLos algoritmos de ML se clasifican ampliamente como aprendizaje supervisado y aprendizaje no supervisado, con otros tipos como el aprendizaje por refuerzo y aprendizaje semisupervisado. Lo más seguro es que tendrás otros posts sobre estos temas.\n\nFlujo de trabajo de Machine Learning\nAntes de profundizar en los detalles, un principiante debe tener una visión holística del flujo de trabajo completo del aprendizaje automático. La visión general del proceso revela que hay cuatro pasos principales en un flujo de trabajo típico de ML: recopilación de conjuntos de datos, preprocesamiento de datos, entrenamiento del modelo y, finalmente, evaluación del modelo. La figura 1 muestra el diagrama de bloques de los cuatro pasos del flujo de trabajo de ML. Estos pasos se siguen generalmente en todas las aplicaciones de ML:\n\n\n\n\n\n\nflowchart LR\n    A(Paso 1: Recopilación de conjunto de datos) --&gt; B(Paso 2: Preprocesamiento de conjunto de datos)\n    B(Paso 2: Preprocesamiento de conjunto de datos) --&gt; C(Paso 3: Entrenamiento del modelo)\n    C(Paso 3: Entrenamiento del modelo) --&gt; D(Paso 4: Evaluación del modelo)\n    D(Paso 4: Evaluación del modelo) --&gt; B(Paso 2: Preprocesamiento de conjunto de datos)\n    D(Paso 4: Evaluación del modelo) --&gt; C(Paso 3: Entrenamiento del modelo)\n    D(Paso 4: Evaluación del modelo) --&gt; A(Paso 1: Recopilación de conjunto de datos)\n\n\n\n\nFigura 1: El diagrama de bloques del flujo de trabajo de aprendizaje automático\n\n\n\n\n\n\nRecopilación de conjuntos de datos: El primer paso del ML es recopilar el conjunto de datos. Este paso depende del tipo de experimentos o proyectos que se desean realizar. Diferentes experimentos o proyectos requieren diferentes datos. También se debe decidir qué tipo de datos se requieren. ¿Serán datos numéricos o categóricos? Por ejemplo, si queremos realizar una predicción sobre los precios de las casas, necesitaríamos la siguiente información: el precio de las casas, la dirección de las casas, el número de habitaciones, el estado de la casa, el tamaño de la casa, etc. Luego surge la pregunta: ¿qué unidad de precio debería ser? ¿Dólares, libras o alguna otra moneda?\nPreprocesamiento de datos: Los datos que recopilamos a menudo están desorganizados y no pueden ser utilizados directamente para entrenar modelos. Antes de proceder al siguiente paso, los datos necesitan ser preprocesados. Primero, el conjunto de datos puede contener datos faltantes o ruidosos. Este problema necesita ser resuelto antes de pasar los datos al modelo. Diferentes datos pueden estar en diferentes rangos, lo que podría ser un problema para los modelos, por lo que los datos necesitan ser estandarizados para que todos los datos estén en el mismo rango. Además, no todos los datos serían igualmente importantes para predecir la variable objetivo. Necesitamos encontrar y seleccionar los datos que contribuyen más a encontrar las variables objetivo. Finalmente, el conjunto de datos debe ser dividido en dos conjuntos: el conjunto de entrenamiento y el conjunto de prueba. La división se hace generalmente en una relación de 80:20, donde el 80% del conjunto de datos es el conjunto de entrenamiento y el 20% es el conjunto de prueba. Esta relación puede variar según el tamaño del conjunto de datos y la naturaleza del problema. Aquí, el conjunto de entrenamiento se utilizará para entrenar los modelos, y el conjunto de prueba se utilizará para evaluar los modelos. A menudo, el conjunto de datos se divide en conjuntos de entrenamiento, validación y prueba. El conjunto de validación se utiliza para ajustar los hiperparámetros, lo que se discutirá en el Capítulo 2 de este libro. La figura 2 muestra los diferentes pasos de preprocesamiento de datos. Estos pasos se explicarán en el Capítulo 3.\nEntrenamiento del modelo: Basado en el problema, se debe seleccionar el tipo de modelo requerido primero. Mientras se selecciona el modelo, se debe considerar la información disponible sobre el conjunto de datos. Por ejemplo, la clasificación supervisada se puede abordar si el conjunto de datos contiene información sobre ambos valores de entrada y salida. A veces, se necesitan utilizar más de un modelo para entrenar y hacer el trabajo. El modelo ajusta o aprende los datos. Este paso es muy importante porque el rendimiento del modelo depende mucho de cómo bien los datos han sido ajustados o aprendidos por el modelo. Mientras se entrena el modelo, se debe tener cuidado de no subajustar o sobreadjustar el modelo. Subajustar y sobreadjustar se han explicado en el Capítulo 2.\nEvaluación del modelo: Una vez que el modelo se ha construido y entrenado, es esencial entender cómo bien se ha entrenado el modelo, cómo bien funcionará y si el modelo será útil para el experimento. Sería inútil si el modelo no funciona bien o no cumple con su propósito. Por lo tanto, se utiliza el conjunto de prueba para probar el modelo, y se utilizan diferentes métricas de evaluación para evaluar y comprender el modelo. Las métricas de evaluación incluyen precisión, recall y algunas otras, que se utilizan para obtener una visión general de cómo bien funcionará el modelo. Las métricas de evaluación se han discutido en el Capítulo 2. Basado en la evaluación del modelo, puede ser necesario regresar a los pasos anteriores y realizarlos de nuevo según sea necesario.\n\n\n\n\n\n\n\nflowchart LR\n    A[\"`**Prepocesamiento de Datos**`\"] --&gt; B(\"`**Integración de Datos**\n    - Integración de esquemas\n    - Problema de identificación de entidad\n    - Detección y resolución de conceptos de valores de datos`\")\n    A[\"`**Prepocesamiento de Datos**`\"] --&gt; C(\"`**Reducción de Datos o Dimensión**\n    - Agregación de cubo de Datos\n    - Selección de subconjunto de Atributos\n    - Reducción de numerosidad\n    - Reducción de dimensionalidad`\")\n    A[\"`**Prepocesamiento de Datos**`\"] --&gt; D(\"`**Transformación de Datos**\n    - Normalización\n    - Selección de Atributos\n    - Discretización\n    - Generación de Jerarquía de Conceptos`\")\n    A[\"`**Prepocesamiento de Datos**`\"] --&gt; E(\"`**Limpieza de Datos**\n    - Datos faltantes\n    - Datos ruidosos`\")\n\n\n\n\nFigura 2: El diagrama de bloques de preprocesamiento de datos\n\n\n\n\n\n\n\nQué no es Machine Learning?\nEl aprendizaje automático es un término en boga en el mundo actual. Casi todos los campos de la ciencia y la tecnología involucran uno o más aspectos del ML. Sin embargo, es necesario distinguir entre lo que es ML y lo que no lo es. Por ejemplo, el programar en sentido general no es ML, ya que un programa explícitamente indica o instruye a una máquina qué hacer y cuándo hacerlo sin permitir que la máquina aprenda por sí misma y aplique el aprendizaje en un entorno similar pero nuevo. Un sistema de recomendación que está diseñado explícitamente para dar recomendaciones no es una aplicación de ML. Si el sistema está diseñado de manera que se le dé un conjunto específico de películas como condiciones y se le sugiera una película explícitamente, como:\n\nSi la persona ha visto Harry Potter o Pirates of the Caribbean o El Señor de los Anillos, entonces recomiende Animales Fantásticos a la persona. También si la persona ha visto Divergente o Maze Runner, recomiende Juegos del Hambre.\n\nEste sistema de recomendación no es una aplicación de ML. Aquí, la máquina no explora ni aprende tendencias, características o características de películas previamente vistas. En su lugar, simplemente se basa en las condiciones dadas y sugiere la película dada. Para un sistema de recomendación basado en ML, el programa no indica explícitamente al sistema qué película recomendar basada en la lista de películas vistas previamente. En su lugar, se programa de manera que el sistema explore la lista de películas vistas previamente. Busca características significativas o características como géneros, actores, directores, productores, etc. También verifica qué películas han sido vistas por otros usuarios para que el sistema pueda formar un tipo de grupo. Basado en este aprendizaje y observación, el sistema concluye y da una recomendación. Por ejemplo, la lista de películas de una persona es como sigue: Sully, Catch Me If You Can, Captain Philips, Inception y Interstellar. Se pueden extraer las siguientes conclusiones de esta lista:\n• Tres de las películas son de género biográfico; las otras dos son de ciencia ficción.\n• Tres de las películas tienen a Tom Hanks en ellas.\n• Las películas de ciencia ficción en la lista están dirigidas por Christopher Nolan.\nBasado en este patrón, el sistema puede recomendar películas biográficas que no incluyan a Tom Hanks. El sistema también recomendará más películas de Tom Hanks que pueden ser biográficas o de otros géneros. También puede recomendar películas de ciencia ficción que hayan estrellado a Tom Hanks. El sistema también recomendará más películas dirigidas por Christopher Nolan. Como este sistema decide por aprender los patrones de la lista de películas vistas, se considerará una aplicación de ML.\n\n\nJerga de Machine Learning\nMientras vamos a través estos posts, vamos a encontrar muchos términos relacionados con el aprendizaje automático. Por lo tanto, es esencial que entendamos este jargon. Los términos que necesitamos entender se discuten en esta sección.\n\nCaracterísticas\nLas características, también conocidas como atributos, variables predictivas o variables independientes, son simplemente las características o etiquetas del conjunto de datos. Supongamos que tenemos información sobre la altura y el peso de sesenta estudiantes en una clase. La altura y el peso son conocidos como características dentro del conjunto de datos. Estas características se extraen del conjunto de datos bruto y se alimentan a los modelos como entradas.\n\n\nVariable objetivo\nSimplemente, las variables objetivo son los outputs que los modelos deben dar. Por ejemplo, una reseña de película debe clasificarse como positiva o negativa. Aquí, la variable positiva/negativa es la variable objetivo en este caso. Primero, esta variable objetivo debe ser determinada por el usuario. Luego, después de que se determine la variable objetivo, se debe entender la relación entre las características y la variable objetivo para realizar operaciones adicionales.\n\n\nProblema de optimización\nLos problemas de optimización se definen como una clase de problemas que buscan la solución óptima bajo un conjunto de condiciones dadas. Estos problemas suelen involucrar un trade-off entre diferentes condiciones. Por ejemplo, un batería debe ser comprada para respaldo de energía en una residencia, pero estamos indecisos sobre el tamaño adecuado de la batería, que viene en \\(6.4\\) y \\(13.5\\) kWh. Si compramos el tamaño más grande, podemos almacenar más energía y disfrutar de una variedad de características adicionales de la batería, pero también debemos pagar más. Si compramos el tamaño más pequeño, podemos almacenar menos energía y obtener poco o nada de características adicionales, pero ahorraremos más dinero. Necesitamos optimizar nuestras necesidades en este escenario. Si solo requerimos respaldo de energía sin requisitos especiales para las características adicionales, el tamaño más pequeño será suficiente para satisfacer la necesidad. Esto sería la solución óptima para el dilema de la batería.\n\n\nFunción objetivo\nGeneralmente, más de una solución existe para un problema. Entre todas las soluciones, se requiere encontrar la solución óptima, lo que se hace usualmente midiendo una cantidad y requiriendo que se ajuste a un estándar. La función objetivo es el estándar que la solución óptima debe cumplir. La función objetivo se diseña para tomar parámetros y evaluar el rendimiento de la solución. El objetivo de la función objetivo puede variar según el problema en consideración. Maximizar o minimizar un parámetro particular puede ser necesario para calificar la solución como óptima. Por ejemplo, muchos algoritmos de aprendizaje automático utilizan una medida de distancia (Euclideana, Manhattan o Minkowski) como función objetivo.\n\n\nFunción de costo\nLa función de costo se utiliza para entender cómo bien se desempeña el modelo en un conjunto de datos dado. La función de costo también calcula la diferencia entre los valores de salida predichos y los valores de salida reales. Por lo tanto, la función de costo y la función de pérdida pueden parecer similares. Sin embargo, la función de pérdida se calcula para un solo punto de datos después de un solo entrenamiento, y la función de costo se calcula para un conjunto de datos dado después de que se complete el entrenamiento del modelo. Por lo tanto, se puede inferir que la función de costo es la función de pérdida promedio para el conjunto de datos completo después del entrenamiento del modelo. Los términos función de pérdida y función de costo se utilizan a menudo de manera intercambiable en el aprendizaje automático. Al igual que las funciones de pérdida, se utilizan diferentes tipos de funciones de costo en diferentes contextos y algoritmos de aprendizaje automático.\nSupongamos que \\(J\\) es una función de costo utilizada para evaluar el rendimiento de un modelo. Generalmente se define con la función de pérdida \\(L\\). La forma generalizada de la función de costo \\(J\\) se da a continuación:\n\\[\nJ(𝛳)=∑^m_{i=1}L(h_{𝛳}(x^i),y^i)\n\\tag{1}\\]\nDonde \\(θ\\) es un parámetro que se está optimizando, \\(m\\) es el número de muestras de entrenamiento, \\(i\\) es el número de ejemplos y salidas, \\(h\\) es la función de hipótesis del modelo, \\(x\\) es el valor predicho estimado, \\(y\\) es el valor verdadero (ground truth value).\n\n\nFunción de pérdida\nSupongamos que se da una función \\(L : (z, y) ∈ ℝ × Y → L(z, y) ∈ ℝ\\). La función \\(L\\) toma \\(z\\) como entradas, donde \\(z\\) es el valor predicho proporcionado por un modelo de aprendizaje automático. La función luego compara \\(z\\) con respecto a su valor real correspondiente \\(y\\) y produce un valor que indica la diferencia entre el valor predicho y el valor real. Esta función se conoce como una función de pérdida.\nLa función de pérdida es significativa porque explícitamente explica cómo los modelos se desempeñan al modelar los datos que se les están proporcionando. La función de pérdida calcula el error, que es la diferencia entre el valor de salida predicho y el valor de salida real. Por lo tanto, es intuitivo que un valor más bajo de la función de pérdida indica un valor de error más bajo, lo que implica que el modelo ha aprendido o ajustado los datos bien. Mientras se aprenden los datos, el objetivo del entrenamiento del modelo es siempre reducir el valor de la función de pérdida.\nDespués de cada iteración de entrenamiento, el modelo sigue haciendo cambios necesarios basados en el valor de la función de pérdida actual para minimizarla. Se utilizan diferentes tipos de funciones de pérdida para diferentes algoritmos de aprendizaje automático.\n\n\nComparación entre la función de pérdida, la función de costo y la función objetivo\nAmbas, la función de pérdida y la función de costo, representan el valor de error, es decir, la diferencia entre el valor de salida y el valor real, para determinar cómo de bien un modelo de aprendizaje automático se desempeña al ajustarse a los datos. Sin embargo, la diferencia entre las funciones de pérdida y costo es que la función de pérdida mide el error para un solo punto de datos solo, mientras que la función de costo mide el error para todo el conjunto de datos. La función de costo suele ser la suma de la función de pérdida y algún tipo de penalización.\nPor otro lado, la función objetivo es una función que necesita ser optimizada, es decir, maximizada o minimizada, para obtener el objetivo deseado. La función de pérdida es parte de la función de costo; al mismo tiempo, la función de costo se puede utilizar como parte de la función objetivo.\nEn resumen, la función de pérdida mide el error para un solo punto de datos, la función de costo mide el error para todo el conjunto de datos y la función objetivo es una función que necesita ser optimizada para obtener el objetivo deseado.\n\n\nAlgoritmo, modelo/hipótesis y técnica\nComo principiante, es esencial poder diferenciar entre modelos y algoritmos de aprendizaje automático. Un algoritmo en ML es la instrucción paso a paso proporcionada en forma de código y ejecutada en un conjunto de datos específico. Este algoritmo es análogo a un código de programación general. Por ejemplo, encontrar el promedio aritmético de un conjunto de números. De manera similar, en ML, un algoritmo se puede aplicar para aprender las estadísticas de un conjunto de datos o aplicar estadísticas actuales para predecir cualquier dato futuro.\nPor otro lado, un modelo de ML puede ser representado como un conjunto de parámetros que se aprenden a partir de datos dados. Por ejemplo, supongamos una función \\(f (x) = xθ\\), donde \\(θ\\) es el parámetro de la función dada y \\(x\\) es la entrada. Así, para una entrada \\(x\\) dado, el output depende del parámetro de la función \\(θ\\). De manera similar, en ML, la entrada \\(x\\) se etiqueta como la característica de entrada, y \\(θ\\) se define como un parámetro de modelo de ML. El objetivo de cualquier algoritmo de ML es aprender el conjunto de parámetros de un modelo dado. En algunos casos, el modelo también se conoce como una hipótesis. Supongamos que la hipótesis o modelo se denota por \\(h_θ\\). Si se ingiere datos \\(x(i)\\) al modelo, el output predicho será \\(h_θ (x(i))\\).\nEn contraste, una técnica de ML puede verse como un enfoque general para intentar resolver un problema en particular. En muchos casos, puede ser necesario combinar una amplia variedad de algoritmos para desarrollar una técnica para resolver un problema de ML.\n\n\n\nDiferencia entre la ciencia de datos, el aprendizaje automático, la inteligencia artificial y el aprendizaje profundo\nLa ciencia de datos (DS), la inteligencia artificial (AI), el aprendizaje automático (ML) y el aprendizaje profund (DL) o son términos relacionados estrechamente, y las personas suelen confundirlos o utilizarlos de manera alternativa. Sin embargo, estos son campos de tecnología claramente separados. El aprendizaje automático cae dentro del subconjunto de la inteligencia artificial, mientras que el aprendizaje profundo se considera que cae dentro del subconjunto del aprendizaje automático, como se demuestra en la Fig. 3.\n\n\n\n\n\n\nFigura 3: Figure 3. El aprendizaje profundo cae dentro del subconjunto del aprendizaje automático, y el aprendizaje automático cae dentro del subconjunto de la inteligencia artificial. La ciencia de datos implica una parte de todos estos tres campos.\n\n\n\nLa diferencia entre el aprendizaje automático y el aprendizaje profundo radica en el hecho de que el aprendizaje profundo requiere más recursos de computación y conjuntos de datos muy grandes. Gracias al avance de los recursos de computación en hardware, las personas están pasando hacia enfoques de aprendizaje profundo para resolver problemas similares que el aprendizaje automático puede resolver. El aprendizaje profundo es especialmente útil para manejar grandes volúmenes de texto o imágenes.\nLa ciencia de datos es un campo interdisciplinario que implica identificar patrones en los datos y hacer inferencias, predicciones o insights a partir de ellos. La ciencia de datos está estrechamente relacionada con el aprendizaje profundo, el minería de datos y los grandes datos. Aquí, la minería de datos es el campo que se ocupa de identificar patrones y extraer información de conjuntos de datos grandes utilizando técnicas que combinan estadística, sistemas de bases de datos y ML, y por definición, los grandes datos se refieren a datos vastos y complejos que son demasiado grandes para ser procesados por sistemas tradicionales utilizando algoritmos tradicionales. El ML es una de los principales herramientas utilizadas para ayudar al proceso de análisis de datos en la ciencia de datos, especialmente para hacer extrapolaciones o predicciones sobre tendencias futuras de datos.\nPor ejemplo, predecir el precio del mercado de casas en el próximo año es una aplicación de ML. Considere un conjunto de datos de muestra como se muestra en la tabla 1.1.\n\n\n\nTabla 1: Tabla 1.1. Muestra de datos de precios de casas.\n\n\n\n\n\nAño\nPrecio\n\n\n\n\n2001\n$200\n\n\n2002\n$400\n\n\n2003\n$800\n\n\n\n\n\n\nLa observación de los datos en la tabla 1.1 nos permite formar la intuición de que el próximo precio en 2004 será de $1600. Esta intuición se forma basada en los precios de las casas de los años anteriores, que muestran una tendencia clara de duplicar el precio cada año.\nSin embargo, para conjuntos de datos grandes y complejos, esta predicción no puede ser tan sencilla. Luego, requerimos un modelo de predicción de ML para predecir los precios de las casas.\nCon suficientes recursos de computación, estos problemas pueden ser resueltos utilizando modelos de aprendizaje profundo categorizados bajo aprendizaje profundo. En general, el aprendizaje automático y el aprendizaje profundo caen dentro de la inteligencia artificial, pero todos requieren el procesamiento, preparación y limpieza de los datos disponibles; por lo tanto, la ciencia de datos es una parte integral de todos estos tres ramas."
  },
  {
    "objectID": "posts/2025-02-05-intro_ml/index.html#desarrollo-histórico-de-machine-learning",
    "href": "posts/2025-02-05-intro_ml/index.html#desarrollo-histórico-de-machine-learning",
    "title": "Introducción al Machine Learning",
    "section": "Desarrollo histórico de Machine Learning",
    "text": "Desarrollo histórico de Machine Learning\nEl aprendizaje automático ha estado en desarrollo desde la década de 1940. No es el fruto de la mente de un humano ingenioso ni el resultado de un evento en particular. La ciencia multifacética del aprendizaje automático ha sido moldeada por años de estudios y investigación, y por los esfuerzos dedicados de numerosos científicos, ingenieros, matemáticos, programadores, investigadores y estudiantes. El aprendizaje automático es un campo en constante progreso y sigue en desarrollo. La tabla 1.2 enumera los hitos más significativos marcados en la historia del desarrollo del aprendizaje automático. No te asustes si no conoces aún algunos de los términos mencionados en la tabla. Los exploraremos más adelante.\n\n\n\nTabla 2: Tabla 1.2. Desarrollo histórico de Machine Learning\n\n\n\n\n\n\n\n\n\nAño\nDesarrollo\n\n\n\n\n1940s\nEl artículo “A logical calculus of the ideas immanent in nervous activity”, credao por Walter Pitts y Warren McCulloch en 1943, es el primero en discutir el modelo matemático de redes neuronales.\n\n\n1950s\n• El término “Aprendizaje Automático” es utilizado por primera vez por Arthur Samuel. Diseñó un programa de ajedrez por computadora que estaba a la altura de los juegos de nivel superior. • En 1951, Marvin Minsky y Dean Edmonds desarrollaron la primera red neuronal artificial compuesta por 40 neuronas. La red neuronal tenía capacidades de memoria a corto y largo plazo. • El taller de dos meses en Dartmouth en 1956 introduce por primera vez la investigación en Inteligencia Artificial (IA) y Aprendizaje Automático (AA). Muchos reconocen este taller como el “lugar de nacimiento de la IA”.\n\n\n1960s\n• En 1960, Alexey (Oleksii) Ivakhnenko y Valentin Lapa presentan la representación jerárquica de una red neuronal. Alexey Ivakhnenko se considera el padre del aprendizaje profundo. • Thomas Cover y Peter E. Hart publicaron un artículo sobre los algoritmos de vecino más cercano en 1967. Estos algoritmos se utilizan ahora para tareas de regresión y clasificación en el aprendizaje automático. • Un proyecto relacionado con un robot inteligente, Stanford Cart, comenzó en esta década. El objetivo era navegar a través de un espacio 3D de manera autónoma.\n\n\n1970s\n• Kunihiko Fukushima, un científico informático japonés, publicó un trabajo sobre reconocimiento de patrones utilizando redes neuronales jerárquicas y multilayered. Este trabajo más tarde sentó las bases para las redes neuronales convolucionales. • El proyecto Stanford Cart finalmente logró recorrer una habitación llena de sillas durante cinco horas sin intervención humana en 1979.\n\n\n1980s\n• En 1985, se inventa la red neuronal artificial llamada NETtalk por Terrence Sejnowski. NETtalk puede simplificar modelos de tareas cognitivas humanas de manera que las máquinas puedan aprender a hacerlas. • La máquina de Boltzmann restringida (RBM), inicialmente llamada Harmonium, inventada por Paul Smolensky, se introduce en 1986. Puede analizar un conjunto de entrada y aprender distribución de probabilidades a partir de él. En la actualidad, la RBM modificada por Geoffrey Hinton se utiliza para modelado de temas, recomendaciones impulsadas por inteligencia artificial, clasificación, regresión, reducción de dimensionalidad, filtrado colaborativo, etc.\n\n\n1990s\n• El boosting para el aprendizaje automático se introduce en el papel “The Strength of Weak Learnability”, creado por Robert Schapire y Yoav Freund en 1990. El algoritmo de boosting aumenta la capacidad predictiva de los modelos de inteligencia artificial. El algoritmo genera y combina muchos modelos débiles utilizando técnicas como la media o la votación en las predicciones. • En 1995, Tin Kam Ho introduce bosques de decisiones aleatorios en su artículo. El algoritmo crea múltiples árboles de decisión aleatoriamente y los combina para crear un “bosque”. El uso de múltiples árboles de decisión mejora significativamente la precisión de los modelos. • En 1997, Christoph Bregler, Michele Covell y Malcolm Slaney desarrollan el software “deepfake” más antiguo del mundo. • El año 1997 será un hito importante en el AI. El programa de ajedrez basado en IA, Deep Blue, derrotó a uno de los mejores jugadores de ajedrez de la historia humana, Garry Kasparov. Este incidente arrojó nueva luz sobre la tecnología de IA.\n\n\n2000\nIgor Aizenberg, un investigador de redes neuronales, introduce por primera vez el término “aprendizaje profundo”. Utilizó este término para describir las redes más grandes compuestas por neuronas de umbral booleano.\n\n\n2009\nFei-Fei Li lanzó el conjunto de datos más extenso de imágenes etiquetadas, ImageNet. Fue diseñado para contribuir a proporcionar datos de entrenamiento versátiles y reales para modelos de IA y ML. The Economist ha comentado sobre ImageNet como un evento excepcional para popularizar la IA a lo largo de la comunidad tecnológica y dar un paso hacia un nuevo era de historia del aprendizaje profundo.\n\n\n2011\nEl equipo de X Lab de Google desarrolla un algoritmo de inteligencia artificial llamado Google Brain para el procesamiento de imágenes, que es capaz de identificar gatos en imágenes.\n\n\n2014\n\nIan Goodfellow y sus colegas desarrollaron redes neuronales generadoras adversarias (GANs). Los marcos se utilizan para que los modelos de IA sean capaces de generar datos enteramente nuevos dados su conjunto de entrenamiento.\nEl equipo de investigación de Facebook desarrolló DeepFace, que puede distinguir caras humanas casi tan bien como los seres humanos con una tasa de precisión del 97,35%. DeepFace es una red neuronal compuesta por nueve capas. La red se entrena en más de 4 millones de imágenes tomadas de usuarios de Facebook.\nGoogle ha comenzado a utilizar Sibyl para hacer predicciones para sus productos. Sibyl es un sistema de aprendizaje automático a escala más amplia. El sistema consta de muchos nuevos algoritmos combinados. Ha mejorado significativamente el rendimiento a través de boosting paralelo y datos orientados a columnas. Además, utiliza el comportamiento de los usuarios para clasificar productos y publicidad.\nEugene Goostman, un chatbot de IA desarrollado por tres amigos de San Petersburgo en 2001, se considera el primer chatbot de IA que se asemeja a la inteligencia humana. Este personaje de IA se representa como un niño de 13 años de Odessa, Ucrania, que tiene un conejo de Indias y un padre ginecólogo. Eugene Goostman superó la competencia del test de Turing el 7 de junio de 2014 en la Royal Society.\n\n\n\n2015\nEl primer programa de IA “AlphaGo” supera a un jugador profesional de Go. Go era un juego que inicialmente era imposible enseñar a una computadora.\n\n\n2016\nUn grupo de científicos presenta Face2Face durante la Conferencia sobre Visión por Computadora y Reconocimiento de Patrones. La mayoría del software “deepfake” utilizado en la actualidad se basa en la lógica y los algoritmos de Face2Face.\n\n\n2017\n\nSe introducen coches autónomos o sin conductor en EE. UU. por parte de Waymo.\nSe publica el famoso papel “Attention is All You Need”, que introduce la arquitectura del Transformer basada en el mecanismo de autoatención, lo que conduce a un progreso significativo en el procesamiento de lenguaje natural.\n\n\n\n2021\nGoogle DeepMind’s AlphaFold 2 model places first in the CASP13 protein folding competition in the free modeling (FM) category, bringing a breakthrough in deep-learning-based protein structure prediction.\n\n\n2022\nOpenAI y Google revolucionan los modelos de lenguaje grande para uso masivo. Diversas aplicaciones del aprendizaje automático han comenzado a convertirse en parte de las actividades diarias."
  },
  {
    "objectID": "posts/2025-02-05-intro_ml/index.html#por-qué-machine-learning",
    "href": "posts/2025-02-05-intro_ml/index.html#por-qué-machine-learning",
    "title": "Introducción al Machine Learning",
    "section": "Por qué Machine Learning?",
    "text": "Por qué Machine Learning?\nAntes de profundizar más, es importante tener una visión clara de la finalidad y los motivos detrás del aprendizaje automático. Por lo tanto, las secciones siguientes discutirán la finalidad, los motivos y la importancia del aprendizaje automático para que pueda implementarse en escenarios de vida real.\n\nMotivación\nLa motivación para crear un campo multidimensional como el aprendizaje automático surgió del trabajo monótono que los seres humanos tenían que realizar. Con el aumento del uso de sistemas de comunicación digital, dispositivos inteligentes y la Internet, se generan grandes cantidades de datos cada momento. Buscar y organizar todos esos datos cada vez que se necesita resolver un tarea es exhaustivo, tiempo consumidor y monótono. Por lo tanto, en lugar de ir a través del proceso laborioso de revisar billones de datos, los seres humanos optaron por un proceso más automatizado. El proceso automatizado busca encontrar patrones relevantes en los datos y luego utilizar estos patrones para evaluar y resolver tareas. Fue entonces cuando surgió el concepto de programación. Sin embargo, incluso con la programación, los seres humanos tenían que codificar explícitamente o instruir a las máquinas sobre qué hacer, cuándo y cómo hacerlo. Para superar el nuevo problema de codificar cada comando para que las máquinas lo entiendan, los seres humanos desarrollaron la idea de hacer que las máquinas aprendieran ellas mismas de la manera en que los seres humanos lo hacen - simplemente reconociendo patrones.\n\n\nPropósito\nEl propósito del aprendizaje automático es hacer que las máquinas inteligentes y automatizar tareas que de otra manera serían tediosas y propensas a errores humanos. El uso de modelos de aprendizaje automático puede hacer que las tareas sean más accesibles y eficientes en el tiempo.\nPor ejemplo, considere un conjunto de datos \\((x, y) = (0, 0);(1, 1);(2, 2);(3, ?)\\). Aquí, para definir la relación entre \\(x\\) y \\(y\\), \\(y\\) se puede expresar como una función de \\(x\\), es decir, \\(y = f (x) = θ x\\). Esta representación de los dos elementos del conjunto de datos se conoce como el modelo. El propósito del aprendizaje automático es aprender qué es \\(θ\\) a partir de los datos existentes y luego aplicar el aprendizaje automático para determinar que \\(θ = 1\\). Este conocimiento se puede utilizar luego para encontrar el valor del valor desconocido de \\(y\\) cuando \\(x = 3\\). Seguro aprenderás cómo formular el modelo hipotético y cómo resolver los valores de \\(θ\\).\n\n\nImportancia\nAl igual que las máquinas, la ciencia del aprendizaje automático se creó con el fin de hacer que las tareas humanas más fáciles. El análisis de datos era un trabajo tedioso y laborioso, propenso a muchos errores cuando se hacía manualmente. Pero gracias al aprendizaje automático, todos los seres humanos tienen que hacer es proporcionar la máquina con el conjunto de datos o la fuente del conjunto de datos, y la máquina puede analizar los datos, reconocer un patrón y tomar decisiones valiosas sobre los datos.\nOtra ventaja del aprendizaje automático es que los seres humanos no necesitan decirle a la máquina cada paso del trabajo. La máquina misma genera las instrucciones después de aprender de la entrada del conjunto de datos. Por ejemplo, un modelo de reconocimiento de imágenes no requiere decirle a la máquina sobre cada objeto en una imagen. En el caso del aprendizaje supervisado, solo necesitamos decirle a la máquina sobre los etiquetas (como vaca o perro) junto con sus atributos (como proporciones faciales, tamaño del cuerpo, tamaño de las orejas, presencia de cuernos, etc.), y la máquina identificará automáticamente los objetos etiquetados en cualquier imagen basada en los atributos marcados.\nEl aprendizaje automático también es esencial en el caso de la predicción de tendencias de datos desconocidos o futuras. Esta aplicación es extremadamente valiosa para crear planes de negocio y esquemas de marketing, y preparar recursos para el futuro. Por ejemplo, el aprendizaje automático puede ayudar a predecir el crecimiento futuro de las instalaciones de módulos solares, incluso hasta 2050 o 2100, basado en tendencias históricas de precios. En comparación con otras herramientas de predicción y técnicas, el aprendizaje automático puede predecir valores con mayor precisión y considerar muchos parámetros adicionales que no se pueden incorporar en fórmulas de predicción definidas utilizadas en herramientas de predicción tradicionales, como la extrapolación de datos estadísticos."
  },
  {
    "objectID": "posts/2025-02-05-intro_ml/index.html#conocimientos-previos-para-aprender-machine-learning",
    "href": "posts/2025-02-05-intro_ml/index.html#conocimientos-previos-para-aprender-machine-learning",
    "title": "Introducción al Machine Learning",
    "section": "Conocimientos previos para aprender Machine Learning",
    "text": "Conocimientos previos para aprender Machine Learning\nEl aprendizaje automático es una ciencia avanzada; una persona no puede simplemente sumergirse en el mundo del ML sin tener algún conocimiento y habilidades básicos. Para poder entender los conceptos de ML, utilizar los algoritmos y aplicar técnicas de ML en casos prácticos, una persona debe estar equipada con varios temas en matemáticas y ciencias avanzadas, algunos de los cuales se discuten en las siguientes secciones.\nEsta sección muestra solo los temas que un entusiasta de ML debe conocer antes de aprender ML. Los temas no se cubren en detalle aquí.\n\nÁlgebra Lineal\nLa álgebra lineal es la rama de matemáticas que se ocupa de las transformaciones lineales. Estas transformaciones lineales se realizan utilizando ecuaciones lineales y funciones lineales. Vectores y matrices se utilizan para notar las ecuaciones lineales y funciones lineales necesarias. Una buena base en álgebra lineal es requerida para entender la intuición más profunda detrás de diferentes algoritmos de ML. Es la base para resolver problemas como aquel de nuestra app de mantenimiento.\n\nEcuaciones Lineales\nLas ecuaciones lineales son más fáciles de describir matemáticamente y pueden combinarse con transformaciones de modelos no lineales. Hay dos propiedades de una ecuación para ser denominada lineal - homogeneidad y superposición. El conocimiento de ecuaciones lineales puede ser conveniente para modelar sistemas lineales. Un ejemplo de ecuación lineal es \\(p_1x_1 + p_2x_2 + ... + p_nx_n + q = 0\\), donde \\(x_1, x_2 ..., x_n\\) son las variables, \\(p_1, p_2 ..., p_n\\) son los coeficientes y \\(q\\) es un constante.\n\n\n\n\n\n\n\n\nFigura 4: Fig. 1.4. Ejemplos de dos líneas rectas con ecuaciones lineales\n\n\n\n\n\nUtilizando álgebra lineal, podemos resolver las ecuaciones de la Fig. 1.4, es decir, podemos encontrar la intersección de estas dos líneas. Las ecuaciones para las dos líneas son las siguientes:\n\\[\ny=\\frac{3}{5}x+2, (1.2)\n\\tag{2}\\]\n\\[\\frac{x}{5} + \\frac{y}{5} = 1.  (1.3) \\tag{3}\\]\nAhora, al resolver la ecuación \\((1.3)\\), obtenemos:\n\\[\nx+y=5,\n\\]\n\\[\n⟹x+(\\frac{3}{5}x+2)=5,\n\\]\n\\[\n⟹8x=15,\n\\]\n\\[\n⟹x=1.875.\n\\]\nPoniendo el valor de \\(x\\) en la ecuación \\((1.2)\\), obtenemos \\(y = 3.125\\). Por lo tanto, el punto de intersección es \\((x, y) = (1.875, 3.125)\\).\n\n\nTensor y Rango de Tensor\nUn tensor es un término general para vectores y matrices. Es la estructura de datos utilizada en modelos de ML. Un tensor puede tener cualquier dimensión. Un escalar es un tensor con cero dimensiones, un vector es un tensor con una dimensión y una matriz tiene dos dimensiones. Cualquier tensor con más de dos dimensiones se llama tensor n-dimensional. Vectores y matrices se discuten a continuación.\n\n\n\n\n\n\n\n\nFigura 5: Fig. 1.5. Ejemplo de un vector\n\n\n\n\n\n\nVector\nUn vector es un array unidimensional de números, términos o elementos. Las características del conjunto de datos se representan como vectores. Un vector se puede representar en dimensiones geométricas. Por ejemplo, un vector \\([3, 5]\\) se puede representar geométricamente en un espacio 2-dimensional, como se muestra en la Fig. 1.5. Este espacio se puede llamar espacio de vectores o espacio de características. En el espacio de vectores, un vector se puede visualizar como una línea con dirección y magnitud.\n\n\nMatriz\nUna matriz es un array bidimensional de escalares con una o más columnas y una o más filas. Un vector con más de una dimensión se llama matriz. El número de filas y columnas se expresa como la dimensión de esa matriz. Por ejemplo, una matriz con una dimensión de \\(4 × 3\\) contiene 4 filas y 3 columnas. Las operaciones de matrices proporcionan cálculos más eficientes que operaciones piecemeal para modelos de aprendizaje automático. Los matrices deben tener la misma dimensión para la suma y resta. Para la multiplicación de matrices, el tamaño de la columna del primer matriz y el tamaño de la fila del segundo matriz deben ser idénticos. Si se multiplica una matriz con dimensión \\(m × n\\) por una matriz con dimensión \\(n × p\\), entonces el resultado de esta multiplicación será una matriz con dimensión \\(m × p\\).\nLa ecuación 1.4 muestra la matriz \\(A\\) con una dimensión de \\(2 × 3\\) y la matriz \\(B\\) con una dimensión de \\(3 × 1\\). Por lo tanto, estas dos matrices se pueden multiplicar porque cumplen con la condición de multiplicación de matrices. El resultado de la multiplicación será la matriz \\(C\\), mostrada en la ecuación 1.5. Tiene una dimensión de \\(2 × 1\\).\n\\[A=\\begin{bmatrix}1&2&3\\\\4&5&6\\end{bmatrix}; B=\\begin{bmatrix}11\\\\12\\\\13\\end{bmatrix}.   (1.4) \\tag{4}\\]\n\\[\nProducto, C=\\begin{bmatrix}74\\\\182\\end{bmatrix}.   (1.5)\n\\tag{5}\\]\nAlgunas matrices fundamentales se utilizan con frecuencia, como la matriz de fila, la matriz cuadrada, la matriz de columna, la matriz de identidad, etc. Por ejemplo, una matriz que consiste solo en una fila se conoce como matriz de fila, y una matriz que consiste solo en una columna se conoce como matriz de columna. Una matriz que consiste en un número igual de filas y columnas se llama matriz cuadrada. Una matriz cuadrada con todos los 1’s a lo largo de su diagonal principal y todos los 0’s en todos los elementos no diagonales es una matriz de identidad. Se muestran ejemplos de matrices diferentes en la Fig. 1.6.\n\n\nRango vs. Dimensión\nRango y dimensión son dos términos relacionados pero distinos en álgebra lineal, aunque a menudo se utilizan indistintamente en aprendizaje automático. En perspectiva de aprendizaje automático, cada columna de una matriz o tensor representa cada característica o subespacio. Por lo tanto, la dimensión de su columna (es decir, subespacio) será el rango de esa matriz o tensor.\n\n\nComparación entre Escalar, Vector, Matriz y Tensor\nUn escalar es simplemente un valor numérico sin dirección asignada. Un vector es un array de números de una dimensión que denota una dirección específica. Una matriz es un array de números de dos dimensiones. Finalmente, un tensor es un array de datos de \\(n\\) dimensiones.\nSegún las cantidades mencionadas, escalares, vectores y matrices también pueden considerarse tensors, pero limitados a 0, 1 y 2 dimensiones, respectivamente. Las tablas 1.3 y 1.4 resumen las diferencias en el rango o dimensión de estas cuatro cantidades con ejemplos.\n \n\n\n\n\\[\\text{Cuadrada 2x2}\\begin{bmatrix}5&2\\\\-6&1\\end{bmatrix};\\\\\n\\text{Rectangular 3x2}\\begin{bmatrix}4&1\\\\2&-1\\\\-7&5\\end{bmatrix};\\\\\n\\text{Ceros 3x5}\\begin{bmatrix}0&0&0&0&0\\\\0&0&0&0&0\\\\0&0&0&0&0\\end{bmatrix};\\\\\n\\text{Fila 1x4}\\begin{bmatrix}5&-1&0&3\\end{bmatrix};\\\\\n\\text{Columna 3x1}\\begin{bmatrix}1\\\\2\\\\-7\\end{bmatrix};\\\\\n\\text{Identidad 3x3}\\begin{bmatrix}1&0&0\\\\0&1&0\\\\0&0&1\\end{bmatrix}\\]\n\n\nFigura 6\n\n\n\n\n\n\nTabla 3: Tabla 1.3. Comparación entre escalar, vector, matrix y tensor.\n\n\n\n\n\nRango/Dimensión\nObjeto\n\n\n\n\n0\nEscalar\n\n\n1\nVector\n\n\n2 o más\nMatriz \\(m * n\\)\n\n\nCualquiera\nTensor\n\n\n\n\n\n\n \n\n\n\nTabla 4: Tabla 1.4. Ejemplos de escalar, vector, matriz y tensor.\n\n\n\n\n\n\n\n\n\n\n\nEscalar\nVector\nMatriz\nTensor\n\n\n\n\n\\(1\\)\n\\(\\begin{bmatrix}1\\\\2\\end{bmatrix}\\)\n\\(\\begin{bmatrix}1&2\\\\3&4\\end{bmatrix}\\)\n\\(\\begin{bmatrix}\\begin{bmatrix}1&2\\end{bmatrix}&\\begin{bmatrix}3&4\\end{bmatrix}\\\\\\begin{bmatrix}5&6\\end{bmatrix}&\\begin{bmatrix}7&8\\end{bmatrix}\\end{bmatrix}\\)\n\n\n\n\n\n\n \n\n\n\nTabla 5: Tabla 1.5. Defición de media, mediana y moda.\n\n\n\n\n\nNombre\nDefinición\n\n\n\n\nMedia\nEl valor promedio aritmético.\n\n\nMediana\nEl valor del medio.\n\n\nModa\nEl valor más común.\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\nFigura 7: Fig. 1.7. Representación gráfica de la media, mediana y moda\n\n\n\n\n\n\n\n\n\nEstadística\nLa estadística es un campo vasto de las matemáticas que ayuda a organizar y analizar conjuntos de datos. El análisis de datos es mucho más fácil, rápido y preciso cuando las máquinas lo realizan. Por lo tanto, el aprendizaje automático se utiliza predominantemente para encontrar patrones dentro de los datos. La estadística es el componente fundamental del aprendizaje automático. Por lo tanto, es necesario tener conocimientos de términos estadísticos para aprovechar plenamente los beneficios del aprendizaje automático.\n\nMedidas de Tendencia Central\nLos tres términos estadísticos más comunes utilizados ampliamente en diversas aplicaciones son la media, la mediana y la moda. Estas tres funciones son las medidas de tendencia central de cualquier conjunto de datos, que denotan los valores centrales o medios del conjunto de datos. La tabla 1.5 establece las distinciones entre estos tres términos. Estas son las medidas de tendencia central de un conjunto de datos. La figura 1.7 proporciona una representación gráfica de la media, la mediana y la moda.\nSe presentan tres ejemplos aquí y en la tabla 1.6. Vamos a considerar el primer conjunto de datos: \\(\\{1, 2, 9, 2, 13, 15\\}\\). Para encontrar la media de este conjunto de datos, debemos calcular la suma de los números. Aquí, la suma es 42. El conjunto de datos tiene seis puntos de datos. Por lo tanto, la media de este conjunto de datos será 42 ÷ 6 = 7. A continuación, para encontrar la mediana del conjunto de datos, el conjunto de datos necesita ser ordenado en orden ascendente: \\(\\{1, 2, 2, 9, 13, 15\\}\\).\n\n\n\nTabla 6: Tabla 1.6. Varios conjuntos de datos y sus medidas de tendencia central\n\n\n\n\n\nConjuntos\n{1,2,9,2,13,15}\n{0,5,5,10}\n{18,22,24,24,25}\n\n\n\n\nMedia\n7\n5\n22.6\n\n\nMediana\n5.5\n5\n24\n\n\nModa\n2\n5\n24\n\n\n\n\n\n\nDado que el número de puntos de datos es par, tomaremos los dos valores medios y los promediamos para calcular la mediana. Para este conjunto de datos, el valor de mediana sería \\((2 + 9) ÷ 2 = 5.5\\). Para la moda, el punto de datos más repetido debe considerarse. Aquí, \\(2\\) es la moda para este conjunto de datos. Este conjunto de datos está desviado hacia la izquierda, es decir, la distribución de los datos es más larga hacia la izquierda o tiene una cola izquierda larga.\nDe manera similar, si consideramos el conjunto de datos \\(\\{0, 5, 5, 10\\}\\), la media, la mediana y la moda todos son \\(5\\). Este conjunto de datos está distribuido normalmente. ¿Puedes calcular la media, la mediana y la moda para el conjunto de datos desviado hacia la derecha \\(\\{18, 22, 24, 24, 25\\}\\)?\n\n\nDesviación Estándar\nLa desviación estándar (SD) se utiliza para medir la estimación de la variación de los puntos de datos en un conjunto de datos en relación con la media aritmética. Un conjunto de datos completo se conoce como una población, mientras que un subconjunto del conjunto de datos se conoce como una muestra. Las ecuaciones para calcular la desviación estándar de la población y la desviación estándar de la muestra se expresan como Ecuaciones 1.6 y 1.7, respectivamente.\n\\[\n\\text{Desviación estándar poblacional, } \\sigma=\\sqrt{\\frac{1}{N}\\sum_{i=1}^N{(x_i-\\mu)^2}}.\n\\tag{6}\\]\nDonde \\(\\sigma\\) simboliza la desviación estándar de la población, \\(i\\) es una variable que enumera los puntos de datos, \\(x_i\\) denota cualquier punto de datos particular, \\(\\mu\\) es la media aritmética de la población y \\(N\\) es el número total de puntos de datos en la población.\n\\[\n\\text{Desviación estándar muestral, } s=\\sqrt{\\frac{1}{N-1}\\sum_{i=1}^N{(x_i-\\overline{x})^2}}.\n\\tag{7}\\]\nDonde \\(s\\) simboliza la desviación estándar de la muestra, \\(i\\) es una variable que enumera los puntos de datos, \\(x_i\\) denota cualquier punto de datos particular, \\(x\\) es la media aritmética de la muestra y \\(N\\) es el número total de puntos de datos en la muestra.\nUn valor bajo de la desviación estándar indica que los puntos de datos se encuentran razonablemente cerca de la media del conjunto de datos, como se muestra en la Fig. 1.8a. Por otro lado, un valor alto de la desviación estándar indica que los puntos de datos se encuentran lejos de la media del conjunto de datos, cubriendo un rango amplio, como se muestra en la Fig. 1.8b.\n\n\n\n\n\n\n\n\nFigura 8: Fig. 1.8. Desviación estándas de los datos\n\n\n\n\n\n\n\nCorrelación\nLa correlación muestra cómo de fuerte es la relación entre dos variables. Es una medida estadística de la relación entre dos (y a veces más) variables. Por ejemplo, si una persona puede nadar, probablemente puede sobrevivir después de caerse de un barco. Sin embargo, la correlación no es causalidad. Una correlación fuerte no siempre significa una relación fuerte entre dos variables; podría ser pura coincidencia. Un ejemplo famoso en este sentido es la correlación entre las ventas de helado y los ataques de tiburones. Hay una correlación fuerte entre las ventas de helado y los ataques de tiburones, pero los ataques de tiburones ciertamente no ocurren debido a las ventas de helado.\nLa correlación se puede clasificar de muchas maneras, como se describe en las secciones siguientes.\n\nCorrelación Positiva, Negativa y Cero\nEn una correlación positiva, la dirección del cambio es la misma para ambas variables, es decir, cuando el valor de una variable aumenta o disminuye, el valor de la otra variable también aumenta o disminuye, respectivamente. En una correlación negativa, la dirección del cambio es opuesta para ambas variables, es decir, cuando el valor de una variable aumenta, el valor de la otra variable disminuye, y viceversa. Para una correlación cero, las dos variables son independientes, es decir, no existe correlación entre ellas. Estos conceptos se presentan detalladamente en la Fig. 1.9.\n\n\nCorrelación Simple, Parcial y Multiple\nLa correlación entre dos variables es una correlación simple. Pero si el número de variables es de tres o más, es una correlación parcial o múltiple. En una correlación parcial, la correlación entre dos variables de interés se determina mientras se mantiene constante la otra variable. Por ejemplo, la correlación entre la cantidad de comida ingerida y la presión arterial para un grupo de edad específico se puede considerar como una correlación parcial. Cuando se determina la correlación entre tres o más variables al mismo tiempo, se llama correlación múltiple. Por ejemplo, la relación entre la cantidad de comida comida, la altura, el peso y la presión arterial se puede considerar como un caso de correlación múltiple.\n\n\n\n\n\n\n\n\nFigura 9: Fig. 1.9. Visualización de correlación cero, positiva y negativa a diferentes niveles\n\n\n\n\n\n\n\nCorrelación Lineal y No Lineal\nCuando la dirección del cambio es constante en todos los puntos para todas las variables, la correlación entre ellas es lineal. Si la dirección del cambio cambia, es decir, no es constante en todos los puntos, entonces se conoce como correlación no lineal, también conocida como correlación curvilínea. Un ejemplo de correlación no lineal sería la relación entre la satisfacción del cliente y la alegría del personal. La alegría del personal podría mejorar la experiencia del cliente, pero demasiada alegría podría tener un efecto negativo.\n\n\nCoeficiente de Correlación\nEl coeficiente de correlación se utiliza para representar la correlación de manera numérica. Indica la fuerza de la relación entre las variables. Hay muchos tipos de coeficientes de correlación. Sin embargo, los dos más utilizados y más importantes se discuten brevemente aquí.\nCoeficiente de Correlación de Pearson\nEl Coeficiente de Correlación de Pearson, también conocido como \\(\\text{r de Pearson}\\), es el más popular y ampliamente utilizado para determinar la correlación lineal entre dos variables. En otras palabras, describe la fuerza de la relación entre dos variables basada en la dirección del cambio en las variables.\nPara el coeficiente de correlación de una muestra,\n\\[\nr_{xy}=\\frac{Cov(x,y)}{s_xs_y}=\\frac{\\frac{\\sum{(x_i-\\overline{x})(y_i-\\overline{y})}}{n-1}}{\\sqrt{\\frac{(x_i-\\overline{x})^2}{n-1}}\\sqrt{\\frac{y_i-\\overline{y})^2}{n-1}}}=\\frac{\\sum{(x_i-\\overline{x})(y_i-\\overline{y})}}{\\sum{(x_i-\\overline{x})^2(y_i-\\overline{y})^2}}\n\\tag{8}\\]\nAquí, \\(r_{xy}\\) es el coeficiente de correlación de muestra entre dos variables \\(x\\) y \\(y\\); \\(Cov(x, y)\\) es la covarianza de muestra entre dos variables \\(x\\) y \\(y\\); \\(s_x\\) , \\(s_y\\) son la desviación estándar de muestra de \\(x\\) y \\(y\\); \\(\\overline{x}\\), \\(\\overline{y}\\) son el valor promedio de \\(x\\) y el valor promedio de \\(y\\); \\(n\\) es el número de puntos de datos en \\(x\\) y \\(y\\).\nPara el coeficiente de correlación de una población,\n\\[\n\\rho_{xy}=\\frac{Cov(x,y)}{\\sigma_x\\sigma_y}=\\frac{\\frac{\\sum{(x_i-\\overline{x})(y_i-\\overline{y})}}{n}}{\\sqrt{\\frac{(x_i-\\overline{x})^2}{n}}\\sqrt{\\frac{y_i-\\overline{y})^2}{n}}}=\\frac{\\sum{(x_i-\\overline{x})(y_i-\\overline{y})}}{\\sum{(x_i-\\overline{x})^2(y_i-\\overline{y})^2}}\n\\tag{9}\\]\nAquí, \\(\\rho_{xy}\\) es el coeficiente de correlación de población entre dos variables \\(x\\) y \\(y\\); \\(Cov(x, y)\\) es la covarianza de población entre dos variables \\(x\\) y \\(y\\); \\(\\sigma_x\\) , \\(\\sigma_y\\) son la desviación estándar de población de \\(x\\) y \\(y\\); \\(\\overline{x}\\), \\(\\overline{y}\\) son el valor promedio de \\(x\\) y el valor promedio de \\(y\\) y \\(n\\) es el número de puntos de datos en \\(x\\) y \\(y\\).\nEl valor del coeficiente de correlación de Pearson varía entre -1 y 1. Aquí, -1 indica una correlación negativa perfecta, y el valor 1 indica una correlación positiva perfecta. Un coeficiente de correlación de 0 significa que no hay correlación. El coeficiente de correlación de Pearson se aplica cuando los datos de ambas variables provienen de una distribución normal, no hay outliers en los datos y la relación entre las dos variables es lineal.\nCoeficiente de Correlación de Spearman\nEl Coeficiente de Correlación de Spearman determina la relación no-paramétrica entre los rangos de dos variables, es decir, el cálculo se realiza entre los rangos de las dos variables en lugar de los datos en sí mismos. Los rangos se determinan generalmente asignando el rango 1 al dato más pequeño, el rango 2 al siguiente dato más pequeño y así sucesivamente hasta el dato más grande. Por ejemplo, los datos contenidos en una variable son {55, 25, 78, 100, 96, 54}. Por lo tanto, el rango para esa variable particular será {3, 1, 4, 6, 5, 2}. Al calcular los rangos de ambas variables, se puede calcular el coeficiente de correlación de Spearman como sigue:\n\\[\n\\rho=1-\\frac{6\\sum{d_i^2}}{n(n^2-1)}.\n\\tag{10}\\]\nAquí, \\(\\rho\\) es el coeficiente de correlación de Spearman, \\(n\\) es el número de puntos de datos en las variables y \\(d_i\\) es la diferencia de rango en el i-ésimo dato.\nEl coeficiente de correlación de Pearson determina la linealidad de la relación, mientras que el coeficiente de correlación de Spearman determina la monotonicidad de la relación. La representación gráfica de la monotonicidad de la relación se muestra en la Fig. 1.10.\nA diferencia de una relación lineal, el ritmo de cambio de los datos no es siempre el mismo en una relación monotónica. Si el ritmo de cambio es en la misma dirección para ambas variables, la relación es positiva monotónica. Por otro lado, si la dirección es opuesta para ambas variables, la relación es negativa monotónica. La relación se llama no-monotónica cuando la dirección del cambio no es siempre la misma o opuesta, sino una combinación.\nEl valor del coeficiente de correlación de Spearman varía entre -1 y 1. Un valor de -1 indica una correlación negativa perfecta (correlación negativa de rango), un valor de 1 indica una correlación positiva perfecta (correlación positiva de rango) y un valor de 0 indica que no hay correlación. El coeficiente de correlación de Spearman se utiliza cuando se cumplen uno o más condiciones del coeficiente de correlación de Pearson.\nAdemás de estos dos coeficientes de correlación, también se utilizan otros como: coeficiente de correlación de rango de Cramer (Cramer’s \\(\\tau\\)), coeficiente de correlación de Kendall (Kendall’s \\(\\varphi\\)), coeficiente biserial de punto. El uso de los diferentes coeficientes de correlación depende del tipo de aplicación y del tipo de datos.\n\n\n\nAnomalías\nUna anomalía es un punto de datos en el conjunto de datos que posee propiedades diferentes a todas las demás y, por lo tanto, varía significativamente del patrón de otras observaciones. Se trata del valor que tiene la mayor deviación del patrón típico seguido por todos los demás valores en el conjunto de datos.\nLos algoritmos de ML tienen una alta sensibilidad a la distribución y el rango de valores de atributos. Las anomalías tienen la tendencia a confundir el proceso de entrenamiento del algoritmo, lo que eventualmente conduce a observaciones erróneas, resultados inexactos, tiempos de entrenamiento más largos y resultados pobres.\nConsidera el conjunto de datos \\((x, y)\\). Aquí, \\(x\\) es la tasa de consumo de agua por día y \\(y\\) es la tasa de consumo de electricidad por día. En la Figura 1.11, podemos ver que estos datos se distribuyen en 2 grupos diferentes, pero uno de los puntos de datos no puede agruparse con ninguno de estos grupos. Este punto de datos actúa como una anomalía en este caso.\n\n\n\n\n\n\n\n\nFigura 10: Fig. 1.11. Representación de un valor atípico. Los puntos negros se encuentran dentro de límites específicos, pero un punto azul está más allá de esos círculos de datos. El punto azul es un valor atípico.\n\n\n\n\n\nEs importante destacar que ruido y anomalías son dos cosas diferentes. Mientras que una anomalía es un valor de datos significativamente desviado, el ruido es simplemente un valor erróneo.\nLa Figura 1.12 visualiza la diferencia entre anomalía y ruido utilizando una señal.\n\n\n\n\n\n\n\n\nFigura 11: Fig. 1.12. Diferencia entre anomalía y ruido.\n\n\n\n\n\nConsidera una lista de 100 precios de casas, que principalmente incluye precios que van desde los 3000 hasta los 5000 dólares. Primero, hay una casa en la lista con un precio de 20,000 dólares. Luego, hay una casa en la lista con un precio de -100 dólares. 20,000 es una anomalía aquí, ya que difiere significativamente de los demás precios de casas. Por otro lado, -100 es un ruido, ya que el precio de algo no puede ser un valor negativo. Dado que la anomalía distorsiona significativamente la media aritmética del conjunto de datos y conduce a observaciones erróneas, eliminar anomalías del conjunto de datos es el requisito previo para lograr el resultado correcto.\n\n\nHistograma\nUn histograma se asemeja a un gráfico de columnas y representa la distribución de frecuencia de los datos en barras verticales en un sistema de ejes bidimensional. Los histogramas tienen la capacidad de expresar los datos de manera estructurada, lo que facilita la visualización de datos. Las barras en un histograma se colocan al lado uno del otro sin espacios en blanco entre ellas. El histograma agrupa los datos en barras, lo que proporciona una comprensión clara de la distribución de los datos. La disposición también proporciona una comprensión clara de la distribución de los datos según sus características en el conjunto de datos.\nLa Figura 1.13 ilustra tres tipos de histogramas, con una distribución desviada a la izquierda, una distribución normal y una distribución desviada a la derecha.\n\n\n\n\n\n\n\n\nFigura 12: Fig. 1.13. Representación de varias distribuciones usando histogramas.\n\n\n\n\n\n\n\nErrores\nEl conocimiento de los errores es útil al evaluar la precisión de un modelo de aprendizaje automático (ML). En particular, cuando se prueba el modelo entrenado contra un conjunto de datos de prueba, se compara el resultado del modelo con el resultado conocido del conjunto de datos de prueba. La deviación entre los datos predichos y los datos reales se conoce como el error. Si el error está dentro de los límites tolerables, entonces el modelo está listo para usar; en caso contrario, debe ser reentrenado para mejorar su precisión.\nHay varios métodos para estimar la precisión del rendimiento de un modelo de ML. Algunos de los métodos más populares son medir el porcentaje de error absoluto promedio (MAPE), el error cuadrado medio (MSE), el error absoluto medio (MAE) y el error raiz cuadrado medio (RMSE). En las ecuaciones de la Tabla 1.7, \\(n\\) representa el número total de veces que ocurre la iteración, \\(t\\) representa una iteración específica o una instancia del conjunto de datos, \\(e_t\\) es la diferencia entre el valor real y el valor predicho del punto de datos, y \\(y_t\\) es el valor real.\n\n\n\nTabla 7: Tabla 1.7. Diferentes tipos de errores\n\n\n\n\n\n\n\n\n\nNombre del error\nEcuación\n\n\n\n\nError cuadrático medio\n\\[\nMSE=\\frac{1}{n}\\sum_{t=1}^ne_t^2\n\\]\n\n\nRaíz del error cuadrático medio\n\\[\nRMSE=\\sqrt{\\frac{1}{n}\\sum_{t=1}^ne_t^2}\n\\]\n\n\nError absoluto medio\n\\[\nMAE=\\sqrt{\\frac{1}{n}\\sum_{t=1}^n|e_t|}\n\\]\n\n\nError porcentual absoluto medio\n\\[\nMAPE=\\frac{100%}{n}\\sqrt{\\sum_{t=1}^n|\\frac{e_t}{y_t}|}\n\\]\n\n\n\n\n\n\nEl concepto de errores es vital para crear un modelo de ML preciso para varios propósitos. Estos se describen con mayor profundidad en la Sección 2.2 del Capítulo 2.\n\n\n\nTeoría de la Probabilidad\nLa probabilidad es una medida de la probabilidad de que un evento específico ocurra.\nLa probabilidad se encuentra entre 0 y 1, donde 0 significa que el evento nunca ocurrirá y 1 significa que el evento es seguro de ocurrir. La probabilidad se define como la ratio del número de resultados deseados al número total de resultados.\n\\[P(A)=\\frac{n(A)}{n}. \\tag{11}\\]\nDonde \\(P (A)\\) denota la probabilidad de un evento \\(A\\), \\(n (A)\\) denota el número de ocurrencias del evento \\(A\\) y \\(n\\) denota el número total de resultados posibles, también conocido como el espacio muestral.\nVamos a ver un ejemplo común. Un dado estándar con seis caras contiene un número entre 1 y 6 en cada una de las caras. Cuando se lanza un dado, cualquier uno de los seis números puede aparecer en la cara superior. Por lo tanto, la probabilidad de obtener un 6 en el dado se determina según se muestra en la ecuación 1.12.\n\\[\nP(6)=\\frac{1}{6}=0.167=16.7\\text{%}\n\\tag{12}\\]\nLa teoría de la probabilidad es el campo que abarca las matemáticas relacionadas con la probabilidad. Cualquier algoritmo de aprendizaje depende de la suposición probabilística de los datos. Como los modelos de ML manejan la incertidumbre de los datos, el ruido, la distribución de probabilidad, etc., varios conceptos fundamentales de la teoría de la probabilidad son necesarios, que se cubren en esta sección 1.5.3.\n\nDistribución de Probabilidad\nEn la teoría de la probabilidad, todos los posibles resultados numéricos de cualquier experimento se representan mediante variables aleatorias. Una función de distribución de probabilidad produce los valores numéricos posibles de una variable aleatoria dentro de un rango específico. Las variables aleatorias son de dos tipos: discretas y continuas. Por lo tanto, la distribución de probabilidad se puede categorizar en dos tipos según el tipo de variable aleatoria involucrada—función de densidad de probabilidad y función de masa de probabilidad.\n\nFunción de Densidad de Probabilidad\nLos valores numéricos posibles de una variable aleatoria continua se pueden calcular utilizando la función de densidad de probabilidad (PDF). La representación gráfica de esta distribución es continua. Por ejemplo, en la Figura 1.14, cuando un modelo busca la probabilidad de la altura de las personas en el rango de 160-170 cm, podría utilizar una PDF para indicar la probabilidad total de que el rango de la variable aleatoria continua ocurra. Aquí, f (x) es la PDF de la variable aleatoria x.\n\n\n\n\n\n\n\n\nFigura 13: Fig. 1.14. Ejemplo de función de densidad de probabilidad.\n\n\n\n\n\n\n\nFunción de Masa de Probabilidad\nCuando se implementa una función para encontrar los valores numéricos posibles de una variable aleatoria discreta, la función se conoce como función de masa de probabilidad (PMF). Las variables aleatorias discretas tienen un número finito de valores. Por lo tanto, no obtenemos una curva continua cuando se representa gráficamente la PMF. Por ejemplo, si consideramos el lanzamiento de un dado de seis caras, tendremos un número finito de resultados, como se muestra en la Figura 1.15.\n\n\n\n\n\n\n\n\nFigura 14: Fig. 1.15. Ejemplo de función de masa de probabilidad.\n\n\n\n\n\n\n\n\nDistribución Gaussiana o Distribución Normal\nLa probabilidad acumulada de variables aleatorias normales se presenta en la distribución Gaussiana o normal. El gráfico depende de la media y la distribución estándar de los datos. En una distribución estándar, la media de los datos es 0 y la desviación estándar es 1. Un gráfico de distribución normal es una curva en forma de campana, como se muestra en la Fig. 1.16. Por lo tanto, también se conoce como distribución de curva en forma de campana.\nLa ecuación que representa la distribución Gaussiana o normal es:\n\\[\nP(x)=\\frac{1}{\\alpha\\sqrt{2\\pi}}e^{\\frac{-(x+\\mu)^2}{2\\alpha^2}}\n\\tag{13}\\]\nDonde \\(P(x)\\) denota la densidad de probabilidad de la distribución normal, \\(α\\) denota la desviación estándar, \\(μ\\) denota la media del conjunto de datos y \\(x\\) denota un punto de datos.\n\n\nDistribución de Bernoulli\nUna distribución de probabilidad sobre el ensayo de Bernoulli es la distribución de Bernoulli. El ensayo de Bernoulli es un experimento o evento que solo tiene dos resultados. Por ejemplo, lanzar una moneda se puede considerar como un ensayo de Bernoulli, ya que solo puede tener dos resultados - cara o sello. Normalmente, los resultados se observan en términos de éxito o fracaso. En este caso, podemos decir que obtener una cara será un éxito. Por otro lado, no obtener una cara o obtener un sello sería un fracaso. La distribución de Bernoulli se ha visualizado en la Fig. 1.17, que plotea la probabilidad de dos ensayos.\n\n\n\n\n\n\n\n\nFigura 15: Fig. 1.16. Distribución normal.\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigura 16: Fig. 1.17. Distribución de Bernoulli\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigura 17: Fig. 1.18. Demostración gráfica del teorema del límite central.\n\n\n\n\n\n\n\nTeorema del Límite Central\nConsidera un conjunto de datos grande de cualquier distribución. El teorema del límite central afirma que, independientemente de la distribución de los números en el conjunto de datos, la media aritmética de las muestras de datos extraídas del conjunto de datos principal tendrá una distribución normal. Cuanto mayor sea el tamaño de la muestra, más cerca estará la media de una distribución normal. El teorema se ha demostrado en la Fig. 1.18. Se puede ver que la población no sigue una distribución normal, pero cuando se muestrea la media, la muestra forma una distribución normal.\n\n\n\nCálculo\nEl cálculo de Newton es ampliamente útil para resolver una variedad de problemas. Uno de los algoritmos más populares de ML es el algoritmo de descenso de gradientes. El algoritmo de descenso de gradientes, junto con la retropropagación (backpropagation), es útil en el proceso de entrenamiento de modelos de ML, que dependen intensivamente del cálculo. Por lo tanto, el cálculo diferencial, el cálculo integral y las ecuaciones diferenciales son todos aspectos necesarios para familiarizarse con antes de estudiar ML.\n\nDerivada y Pendiente\nLa derivada se define como la tasa de cambio de una función con respecto a una variable. Por ejemplo, la velocidad de un coche es la derivada de la desplazamiento del coche con respecto al tiempo. La derivada es equivalente a la pendiente de una línea en un punto específico. La pendiente ayuda a visualizar cómo empinada es una línea. Una línea con una pendiente más alta es más empinada que una línea con una pendiente más baja. El concepto de pendiente se muestra en la Figura 1.19.\n\\[\npendiente, m =\\frac{\\Delta{y}}{\\Delta{x}}\n\\tag{14}\\]\nSe utiliza ampliamente la derivada en ML, especialmente en problemas de optimización, como el descenso de gradientes. Por ejemplo, en el descenso de gradientes, se utilizan derivadas para encontrar el camino más empinado para maximizar o minimizar una función objetivo (por ejemplo, la precisión o función de error de un modelo).\n\n\n\n\n\n\n\n\nFigura 18: Fig. 1.19. Ilustración concepto de pendiente.\n\n\n\n\n\n\n\nDerivadas Parciales\nSi una función depende de dos o más variables, entonces la derivada parcial de la función es su derivada con respecto a una de las variables, manteniendo las otras variables constantes. Las derivadas parciales se requieren para técnicas de optimización en ML, que utilizan derivadas parciales para ajustar los pesos para cumplir con la función objetivo. Las funciones objetivo son diferentes para cada problema. Por lo tanto, la derivada parcial ayuda a decidir si aumentar o disminuir los pesos para hacer un ajuste a la función objetivo.\n\n\nMáximos y Mínimos\nPara una función no lineal, el pico más alto o el valor máximo se refiere a los máximos, y el pico más bajo o el valor mínimo se refiere a los mínimos. En otras palabras, el punto en el que la derivada de una función es cero se define como los máximos o los mínimos. Estos son los puntos en los que el valor de la función se mantiene constante, es decir, la tasa de cambio es cero. Este concepto de máximos y mínimos es necesario para minimizar la función de coste (diferencia entre el valor verdadero y el valor de salida) de cualquier modelo de ML. Un mínimo local es el valor de una función que es menor que los puntos vecinos, pero no necesariamente menor que todos los puntos en el espacio de solución. Un mínimo global es el valor más pequeño de la función que existe en ese espacio de solución. El caso es el mismo para máximos globales y locales. Un máximo local es el valor de una función que es mayor que los puntos vecinos, pero no necesariamente mayor que todos los puntos en el espacio de solución. Un máximo global es el valor más grande de la función que existe en ese espacio de solución. La figura 1.20 muestra máximos y mínimos globales y locales en un espacio de solución.\n\n\n\n\n\n\n\n\nFigura 19: Fig. 1.20. Representación de máximos y mínimos.\n\n\n\n\n\n\n\nEcuación Diferencial\nUna ecuación diferencial (ED) representa la relación entre una o más funciones y sus derivadas con respecto a una o más variables. Las EDs son muy útiles en el modelado de sistemas y, por lo tanto, se pueden utilizar en ML para modelado dinámico, especialmente en redes neuronales.\nEl siguiente es un ejemplo de una ecuación diferencial:\n\\[\n\\frac{d^2y}{dx^2}+4=1.\n\\tag{15}\\]\n\nOrden y Grado\nEn ecuaciones diferenciales, el orden más alto de la derivada utilizada en la ecuación es el orden de la ecuación. El grado de una ecuación diferencial es el poder de su derivada más alta. Por ejemplo, esta es una ecuación diferencial de cuarto orden y primer grado:\n\\[\n\\frac{d^4y}{dx^4}+(\\frac{d^2y}{dx^2})^2+4\\frac{dy}{dx}+6x=0.\n\\tag{16}\\]\naquí, la derivada más alta es \\(\\frac{d^4y}{dx^4}\\). El orden de la derivada más alta es 4, por lo que esta es una ecuación diferencial de cuarto orden. El poder de la derivada más alta es 1, y por lo tanto, esta es una ecuación diferencial de primer grado. Algunos ejemplos adicionales se muestran en la Tabla 1.8\n\n\n\nTabla 8: Tabla 1.8. Ecuaciones diferenciales con su grado y orden.\n\n\n\n\n\n\n\n\n\n\nEcuación\nOrden\nGrado\n\n\n\n\n\\[\n    \\frac{d^3y}{dx^3}+6x\\frac{dy}{dx}=e^y\n                              \\]\n3\n1\n\n\n\\[\n    \\frac{dy}{dx}+(\\frac{d^2y}{dx^2})^3=7x\n                              \\]\n2\n3\n\n\n\\[\n    \\frac{d^2y}{dx^2}+(\\frac{dy}{dx})^3=7x\n                              \\]\n2\n1\n\n\n\n\n\n\n\n\nEcuación Diferencial Ordinaria y Parcial\nComo se discutió anteriormente, las ecuaciones diferenciales pueden tener más de una variable. Cuando una ecuación consiste en diferenciales con respecto a una variable, se llama ecuación diferencial ordinaria (EDO). Por otro lado, cuando la ecuación involucra diferenciales con respecto a más de una variable, se conoce como ecuación diferencial parcial (EDP). El símbolo \\(d\\) se utiliza para ecuaciones diferenciales ordinarias y el símbolo \\(\\partial\\) se utiliza para ecuaciones diferenciales parciales.\nPor ejemplo: \\(\\frac{d^2y}{dx^2} + \\frac{dy}{dx} + 1 = 0\\) es una EDO y \\(\\frac{\\partial^2y}{\\partial{x}^2} + \\frac{\\partial{y}}{\\partial{x}} + 1 = 0\\) es una EDP.\n\n\nEcuación Lineal y No Lineal\nLas ecuaciones pueden tener variables dependientes e independientes. Estas variables pueden tener grados más altos dependiendo del tipo de ecuación. Cuando las ecuaciones diferenciales contienen variables dependientes con grado 1, se consideran ecuaciones diferenciales lineales. Por otro lado, si las ecuaciones diferenciales contienen variables dependientes con un grado más alto, se consideran ecuaciones diferenciales no lineales.\nPor ejemplo, en la ecuación \\(\\frac{d^2y}{dx^2} + \\frac{dy}{dx} + 1 = 0\\), el grado de la derivada más alta es 1. Por lo tanto, es una ecuación lineal. De nuevo, la ecuación \\((\\frac{dy}{dx})^2 + x = 0\\) tiene 2 como su grado de la derivada más alta. Por lo tanto, es un ejemplo de ecuación no lineal.\nHasta aquí tienes los conceptos básicos que deberías revisar, repasar, aprender o profundizar, para lograr aplicar ML."
  },
  {
    "objectID": "posts/2025-02-04-advance_mtto_shiny_app/index.html",
    "href": "posts/2025-02-04-advance_mtto_shiny_app/index.html",
    "title": "Una aplicación robusta para Mantenimiento",
    "section": "",
    "text": "Hasta ahora solo teniamos una app sencilla. Vamos a ponerle un poco más de dificultad."
  },
  {
    "objectID": "posts/2025-02-04-advance_mtto_shiny_app/index.html#implementación-de-duración-de-mantenimientos",
    "href": "posts/2025-02-04-advance_mtto_shiny_app/index.html#implementación-de-duración-de-mantenimientos",
    "title": "Una aplicación robusta para Mantenimiento",
    "section": "Implementación de duración de mantenimientos",
    "text": "Implementación de duración de mantenimientos\nEs posible que algunas tareas o rutinas de mantenimiento tomen más tiempo que un solo periodo de planeación.\n\nActualización de la restricción de mantenimiento basada en operación\nSi un período de mantenimiento es mayor a un mes, la Eq.4 debe actualizarse para en lugar de agregar \\(T_i\\) cuando \\(y_{i,t} = 1\\), solo haga esto cuando finalice todo el período de mantenimiento. La restricción se reescribe como:\n\\[\n\\sum_{j=t}^{t+u}x_{i,t} \\le T_i + T_i \\sum_{j=t}^{t+u}z_{i,j}, \\quad ∀i,t,u ∈ \\{o,1,...,H-t\\},\n\\tag{1}\\]\ndonde \\(z_{i,t}\\) es una variable binaria que implica:\n\\[\nz_{i,t} = \\cases{1, \\quad \\text{si }y_{i,t}=1,\\text{ } y_{i,t+1}=0 \\\\0, \\quad \\text{de lo contrario}}\n\\]\nque es equivalente a:\n\\[\nz_{i,t}= \\cases{1, \\quad \\text{si t es el último mes en un periodo de mantenimiento para la unidad i}\\\\0, \\quad \\text{de lo contrario}}\n\\]\nPara tener \\(z_{i,t}\\) así, se deben incluir las siguientes tres restricciones:\n\\[\nz_{i,\\tau} - y_{i,\\tau}+y_{i,\\tau +1} \\ge 0, \\quad ∀i, \\tau ∈ \\{1,2,...,H-1\\},\n\\]\n\\[\nz_{i,\\tau} + y_{i,\\tau +1} \\le 1, \\quad ∀i, \\tau ∈ \\{1,2,...,H-1\\}\n\\]\n\\[\nz_{i,\\tau} - y_{i,\\tau} \\le 0, \\quad ∀i, \\tau ∈ \\{1,2,...,H-1\\}\n\\]\nLa restricción de mantenimiento basada en el calendario no se modifica para restringir la suma de \\(z_{i,t}\\) en lugar de \\(y_{i,t}\\) ya que queremos permitir que un período de mantenimiento haya comenzado pero no haya terminado al final del período de planeación. Sin embargo, esto no supone un problema con la restricción 2.1. ya que \\(x_{i,t} = 0\\) cuando \\(y_{i,t} = 1\\) y la restricción no se hace más estricta para las franjas incluidas con \\(x_{i,t} = 0\\). Por la misma razón, no es un problema que \\(z_{i,t}\\) no esté definido para \\(t = H\\).\n\n\nRestricción de la duración de los mantenimientos\nSi la duración del mantenimiento para una unidad \\(i\\) es superior a un mes y se representa como un parámetro entero \\(M_i &gt; 1\\), se puede escribir una restricción para controlar la duración del mantenimiento como:\n\\[\ny_{i,\\tau - j} - z_{i,\\tau} \\ge 0, \\quad ∀i, \\tau ∈ \\{M_i,M_i+1,...,H\\}, j ∈ \\{1,2,...,M_i-1\\}\n\\tag{2}\\]\nque asegura que \\(M_i\\) periodos consecutivos tiene \\(y_{i,t}=1\\) cuando el mantenimiento es planeado. Entonces nos quedan las siguientes deducciones:\n\\[\nz_{i,\\tau}=1 ⟶ y_{i,\\tau - j}=1,\n\\]\n\\[\ny_{i,\\tau - j}=0 ⟶ z_{i, \\tau}=0\n\\]\ny como esto se hace para todos los \\(\\tau\\) y \\(j\\) definidos, el mantenimiento se extenderá a lo largo de \\(M_i\\) meses. Si un período de mantenimiento es de un mes, \\(z_{i,t}\\) es igual a \\(y_{i,t}\\) y la restricción 2.2. no es necesaria ni está definida.\nSeguro que con estas versiones de las restricciones que habías conocido, ya se empieza a ajustar el modelo a lo que podrías estar necesitando."
  },
  {
    "objectID": "posts/2025-01-27-maintenance_management/index.html",
    "href": "posts/2025-01-27-maintenance_management/index.html",
    "title": "Gestión de sistemas de mantenimiento",
    "section": "",
    "text": "Usar un software de mantenimiento para la gestión de flotas es, sin lugar a dudas, una de las mejores decisiones estratégicas que se pueden asumir en coherencia con la gerencia.\nCualquier software de gestión de mantenimiento debe ser una herramienta valiosa para las empresas que buscan optimizar sus operaciones de mantenimiento. Uno de los beneficios más importantes es la mejora en la planeación y programación. Debes ser capaz de planificar y programar los mantenimientos con anticipación, evitando retrasos y reduciendo los tiempos de inactividad de los vehículos. Esto es especialmente importante en industrias como la logística y el transporte, donde la disponibilidad de los vehículos es crucial para el éxito de la empresa. Además, la planeación y programación efectiva también puede ayudar a reducir costos y mejorar la eficiencia de los procesos.\nOtro beneficio importante es la mejora en la toma de decisiones. El software de gestión de mantenimiento debe proporcionar información detallada sobre los activos y los procesos para que los gerentes puedan tomar decisiones informadas sobre cómo manejar sus activos. Esto puede incluir decisiones sobre cuando reemplazar un componente, cómo asignar recursos y cómo optimizar los procesos. Con esta información, los gerentes pueden identificar oportunidades para reducir costos y mejorar la eficiencia, lo que puede tener un impacto significativo en el éxito de la empresa.\nLa reducción de costos es otro beneficio importante del software de gestión de mantenimiento. Al monitorear el progreso de los mantenimientos y los costos asociados, las empresas pueden identificar oportunidades para reducir gastos y optimizar sus procesos de mantenimiento. Esto puede incluir la identificación de componentes que no son esenciales para el funcionamiento del vehículo, la optimización de los procesos de mantenimiento y la reducción de los costos de repuestos. Además, la reducción de costos también puede ayudar a mejorar la eficiencia y la productividad de los empleados, lo que puede tener un impacto positivo en la cultura de la empresa."
  },
  {
    "objectID": "posts/2025-01-27-maintenance_management/index.html#proyecto-optimización-de-mantenimiento",
    "href": "posts/2025-01-27-maintenance_management/index.html#proyecto-optimización-de-mantenimiento",
    "title": "Gestión de sistemas de mantenimiento",
    "section": "Proyecto optimización de mantenimiento",
    "text": "Proyecto optimización de mantenimiento\nCrearemos un modelo que proyecte el calendario de mantenimiento óptimo para una flota de \\(m\\) unidades y \\(H\\) periodos de tiempo. El mantenimiento se refiere a cuándo debe ocurrir y cuántas horas de funcionamiento se planean para cada unidad en cada período de tiempo. Las unidades \\(i\\) y los periodos de tiempo \\(t\\) se representan mediante conjuntos.\n\\[i ∈ \\{1,2,...,m\\}\\]\ny\n\\[\nt ∈ \\{1,2,...,H\\}\n\\]\nEn primer lugar, se utilizan dos variables para definir un calendario. Una variable binaria que almacena el mantenimiento planeado.\n\\[\ny_{i,t}=\\cases{1, \\text{si se realiza mantenimiento de la unidad i en el tiempo t}\\\\0, \\text{de lo contrario}}\n\\]\nY una variable \\(x_{i,t} ≥ 0\\) que representa el número de horas de funcionamiento para la unidad \\(i\\) en el período de tiempo \\(t\\).\nPara encontrar un calendario de mantenimiento óptimo para una flota, se escribe un MILP (Programación Lineal Entera Mixta) donde el objetivo es minimizar el número de ocasiones de mantenimiento planeadas, es decir, minimizar la suma de \\(y_{i,t}\\) sobre cada unidad \\(i\\) y período de tiempo \\(t\\). Para el programa principal, las restricciones incluidas son una demanda de tiempo de funcionamiento para la flota completa de \\(D\\) horas y requisitos de mantenimiento después de al menos \\(U_i\\) tiempo periodos o \\(T_i\\) horas de funcionamiento desde el último mantenimiento, lo que sea lo primero. Esto se puede escribir como:\n\\[\nmin \\sum_{i=1}^{m}\\sum_{t=1}^{H}y_{i,t}\n\\]\n\\[\n\\text{sujeto a } \\sum_{i=1}^{m}\\sum_{t=1}^{H}x_{i,t}\\ge D,\n\\]\n\\[\n\\sum_{j=\\tau}^{\\tau+U_i}y_{i,t} \\ge 1, \\quad ∀i, \\tau ∈ \\{1,2,...,H-U_i\\},\n\\]\n\\[\n\\sum_{j=t}^{t+u}x_{i,t}\\le T_i+T_i \\sum_{j=t}^{t+u}y_{i,t}, \\quad ∀i, t, u ∈ \\{0,1,...,H-t\\},\n\\]\n\\[\nx_{i,t} + x^{max}y_{i,t} \\le x^{max}, \\quad ∀i, t,\n\\]\n\\[\nx_{i,t} \\ge 0, \\quad ∀i, t,\n\\]\n\\[\ny_{i,t} ∈ \\{0,1\\}, \\quad ∀i,t,\n\\]\nDonde Eq.2 garantiza que se cumple la demanda de horas de funcionamiento y Eq.3 y Eq.4 manejan las restricciones de mantenimiento. La restricción Eq.5 garantiza que no se planean operaciones para una unidad que está en mantenimiento, es decir, fuerza la deducción:\n\\[\ny_{i,t}=1 ⟶ x_{i,t}=0, \\quad ∀i, t.\n\\]\nEl parámetro \\(x^{max}\\) es el límite superior de \\(x_{i,t}\\), que se establece en \\(744\\) horas, ya que ese es el máximo número de horas que un mes puede tener."
  },
  {
    "objectID": "posts/2025-01-27-maintenance_management/index.html#restricción-de-programación-de-mantenimiento-según-calendario",
    "href": "posts/2025-01-27-maintenance_management/index.html#restricción-de-programación-de-mantenimiento-según-calendario",
    "title": "Gestión de sistemas de mantenimiento",
    "section": "Restricción de programación de mantenimiento según calendario",
    "text": "Restricción de programación de mantenimiento según calendario\nLa Eq.3 controla que el mantenimiento se realice al menos después de \\(U_i\\) periodos de tiempo desde el último mantenimiento. Esta restricción establece que para la suma de \\(y_{i,t}\\) dentro de todos los periodos de tamaño \\(U_i + 1\\), al menos uno de los periodos tiene que tener un evento de mantenimiento planeado con \\(y_{i,t} = 1\\), según el requisito de mantenimiento basado en calendario. Para visualizar las restricciones, se muestra un ejemplo para una unidad \\(j\\) con \\(U_j = 3\\) y \\(H = 8\\).\n\n\n\n\n\n\nFigura 1: Ejemplo de restricción de programación de mantenimiento según calendario."
  },
  {
    "objectID": "posts/2025-01-27-maintenance_management/index.html#restricción-de-programación-de-mantenimiento-según-uso",
    "href": "posts/2025-01-27-maintenance_management/index.html#restricción-de-programación-de-mantenimiento-según-uso",
    "title": "Gestión de sistemas de mantenimiento",
    "section": "Restricción de programación de mantenimiento según uso",
    "text": "Restricción de programación de mantenimiento según uso\nLa restricción Eq.4 se compone de la suma del tiempo de funcionamiento, operación o funcionamiento,\n\\[\n\\sum_{j=t}^{t+u}x_{i,t}, \\quad ∀i, t, u ∈ \\{0,1,...,H-t\\},\n\\] y la suma de eventos de mantenimiento\n\\[\n\\sum_{j=t}^{t+u}y_{i,t}, \\quad ∀i, t, u ∈ \\{0,1,...,H-t\\}\n\\]\nsobre todos los periodos de tiempo continuos de diferentes tamaños. Para cada evento de mantenimiento en el período, se agregan \\(T_i\\) unidades de tiempo dentro del área aceptable de tiempo de funcionamiento. Por lo tanto, la restricción se escribe como: \\[\n\\sum_{j=t}^{t+u}x_{i,t}\\le T_i+T_i \\sum_{j=t}^{t+u}y_{i,t}, \\quad ∀i, t, u ∈ \\{0,1,...,H-t\\},\n\\]\nLos periodos desde \\(t\\) hasta \\(t + u\\) se visualizan en la Figura 2 para una unidad y \\(H = 6\\).\n\n\n\n\n\n\nFigura 2: Ejemplo de restricción de programación de mantenimiento según operación.\n\n\n\nLas ecuaciones de la restricción Eq.4 escritas son:\n\\[\nx_{i,1} \\le T_i+T_iy_{i,1}\n\\]\n\\[\nx_{i,1} + x_{i,2}\\le T_i+T_iy_{i,1} + T_iy_{i,2}\n\\]\n\\[\nx_{i,1} +x_{i,2} +x_{i,3}\\le T_i+T_iy_{i,1} +T_iy_{i,2}+T_iy_{i,3}\n\\]\n\\[\n⠇\n\\]\n\\[\nx_{i,1} +x_{i,2} +...+x_{i,H}\\le T_i+T_iy_{i,1} +T_iy_{i,2}+...+T_iy_{i,H}\n\\]\n\n\\[\nx_{i,2} \\le T_i+T_iy_{i,2}\n\\]\n\\[\nx_{i,2} + x_{i,3}\\le T_i+T_iy_{i,2} + T_iy_{i,3}\n\\]\n\\[\nx_{i,2} +x_{i,3} +x_{i,4}\\le T_i+T_iy_{i,2} +T_iy_{i,3}+T_iy_{i,4}\n\\]\n\\[\n⠇\n\\]\n\\[\nx_{i,2} +x_{i,3} +...+x_{i,H}\\le T_i+T_iy_{i,2} +T_iy_{i,3}+...+T_iy_{i,H}\n\\]\n\\[\n⠇\n\\]\n\\[\nx_{i,H-1} \\le T_i+T_iy_{i,H-1}\n\\]\n\\[\nx_{i,H-1} + x_{i,H}\\le T_i+T_iy_{i,H-1} + T_iy_{i,H}\n\\]\n\n\\[\nx_{i,H} \\le T_i+T_iy_{i,H}\n\\]\npara cada unidad \\(i\\)."
  },
  {
    "objectID": "posts/2025-01-27-maintenance_management/index.html#ejemplo",
    "href": "posts/2025-01-27-maintenance_management/index.html#ejemplo",
    "title": "Gestión de sistemas de mantenimiento",
    "section": "Ejemplo",
    "text": "Ejemplo\nUn pequeño ejemplo del modelo descrito, con valores de parámetros de entrada listados en la Tabla No.1, se resuelve:\n\nTabla No.1. Valores de entrada para un pequeño ejemplo.\n\n\nParámetro\nValor\n\n\n\n\n\\(m\\)\n2\n\n\n\\(H\\)\n8\n\n\n\\(D\\)\n480\n\n\n\\(U_i\\)\nc(3, 3)\n\n\n\\(T_i\\)\nc(90, 90)\n\n\n\nEl número total de horas de operación para la solución es:\n\\[\n\\sum_{i=1}^{m}\\sum_{t=1}^{H}x_{i,t}^{*}=D,\n\\]\nlas horas máximas de funcionamiento y los periodos de tiempo entre mantenimientos son iguales a \\(T_i\\) y \\(U_i\\) ,respectivamente, y el número de eventos de mantenimiento es:\n\\[\ny_{tot}^{*}=\\sum_{i=1}^{m}\\sum_{t=1}^{H}y_{i,t}^{*}=4\n\\]\nEs claro que el problema planteado aquí es en extremo básico, y seguramente no se ajusta a cualquiera que sea tu necesidad. Pero, en mi defensa, mi intención es mostrar que no es imposible crear un servicio en la nube para lograr optimizar los recursos que se encuentran bajo tu control y administración."
  },
  {
    "objectID": "posts/2025-02-07-equity_colombia/index.html",
    "href": "posts/2025-02-07-equity_colombia/index.html",
    "title": "Análisis de las razones financieras",
    "section": "",
    "text": "Aquí vamos a explorar los estados de resultados de las empresas en Colombia.\nLo primero, por si no lo sabías, existe un Sistema Integrado de Información Societaria donde puedes ver el Estado de Situación Financiera, el Estado de Resultado Integral, entre otros, que reportan las empresas. Lo administra una entidad adscrita del Ministerio de Comercio, Industria y Turismo: la Superintendencia de Sociedades.\nCódigo\nlibrary(tidyverse)\nlibrary(data.table)\nlibrary(gt)\n\nknitr::opts_chunk$set(message = FALSE, warning = FALSE, fig.align = \"center\")\n\nestilo_summary &lt;- function(resumen){\n    resumen |&gt; \n        summary() |&gt; \n        as.data.frame() |&gt; \n        rownames_to_column() |&gt; \n        #dplyr::select(c(Var2,Freq)) |&gt; \n        rename(Medida = rowname,\n               Frecuencia = x) |&gt; \n        mutate(Frecuencia = round(Frecuencia,4))\n}\n\naplicar_theme_table &lt;- function(gt_table) {\n    gt_table %&gt;%\n        cols_align(align = \"center\") |&gt; \n        tab_options(\n            table.border.top.color = \"orange\",\n            table.font.color = \"#1e2c46\",\n            table_body.hlines.color = \"orange\",\n            column_labels.background.color = \"#1e2c46\"\n        )\n}\nVamos a revisar los datos:\nCódigo\ndata &lt;- openxlsx::read.xlsx(\"./210030_Estado de situación financiera, corriente_no corriente.xlsx\") |&gt; \n    data.table()\n\n# Función para extraer texto dentro de parentesis\nextraer_texto &lt;- function(texto){\n    inicial &lt;- gregexpr(\"\\\\(\", texto)[[1]]\n    final &lt;- gregexpr(\"\\\\)\", texto)[[1]]\n    substring(texto, inicial + 1, final - 1)\n}\n\n# Vector con los nombres extraídos\nnuevo_nombre &lt;- colnames(data) |&gt; \n    purrr::map(~extraer_texto(.x)) |&gt; \n    unlist()\n\n# Asignar nombres en inglés\ndata &lt;- setNames(data, ifelse(nuevo_nombre != \"\", nuevo_nombre, colnames(data)))\n\n# Cambiar otros nombres\ndata &lt;- data |&gt; \n    rename(Razon.Social = \"Raz&#243;n.social.de.la.sociedad\",\n           Direccion = \"Direcci&#243;n.de.notificaci&#243;n.judicial.registrada.en.C&#225;mara.de.Comercio\",\n           Departamento = \"Departamento.de.la.direcci&#243;n.del.domicilio\",\n           Ciudad = \"Ciudad.de.la.direcci&#243;n.del.domicilio\",\n           TotalCurrentFinancialAssetsSELL= \"Total_activos_corrientes_distintos_de_los_activos_no_corrientes_o_grupo_de_activos_para_su_disposicion_clasificados_como_mantenidos_para_la_venta_o_como_mantenidos_para_distribuir_a_los_propietarios\",\n           OtherCurrentFinancialAssetsSELL= \"Activos_no_corrientes_o_grupos_de_activos_para_su_disposicion_clasificados_como_mantenidos_para_la_venta_o_como_mantenidos_para_distribuir_a_los_propietarios\",\n           PropertyPlantAndEquipmentWithDEP= \"Propiedades_de_inversi&#243;n_al_costo_menos_depreciacion_acumulada_y_deterioro\",\n           TotalCurrentFinancialLiabilitiesSELL = \"Total_pasivos_corrientes_distintos_de_los_pasivos_incluidos_en_grupos_de_activos_para_su_disposicion_clasificados_como_mantenidos_para_la_venta\",\n           OtherCurrentFinancialLiabilitiesSELL= \"Pasivos_incluidos_en_grupos_de_activos_para_su_disposicion_clasificados_como_mantenidos_para_la_venta\")\n\n# Solo veremos el periodo final\ndata &lt;- data |&gt; \n    filter(Periodo == \"Periodo Actual\",\n           Fecha.de.Corte == \"2022-12-31\")\n\n\ngt(head(data,5)) |&gt; \n    aplicar_theme_table() |&gt; \n    tab_options(table.width = pct(50))\n\n\n\n\n\n\n\n\nPunto.de.Entrada\nNombre.Formulario\nNIT\nFecha.de.Corte\nRazon.Social\nCIIU\nTipo.societario\nDireccion\nDepartamento\nCiudad\nPeriodo\nCashAndCashEquivalents\nTradeAndOtherCurrentReceivables\nInventories\nCurrentTaxAssetsCurrent\nCurrentBiologicalAssetsAtCost\nCurrentBiologicalAssetsAtFairValue\nOtherCurrentFinancialAssets\nOtherCurrentNonfinancialAssets\nCurrentNoncashAssetsPledgedAsCollateralForWhichTransfereeHasRightByContractOrCustomToSellOrRepledgeCollateral\nTotalCurrentFinancialAssetsSELL\nOtherCurrentFinancialAssetsSELL\nCurrentAssets\nPropertyPlantAndEquipment\nPropertyPlantAndEquipmentWithDEP\nInvestmentProperty\nGoodwill\nIntangibleAssetsOtherThanGoodwill\nNoncurrentBiologicalAssetsAtCost\nNoncurrentBiologicalAssetsAtFairValue\nNoncurrentReceivables\nNoncurrentInventories\nDeferredTaxAssets\nCurrentTaxAssetsNoncurrent\nOtherNoncurrentFinancialAssets\nOtherNoncurrentNonfinancialAssets\nNoncurrentNoncashAssetsPledgedAsCollateralForWhichTransfereeHasRightByContractOrCustomToSellOrRepledgeCollateral\nNoncurrentAssets\nAssets\nCurrentProvisionsForEmployeeBenefits\nOtherShorttermProvisions\nCurrentProvisions\nTradeAndOtherCurrentPayables\nCurrentTaxLiabilitiesCurrent\nOtherCurrentFinancialLiabilities\nShorttermBorrowings\nCurrentPortionOfLongtermBorrowings\nOtherCurrentNonfinancialLiabilities\nTotalCurrentFinancialLiabilitiesSELL\nOtherCurrentFinancialLiabilitiesSELL\nCurrentLiabilities\nNoncurrentProvisionsForEmployeeBenefits\nOtherLongtermProvisions\nNoncurrentProvisions\nNoncurrentPayables\nDeferredTaxLiabilities\nCurrentTaxLiabilitiesNoncurrent\nOtherNoncurrentFinancialLiabilities\nLongtermBorrowings\nOtherNoncurrentNonfinancialLiabilities\nNoncurrentLiabilities\nLiabilities\nIssuedCapital\nSharePremium\nTreasuryShares\nInversionSuplementariaAlCapitalAsignado\nOtherEquityInterest\nSuperavitPorRevaluacion\nOtherReserves\nRetainedEarnings\nEquity\nEquityAndLiabilities\n\n\n\n\nPymes-Individuales\nEstado de situaci&#243;n financiera, corriente/no corriente\n800000090\n2022-12-31\nIngenieros Servicios Constructivos SAS\nF4111 - Construcci&#243;n de edificios residenciales\n08. SOCIEDAD POR ACCIONES SIMPLIFICADA SAS\nCarrera 38 26 17 OFICINA 922 y 926\nANTIOQUIA\nMEDELLIN-ANTIOQUIA\nPeriodo Actual\n2922\n3769426\n0\n108391\nNA\nNA\nNA\n8548153\nNA\n12428892\nNA\n12428892\n357599\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n357599\n12786491\n304289\n3279\n307568\n1292633\n733077\n1235364\n1235364\nNA\nNA\n3568642\nNA\n3568642\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n4743536\n4743536\n8312178\n1500000\n2392140\nNA\nNA\n0\nNA\n10616\n571557\n4474313\n12786491\n\n\nPymes-Individuales\nEstado de situaci&#243;n financiera, corriente/no corriente\n800000241\n2022-12-31\nCERERIA EL SAGRADO CORAZON LTDA\nC3290 - Otras industrias manufactureras n.c.p.\n03. SOCIEDAD LIMITADA\nKM 5.5 VIA LA BUITRERA PREDIO LA CANANEA\nVALLE\nCALI-VALLE\nPeriodo Actual\n434850\n3294074\n2412864\nNA\nNA\nNA\n51621\nNA\nNA\n6193409\nNA\n6193409\n564126\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n18708\nNA\nNA\n582834\n6776243\n114962\nNA\n114962\n2775642\n294400\n253216\n253216\nNA\nNA\n3438220\nNA\n3438220\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n3438220\n200000\nNA\nNA\nNA\nNA\n132740\n130902\n2874381\n3338023\n6776243\n\n\nPymes-Individuales\nEstado de situaci&#243;n financiera, corriente/no corriente\n800000268\n2022-12-31\nINVERSIONES SCHLEGEL DONADO SAS\nL6810 - Actividades inmobiliarias realizadas con bienes propios o arrendados\n08. SOCIEDAD POR ACCIONES SIMPLIFICADA SAS\nCARRERA 53 82 115\nATLANTICO\nBARRANQUILLA-ATLANTICO\nPeriodo Actual\n53687\n0\n25408\n17038\n0\n0\n0\n516081\n0\n612214\n0\n612214\nNA\n4939698\n2189617\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n7129315\n7741529\n0\n0\n0\n1531298\n44434\n0\n0\n0\n0\n1575732\n0\n1575732\n0\n0\n0\n0\n345913\n0\n2780438\n2780438\n0\n3126351\n4702083\n70000\n0\n0\n0\n0\n1970655\n35000\n963791\n3039446\n7741529\n\n\nPymes-Individuales\nEstado de situaci&#243;n financiera, corriente/no corriente\n800000276\n2022-12-31\nAVICOLA EL MADRO&#209;O SA\nA0145 - Cr&#237;a de aves de corral\n01. SOCIEDAD AN&#211;NIMA\nKM 6 VIA GIRON CR 12 # 57 - 88\nSANTANDER\nBUCARAMANGA-SANTANDER\nPeriodo Actual\n2331706\n60436680\n42997280\n14035926\n20869714\nNA\n1391059\n3106904\nNA\n145169269\nNA\n145169269\n132086107\nNA\nNA\nNA\n50000\nNA\nNA\nNA\nNA\n1266864\nNA\n141186\nNA\nNA\n133544157\n278713426\n4079708\nNA\n4079708\n84899951\n8285620\n26275037\n18918026\n7357011\n69993\n123610309\nNA\n123610309\nNA\nNA\nNA\nNA\n10438735\nNA\n47342439\n47342439\n2230000\n60011174\n183621483\n3576000\n17073150\nNA\nNA\nNA\n41224684\n1788000\n31430109\n95091943\n278713426\n\n\nPymes-Individuales\nEstado de situaci&#243;n financiera, corriente/no corriente\n800000296\n2022-12-31\nZR INGENIERIA SA\nF4290 - Construcci&#243;n de otras obras de ingenier&#237;a civil\n01. SOCIEDAD AN&#211;NIMA\nCL 106 57 23 OF 204\nBOGOTA D.C.\nBOGOTA D.C.\nPeriodo Actual\n8991\n416673\n1482034\nNA\nNA\nNA\n527379\nNA\nNA\n2435077\nNA\n2435077\n648\nNA\nNA\nNA\nNA\nNA\nNA\n4202324\nNA\nNA\nNA\n27131\nNA\n200\n4230303\n6665380\n25059\nNA\n25059\n28018\n21233\nNA\nNA\nNA\n37349\n111659\nNA\n111659\nNA\nNA\nNA\n2665814\n49490\n232926\nNA\nNA\nNA\n2948230\n3059889\n1000000\nNA\nNA\nNA\nNA\nNA\n276021\n2329470\n3605491\n6665380\nRevisemos cuántos datos tenemos envolatados (missing values):\nCódigo\n# Aplicar a cada columna una validación de NA\nsapply(data, function(x) sum(is.na(x))) |&gt; \n    data.frame() |&gt; \n    rownames_to_column() |&gt; \n    setNames(c(\"Rubro\",\"Missing\")) |&gt; \n    gt_preview(top_n = 5, bottom_n = 10) |&gt; \n    aplicar_theme_table()\n\n\n\n\n\n\n\n\n\nRubro\nMissing\n\n\n\n\n1\nPunto.de.Entrada\n0\n\n\n2\nNombre.Formulario\n0\n\n\n3\nNIT\n0\n\n\n4\nFecha.de.Corte\n0\n\n\n5\nRazon.Social\n0\n\n\n6..62\n\n\n\n\n63\nIssuedCapital\n0\n\n\n64\nSharePremium\n17590\n\n\n65\nTreasuryShares\n21859\n\n\n66\nInversionSuplementariaAlCapitalAsignado\n21697\n\n\n67\nOtherEquityInterest\n19220\n\n\n68\nSuperavitPorRevaluacion\n16563\n\n\n69\nOtherReserves\n5426\n\n\n70\nRetainedEarnings\n22\n\n\n71\nEquity\n0\n\n\n72\nEquityAndLiabilities\n0\nY qué pasa entonces con los valores en cero:\nCódigo\n# Aplicar a cada columna una validación de CEROS\nsapply(data, function(x) sum(x==0, na.rm = TRUE)) |&gt; \n    data.frame() |&gt; \n    rownames_to_column() |&gt; \n    setNames(c(\"Rubro\",\"Missing\")) |&gt; \n    gt_preview(top_n = 5, bottom_n = 10) |&gt; \n    aplicar_theme_table()\n\n\n\n\n\n\n\n\n\nRubro\nMissing\n\n\n\n\n1\nPunto.de.Entrada\n0\n\n\n2\nNombre.Formulario\n0\n\n\n3\nNIT\n0\n\n\n4\nFecha.de.Corte\n0\n\n\n5\nRazon.Social\n0\n\n\n6..62\n\n\n\n\n63\nIssuedCapital\n0\n\n\n64\nSharePremium\n2136\n\n\n65\nTreasuryShares\n2678\n\n\n66\nInversionSuplementariaAlCapitalAsignado\n2607\n\n\n67\nOtherEquityInterest\n2331\n\n\n68\nSuperavitPorRevaluacion\n1977\n\n\n69\nOtherReserves\n695\n\n\n70\nRetainedEarnings\n12\n\n\n71\nEquity\n2\n\n\n72\nEquityAndLiabilities\n3\nMe parece razonable suponer que habrán errores en las empresas que no reportan, o que reportan en ceros, Assets, Liabilities, Equity y EquityAndLiabilities. Así que van para afuera.\nCódigo\n# Descartar NA y 0's\n# data &lt;- data |&gt; \n#     filter_at(vars(Assets, Liabilities, Equity, EquityAndLiabilities),\n#               all_vars(!is.na(.))) |&gt; \n#     filter_at(vars(Assets, Liabilities, Equity, EquityAndLiabilities),\n#               all_vars(!.==0))\n\ncols &lt;- c(\"Assets\", \"Liabilities\", \"Equity\", \"EquityAndLiabilities\")\n\ndata &lt;- data |&gt;\n  filter_at(vars(!!!cols), ~ !is.na(.) & . != 0)\nVamos a ver por departamento cuántas empresas tiene el reporte:\nCódigo\n# Tabla para cantidad de empresas por departamento\ndata |&gt; \n    group_by(Departamento) |&gt; \n    summarise(Cantidad = n()) |&gt; \n    arrange(desc(Cantidad)) |&gt; \n    mutate(Proporcion = round(100*Cantidad / sum(Cantidad),2),\n           Acumulado = paste0(cumsum(Proporcion),\"%\")) |&gt; \n    gt_preview() |&gt; \n    aplicar_theme_table()\n\n\n\n\n\n\n\n\n\nDepartamento\nCantidad\nProporcion\nAcumulado\n\n\n\n\n1\nBOGOTA D.C.\n10207\n41.61\n41.61%\n\n\n2\nANTIOQUIA\n4308\n17.56\n59.17%\n\n\n3\nVALLE\n2386\n9.73\n68.9%\n\n\n4\nATLANTICO\n1548\n6.31\n75.21%\n\n\n5\nCUNDINAMARCA\n1254\n5.11\n80.32%\n\n\n6..31\n\n\n\n\n\n\n32\nGUAINIA\n1\n0.00\n100%\nEl balance general resume los bienes, pasivos y capital de los dueños de un negocio en un momento, que generalmente es a final del año o de un trimestre. El estado de pérdidas y ganancias resume los ingresos y gastos de la compañía durante un periodo determinado. El primero es una foto de la posición financiera, el segundo es el resumen de la rentabilidad en el tiempo.\nExisten razones financieras para comparar las empresas."
  },
  {
    "objectID": "posts/2025-02-07-equity_colombia/index.html#razones-de-liquidez",
    "href": "posts/2025-02-07-equity_colombia/index.html#razones-de-liquidez",
    "title": "Análisis de las razones financieras",
    "section": "Razones de liquidez",
    "text": "Razones de liquidez\nCapacidad de una empresa para cumplir con sus obligaciones a corto plazo.\n\nLiquidez corriente\n\\[\n\\frac{\\text{Activos corriente}}{\\text{Pasivos corrientes}}\n\\]\nEn teoría, entre más alta sea la liquidez corriente, mayor será la capacidad de la empresa para pagar sus deudas. Aunque esta razón debe verse como una medida burda porque no toma en cuenta la liquidez de los componentes individuales de los activos corrientes. Una empresa que tiene activos corrientes compuestos principalmente de efectivo y cuentas por cobrar no vencidas, en general se ve como con más liquidez que una empresa cuyos activos corrientes son principalmente inventarios. En consecuencia, recurrimos a una prueba de la liquidez de la empresa más severa: la razón de la prueba ácida.\n\n\n\n\n\n\nLa liquidez tiene dos dimensiones:\n1. El tiempo requerido para convertir el activo en efectivo.\n2. La certidumbre del precio obtenido.\nIncluso si el precio obtenido en cuentas por cobrar fuera tan predecible como el obtenido sobre los inventarios, las cuentas por cobrar serían un activo más líquido que los inventarios, en virtud del tiempo más corto requerido para convertir el activo en efectivo. Si se tuviera más certidumbre del precio obtenido sobre las cuentas por cobrar que sobre los inventarios, las cuentas por cobrar se considerarían de mayor liquidez.\n\n\n\n\n\nCódigo\ndata |&gt; \n    filter(Departamento == \"VALLE\") |&gt; \n    mutate(liquidez_corriente = CurrentAssets/CurrentLiabilities) |&gt; \n    filter(liquidez_corriente &lt; 10) |&gt; \n    ggplot(aes(liquidez_corriente))+\n    geom_density(col = \"orange\", size = 1.2) +\n    labs(x = \"RAZÓN LIQUIDEZ CORRIENTE\", y = \"DENSIDAD\",\n         title = \"LIQUIDEZ CORRIENTE EN EL VALLE DEL CAUCA\")+\n    scale_x_continuous(breaks = c(seq(0, 100, by = 1)))+\n    theme_minimal()+\n    theme(text = element_text(color = \"#1e2c46\"))\n\n\n\n\n\n\n\n\n\nAquí las cifras más aterrizadas para los que les gustan los datos;\n\n\nCódigo\nresultado_liquidez_corriente &lt;- data |&gt; \n    filter(Departamento == \"VALLE\") |&gt; \n    mutate(liquidez_corriente = CurrentAssets/CurrentLiabilities) |&gt; \n    filter(liquidez_corriente &lt; 10) |&gt; \n    with(ecdf(liquidez_corriente)) |&gt; \n    estilo_summary() |&gt; \n    gt() |&gt; \n    aplicar_theme_table()\n\nresultado_liquidez_corriente\n\n\n\n\n\n\n\n\nMedida\nFrecuencia\n\n\n\n\nMin.\n0.0000\n\n\n1st Qu.\n1.1563\n\n\nMedian\n1.6934\n\n\nMean\n2.3014\n\n\n3rd Qu.\n2.7441\n\n\nMax.\n9.9827\n\n\n\n\n\n\n\n\n\nRazon de la prueba ácida (rápida)\n\\[\n\\frac{\\text{Activos corrientes - Inventarios}}{\\text{Pasivos corrientes}}\n\\]\nEsta razón sirve como complemento de la liquidez corriente al analizar la liquidez. Excluye los inventarios —que se supone es la porción menos líquida de los activos corrientes— del numerador. La razón se concentra principalmente en los activos corrientes más líquidos —efectivo, valores de corto plazo y cuentas por cobrar— en relación con las obligaciones actuales. Así, esta razón ofrece una medida más precisa de la liquidez que la liquidez corriente:\n\n\nCódigo\ndata |&gt; \n    filter(Departamento == \"VALLE\") |&gt; \n    mutate(prueba_acida = (CurrentAssets - Inventories)/CurrentLiabilities) |&gt; \n    filter(prueba_acida &lt; 10) |&gt; \n    ggplot(aes(prueba_acida))+\n    geom_density(col = \"orange\", size = 1.2) +\n    labs(x = \"RAZÓN LIQUIDEZ CORRIENTE (sin Inventarios)\", y = \"DENSIDAD\",\n         title = \"PRUEBA ÁCIDA EN EL VALLE DEL CAUCA\")+\n    scale_x_continuous(breaks = c(seq(0, 100, by = 1)))+\n    theme_minimal()+\n    theme(text = element_text(color = \"#1e2c46\"))\n\n\n\n\n\n\n\n\n\n\n\nCódigo\nresultado_prueba_acida &lt;- data |&gt; \n    filter(Departamento == \"VALLE\") |&gt; \n    mutate(prueba_acida = (CurrentAssets - Inventories)/CurrentLiabilities) |&gt; \n    filter(prueba_acida &lt; 10) |&gt;\n    with(ecdf(prueba_acida)) |&gt; \n    estilo_summary() |&gt; \n    gt() |&gt; \n    aplicar_theme_table()\n\nresultado_prueba_acida\n\n\n\n\n\n\n\n\nMedida\nFrecuencia\n\n\n\n\nMin.\n0.0000\n\n\n1st Qu.\n0.6344\n\n\nMedian\n1.0728\n\n\nMean\n1.6211\n\n\n3rd Qu.\n1.8941\n\n\nMax.\n9.9846\n\n\n\n\n\n\n\nTenemos una diferencia de NA, 0.6206 entre las medianas de las razones.\n\n\n\n\n\n\nEstas razones no nos dicen si las cuentas por cobrar y/o los inventarios de hecho son demasiado altos. Si lo son, esto afectaría nuestra impresión inicial favorable de la liquidez de la compañía. Por eso, necesitamos ir detrás de las razones y examinar el tamaño, la composición y la calidad de estos dos activos corrientes importantes"
  },
  {
    "objectID": "posts/2025-02-07-equity_colombia/index.html#razones-de-apalancamiento-financiero-deuda",
    "href": "posts/2025-02-07-equity_colombia/index.html#razones-de-apalancamiento-financiero-deuda",
    "title": "Análisis de las razones financieras",
    "section": "Razones de apalancamiento financiero (deuda)",
    "text": "Razones de apalancamiento financiero (deuda)\nIndican el grado en el que una empresa se financia mediante deuda.\n\nRazón entre deuda y capital\n\\[\n\\frac{\\text{Deuda total}}{\\text{Capital de accionistas}}\n\\]\nNos dice cuánto de cada peso aportan los accionistas como financiamiento. En general, si fueras un acreedor, querrías tener una razón baja, porque así será mayor el nivel de financiamiento de la empresa que aportan los accionistas, el márgen de protección de los acreedores en caso de una disminución del valor de los activos o de pérdidas totales.\n\n\nCódigo\ndata |&gt; \n    filter(Departamento == \"VALLE\") |&gt; \n    mutate(deuda_capital = Liabilities/Equity) |&gt; \n    filter(deuda_capital &gt;= 0, deuda_capital &lt;= 5) |&gt; \n    ggplot(aes(deuda_capital))+\n    geom_density(col = \"orange\", size = 1.2) +\n    labs(x = \"RAZÓN DEUDA CAPITAL\", y = \"DENSIDAD\",\n         title = \"DEUDA / CAPITAL EN EL VALLE DEL CAUCA\")+\n    #scale_x_continuous(breaks = c(seq(0, 100, by = 1)))+\n    theme_minimal()+\n    theme(text = element_text(color = \"#1e2c46\"))\n\n\n\n\n\n\n\n\n\nPodría requerirse, dependiendo de la naturaleza del negocio, excluir las acciones preferenciales del capital e incluirlo en deuda porque representan una reclamación anterior desde el punto de vista de los inversionistas en acciones ordinarias. Pero aquí, lo hacemos de manera sencilla.\n\n\nCódigo\ndata |&gt; \n    filter(Departamento == \"VALLE\") |&gt; \n    mutate(deuda_capital = Liabilities/Equity) |&gt; \n    filter(deuda_capital &gt;= 0, deuda_capital &lt;= 5) |&gt; \n    with(ecdf(deuda_capital)) |&gt; \n    estilo_summary() |&gt; \n    gt() |&gt; \n    aplicar_theme_table()\n\n\n\n\n\n\n\n\nMedida\nFrecuencia\n\n\n\n\nMin.\n0.0000\n\n\n1st Qu.\n0.2174\n\n\nMedian\n0.7107\n\n\nMean\n1.0686\n\n\n3rd Qu.\n1.5373\n\n\nMax.\n4.9913\n\n\n\n\n\n\n\nUna comparación de la razón entre deuda y capital para una companía dada con empresas similares nos indica si es digna de crédito, así como el riesgo financiero de la empresa.\n\n\nRazón entre deuda y activos totales\nEsta razón tiene un propósito similar a la razón entre deuda y capital. Resalta la importancia relativa del financiamiento mediante deuda mostrando el porcentaje de los activos de la empresa que está solventado por el financiamiento mediante deuda.\n\\[\n\\frac{\\text{Deuda total}}{\\text{Activos totales}}\n\\]\nSi la empresa tuviera que liquidarse ya, los activos podrían venderse por una cantidad neta antes de que los acreedores tuvieran pérdidas. Cuanto más alta esta razón, más alto el riesgo de financiamiento.\n\n\nCódigo\ndata |&gt; \n    filter(Departamento == \"VALLE\") |&gt; \n    mutate(deuda_activos_total = Liabilities/Assets) |&gt; \n    filter(deuda_activos_total &gt;= 0, deuda_activos_total &lt;= 2) |&gt; \n    ggplot(aes(deuda_activos_total))+\n    geom_density(col = \"orange\", size = 1.2) +\n    labs(x = \"RAZÓN DEUDA ACTIVOS TOTALES\", y = \"DENSIDAD\",\n         title = \"DEUDA / ACTIVOS TOTALES EN EL VALLE DEL CAUCA\")+\n    #scale_x_continuous(breaks = c(seq(0, 100, by = 1)))+\n    theme_minimal()+\n    theme(text = element_text(color = \"#1e2c46\"))\n\n\n\n\n\n\n\n\n\nAquí se nos presenta una distribución con dos picos. Seguro que algún día les explico cómo enfrentarse a esto.\n\n\nCódigo\ndata |&gt; \n    filter(Departamento == \"VALLE\") |&gt; \n    mutate(deuda_activos_total = Liabilities/Assets) |&gt; \n    filter(deuda_activos_total &gt;= 0, deuda_activos_total &lt;= 2) |&gt; \n    with(ecdf(deuda_activos_total)) |&gt; \n    estilo_summary() |&gt; \n    gt() |&gt; \n    aplicar_theme_table()\n\n\n\n\n\n\n\n\nMedida\nFrecuencia\n\n\n\n\nMin.\n0.0000\n\n\n1st Qu.\n0.2057\n\n\nMedian\n0.4680\n\n\nMean\n0.4656\n\n\n3rd Qu.\n0.6832\n\n\nMax.\n1.9793\n\n\n\n\n\n\n\nPodríamos decir por ahora que el 46% de los bienes de la empresa están financiados con deuda, de varios tipos. Y el 54% restante del financiamiento proviene del capital de los accionistas.\nLos datos anteriores reflejan cortes de diciembre del año 2022. Si te interesa conocer la información más actual, o profundizar en otro tipo de análisis no dudes en contactarme.\nRecuerda que ninguna razón por sí sola nos entrega suficiente información para juzgar las condiciones financieras y el desempeño de una empresa. Debemos asegurarnos de analizar un grupo de indicadores, determinar si hay estacionalidad en las cifras, revisar las tendencias."
  },
  {
    "objectID": "posts/2025-02-07-equity_colombia/index.html#razones-de-cobertura",
    "href": "posts/2025-02-07-equity_colombia/index.html#razones-de-cobertura",
    "title": "Análisis de las razones financieras",
    "section": "Razones de cobertura",
    "text": "Razones de cobertura\nRelacionan los cargos financieros de una empresa con su capacidad para servirlos o cubrirlos.\n\nRazón de cobertura de interés\n\n\nCódigo\n# Función para extraer texto dentro de parentesis\nextraer_texto &lt;- function(texto){\n    inicial &lt;- gregexpr(\"\\\\(\", texto)[[1]]\n    final &lt;- gregexpr(\"\\\\)\", texto)[[1]]\n    substring(texto, inicial + 1, final - 1)\n}\n\n# Vector con los nombres extraídos\nnuevo_nombre &lt;- function(info){\n    colnames(info) |&gt; \n    purrr::map(~last(extraer_texto(.x))) |&gt; \n    unlist()\n}\n\npyg &lt;- openxlsx::read.xlsx(\"./310030_Estado de resultado integral, resultado del periodo, por funcion de gasto(3).xlsx\") |&gt; \n    data.table() |&gt; \n    filter(Fecha.de.Corte == \"2022-12-31\")\n\n# Asignar nombres en inglés\npyg &lt;- setNames(pyg, ifelse(nuevo_nombre(pyg) != \"\", nuevo_nombre(pyg), colnames(pyg)))\n\npyg &lt;- pyg |&gt; \n    filter(Periodo == \"Periodo Actual\", \n           `Departamento.de.la.direcci&#243;n.del.domicilio` == \"VALLE\")\n\n\nEsta razón sirve como medida de la capacidad de una empresa para cumplir con los pagos de interés y evitar bancarrota. A mayor valor, mayor la probabilidad de lograr cubrir pagos sin dificultad. Además, da información acerca de la posibilidad de enfrentar nueva deuda.\n\n\nCódigo\npyg |&gt; \n    mutate(cobertura_interes = ProfitLossBeforeTax/FinanceCosts) |&gt; \n    filter(cobertura_interes &gt;= 0, cobertura_interes &lt;= 20) |&gt; \n    ggplot(aes(cobertura_interes))+\n    geom_density(col = \"orange\", size = 1.2) +\n    labs(x = \"RAZÓN COBERTURA INTERÉS\", y = \"DENSIDAD\",\n         title = \"UAII/GASTO INTERÉS EN EL VALLE DEL CAUCA\")+\n    #scale_x_continuous(breaks = c(seq(0, 100, by = 1)))+\n    theme_minimal()+\n    theme(text = element_text(color = \"#1e2c46\"))\n\n\n\n\n\n\n\n\n\nEstos son los resultados para la razón de cobertura de interés:\n\n\nCódigo\npyg |&gt; \n    mutate(cobertura_interes = ProfitLossBeforeTax/FinanceCosts) |&gt; \n    filter(cobertura_interes &gt;= 0, cobertura_interes &lt;= 20) |&gt; \n    with(ecdf(cobertura_interes)) |&gt; \n    estilo_summary() |&gt; \n    gt() |&gt; \n    aplicar_theme_table()\n\n\n\n\n\n\n\n\nMedida\nFrecuencia\n\n\n\n\nMin.\n0.0007\n\n\n1st Qu.\n1.0434\n\n\nMedian\n2.7108\n\n\nMean\n4.5117\n\n\n3rd Qu.\n6.4900\n\n\nMax.\n19.9509\n\n\n\n\n\n\n\nAdemás de los pagos de interés, podemos agregar pagos del principal sobre las obligaciones de deuda, los dividendos de acciones preferenciales y los pagos de arrendamiento. Un análisis más amplio evaluará la capacidad de una empresa para cubrir todos los cargos de naturaleza fija."
  },
  {
    "objectID": "posts/2025-02-07-equity_colombia/index.html#razones-de-actividad",
    "href": "posts/2025-02-07-equity_colombia/index.html#razones-de-actividad",
    "title": "Análisis de las razones financieras",
    "section": "Razones de actividad",
    "text": "Razones de actividad\nMiden qué tan efectiva es la manera en que la empresa usa sus activos.\n\nRazón de rotación de cuentas por cobrar\nProporciona un panorama de la calidad de las cuentas por cobrar de la empresa y qué tan exitosa es en sus cobros.\n\\[\n\\frac{\\text{Ventas netas a crédito anuales}}{\\text{Cuentas por cobrar}}\n\\]\n\n\nCódigo\ncaratula &lt;- openxlsx::read.xlsx(\"./10000_Carátula.xlsx\") |&gt; \n    data.table()\n\nfull_join(\ndata |&gt; \n    filter(Periodo == \"Periodo Actual\") |&gt; \n    dplyr::select(c(3,4,5,13,14,62,72)) |&gt; \n    unique() \n,\npyg |&gt; \n    filter(Periodo == \"Periodo Actual\") |&gt; \n    dplyr::select(c(3,4,5,12)) |&gt; \n    unique()\n) |&gt; \n    left_join(caratula[,c(3,11)], by = c(\"NIT\")) |&gt; \n    mutate(RCC = Revenue / `TradeAndOtherCurrentReceivables`,\n           tiempo = 2024 - as.numeric(substr(`Fecha.de.constitución.(Aaaa-Mm-Dd)`,1,4))) |&gt; \n    filter(RCC &gt; 0, RCC &lt;= 20, !is.na(RCC), tiempo &gt;=0, !is.na(tiempo)) |&gt; \n    filter(tiempo &lt; 50) |&gt; \n   # ggplot(aes(as.numeric(tiempo), RCC, group = as.factor(tiempo)))+\n    ggplot(aes(RCC))+\n    geom_density(col = \"orange\", size = 1.2) +\n    labs(x = \"RAZÓN ROTACIÓN CUENTAS POR COBRAR\", y = \"DENSIDAD\",\n         title = \"VENTAS A CRÉDITO / CUENTAS POR COBRAR EN EL VALLE DEL CAUCA\")+\n    #scale_x_continuous(breaks = c(seq(0, 100, by = 1)))+\n    theme_minimal()+\n    theme(text = element_text(color = \"#1e2c46\"))\n\n\n\n\n\n\n\n\n\nNos dice el número de veces que las cuentas por cobrar se han convertido en efectivo durante el año. Aquí estamos suponiendo que todos los ingresos fueron por ventas a crédito (no tenemos información acerca de la cantidad exacta a través de los archivos de SIIS).\n\n\nCódigo\nfull_join(\ndata |&gt; \n    filter(Periodo == \"Periodo Actual\") |&gt; \n    dplyr::select(c(3,4,5,13,14,62,72)) |&gt; \n    unique() \n,\npyg |&gt; \n    filter(Periodo == \"Periodo Actual\") |&gt; \n    dplyr::select(c(3,4,5,12)) |&gt; \n    unique()\n) |&gt; \n    left_join(caratula[,c(3,11)], by = c(\"NIT\")) |&gt; \n    mutate(RCC = Revenue / `TradeAndOtherCurrentReceivables`,\n           tiempo = 2024 - as.numeric(substr(`Fecha.de.constitución.(Aaaa-Mm-Dd)`,1,4))) |&gt; \n    filter(RCC &gt; 0, RCC &lt;= 20, !is.na(RCC), tiempo &gt;=0, !is.na(tiempo)) |&gt; \n    filter(tiempo &lt; 50) |&gt; \n    with(ecdf(RCC)) |&gt; \n    estilo_summary() |&gt; \n    gt() |&gt; \n    aplicar_theme_table()\n\n\n\n\n\n\n\n\nMedida\nFrecuencia\n\n\n\n\nMin.\n0.0000\n\n\n1st Qu.\n1.5373\n\n\nMedian\n4.0015\n\n\nMean\n5.0863\n\n\n3rd Qu.\n7.3056\n\n\nMax.\n19.8855\n\n\n\n\n\n\n\nCuando las ventas son estacionales o han aumentado considerablemente en el año, usar el balance de las cuentas por cobrar al final del año puede no ser adecuado. Con estacionalidad, un promedio de los balances mensuales puede ser lo más apropiado. Con crecimiento, el balance de las cuentas por cobrar será engañosamente alto en relación con las ventas. El resultado es que la conversión de cuentas por cobrar en efectivo calculado es una estimación sesgada y baja del número de conversiones durante el año. En este caso, un promedio de las cuentas por cobrar al inicio y final del año será adecuado si el crecimiento en las ventas fue estable en el año.\n\n\nRotación de cuentas por cobrar en días\n\\[\n\\frac{\\text{Días del año}}{\\text{Rotación de cuentas por cobrar}} = \\frac{\\text{Cuentas por cobrar x días del año}}{\\text{Ventas a crédito anuales}}\n\\]\nNos dice el número promedio de días que las cuentas por cobrar están en circulación antes de ser cobradas, que para el caso de las empresas del Valle del Cauca es:\n\\[\n\\frac{365}{4}≅90\n\\]\nPodríamos decir que aunque un periodo promedio de cobro demasiado alto suele ser malo, un promedio muy bajo no necesariamente es bueno. Un periodo promedio muy bajo de cobro puede ser un síntoma de una política de crédito excesivamente restrictiva. Las pocas cuentas por cobrar que aparecen en los libros tal vez sean de primera calidad, pero las ventas quizás estén indebidamente restringidas —y las ganancias son menores a las que podrían ser— debido a que se otorgan créditos con muchas restricciones a los clientes.\n\n\nRazón de rotación de cuentas por pagar\nCapacidad de pago oportuno a los proveedores o el de algún potencial cliente candidato a crédito.\n\\[\n\\frac{\\text{Días en el año}}{\\text{Rotación de cuentas por pagar}}=\\frac{\\text{Cuentas por pagar x días en el año}}{\\text{Compras a crédito anuales}}\n\\]\n\n\nCódigo\nfull_join(\ndata |&gt; \n    filter(Periodo == \"Periodo Actual\") |&gt; \n    dplyr::select(c(3,4,5,13,14,43,51,62,72)) |&gt; \n    unique() \n,\npyg |&gt; \n    filter(Periodo == \"Periodo Actual\") |&gt; \n    dplyr::select(c(3,4,5,12,13)) |&gt; \n    unique()\n) |&gt; \n    left_join(caratula[,c(3,11)], by = c(\"NIT\")) |&gt; \n    mutate(RCP = (CurrentLiabilities+Inventories) / CostOfSales,\n           tiempo = 2024 - as.numeric(substr(`Fecha.de.constitución.(Aaaa-Mm-Dd)`,1,4))) |&gt; \n    filter(RCP &gt; 0, RCP &lt; 5, !is.na(RCP), tiempo &gt;=0, !is.na(tiempo)) |&gt; \n    filter(tiempo &lt; 50) |&gt; \n   # ggplot(aes(as.numeric(tiempo), RCC, group = as.factor(tiempo)))+\n    ggplot(aes(RCP))+\n    geom_density(col = \"orange\", size = 1.2) +\n    labs(x = \"RAZÓN ROTACIÓN CUENTAS POR PAGAR\", y = \"DENSIDAD\",\n         title = \"CUENTAS POR PAGAR / COMPRAS A CRÉDITO EN EL VALLE DEL CAUCA\")+\n    #scale_x_continuous(breaks = c(seq(0, 100, by = 1)))+\n    theme_minimal()+\n    theme(text = element_text(color = \"#1e2c46\"))\n\n\n\n\n\n\n\n\n\n\n\nCódigo\nfull_join(\ndata |&gt; \n    filter(Periodo == \"Periodo Actual\") |&gt; \n    dplyr::select(c(3,4,5,13,14,43,51,62,72)) |&gt; \n    unique() \n,\npyg |&gt; \n    filter(Periodo == \"Periodo Actual\") |&gt; \n    dplyr::select(c(3,4,5,12,13)) |&gt; \n    unique()\n) |&gt; \n    left_join(caratula[,c(3,11)], by = c(\"NIT\")) |&gt; \n    mutate(RCP = (CurrentLiabilities+Inventories) / CostOfSales,\n           tiempo = 2024 - as.numeric(substr(`Fecha.de.constitución.(Aaaa-Mm-Dd)`,1,4))) |&gt; \n    filter(RCP &gt; 0, RCP &lt; 5, !is.na(RCP), tiempo &gt;=0, !is.na(tiempo)) |&gt; \n    filter(tiempo &lt; 50) |&gt; \n    with(ecdf(RCP)) |&gt; \n    estilo_summary() |&gt; \n    gt() |&gt; \n    aplicar_theme_table()\n\n\n\n\n\n\n\n\nMedida\nFrecuencia\n\n\n\n\nMin.\n0.0019\n\n\n1st Qu.\n0.3258\n\n\nMedian\n0.5793\n\n\nMean\n0.8367\n\n\n3rd Qu.\n1.0276\n\n\nMax.\n4.9754\n\n\n\n\n\n\n\n\n\nRazón de rotación de inventarios\nDetermina qué tan efectiva es la empresa al administrar el inventario y también es una indicación de la liquidez del inventario.\n\\[\n\\frac{\\text{Costo de bienes vendidos}}{\\text{Inventarios}}\n\\]\n\n\nCódigo\nfull_join(\ndata |&gt; \n    filter(Periodo == \"Periodo Actual\") |&gt; \n    dplyr::select(c(3,4,5,13,14,62,72)) |&gt; \n    unique() \n,\npyg |&gt; \n    filter(Periodo == \"Periodo Actual\") |&gt; \n    dplyr::select(c(3,4,5,12,13)) |&gt; \n    unique()\n) |&gt; \n    left_join(caratula[,c(3,11)], by = c(\"NIT\")) |&gt; \n    mutate(RDI = CostOfSales / Inventories,\n           tiempo = 2024 - as.numeric(substr(`Fecha.de.constitución.(Aaaa-Mm-Dd)`,1,4))) |&gt; \n    filter(RDI &gt; 0, RDI &lt;= 20, !is.na(RDI), tiempo &gt;=0, !is.na(tiempo)) |&gt; \n    filter(tiempo &lt; 50) |&gt; \n    ggplot(aes(RDI))+\n    geom_density(col = \"orange\", size = 1.2) +\n    labs(x = \"RAZÓN ROTACIÓN INVENTARIOS\", y = \"DENSIDAD\",\n         title = \"COSTO DE BIENES / INVENTARIOS EN EL VALLE DEL CAUCA\")+\n    #scale_x_continuous(breaks = c(seq(0, 100, by = 1)))+\n    theme_minimal()+\n    theme(text = element_text(color = \"#1e2c46\"))\n\n\n\n\n\n\n\n\n\nLa razón de rotación de inventario nos dice cuántas veces el inventario se convierte en cuentas por cobrar a través de las ventas durante el año. Esta razón, como las otras, debe juzgarse en relación con las razones del pasado y el futuro esperado de la empresa y en relación con las razones de empresas similares, o el promedio de la industria o ambos.\n\n\nCódigo\nfull_join(\ndata |&gt; \n    filter(Periodo == \"Periodo Actual\") |&gt; \n    dplyr::select(c(3,4,5,13,14,62,72)) |&gt; \n    unique() \n,\npyg |&gt; \n    filter(Periodo == \"Periodo Actual\") |&gt; \n    dplyr::select(c(3,4,5,12,13)) |&gt; \n    unique()\n) |&gt; \n    left_join(caratula[,c(3,11)], by = c(\"NIT\")) |&gt; \n    mutate(RDI = CostOfSales / Inventories,\n           tiempo = 2024 - as.numeric(substr(`Fecha.de.constitución.(Aaaa-Mm-Dd)`,1,4))) |&gt; \n    filter(RDI &gt; 0, RDI &lt;= 20, !is.na(RDI), tiempo &gt;=0, !is.na(tiempo)) |&gt; \n    filter(tiempo &lt; 50) |&gt; \n    with(ecdf(RDI)) |&gt; \n    estilo_summary() |&gt; \n    gt() |&gt; \n    aplicar_theme_table()\n\n\n\n\n\n\n\n\nMedida\nFrecuencia\n\n\n\n\nMin.\n0.0002\n\n\n1st Qu.\n1.7339\n\n\nMedian\n3.6109\n\n\nMean\n5.1111\n\n\n3rd Qu.\n7.3148\n\n\nMax.\n19.9807\n\n\n\n\n\n\n\nEn general, cuanto más alta sea la rotación de inventario, más eficiente será su manejo, y más “fresco” y líquido será ese inventario. Sin embargo, algunas veces una rotación alta del inventario indica una existencia precaria. Por lo tanto, en realidad puede ser un síntoma de que hay un nivel de inventario muy bajo y con frecuencia se incurre en faltantes. Una rotación de inventario relativa- mente baja muchas veces es señal de un movimiento lento o de artículos obsoletos en el inventario\nRotación de inventario en días\n\\[\n\\frac{\\text{Días del año}}{\\text{Rotación de inventario}}=\\frac{\\text{Inventario x Días en el año}}{\\text{Costo de bienes vendidos}}\n\\]\nNos dice cuántos días, en promedio, pasan antes de que el inventario se convierta en cuentas por pagar mediante las ventas.\n\\[\n\\frac{365}{3.61}≅100\n\\]\n\n\nCiclo de operación\nEs el tiempo que transcurre desde el compromiso de efectivo para compras hasta el cobro de las cuentas por cobrar que resultan de la venta de bienes o servicios.\n\\[\n\\text{Rotación de inventario en días } +\\text{ Rotación de cuentas por cobrar en días}\n\\]\nLa mayoría de las empresas no pagan la materia prima de inmediato, sino compran a crédito e incurren en una cuenta por pagar.\n\\[\n100+90=190 \\text{ días para empresas del Valle del Cauca}\n\\]\n¿Por qué preocuparse por el ciclo de operación de una empresa? Una empresa con un ciclo de operación muy corto puede operar de manera efectiva con una cantidad relativamente pequeña de activos corrientes, y liquidez corriente y razón de prueba ácida relativamente bajas. Esta empresa tiene una liquidez relativa en un sentido “dinámico”: puede generar un producto, venderlo y cobrar en efectivo por él, todo en un periodo relativamente corto. No tiene que apoyarse en niveles de liquidez “estáticos” altos como los mide la liquidez corriente o la razón de la prueba ácida.\n\n\nRazón de rotación de activos totales\nNos indica la eficiencia relativa con la que una empresa usa sus activos totales para generar ventas.\n\\[\n\\frac{\\text{Ventas netas}}{\\text{Activos totales}}\n\\]\n\n\nCódigo\nfull_join(\ndata |&gt; \n    filter(Periodo == \"Periodo Actual\") |&gt; \n    dplyr::select(c(3,4,5,13,39,62,72)) |&gt; \n    unique() \n,\npyg |&gt; \n    filter(Periodo == \"Periodo Actual\") |&gt; \n    dplyr::select(c(3,4,5,12,13)) |&gt; \n    unique()\n) |&gt; \n    left_join(caratula[,c(3,11)], by = c(\"NIT\")) |&gt; \n    mutate(rotacion_capital = Revenue / Assets,\n           tiempo = 2024 - as.numeric(substr(`Fecha.de.constitución.(Aaaa-Mm-Dd)`,1,4))) |&gt; \n    filter(rotacion_capital &gt; 0, rotacion_capital &lt;= 5, !is.na(rotacion_capital), tiempo &gt;=0, !is.na(tiempo)) |&gt; \n    filter(tiempo &lt; 50) |&gt; \n    ggplot(aes(rotacion_capital))+\n    geom_density(col = \"orange\", size = 1.2) +\n    labs(x = \"RAZÓN ROTACIÓN ACTIVOS TOTALES\", y = \"DENSIDAD\",\n         title = \"VENTAS NETAS / ACTIVOS TOTALES EN EL VALLE DEL CAUCA\")+\n    #scale_x_continuous(breaks = c(seq(0, 100, by = 1)))+\n    theme_minimal()+\n    theme(text = element_text(color = \"#1e2c46\"))\n\n\n\n\n\n\n\n\n\n\n\nCódigo\nfull_join(\ndata |&gt; \n    filter(Periodo == \"Periodo Actual\") |&gt; \n    dplyr::select(c(3,4,5,13,39,62,72)) |&gt; \n    unique() \n,\npyg |&gt; \n    filter(Periodo == \"Periodo Actual\") |&gt; \n    dplyr::select(c(3,4,5,12,13)) |&gt; \n    unique()\n) |&gt; \n    left_join(caratula[,c(3,11)], by = c(\"NIT\")) |&gt; \n    mutate(rotacion_capital = Revenue / Assets,\n           tiempo = 2024 - as.numeric(substr(`Fecha.de.constitución.(Aaaa-Mm-Dd)`,1,4))) |&gt; \n    filter(rotacion_capital &gt; 0, rotacion_capital &lt;= 5, !is.na(rotacion_capital), tiempo &gt;=0, !is.na(tiempo)) |&gt; \n    filter(tiempo &lt; 50) |&gt; \n    with(ecdf(rotacion_capital)) |&gt; \n    estilo_summary() |&gt; \n    gt() |&gt; \n    aplicar_theme_table()\n\n\n\n\n\n\n\n\nMedida\nFrecuencia\n\n\n\n\nMin.\n0.0000\n\n\n1st Qu.\n0.1534\n\n\nMedian\n0.7450\n\n\nMean\n1.0356\n\n\n3rd Qu.\n1.5722\n\n\nMax.\n4.9878\n\n\n\n\n\n\n\nPodría existir una inversión excesiva en cuentas por cobrar y en inventarios."
  },
  {
    "objectID": "posts/2025-02-07-equity_colombia/index.html#razones-de-rentabilidad",
    "href": "posts/2025-02-07-equity_colombia/index.html#razones-de-rentabilidad",
    "title": "Análisis de las razones financieras",
    "section": "Razones de rentabilidad",
    "text": "Razones de rentabilidad\nRelacionan las ganancias con las ventas y la inversión.\n\nMárgen de ganancias brutas\nNos da la ganancia de la empresa relativa a las ventas, después de deducir el costo de producir los bienes. Es una medida de la eficiencia en la operación de la empresa, al igual que un indicador de cómo se asigna precio a los productos.\n\\[\n\\frac{\\text{Ventas netas - Costo de bienes vendidos}}{\\text{Ventas netas}}\n\\]\n\n\nCódigo\npyg |&gt; \n    left_join(caratula[,c(3,11)], by = c(\"NIT\")) |&gt; \n    mutate(margen_bruto = 100 * (Revenue-CostOfSales)/Revenue,\n           tiempo = 2024 - as.numeric(substr(`Fecha.de.constitución.(Aaaa-Mm-Dd)`,1,4))) |&gt; \n    filter(margen_bruto &gt; 0, margen_bruto &lt;= 200, !is.na(margen_bruto), tiempo &gt;=0, !is.na(tiempo)) |&gt; \n    ggplot(aes(margen_bruto))+\n    geom_density(col = \"orange\", size = 1.2) +\n    labs(x = \"MARGEN DE GANANCIAS BRUTAS (%)\", y = \"DENSIDAD\",\n         title = \"RENTABILIDAD (VENTAS) EN EL VALLE DEL CAUCA\")+\n    #scale_x_continuous(breaks = c(seq(0, 100, by = 1)))+\n    theme_minimal()+\n    theme(text = element_text(color = \"#1e2c46\"))\n\n\n\n\n\n\n\n\n\n\n\nCódigo\npyg |&gt; \n    left_join(caratula[,c(3,11)], by = c(\"NIT\")) |&gt; \n    mutate(margen_bruto = 100 * (Revenue-CostOfSales)/Revenue,\n           tiempo = 2024 - as.numeric(substr(`Fecha.de.constitución.(Aaaa-Mm-Dd)`,1,4))) |&gt; \n    filter(margen_bruto &gt; 0, margen_bruto &lt;= 200, !is.na(margen_bruto), tiempo &gt;=0, !is.na(tiempo)) |&gt; \n    with(ecdf(margen_bruto)) |&gt; \n    estilo_summary() |&gt; \n    gt() |&gt; \n    aplicar_theme_table()\n\n\n\n\n\n\n\n\nMedida\nFrecuencia\n\n\n\n\nMin.\n0.0747\n\n\n1st Qu.\n18.2208\n\n\nMedian\n29.5569\n\n\nMean\n35.1813\n\n\n3rd Qu.\n46.7363\n\n\nMax.\n100.0000\n\n\n\n\n\n\n\nSi el márgen de tu empresa está por encima del 30% significa que es más efectiva al producir y vender productos por arriba del costo que la mitad de las empresas en la región considerada.\n\n\nMárgen de ganancia neta\nUna medida de la rentabilidad de las ventas después de impuestos de la empresa tomando en cuenta todos los gastos e impuestos sobre la renta. Nos indica el ingreso neto por peso de venta.\n\\[\n\\frac{\\text{Ganancia neta después de impuestos}}{\\text{Ventas netas}}\n\\]\n\n\nCódigo\npyg |&gt; \n    left_join(caratula[,c(3,11)], by = c(\"NIT\")) |&gt; \n    mutate(margen_neto = 100 * (ProfitLoss)/Revenue,\n           tiempo = 2024 - as.numeric(substr(`Fecha.de.constitución.(Aaaa-Mm-Dd)`,1,4))) |&gt; \n    filter(margen_neto &gt; 0, margen_neto &lt;= 30, !is.na(margen_neto), tiempo &gt;=0, !is.na(tiempo)) |&gt; \n    ggplot(aes(margen_neto))+\n    geom_density(col = \"orange\", size = 1.2) +\n    labs(x = \"MARGEN DE GANANCIAS NETAS (%)\", y = \"DENSIDAD\",\n         title = \"RENTABILIDAD (VENTAS) EN EL VALLE DEL CAUCA\")+\n    #scale_x_continuous(breaks = c(seq(0, 100, by = 1)))+\n    theme_minimal()+\n    theme(text = element_text(color = \"#1e2c46\"))\n\n\n\n\n\n\n\n\n\n\n\nCódigo\npyg |&gt; \n    left_join(caratula[,c(3,11)], by = c(\"NIT\")) |&gt; \n    mutate(margen_neto = 100 * (ProfitLoss)/Revenue,\n           tiempo = 2024 - as.numeric(substr(`Fecha.de.constitución.(Aaaa-Mm-Dd)`,1,4))) |&gt; \n    filter(margen_neto &gt; 0, margen_neto &lt;= 30, !is.na(margen_neto), tiempo &gt;=0, !is.na(tiempo)) |&gt; \n    with(ecdf(margen_neto)) |&gt; \n    estilo_summary() |&gt; \n    gt() |&gt; \n    aplicar_theme_table()\n\n\n\n\n\n\n\n\nMedida\nFrecuencia\n\n\n\n\nMin.\n0.0118\n\n\n1st Qu.\n2.1408\n\n\nMedian\n4.5822\n\n\nMean\n6.5547\n\n\n3rd Qu.\n8.5911\n\n\nMax.\n29.9613\n\n\n\n\n\n\n\nSi el margen de ganancia bruta en esencia no cambia en un periodo de varios años, pero el margen de ganancia neta disminuye en el mismo periodo, sabemos que se puede deber a gastos de ventas, generales y administrativos más altos en relación con las ventas o a una tasa de impuestos más alta. Por otro lado, si el margen de ganancia bruta disminuye, sabemos que el costo de producir bienes con respecto a las ventas ha aumentado. Este suceso, a la vez, puede deberse a precios más bajos o a menor eficiencia operativa en relación con el volumen.\n\n\nRendimiento sobre la inversión\nEs la capacidad de generar ganancias sobre los activos totales.\n\\[\n\\text{Capacidad para generar ganancias = Rentabilidad x Eficiencia de activos}\n\\]\n\\[\n\\text{RSI = Márgen de ganancia neta x Rotación de activos totales}\n\\]\nNi el margen de ganancia neta ni la razón de rotación de activos totales, por sí mismos, representan una medida adecuada de la efectividad global. El margen de ganancia neta ignora la utilización de activos, y la razón de rotación de los activos totales ignora la rentabilidad sobre las ventas. La razón del rendimiento sobre la inversión, o capacidad de generar ganancias, resuelve estas deficiencias.\nPara el Valle del Cauca:\n\\[\n\\text{4.58% x 0.74= 3.38%}\n\\]\nAquí lo calculamos usando valores de la mediana y no la media.\n\n\nRendimiento sobre capital\nCompara la ganancia neta después de impuestos (menos los dividendos de acciones preferenciales, si las hay) con el capital que los accionistas han invertido en la empresa:\n\\[\n\\frac{\\text{Ganancia neta después de impuestos}}{\\text{Capital de accionistas}}\n\\]\nO con el enfoque Du Pont:\n\\[\n\\text{Rendimiento sobre capital = Márgen de ganancia neta x Rotación de activos totales x Multiplicador de capital}\n\\]\n\n\nCódigo\ndata |&gt; \n    left_join(caratula[,c(3,11)], by = c(\"NIT\")) |&gt; \n    mutate(multiplicador = Assets/Equity,\n           tiempo = 2024 - as.numeric(substr(`Fecha.de.constitución.(Aaaa-Mm-Dd)`,1,4))) |&gt; \n    filter(multiplicador &gt; 0, multiplicador &lt;= 30, !is.na(multiplicador), tiempo &gt;=0, !is.na(tiempo)) |&gt; \n    with(ecdf(multiplicador)) |&gt; \n    estilo_summary() |&gt; \n    gt() |&gt; \n    aplicar_theme_table()\n\n\n\n\n\n\n\n\nMedida\nFrecuencia\n\n\n\n\nMin.\n1.0000\n\n\n1st Qu.\n1.2796\n\n\nMedian\n1.8143\n\n\nMean\n2.8331\n\n\n3rd Qu.\n2.9409\n\n\nMax.\n29.9845\n\n\n\n\n\n\n\nEl multiplicador de capital se calcula como \\(\\text{Activos totales / Capital accionistas}\\) por lo que para el Valle del Cauca el rendimiento sobre capital es \\(\\text{3.38% x 1.81=6.11%}\\)\nAquí terminamos con las bases para nuestra serie."
  },
  {
    "objectID": "posts/2025-02-17-inventory_management/index.html",
    "href": "posts/2025-02-17-inventory_management/index.html",
    "title": "El impacto de los inventarios",
    "section": "",
    "text": "Existen cuatro áreas de gran impacto en el costo logístico de las empresas: transporte, inventario, almacenamiento y costos administrativos. Eso es lo que refleja la Encuesta Nacional de Logística (ENL).\nEl costo logístico es calculado como la razón entre el costo de las actividades logísticas de una empresa sobre el total de sus ventas en un periodo de tiempo.\nEsto es lo que contiene cada rubro:\nEsta serie de posts aborda inventarios y almacenamiento."
  },
  {
    "objectID": "posts/2025-02-17-inventory_management/index.html#qué-son-los-inventarios",
    "href": "posts/2025-02-17-inventory_management/index.html#qué-son-los-inventarios",
    "title": "El impacto de los inventarios",
    "section": "Qué son los inventarios?",
    "text": "Qué son los inventarios?\nEl inventario es un amortiguador entre dos procesos: el abastecimiento y la demanda. El proceso de abastecimiento contribuye con bienes al inventario, mientras que la demanda consume el mismo inventario.\nEl inventario es necesario debido a las diferencias en las tasas y los tiempos entre el abastecimiento y la demanda, y esa diferencia se puede atribuir tanto a factores internos como externos. Los factores externos difícilmente son controlables (incertidumbre). Lo que podría estar en control son los internos:\n\nEconomías de escala.\nSuavizamiento de la operación.\nServicio al cliente.\n\nComo los inventarios son “cantidad de un bien”, como tal, incurre en costos. Aquí tenemos una estructura general:\n\nCosto de compra: costo por artículo pagado a un proveedor.\nCosto de ordenar: se incurre cada que se coloca una orden y es independiente del tamaño del lote.\nCosto de almacenar o mantener: es un costo de oportunidad que se expresa, por lo general, como un porcentaje de la inversión en el inventario. El valor más bajo de este costo de oportunidad es el interés que ganaría el dinero en una cuenta de ahorros.\nCosto por faltante: un faltante ocurre cuando existe una demanda de un producto que no se tiene. En este caso puedes entregarlo con retraso (costo adicional de registro en libros o reprocesos) o simplemente perder la venta (perder la ganancia).\nCostos de operación o administrativos."
  },
  {
    "objectID": "posts/2025-02-17-inventory_management/index.html#cuál-es-el-verdadero-costo-de-almacenar-inventario",
    "href": "posts/2025-02-17-inventory_management/index.html#cuál-es-el-verdadero-costo-de-almacenar-inventario",
    "title": "El impacto de los inventarios",
    "section": "Cuál es el verdadero costo de almacenar inventario?",
    "text": "Cuál es el verdadero costo de almacenar inventario?\nEl buen manejo de inventario es un poderoso impulsor del desempeño financiero. En respuesta al crecimiento lento y las presiones sobre la rentabilidad, es claro que muchas empresas hoy en día están explorando nuevas formas de manejar mejor el inventario porque:\n\nLibera fondos para invertir en otros lugares.\nPermite vender productos a precios más bajos.\nFacilita el ingreso a nuevos mercados.\nEntrega otros beneficios que mejoran el desempeño financiero.\nCrean ventajas competitivas.\n\nSin embargo, a pesar de la importancia del manejo de inventario, parece haber poco consenso sobre cómo estimar el verdadero costo de mantener inventario - el costo total. Saber ese costo es clave para analizar los beneficios y costos asociados con cualquier iniciativa de manejo de inventario.\nEn esta serie vamos a explorar los principales factores que componen el costo total de mantener inventario, que incluyen tanto costos no capitalizados de mantener el inventario y costos de capital de inventario. Entenderemos por qué los profesionales de gestión de cadenas de suministro necesitan desarrollar estimaciones más precisas de costos no capitalizados para calcular el verdadero valor de proyectos diseñados para reducir inventario. La exclusión o minimización de estos costos puede subestimar el valor de proyectos de cadena de suministro y puede llevar al rechazo de proyectos que deberían ser aceptados. Es posible que muchas empresas usen un costo de capital que significativamente subestima la carga de capital de inventario y, por lo tanto, lleva a decisiones no óptimas en áreas como transporte, abastecimiento y diseño de red. Veremos por qué el uso de un costo de capital promedio ponderado es un enfoque mejor y cómo, al final, conduce a mejores decisiones de manejo de inventario.\n\nCosto Total de Mantener Inventario\nLos elementos que componen el costo total de mantener inventario (costos no capitalizados del inventario más la carga de capital del inventario) se muestran en la figura 1. Este costo total a menudo se expresa como un porcentaje de la inversión total en inventario para facilitar la comparación a lo largo del tiempo y entre empresas. Un desafío que existe es hacer estimaciones creíbles de los componentes de costos no capitalizados para fines de toma de decisiones.\n\n\n\n\n\n\nFigura 1: Estructura de costos de mantener inventario.\n\n\n\nOtro desafío importante se encuentra en las cifras de costo de capital utilizadas. Antes de presentar el método para llegar a un número de carga de capital más preciso, revisarémos brevemente los temas relacionados con la estimación de costos no capitalizados del inventario en los siguientes posts."
  },
  {
    "objectID": "posts/2025-02-18-holding_cost/index.html",
    "href": "posts/2025-02-18-holding_cost/index.html",
    "title": "Cuáles son los costos no capitalizados de mantener los inventarios?",
    "section": "",
    "text": "Costos No Capitalizados del Inventario\nLa ENL producida por el Departamento Nacional de Planeación (DNP) estima que, a nivel macro, los costos no capitalizados del inventario son aproximadamente del 13% - 25% del inventario.\n\n\n\n\n\n\n\n\nConcepto\nENL_2020\nENL_2022\n\n\n\n\nCostos Logístico como % de Ventas\n12.60%\n17.90%\n\n\n\n\n\n\n\nEstos porcentajes de costo logístico se dividen de la siguiente forma:\n\n\n\n\n\n\n\n\nConcepto\nENL_2020\nENL_2022\n\n\n\n\nTransporte\n30.70%\n35.90%\n\n\nAlmacenamiento\n13.90%\n25.10%\n\n\nInventarios\n29.30%\n25.50%\n\n\nAdministrativos\n17.80%\n10.20%\n\n\nOtros costos\n8.30%\n3.30%\n\n\n\n\n\n\n\nSeguro que la tasa tiende a variar según la industria, siendo un factor clave siendo el riesgo de obsolescencia. Hace falta ver el caso de NVIDIA vs DeepSeek e imaginar cúal fue el impacto en el tiempo de más que los procesadores más avanzados del primero se quedaron en las bodegas.\nHay varios desafíos en la estimación de costos no capitalizados del inventario. Estos se refieren a los costos asociados con el mantenimiento que no se capitalizan, es decir, que no se consideran parte del valor del activo y se registran como gastos en el momento en que se incurren. Por un lado, muchos sistemas de información de las empresas no capturan estos costos de manera que proporcione información útil para la toma de decisiones. Aunque esta información de costos puede ser capturada a nivel empresarial y aplicada a todo el inventario, a menudo no está disponible para una línea de productos, una región, un grupo de clientes o un canal.\nOtro desafío es comprender cómo estos costos, que pueden ser fijos o variables, fluctúan con los movimientos en el inventario. Por ejemplo, una reducción en el inventario resultante de una mejor gestión de la cadena de suministro tiende a reducir la obsolescencia, seguros e impuestos. Pero a menos que haya un cambio significativo en la red, los costos de almacenamiento y otros costos relacionados con el inventario tienden a permanecer constantes.\nCuando se evalúan iniciativas de cadena de suministro, las empresas a menudo descuentan, o incluso omiten, los beneficios de reducir costos no capitalizados del inventario porque no poseen estimaciones creíbles de estos costos. Muchos estarán de acuerdo con que estos beneficios existen. Pero sin estimaciones creíbles, los beneficios suelen ser excluidos del análisis. Si el impacto en estos costos no puede ser medido razonablemente, el valor verdadero de muchas iniciativas de cadena de suministro será subestimado.\nSupongamos que con un proyecto se espera reducir permanentemente el inventario en $10 millones. Los costos no capitalizados variables como porcentaje del inventario son del 10%. La tasa marginal de impuestos es del 40% y el costo de capital después de impuestos es del 9%. La ecuación siguiente muestra que el valor de este proyecto es el cambio en el valor total del inventario. Ese valor es de 10 millones si se excluyen los costos no capitalizados. Sin embargo, el valor es sustancialmente más alto - prácticamente $7 millones más alto- cuando se incluye el impacto en los costos no capitalizados.\n\n\n\n\n\n\n\n\nConcepto\nIncluído\nExcluído\n\n\n\n\nCambio en Inventario\n$10.0m\n$10.0m\n\n\n% No capitalizado\n10.0%\n-\n\n\nCambio en Costo No capitalizado\n$1.0m\n-\n\n\nTasa Impuestos\n40.0%\n-\n\n\nImpuestos\n$0.4m\n-\n\n\nCambio en Utilidad después de Impuestos anual\n$0.60\n-\n\n\nValor presente de Utilidad después de Impuestos @ 9.0% Costo de Capital (%0.6m/9.0%)\n$6.7m\n-\n\n\nValor Total\n$16.7m\n$10.0m\n\n\n\n\n\nEvaluación Ilustrativa del Cambio en el Inventario\n\n\nEste ejemplo destaca la necesidad de que los profesionales de la cadena de suministro construyan estimaciones más creíbles de los costos no capitalizados del inventario. El fracaso en hacerlo conduce a subestimar el valor real de las iniciativas de la cadena de suministro, lo que puede llevar al rechazo de proyectos que deberían ser aceptados.\nConsidero que el enfoque debe estar en las estimaciones de los componentes de costos no capitalizados relacionados con la obsolescencia, seguros y los impuestos por las siguientes razones:\n\nCon mucha probabilidad van a ser variables.\nLa información para estos componentes suelen estar disponibles o pueden ser extraídos fácilmente.\nNo requieren la asignación de costos generales fijos.\n\nCon esto en mente, nuestra tarea ahora es encontrar una buena estimación para incluir este costo en el total.\n\n\n\n\nCómo citarBibTeX@online{chiquito_valencia2025,\n  author = {Chiquito Valencia, Cristian},\n  title = {Cuáles Son Los Costos No Capitalizados de Mantener Los\n    Inventarios?},\n  date = {2025-02-18},\n  url = {https://cchiquitovalencia.github.io/posts/2025-02-18-holding_cost/},\n  langid = {en}\n}\nPor favor, cita este trabajo como:\nChiquito Valencia, Cristian. 2025. “Cuáles Son Los Costos No\nCapitalizados de Mantener Los Inventarios?” February 18, 2025. https://cchiquitovalencia.github.io/posts/2025-02-18-holding_cost/."
  },
  {
    "objectID": "posts/2025-02-19-charge_inventory/index.html",
    "href": "posts/2025-02-19-charge_inventory/index.html",
    "title": "Ahora la carga de capital de inventario",
    "section": "",
    "text": "Carga de Capital del Inventario\nRecuerda que aquí definimos la carga de capital del inventario como: \\(inventario × \\text{costo de capital}\\). Cuando se calcula correctamente, esta carga a menudo supera los costos no capitalizados. Desafortunadamente, la carga de capital a menudo se subestima porque se aplica un costo de capital incorrecto. Normalmente, esto es el resultado de uno de dos factores:\n\nEl riesgo del inventario y el costo de capital no coinciden.\nLa mezcla de cargas de capital después de impuestos con cargas no capitalizadas antes de impuestos.\n\nVamos a explorar cómo hacer coincidir adecuadamente el riesgo del inventario con el costo de capital apropiado.\nEl costo de capital es uno de los conceptos financieros más importantes y un bloque fundamental en la valoración y en la estimación de costos totales. Desafortunadamente, a menudo se ve como uno de los conceptos financieros más esotéricos. Además, es uno de los más confusos para aquellos que deben utilizarlo para tomar decisiones. Esta confusión a menudo se debe a una falta de entendimiento de qué comprende el costo de capital y la naturaleza de las relaciones riesgo-retorno.\nBásicamente, el costo de capital es el costo oportunidad de invertir en un activo en relación con el retorno esperado de activos con riesgo similar. Esto es comparable a cómo evaluamos inversiones en nuestras vidas personales. Por ejemplo, supongamos que durante el último año ganamos un 12% en un portafolio de acciones.\n\n\n¿Cómo se desempeñó nuestro portafolio?\nPara responder a esta pregunta, muchos de nosotros comparamos el retorno de nuestro portafolio con el desempeño de un índice de acciones de riesgo similar. Si nuestro portafolio está compuesto por un grupo diversificado de acciones, probablemente usaríamos un índice como el MSCI COLCAP.\n\n\n\n\n\n\nFigura 1: Rendimiento COLCAP.\n\n\n\nSupongamos que durante el último año, el COLCAP devolvió un 16%. Entonces, nuestro retorno del 12% se compara menos favorable. Si el COLCAP devolvió un 10%, por otro lado, entonces ese retorno, nuestro, del 12% fue favorable.\nEn este ejemplo, el retorno del COLCAP es el costo oportunidad del dinero. Si esperamos que el COLCAP genere un 10% en el futuro, entonces utilizaríamos este benchmark para evaluar inversiones con riesgo similar en planeación para la pensión, educación de los hijos, etc.\nAhora supongamos que nuestra tolerancia al riesgo era mucho más baja que la requerida para inversiones en acciones. Supongamos que estamos pensionados y nos enfocamos más en la generación de ingresos y en mantener el valor del principio de nuestra inversión. En este caso, el costo oportunidad de capital podría ser el retorno de las obligaciones del Títulos de Tesorería (TES), que actualmente (al momento de crear este post) es de alrededor del 9.31%.\n\n\n\n\n\n\nFigura 2: Rendimiento TES.\n\n\n\nSupongamos que fuéramos extremadamente enemigos al riesgo y valoráramos mucho mantener el valor del principio y, al mismo tiempo, quisiéramos un muy alto grado de liquidez porque vamos a hacer un pago inicial en una casa u otra compra importante en unos meses. En este ejemplo, el costo oportunidad de capital probablemente sería el retorno de un certificado de depósito a corto plazo, o aproximadamente un 9% (de nuevo, para la fecha de creación de este post, en los bancos usuales).\nDeterminar el riesgo del inventario es clave para decidir qué costo de capital debe utilizarse para calcular la carga de capital del inventario. El mayor riesgo de mantener inventario es que su valor se vuelve menos valioso debido a reducciones de precios, demanda baja y obsolescencia.\nAlgunos eventos en la industria de alta tecnología han marcado el riesgo de mantener inventario.\n\nMicron Technology: DRAM (memoria dinámica de acceso aleatorio).\nCisco Systems.\n\nAmbos casos resaltan el hecho de que la inversión en inventario no está exenta de riesgo.\n\n\n\n\nCómo citarBibTeX@online{chiquito_valencia2025,\n  author = {Chiquito Valencia, Cristian},\n  title = {Ahora La Carga de Capital de Inventario},\n  date = {2025-02-19},\n  url = {https://cchiquitovalencia.github.io/posts/2025-02-19-charge_inventory/},\n  langid = {en}\n}\nPor favor, cita este trabajo como:\nChiquito Valencia, Cristian. 2025. “Ahora La Carga de Capital de\nInventario.” February 19, 2025. https://cchiquitovalencia.github.io/posts/2025-02-19-charge_inventory/."
  },
  {
    "objectID": "posts/2025-02-20-WACC/index.html",
    "href": "posts/2025-02-20-WACC/index.html",
    "title": "Usa el costo de capital promedio ponderado",
    "section": "",
    "text": "Costo de Capital Promedio Ponderado\nDado el riesgo inherente del inventario, lo mejor es usar un costo promedio ponderado de capital (WACC, por sus siglas en inglés) para calcular la carga de capital del inventario. El WACC es el costo oportunidad para una empresa de su inversión de riesgo promedio. Teóricamente, un WACC diferente debería aplicarse a inversiones de riesgo diferente. Sin embargo, como asunto práctico, el mismo WACC se aplica internamente a todas las inversiones a menos que haya una diferencia sustancial en el riesgo.\nEl WACC se compone del costo del capital propio (patrimonio) y el costo de la deuda después de impuestos. El costo del capital propio es el costo de proporcionar a los accionistas retornos competitivos en su dinero invertidos. El costo de la deuda es simplemente la tasa de interés general en la deuda tomada para financiar el proyecto, reducida por el beneficio fiscal del gasto en intereses. Expresado como un porcentaje, el costo de capital es el promedio del retorno requerido de capital propio y la tasa de interés en la deuda, ponderado por la proporción de capital propio y deuda, respectivamente, en la capitalización total.\nEl concepto del costo de capital promedio ponderado se puede explicar en el contexto de una cartera de inversiones personales.\n\nSupongamos que tu portafolio tiene un \\(30\\%\\) invertido en TES que tienen una rentabilidad esperada del \\(6\\%\\).\nEl \\(70\\%\\) restante está invertido en acciones con una rentabilidad esperada a largo plazo del \\(11\\%\\).\nLa rentabilidad promedio ponderada de tu portafolio es aproximadamente del \\(9.5\\% = (30\\% × 6\\% + 70\\% × 11\\%)\\).\nAl evaluar el valor futuro de los ahorros para la pensión y otras decisiones, utilizarías la tasa promedio del \\(9.5\\%\\). Esto es, si alguien te ofrece invertir en un negocio que promete un \\(8\\%\\) debes tener claro que es una mala inversión, porque tu portafolio te da más que eso.\n\nEl costo promedio ponderado del capital (WACC) de una empresa se calcula de la siguiente manera:\n\\(WACC = \\text{\\% capital propio} × \\text{Costo de capital propio} + \\text{\\% Deuda} × \\text{Costo de la Deuda} × \\text{(100\\% - Tasa Impositiva Marginal)}\\)\nDonde:\n\n\\(\\text{\\% Capital propio}\\) es el porcentaje objetivo de capital financiado con capital propio.\n\\(\\text{\\% Deuda}\\) es el porcentaje objetivo de capital financiado con deuda.\n\\(\\% \\text{ Capital propio} + \\% \\text{ Deuda} = 100\\%\\).\n\nEstimar el costo de capital propio es la parte más desafiante al derivar el WACC. Hay diversas metodologías utilizadas para estimar el costo de capital propio. Usaremos una de ellas en otro post. Pero basta decir que la mayoría de las empresas actualizan la estimación del costo de capital propio, así como los demás componentes del WACC, una vez al año.\nPor ahora asumamos que tenemos un WACC de \\(9\\%\\), como se determina a continuación:\n\\[\n\\text{70\\% de capital propio × 11\\% de Costo de capital propio }+\n\\]\n\\[\n\\text{30\\% de Deuda × 6.5\\% de Costo de la Deuda × (100\\% - 40\\% de Tasa Impositiva Marginal)}\n\\]\n\\[\n\\text{≅ 9.0\\% de Costo Promedio Ponderado del Capital}\n\\]\nEs importante destacar que el WACC es una tasa después de impuestos. El \\(11\\%\\) de costo de capital propio utilizado aquí es un costo después de impuestos porque comprende los dividendos pagados a los accionistas y el crecimiento del precio de las acciones, ninguno de los cuales es deducible de impuestos. El \\(6.5\\%\\) de costo de la deuda es una tasa antes de impuestos que se ajusta a una tasa después de impuestos multiplicándolo por el término \\((100\\% - 40\\% \\text{ de tasa impositiva marginal)}\\). Este ajuste tiene en cuenta la deducibilidad fiscal de los intereses.\n\n\n\n\nCómo citarBibTeX@online{chiquito_valencia2025,\n  author = {Chiquito Valencia, Cristian},\n  title = {Usa El Costo de Capital Promedio Ponderado},\n  date = {2025-02-20},\n  url = {https://cchiquitovalencia.github.io/posts/2025-02-20-WACC/},\n  langid = {en}\n}\nPor favor, cita este trabajo como:\nChiquito Valencia, Cristian. 2025. “Usa El Costo de Capital\nPromedio Ponderado.” February 20, 2025. https://cchiquitovalencia.github.io/posts/2025-02-20-WACC/."
  },
  {
    "objectID": "posts/2025-02-21-finantial_ratios/index.html",
    "href": "posts/2025-02-21-finantial_ratios/index.html",
    "title": "Análisis de las razones financieras",
    "section": "",
    "text": "Para continuar con nuestro análisis del impacto de la administración de inventarios, debemos tener presente algunas razones financieras. No vamos a cubrirlas todas, pero sí vamos a estimar los valores de las Pymes en el Valle del Cauca, con la intención de que puedas usar estos datos para el desarrollo de la serie.\nLo primero, por si no lo sabías, existe un Sistema Integrado de Información Societaria donde puedes ver el Estado de Situación Financiera, el Estado de Resultado Integral, entre otros, que reportan las empresas. Lo administra una entidad adscrita del Ministerio de Comercio, Industria y Turismo: la Superintendencia de Sociedades.\nCódigo\nlibrary(tidyverse)\nlibrary(data.table)\nlibrary(gt)\n\nknitr::opts_chunk$set(message = FALSE, warning = FALSE, fig.align = \"center\")\n\nestilo_summary &lt;- function(resumen){\n    resumen |&gt; \n        summary() |&gt; \n        as.data.frame() |&gt; \n        rownames_to_column() |&gt; \n        #dplyr::select(c(Var2,Freq)) |&gt; \n        rename(Medida = rowname,\n               Frecuencia = x) |&gt; \n        mutate(Frecuencia = round(Frecuencia,4))\n}\n\naplicar_theme_table &lt;- function(gt_table) {\n    gt_table %&gt;%\n        cols_align(align = \"center\") |&gt; \n        tab_options(\n            table.border.top.color = \"orange\",\n            table.font.color = \"#1e2c46\",\n            table_body.hlines.color = \"orange\",\n            column_labels.background.color = \"#1e2c46\"\n        )\n}\nVamos a revisar los datos:\nCódigo\ndata &lt;- openxlsx::read.xlsx(\"./210030_Estado de situación financiera, corriente_no corriente.xlsx\") |&gt; \n    data.table()\n\n# Función para extraer texto dentro de parentesis\nextraer_texto &lt;- function(texto){\n    inicial &lt;- gregexpr(\"\\\\(\", texto)[[1]]\n    final &lt;- gregexpr(\"\\\\)\", texto)[[1]]\n    substring(texto, inicial + 1, final - 1)\n}\n\n# Vector con los nombres extraídos\nnuevo_nombre &lt;- colnames(data) |&gt; \n    purrr::map(~extraer_texto(.x)) |&gt; \n    unlist()\n\n# Asignar nombres en inglés\ndata &lt;- setNames(data, ifelse(nuevo_nombre != \"\", nuevo_nombre, colnames(data)))\n\n# Cambiar otros nombres\ndata &lt;- data |&gt; \n    rename(Razon.Social = \"Raz&#243;n.social.de.la.sociedad\",\n           Direccion = \"Direcci&#243;n.de.notificaci&#243;n.judicial.registrada.en.C&#225;mara.de.Comercio\",\n           Departamento = \"Departamento.de.la.direcci&#243;n.del.domicilio\",\n           Ciudad = \"Ciudad.de.la.direcci&#243;n.del.domicilio\",\n           TotalCurrentFinancialAssetsSELL= \"Total_activos_corrientes_distintos_de_los_activos_no_corrientes_o_grupo_de_activos_para_su_disposicion_clasificados_como_mantenidos_para_la_venta_o_como_mantenidos_para_distribuir_a_los_propietarios\",\n           OtherCurrentFinancialAssetsSELL= \"Activos_no_corrientes_o_grupos_de_activos_para_su_disposicion_clasificados_como_mantenidos_para_la_venta_o_como_mantenidos_para_distribuir_a_los_propietarios\",\n           PropertyPlantAndEquipmentWithDEP= \"Propiedades_de_inversi&#243;n_al_costo_menos_depreciacion_acumulada_y_deterioro\",\n           TotalCurrentFinancialLiabilitiesSELL = \"Total_pasivos_corrientes_distintos_de_los_pasivos_incluidos_en_grupos_de_activos_para_su_disposicion_clasificados_como_mantenidos_para_la_venta\",\n           OtherCurrentFinancialLiabilitiesSELL= \"Pasivos_incluidos_en_grupos_de_activos_para_su_disposicion_clasificados_como_mantenidos_para_la_venta\")\n\n# Solo veremos el periodo final\ndata &lt;- data |&gt; \n    filter(Periodo == \"Periodo Actual\",\n           Fecha.de.Corte == \"2022-12-31\")\n\n\ngt(head(data,5)) |&gt; \n    aplicar_theme_table() |&gt; \n    tab_options(table.width = pct(50))\n\n\n\n\n\n\n\n\nPunto.de.Entrada\nNombre.Formulario\nNIT\nFecha.de.Corte\nRazon.Social\nCIIU\nTipo.societario\nDireccion\nDepartamento\nCiudad\nPeriodo\nCashAndCashEquivalents\nTradeAndOtherCurrentReceivables\nInventories\nCurrentTaxAssetsCurrent\nCurrentBiologicalAssetsAtCost\nCurrentBiologicalAssetsAtFairValue\nOtherCurrentFinancialAssets\nOtherCurrentNonfinancialAssets\nCurrentNoncashAssetsPledgedAsCollateralForWhichTransfereeHasRightByContractOrCustomToSellOrRepledgeCollateral\nTotalCurrentFinancialAssetsSELL\nOtherCurrentFinancialAssetsSELL\nCurrentAssets\nPropertyPlantAndEquipment\nPropertyPlantAndEquipmentWithDEP\nInvestmentProperty\nGoodwill\nIntangibleAssetsOtherThanGoodwill\nNoncurrentBiologicalAssetsAtCost\nNoncurrentBiologicalAssetsAtFairValue\nNoncurrentReceivables\nNoncurrentInventories\nDeferredTaxAssets\nCurrentTaxAssetsNoncurrent\nOtherNoncurrentFinancialAssets\nOtherNoncurrentNonfinancialAssets\nNoncurrentNoncashAssetsPledgedAsCollateralForWhichTransfereeHasRightByContractOrCustomToSellOrRepledgeCollateral\nNoncurrentAssets\nAssets\nCurrentProvisionsForEmployeeBenefits\nOtherShorttermProvisions\nCurrentProvisions\nTradeAndOtherCurrentPayables\nCurrentTaxLiabilitiesCurrent\nOtherCurrentFinancialLiabilities\nShorttermBorrowings\nCurrentPortionOfLongtermBorrowings\nOtherCurrentNonfinancialLiabilities\nTotalCurrentFinancialLiabilitiesSELL\nOtherCurrentFinancialLiabilitiesSELL\nCurrentLiabilities\nNoncurrentProvisionsForEmployeeBenefits\nOtherLongtermProvisions\nNoncurrentProvisions\nNoncurrentPayables\nDeferredTaxLiabilities\nCurrentTaxLiabilitiesNoncurrent\nOtherNoncurrentFinancialLiabilities\nLongtermBorrowings\nOtherNoncurrentNonfinancialLiabilities\nNoncurrentLiabilities\nLiabilities\nIssuedCapital\nSharePremium\nTreasuryShares\nInversionSuplementariaAlCapitalAsignado\nOtherEquityInterest\nSuperavitPorRevaluacion\nOtherReserves\nRetainedEarnings\nEquity\nEquityAndLiabilities\n\n\n\n\nPymes-Individuales\nEstado de situaci&#243;n financiera, corriente/no corriente\n800000090\n2022-12-31\nIngenieros Servicios Constructivos SAS\nF4111 - Construcci&#243;n de edificios residenciales\n08. SOCIEDAD POR ACCIONES SIMPLIFICADA SAS\nCarrera 38 26 17 OFICINA 922 y 926\nANTIOQUIA\nMEDELLIN-ANTIOQUIA\nPeriodo Actual\n2922\n3769426\n0\n108391\nNA\nNA\nNA\n8548153\nNA\n12428892\nNA\n12428892\n357599\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n357599\n12786491\n304289\n3279\n307568\n1292633\n733077\n1235364\n1235364\nNA\nNA\n3568642\nNA\n3568642\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n4743536\n4743536\n8312178\n1500000\n2392140\nNA\nNA\n0\nNA\n10616\n571557\n4474313\n12786491\n\n\nPymes-Individuales\nEstado de situaci&#243;n financiera, corriente/no corriente\n800000241\n2022-12-31\nCERERIA EL SAGRADO CORAZON LTDA\nC3290 - Otras industrias manufactureras n.c.p.\n03. SOCIEDAD LIMITADA\nKM 5.5 VIA LA BUITRERA PREDIO LA CANANEA\nVALLE\nCALI-VALLE\nPeriodo Actual\n434850\n3294074\n2412864\nNA\nNA\nNA\n51621\nNA\nNA\n6193409\nNA\n6193409\n564126\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n18708\nNA\nNA\n582834\n6776243\n114962\nNA\n114962\n2775642\n294400\n253216\n253216\nNA\nNA\n3438220\nNA\n3438220\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n3438220\n200000\nNA\nNA\nNA\nNA\n132740\n130902\n2874381\n3338023\n6776243\n\n\nPymes-Individuales\nEstado de situaci&#243;n financiera, corriente/no corriente\n800000268\n2022-12-31\nINVERSIONES SCHLEGEL DONADO SAS\nL6810 - Actividades inmobiliarias realizadas con bienes propios o arrendados\n08. SOCIEDAD POR ACCIONES SIMPLIFICADA SAS\nCARRERA 53 82 115\nATLANTICO\nBARRANQUILLA-ATLANTICO\nPeriodo Actual\n53687\n0\n25408\n17038\n0\n0\n0\n516081\n0\n612214\n0\n612214\nNA\n4939698\n2189617\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n7129315\n7741529\n0\n0\n0\n1531298\n44434\n0\n0\n0\n0\n1575732\n0\n1575732\n0\n0\n0\n0\n345913\n0\n2780438\n2780438\n0\n3126351\n4702083\n70000\n0\n0\n0\n0\n1970655\n35000\n963791\n3039446\n7741529\n\n\nPymes-Individuales\nEstado de situaci&#243;n financiera, corriente/no corriente\n800000276\n2022-12-31\nAVICOLA EL MADRO&#209;O SA\nA0145 - Cr&#237;a de aves de corral\n01. SOCIEDAD AN&#211;NIMA\nKM 6 VIA GIRON CR 12 # 57 - 88\nSANTANDER\nBUCARAMANGA-SANTANDER\nPeriodo Actual\n2331706\n60436680\n42997280\n14035926\n20869714\nNA\n1391059\n3106904\nNA\n145169269\nNA\n145169269\n132086107\nNA\nNA\nNA\n50000\nNA\nNA\nNA\nNA\n1266864\nNA\n141186\nNA\nNA\n133544157\n278713426\n4079708\nNA\n4079708\n84899951\n8285620\n26275037\n18918026\n7357011\n69993\n123610309\nNA\n123610309\nNA\nNA\nNA\nNA\n10438735\nNA\n47342439\n47342439\n2230000\n60011174\n183621483\n3576000\n17073150\nNA\nNA\nNA\n41224684\n1788000\n31430109\n95091943\n278713426\n\n\nPymes-Individuales\nEstado de situaci&#243;n financiera, corriente/no corriente\n800000296\n2022-12-31\nZR INGENIERIA SA\nF4290 - Construcci&#243;n de otras obras de ingenier&#237;a civil\n01. SOCIEDAD AN&#211;NIMA\nCL 106 57 23 OF 204\nBOGOTA D.C.\nBOGOTA D.C.\nPeriodo Actual\n8991\n416673\n1482034\nNA\nNA\nNA\n527379\nNA\nNA\n2435077\nNA\n2435077\n648\nNA\nNA\nNA\nNA\nNA\nNA\n4202324\nNA\nNA\nNA\n27131\nNA\n200\n4230303\n6665380\n25059\nNA\n25059\n28018\n21233\nNA\nNA\nNA\n37349\n111659\nNA\n111659\nNA\nNA\nNA\n2665814\n49490\n232926\nNA\nNA\nNA\n2948230\n3059889\n1000000\nNA\nNA\nNA\nNA\nNA\n276021\n2329470\n3605491\n6665380\nRevisemos cuántos datos tenemos envolatados (missing values):\nCódigo\n# Aplicar a cada columna una validación de NA\nsapply(data, function(x) sum(is.na(x))) |&gt; \n    data.frame() |&gt; \n    rownames_to_column() |&gt; \n    setNames(c(\"Rubro\",\"Missing\")) |&gt; \n    gt_preview(top_n = 5, bottom_n = 10) |&gt; \n    aplicar_theme_table()\n\n\n\n\n\n\n\n\n\nRubro\nMissing\n\n\n\n\n1\nPunto.de.Entrada\n0\n\n\n2\nNombre.Formulario\n0\n\n\n3\nNIT\n0\n\n\n4\nFecha.de.Corte\n0\n\n\n5\nRazon.Social\n0\n\n\n6..62\n\n\n\n\n63\nIssuedCapital\n0\n\n\n64\nSharePremium\n17590\n\n\n65\nTreasuryShares\n21859\n\n\n66\nInversionSuplementariaAlCapitalAsignado\n21697\n\n\n67\nOtherEquityInterest\n19220\n\n\n68\nSuperavitPorRevaluacion\n16563\n\n\n69\nOtherReserves\n5426\n\n\n70\nRetainedEarnings\n22\n\n\n71\nEquity\n0\n\n\n72\nEquityAndLiabilities\n0\nY qué pasa entonces con los valores en cero:\nCódigo\n# Aplicar a cada columna una validación de CEROS\nsapply(data, function(x) sum(x==0, na.rm = TRUE)) |&gt; \n    data.frame() |&gt; \n    rownames_to_column() |&gt; \n    setNames(c(\"Rubro\",\"Missing\")) |&gt; \n    gt_preview(top_n = 5, bottom_n = 10) |&gt; \n    aplicar_theme_table()\n\n\n\n\n\n\n\n\n\nRubro\nMissing\n\n\n\n\n1\nPunto.de.Entrada\n0\n\n\n2\nNombre.Formulario\n0\n\n\n3\nNIT\n0\n\n\n4\nFecha.de.Corte\n0\n\n\n5\nRazon.Social\n0\n\n\n6..62\n\n\n\n\n63\nIssuedCapital\n0\n\n\n64\nSharePremium\n2136\n\n\n65\nTreasuryShares\n2678\n\n\n66\nInversionSuplementariaAlCapitalAsignado\n2607\n\n\n67\nOtherEquityInterest\n2331\n\n\n68\nSuperavitPorRevaluacion\n1977\n\n\n69\nOtherReserves\n695\n\n\n70\nRetainedEarnings\n12\n\n\n71\nEquity\n2\n\n\n72\nEquityAndLiabilities\n3\nMe parece razonable suponer que habrán errores en las empresas que no reportan, o que reportan en ceros, Assets, Liabilities, Equity y EquityAndLiabilities. Así que van para afuera.\nCódigo\n# Descartar NA y 0's\n# data &lt;- data |&gt; \n#     filter_at(vars(Assets, Liabilities, Equity, EquityAndLiabilities),\n#               all_vars(!is.na(.))) |&gt; \n#     filter_at(vars(Assets, Liabilities, Equity, EquityAndLiabilities),\n#               all_vars(!.==0))\n\ncols &lt;- c(\"Assets\", \"Liabilities\", \"Equity\", \"EquityAndLiabilities\")\n\ndata &lt;- data |&gt;\n  filter_at(vars(!!!cols), ~ !is.na(.) & . != 0)\nVamos a ver por departamento cuántas empresas tiene el reporte:\nCódigo\n# Tabla para cantidad de empresas por departamento\ndata |&gt; \n    group_by(Departamento) |&gt; \n    summarise(Cantidad = n()) |&gt; \n    arrange(desc(Cantidad)) |&gt; \n    mutate(Proporcion = round(100*Cantidad / sum(Cantidad),2),\n           Acumulado = paste0(cumsum(Proporcion),\"%\")) |&gt; \n    gt_preview() |&gt; \n    aplicar_theme_table()\n\n\n\n\n\n\n\n\n\nDepartamento\nCantidad\nProporcion\nAcumulado\n\n\n\n\n1\nBOGOTA D.C.\n10207\n41.61\n41.61%\n\n\n2\nANTIOQUIA\n4308\n17.56\n59.17%\n\n\n3\nVALLE\n2386\n9.73\n68.9%\n\n\n4\nATLANTICO\n1548\n6.31\n75.21%\n\n\n5\nCUNDINAMARCA\n1254\n5.11\n80.32%\n\n\n6..31\n\n\n\n\n\n\n32\nGUAINIA\n1\n0.00\n100%\nEl balance general resume los bienes, pasivos y capital de los dueños de un negocio en un momento, que generalmente es a final del año o de un trimestre. El estado de pérdidas y ganancias resume los ingresos y gastos de la compañía durante un periodo determinado. El primero es una foto de la posición financiera, el segundo es el resumen de la rentabilidad en el tiempo.\nExisten razones financieras para comparar las empresas."
  },
  {
    "objectID": "posts/2025-02-21-finantial_ratios/index.html#razones-de-liquidez",
    "href": "posts/2025-02-21-finantial_ratios/index.html#razones-de-liquidez",
    "title": "Análisis de las razones financieras",
    "section": "Razones de liquidez",
    "text": "Razones de liquidez\nCapacidad de una empresa para cumplir con sus obligaciones a corto plazo.\n\nLiquidez corriente\n\\[\n\\frac{\\text{Activos corriente}}{\\text{Pasivos corrientes}}\n\\]\nEn teoría, entre más alta sea la liquidez corriente, mayor será la capacidad de la empresa para pagar sus deudas. Aunque esta razón debe verse como una medida burda porque no toma en cuenta la liquidez de los componentes individuales de los activos corrientes. Una empresa que tiene activos corrientes compuestos principalmente de efectivo y cuentas por cobrar no vencidas, en general se ve como con más liquidez que una empresa cuyos activos corrientes son principalmente inventarios. En consecuencia, recurrimos a una prueba de la liquidez de la empresa más severa: la razón de la prueba ácida.\n\n\n\n\n\n\nLa liquidez tiene dos dimensiones:\n1. El tiempo requerido para convertir el activo en efectivo.\n2. La certidumbre del precio obtenido.\nIncluso si el precio obtenido en cuentas por cobrar fuera tan predecible como el obtenido sobre los inventarios, las cuentas por cobrar serían un activo más líquido que los inventarios, en virtud del tiempo más corto requerido para convertir el activo en efectivo. Si se tuviera más certidumbre del precio obtenido sobre las cuentas por cobrar que sobre los inventarios, las cuentas por cobrar se considerarían de mayor liquidez.\n\n\n\n\n\nCódigo\ndata |&gt; \n    filter(Departamento == \"VALLE\") |&gt; \n    mutate(liquidez_corriente = CurrentAssets/CurrentLiabilities) |&gt; \n    filter(liquidez_corriente &lt; 10) |&gt; \n    ggplot(aes(liquidez_corriente))+\n    geom_density(col = \"orange\", size = 1.2) +\n    labs(x = \"RAZÓN LIQUIDEZ CORRIENTE\", y = \"DENSIDAD\",\n         title = \"LIQUIDEZ CORRIENTE EN EL VALLE DEL CAUCA\")+\n    scale_x_continuous(breaks = c(seq(0, 100, by = 1)))+\n    theme_minimal()+\n    theme(text = element_text(color = \"#1e2c46\"))\n\n\n\n\n\n\n\n\n\nAquí las cifras más aterrizadas para los que les gustan los datos;\n\n\nCódigo\nresultado_liquidez_corriente &lt;- data |&gt; \n    filter(Departamento == \"VALLE\") |&gt; \n    mutate(liquidez_corriente = CurrentAssets/CurrentLiabilities) |&gt; \n    filter(liquidez_corriente &lt; 10) |&gt; \n    with(ecdf(liquidez_corriente)) |&gt; \n    estilo_summary() |&gt; \n    gt() |&gt; \n    aplicar_theme_table()\n\nresultado_liquidez_corriente\n\n\n\n\n\n\n\n\nMedida\nFrecuencia\n\n\n\n\nMin.\n0.0000\n\n\n1st Qu.\n1.1563\n\n\nMedian\n1.6934\n\n\nMean\n2.3014\n\n\n3rd Qu.\n2.7441\n\n\nMax.\n9.9827\n\n\n\n\n\n\n\n\n\nRazon de la prueba ácida (rápida)\n\\[\n\\frac{\\text{Activos corrientes - Inventarios}}{\\text{Pasivos corrientes}}\n\\]\nEsta razón sirve como complemento de la liquidez corriente al analizar la liquidez. Excluye los inventarios —que se supone es la porción menos líquida de los activos corrientes— del numerador. La razón se concentra principalmente en los activos corrientes más líquidos —efectivo, valores de corto plazo y cuentas por cobrar— en relación con las obligaciones actuales. Así, esta razón ofrece una medida más precisa de la liquidez que la liquidez corriente:\n\n\nCódigo\ndata |&gt; \n    filter(Departamento == \"VALLE\") |&gt; \n    mutate(prueba_acida = (CurrentAssets - Inventories)/CurrentLiabilities) |&gt; \n    filter(prueba_acida &lt; 10) |&gt; \n    ggplot(aes(prueba_acida))+\n    geom_density(col = \"orange\", size = 1.2) +\n    labs(x = \"RAZÓN LIQUIDEZ CORRIENTE (sin Inventarios)\", y = \"DENSIDAD\",\n         title = \"PRUEBA ÁCIDA EN EL VALLE DEL CAUCA\")+\n    scale_x_continuous(breaks = c(seq(0, 100, by = 1)))+\n    theme_minimal()+\n    theme(text = element_text(color = \"#1e2c46\"))\n\n\n\n\n\n\n\n\n\n\n\nCódigo\nresultado_prueba_acida &lt;- data |&gt; \n    filter(Departamento == \"VALLE\") |&gt; \n    mutate(prueba_acida = (CurrentAssets - Inventories)/CurrentLiabilities) |&gt; \n    filter(prueba_acida &lt; 10) |&gt;\n    with(ecdf(prueba_acida)) |&gt; \n    estilo_summary() |&gt; \n    gt() |&gt; \n    aplicar_theme_table()\n\nresultado_prueba_acida\n\n\n\n\n\n\n\n\nMedida\nFrecuencia\n\n\n\n\nMin.\n0.0000\n\n\n1st Qu.\n0.6344\n\n\nMedian\n1.0728\n\n\nMean\n1.6211\n\n\n3rd Qu.\n1.8941\n\n\nMax.\n9.9846\n\n\n\n\n\n\n\nTenemos una diferencia de NA, 0.6206 entre las medianas de las razones.\n\n\n\n\n\n\nEstas razones no nos dicen si las cuentas por cobrar y/o los inventarios de hecho son demasiado altos. Si lo son, esto afectaría nuestra impresión inicial favorable de la liquidez de la compañía. Por eso, necesitamos ir detrás de las razones y examinar el tamaño, la composición y la calidad de estos dos activos corrientes importantes"
  },
  {
    "objectID": "posts/2025-02-21-finantial_ratios/index.html#razones-de-apalancamiento-financiero-deuda",
    "href": "posts/2025-02-21-finantial_ratios/index.html#razones-de-apalancamiento-financiero-deuda",
    "title": "Análisis de las razones financieras",
    "section": "Razones de apalancamiento financiero (deuda)",
    "text": "Razones de apalancamiento financiero (deuda)\nIndican el grado en el que una empresa se financia mediante deuda.\n\nRazón entre deuda y capital\n\\[\n\\frac{\\text{Deuda total}}{\\text{Capital de accionistas}}\n\\]\nNos dice cuánto de cada peso aportan los accionistas como financiamiento. En general, si fueras un acreedor, querrías tener una razón baja, porque así será mayor el nivel de financiamiento de la empresa que aportan los accionistas, el márgen de protección de los acreedores en caso de una disminución del valor de los activos o de pérdidas totales.\n\n\nCódigo\ndata |&gt; \n    filter(Departamento == \"VALLE\") |&gt; \n    mutate(deuda_capital = Liabilities/Equity) |&gt; \n    filter(deuda_capital &gt;= 0, deuda_capital &lt;= 5) |&gt; \n    ggplot(aes(deuda_capital))+\n    geom_density(col = \"orange\", size = 1.2) +\n    labs(x = \"RAZÓN DEUDA CAPITAL\", y = \"DENSIDAD\",\n         title = \"DEUDA / CAPITAL EN EL VALLE DEL CAUCA\")+\n    #scale_x_continuous(breaks = c(seq(0, 100, by = 1)))+\n    theme_minimal()+\n    theme(text = element_text(color = \"#1e2c46\"))\n\n\n\n\n\n\n\n\n\nPodría requerirse, dependiendo de la naturaleza del negocio, excluir las acciones preferenciales del capital e incluirlo en deuda porque representan una reclamación anterior desde el punto de vista de los inversionistas en acciones ordinarias. Pero aquí, lo hacemos de manera sencilla.\n\n\nCódigo\ndata |&gt; \n    filter(Departamento == \"VALLE\") |&gt; \n    mutate(deuda_capital = Liabilities/Equity) |&gt; \n    filter(deuda_capital &gt;= 0, deuda_capital &lt;= 5) |&gt; \n    with(ecdf(deuda_capital)) |&gt; \n    estilo_summary() |&gt; \n    gt() |&gt; \n    aplicar_theme_table()\n\n\n\n\n\n\n\n\nMedida\nFrecuencia\n\n\n\n\nMin.\n0.0000\n\n\n1st Qu.\n0.2174\n\n\nMedian\n0.7107\n\n\nMean\n1.0686\n\n\n3rd Qu.\n1.5373\n\n\nMax.\n4.9913\n\n\n\n\n\n\n\nUna comparación de la razón entre deuda y capital para una companía dada con empresas similares nos indica si es digna de crédito, así como el riesgo financiero de la empresa.\n\n\nRazón entre deuda y activos totales\nEsta razón tiene un propósito similar a la razón entre deuda y capital. Resalta la importancia relativa del financiamiento mediante deuda mostrando el porcentaje de los activos de la empresa que está solventado por el financiamiento mediante deuda.\n\\[\n\\frac{\\text{Deuda total}}{\\text{Activos totales}}\n\\]\nSi la empresa tuviera que liquidarse ya, los activos podrían venderse por una cantidad neta antes de que los acreedores tuvieran pérdidas. Cuanto más alta esta razón, más alto el riesgo de financiamiento.\n\n\nCódigo\ndata |&gt; \n    filter(Departamento == \"VALLE\") |&gt; \n    mutate(deuda_activos_total = Liabilities/Assets) |&gt; \n    filter(deuda_activos_total &gt;= 0, deuda_activos_total &lt;= 2) |&gt; \n    ggplot(aes(deuda_activos_total))+\n    geom_density(col = \"orange\", size = 1.2) +\n    labs(x = \"RAZÓN DEUDA ACTIVOS TOTALES\", y = \"DENSIDAD\",\n         title = \"DEUDA / ACTIVOS TOTALES EN EL VALLE DEL CAUCA\")+\n    #scale_x_continuous(breaks = c(seq(0, 100, by = 1)))+\n    theme_minimal()+\n    theme(text = element_text(color = \"#1e2c46\"))\n\n\n\n\n\n\n\n\n\nAquí se nos presenta una distribución con dos picos. Seguro que algún día les explico cómo enfrentarse a esto.\n\n\nCódigo\ndata |&gt; \n    filter(Departamento == \"VALLE\") |&gt; \n    mutate(deuda_activos_total = Liabilities/Assets) |&gt; \n    filter(deuda_activos_total &gt;= 0, deuda_activos_total &lt;= 2) |&gt; \n    with(ecdf(deuda_activos_total)) |&gt; \n    estilo_summary() |&gt; \n    gt() |&gt; \n    aplicar_theme_table()\n\n\n\n\n\n\n\n\nMedida\nFrecuencia\n\n\n\n\nMin.\n0.0000\n\n\n1st Qu.\n0.2057\n\n\nMedian\n0.4680\n\n\nMean\n0.4656\n\n\n3rd Qu.\n0.6832\n\n\nMax.\n1.9793\n\n\n\n\n\n\n\nPodríamos decir por ahora que el 46% de los bienes de la empresa están financiados con deuda, de varios tipos. Y el 54% restante del financiamiento proviene del capital de los accionistas.\nLos datos anteriores reflejan cortes de diciembre del año 2022. Si te interesa conocer la información más actual, o profundizar en otro tipo de análisis no dudes en contactarme.\nRecuerda que ninguna razón por sí sola nos entrega suficiente información para juzgar las condiciones financieras y el desempeño de una empresa. Debemos asegurarnos de analizar un grupo de indicadores, determinar si hay estacionalidad en las cifras, revisar las tendencias."
  },
  {
    "objectID": "posts/2025-02-21-finantial_ratios/index.html#razones-de-cobertura",
    "href": "posts/2025-02-21-finantial_ratios/index.html#razones-de-cobertura",
    "title": "Análisis de las razones financieras",
    "section": "Razones de cobertura",
    "text": "Razones de cobertura\nRelacionan los cargos financieros de una empresa con su capacidad para servirlos o cubrirlos.\n\nRazón de cobertura de interés\n\n\nCódigo\n# Función para extraer texto dentro de parentesis\nextraer_texto &lt;- function(texto){\n    inicial &lt;- gregexpr(\"\\\\(\", texto)[[1]]\n    final &lt;- gregexpr(\"\\\\)\", texto)[[1]]\n    substring(texto, inicial + 1, final - 1)\n}\n\n# Vector con los nombres extraídos\nnuevo_nombre &lt;- function(info){\n    colnames(info) |&gt; \n    purrr::map(~last(extraer_texto(.x))) |&gt; \n    unlist()\n}\n\npyg &lt;- openxlsx::read.xlsx(\"./310030_Estado de resultado integral, resultado del periodo, por funcion de gasto(3).xlsx\") |&gt; \n    data.table() |&gt; \n    filter(Fecha.de.Corte == \"2022-12-31\")\n\n# Asignar nombres en inglés\npyg &lt;- setNames(pyg, ifelse(nuevo_nombre(pyg) != \"\", nuevo_nombre(pyg), colnames(pyg)))\n\npyg &lt;- pyg |&gt; \n    filter(Periodo == \"Periodo Actual\", \n           `Departamento.de.la.direcci&#243;n.del.domicilio` == \"VALLE\")\n\n\nEsta razón sirve como medida de la capacidad de una empresa para cumplir con los pagos de interés y evitar bancarrota. A mayor valor, mayor la probabilidad de lograr cubrir pagos sin dificultad. Además, da información acerca de la posibilidad de enfrentar nueva deuda.\n\n\nCódigo\npyg |&gt; \n    mutate(cobertura_interes = ProfitLossBeforeTax/FinanceCosts) |&gt; \n    filter(cobertura_interes &gt;= 0, cobertura_interes &lt;= 20) |&gt; \n    ggplot(aes(cobertura_interes))+\n    geom_density(col = \"orange\", size = 1.2) +\n    labs(x = \"RAZÓN COBERTURA INTERÉS\", y = \"DENSIDAD\",\n         title = \"UAII/GASTO INTERÉS EN EL VALLE DEL CAUCA\")+\n    #scale_x_continuous(breaks = c(seq(0, 100, by = 1)))+\n    theme_minimal()+\n    theme(text = element_text(color = \"#1e2c46\"))\n\n\n\n\n\n\n\n\n\nEstos son los resultados para la razón de cobertura de interés:\n\n\nCódigo\npyg |&gt; \n    mutate(cobertura_interes = ProfitLossBeforeTax/FinanceCosts) |&gt; \n    filter(cobertura_interes &gt;= 0, cobertura_interes &lt;= 20) |&gt; \n    with(ecdf(cobertura_interes)) |&gt; \n    estilo_summary() |&gt; \n    gt() |&gt; \n    aplicar_theme_table()\n\n\n\n\n\n\n\n\nMedida\nFrecuencia\n\n\n\n\nMin.\n0.0007\n\n\n1st Qu.\n1.0434\n\n\nMedian\n2.7108\n\n\nMean\n4.5117\n\n\n3rd Qu.\n6.4900\n\n\nMax.\n19.9509\n\n\n\n\n\n\n\nAdemás de los pagos de interés, podemos agregar pagos del principal sobre las obligaciones de deuda, los dividendos de acciones preferenciales y los pagos de arrendamiento. Un análisis más amplio evaluará la capacidad de una empresa para cubrir todos los cargos de naturaleza fija."
  },
  {
    "objectID": "posts/2025-02-21-finantial_ratios/index.html#razones-de-actividad",
    "href": "posts/2025-02-21-finantial_ratios/index.html#razones-de-actividad",
    "title": "Análisis de las razones financieras",
    "section": "Razones de actividad",
    "text": "Razones de actividad\nMiden qué tan efectiva es la manera en que la empresa usa sus activos.\n\nRazón de rotación de cuentas por cobrar\nProporciona un panorama de la calidad de las cuentas por cobrar de la empresa y qué tan exitosa es en sus cobros.\n\\[\n\\frac{\\text{Ventas netas a crédito anuales}}{\\text{Cuentas por cobrar}}\n\\]\n\n\nCódigo\ncaratula &lt;- openxlsx::read.xlsx(\"./10000_Carátula.xlsx\") |&gt; \n    data.table()\n\nfull_join(\ndata |&gt; \n    filter(Periodo == \"Periodo Actual\") |&gt; \n    dplyr::select(c(3,4,5,13,14,62,72)) |&gt; \n    unique() \n,\npyg |&gt; \n    filter(Periodo == \"Periodo Actual\") |&gt; \n    dplyr::select(c(3,4,5,12)) |&gt; \n    unique()\n) |&gt; \n    left_join(caratula[,c(3,11)], by = c(\"NIT\")) |&gt; \n    mutate(RCC = Revenue / `TradeAndOtherCurrentReceivables`,\n           tiempo = 2024 - as.numeric(substr(`Fecha.de.constitución.(Aaaa-Mm-Dd)`,1,4))) |&gt; \n    filter(RCC &gt; 0, RCC &lt;= 20, !is.na(RCC), tiempo &gt;=0, !is.na(tiempo)) |&gt; \n    filter(tiempo &lt; 50) |&gt; \n   # ggplot(aes(as.numeric(tiempo), RCC, group = as.factor(tiempo)))+\n    ggplot(aes(RCC))+\n    geom_density(col = \"orange\", size = 1.2) +\n    labs(x = \"RAZÓN ROTACIÓN CUENTAS POR COBRAR\", y = \"DENSIDAD\",\n         title = \"VENTAS A CRÉDITO / CUENTAS POR COBRAR EN EL VALLE DEL CAUCA\")+\n    #scale_x_continuous(breaks = c(seq(0, 100, by = 1)))+\n    theme_minimal()+\n    theme(text = element_text(color = \"#1e2c46\"))\n\n\n\n\n\n\n\n\n\nNos dice el número de veces que las cuentas por cobrar se han convertido en efectivo durante el año. Aquí estamos suponiendo que todos los ingresos fueron por ventas a crédito (no tenemos información acerca de la cantidad exacta a través de los archivos de SIIS).\n\n\nCódigo\nfull_join(\ndata |&gt; \n    filter(Periodo == \"Periodo Actual\") |&gt; \n    dplyr::select(c(3,4,5,13,14,62,72)) |&gt; \n    unique() \n,\npyg |&gt; \n    filter(Periodo == \"Periodo Actual\") |&gt; \n    dplyr::select(c(3,4,5,12)) |&gt; \n    unique()\n) |&gt; \n    left_join(caratula[,c(3,11)], by = c(\"NIT\")) |&gt; \n    mutate(RCC = Revenue / `TradeAndOtherCurrentReceivables`,\n           tiempo = 2024 - as.numeric(substr(`Fecha.de.constitución.(Aaaa-Mm-Dd)`,1,4))) |&gt; \n    filter(RCC &gt; 0, RCC &lt;= 20, !is.na(RCC), tiempo &gt;=0, !is.na(tiempo)) |&gt; \n    filter(tiempo &lt; 50) |&gt; \n    with(ecdf(RCC)) |&gt; \n    estilo_summary() |&gt; \n    gt() |&gt; \n    aplicar_theme_table()\n\n\n\n\n\n\n\n\nMedida\nFrecuencia\n\n\n\n\nMin.\n0.0000\n\n\n1st Qu.\n1.5373\n\n\nMedian\n4.0015\n\n\nMean\n5.0863\n\n\n3rd Qu.\n7.3056\n\n\nMax.\n19.8855\n\n\n\n\n\n\n\nCuando las ventas son estacionales o han aumentado considerablemente en el año, usar el balance de las cuentas por cobrar al final del año puede no ser adecuado. Con estacionalidad, un promedio de los balances mensuales puede ser lo más apropiado. Con crecimiento, el balance de las cuentas por cobrar será engañosamente alto en relación con las ventas. El resultado es que la conversión de cuentas por cobrar en efectivo calculado es una estimación sesgada y baja del número de conversiones durante el año. En este caso, un promedio de las cuentas por cobrar al inicio y final del año será adecuado si el crecimiento en las ventas fue estable en el año.\n\n\nRotación de cuentas por cobrar en días\n\\[\n\\frac{\\text{Días del año}}{\\text{Rotación de cuentas por cobrar}} = \\frac{\\text{Cuentas por cobrar x días del año}}{\\text{Ventas a crédito anuales}}\n\\]\nNos dice el número promedio de días que las cuentas por cobrar están en circulación antes de ser cobradas, que para el caso de las empresas del Valle del Cauca es:\n\\[\n\\frac{365}{4}≅90\n\\]\nPodríamos decir que aunque un periodo promedio de cobro demasiado alto suele ser malo, un promedio muy bajo no necesariamente es bueno. Un periodo promedio muy bajo de cobro puede ser un síntoma de una política de crédito excesivamente restrictiva. Las pocas cuentas por cobrar que aparecen en los libros tal vez sean de primera calidad, pero las ventas quizás estén indebidamente restringidas —y las ganancias son menores a las que podrían ser— debido a que se otorgan créditos con muchas restricciones a los clientes.\n\n\nRazón de rotación de cuentas por pagar\nCapacidad de pago oportuno a los proveedores o el de algún potencial cliente candidato a crédito.\n\\[\n\\frac{\\text{Días en el año}}{\\text{Rotación de cuentas por pagar}}=\\frac{\\text{Cuentas por pagar x días en el año}}{\\text{Compras a crédito anuales}}\n\\]\n\n\nCódigo\nfull_join(\ndata |&gt; \n    filter(Periodo == \"Periodo Actual\") |&gt; \n    dplyr::select(c(3,4,5,13,14,43,51,62,72)) |&gt; \n    unique() \n,\npyg |&gt; \n    filter(Periodo == \"Periodo Actual\") |&gt; \n    dplyr::select(c(3,4,5,12,13)) |&gt; \n    unique()\n) |&gt; \n    left_join(caratula[,c(3,11)], by = c(\"NIT\")) |&gt; \n    mutate(RCP = (CurrentLiabilities+Inventories) / CostOfSales,\n           tiempo = 2024 - as.numeric(substr(`Fecha.de.constitución.(Aaaa-Mm-Dd)`,1,4))) |&gt; \n    filter(RCP &gt; 0, RCP &lt; 5, !is.na(RCP), tiempo &gt;=0, !is.na(tiempo)) |&gt; \n    filter(tiempo &lt; 50) |&gt; \n   # ggplot(aes(as.numeric(tiempo), RCC, group = as.factor(tiempo)))+\n    ggplot(aes(RCP))+\n    geom_density(col = \"orange\", size = 1.2) +\n    labs(x = \"RAZÓN ROTACIÓN CUENTAS POR PAGAR\", y = \"DENSIDAD\",\n         title = \"CUENTAS POR PAGAR / COMPRAS A CRÉDITO EN EL VALLE DEL CAUCA\")+\n    #scale_x_continuous(breaks = c(seq(0, 100, by = 1)))+\n    theme_minimal()+\n    theme(text = element_text(color = \"#1e2c46\"))\n\n\n\n\n\n\n\n\n\n\n\nCódigo\nfull_join(\ndata |&gt; \n    filter(Periodo == \"Periodo Actual\") |&gt; \n    dplyr::select(c(3,4,5,13,14,43,51,62,72)) |&gt; \n    unique() \n,\npyg |&gt; \n    filter(Periodo == \"Periodo Actual\") |&gt; \n    dplyr::select(c(3,4,5,12,13)) |&gt; \n    unique()\n) |&gt; \n    left_join(caratula[,c(3,11)], by = c(\"NIT\")) |&gt; \n    mutate(RCP = (CurrentLiabilities+Inventories) / CostOfSales,\n           tiempo = 2024 - as.numeric(substr(`Fecha.de.constitución.(Aaaa-Mm-Dd)`,1,4))) |&gt; \n    filter(RCP &gt; 0, RCP &lt; 5, !is.na(RCP), tiempo &gt;=0, !is.na(tiempo)) |&gt; \n    filter(tiempo &lt; 50) |&gt; \n    with(ecdf(RCP)) |&gt; \n    estilo_summary() |&gt; \n    gt() |&gt; \n    aplicar_theme_table()\n\n\n\n\n\n\n\n\nMedida\nFrecuencia\n\n\n\n\nMin.\n0.0019\n\n\n1st Qu.\n0.3258\n\n\nMedian\n0.5793\n\n\nMean\n0.8367\n\n\n3rd Qu.\n1.0276\n\n\nMax.\n4.9754\n\n\n\n\n\n\n\n\n\nRazón de rotación de inventarios\nDetermina qué tan efectiva es la empresa al administrar el inventario y también es una indicación de la liquidez del inventario.\n\\[\n\\frac{\\text{Costo de bienes vendidos}}{\\text{Inventarios}}\n\\]\n\n\nCódigo\nfull_join(\ndata |&gt; \n    filter(Periodo == \"Periodo Actual\") |&gt; \n    dplyr::select(c(3,4,5,13,14,62,72)) |&gt; \n    unique() \n,\npyg |&gt; \n    filter(Periodo == \"Periodo Actual\") |&gt; \n    dplyr::select(c(3,4,5,12,13)) |&gt; \n    unique()\n) |&gt; \n    left_join(caratula[,c(3,11)], by = c(\"NIT\")) |&gt; \n    mutate(RDI = CostOfSales / Inventories,\n           tiempo = 2024 - as.numeric(substr(`Fecha.de.constitución.(Aaaa-Mm-Dd)`,1,4))) |&gt; \n    filter(RDI &gt; 0, RDI &lt;= 20, !is.na(RDI), tiempo &gt;=0, !is.na(tiempo)) |&gt; \n    filter(tiempo &lt; 50) |&gt; \n    ggplot(aes(RDI))+\n    geom_density(col = \"orange\", size = 1.2) +\n    labs(x = \"RAZÓN ROTACIÓN INVENTARIOS\", y = \"DENSIDAD\",\n         title = \"COSTO DE BIENES / INVENTARIOS EN EL VALLE DEL CAUCA\")+\n    #scale_x_continuous(breaks = c(seq(0, 100, by = 1)))+\n    theme_minimal()+\n    theme(text = element_text(color = \"#1e2c46\"))\n\n\n\n\n\n\n\n\n\nLa razón de rotación de inventario nos dice cuántas veces el inventario se convierte en cuentas por cobrar a través de las ventas durante el año. Esta razón, como las otras, debe juzgarse en relación con las razones del pasado y el futuro esperado de la empresa y en relación con las razones de empresas similares, o el promedio de la industria o ambos.\n\n\nCódigo\nfull_join(\ndata |&gt; \n    filter(Periodo == \"Periodo Actual\") |&gt; \n    dplyr::select(c(3,4,5,13,14,62,72)) |&gt; \n    unique() \n,\npyg |&gt; \n    filter(Periodo == \"Periodo Actual\") |&gt; \n    dplyr::select(c(3,4,5,12,13)) |&gt; \n    unique()\n) |&gt; \n    left_join(caratula[,c(3,11)], by = c(\"NIT\")) |&gt; \n    mutate(RDI = CostOfSales / Inventories,\n           tiempo = 2024 - as.numeric(substr(`Fecha.de.constitución.(Aaaa-Mm-Dd)`,1,4))) |&gt; \n    filter(RDI &gt; 0, RDI &lt;= 20, !is.na(RDI), tiempo &gt;=0, !is.na(tiempo)) |&gt; \n    filter(tiempo &lt; 50) |&gt; \n    with(ecdf(RDI)) |&gt; \n    estilo_summary() |&gt; \n    gt() |&gt; \n    aplicar_theme_table()\n\n\n\n\n\n\n\n\nMedida\nFrecuencia\n\n\n\n\nMin.\n0.0002\n\n\n1st Qu.\n1.7339\n\n\nMedian\n3.6109\n\n\nMean\n5.1111\n\n\n3rd Qu.\n7.3148\n\n\nMax.\n19.9807\n\n\n\n\n\n\n\nEn general, cuanto más alta sea la rotación de inventario, más eficiente será su manejo, y más “fresco” y líquido será ese inventario. Sin embargo, algunas veces una rotación alta del inventario indica una existencia precaria. Por lo tanto, en realidad puede ser un síntoma de que hay un nivel de inventario muy bajo y con frecuencia se incurre en faltantes. Una rotación de inventario relativa- mente baja muchas veces es señal de un movimiento lento o de artículos obsoletos en el inventario\nRotación de inventario en días\n\\[\n\\frac{\\text{Días del año}}{\\text{Rotación de inventario}}=\\frac{\\text{Inventario x Días en el año}}{\\text{Costo de bienes vendidos}}\n\\]\nNos dice cuántos días, en promedio, pasan antes de que el inventario se convierta en cuentas por pagar mediante las ventas.\n\\[\n\\frac{365}{3.61}≅100\n\\]\n\n\nCiclo de operación\nEs el tiempo que transcurre desde el compromiso de efectivo para compras hasta el cobro de las cuentas por cobrar que resultan de la venta de bienes o servicios.\n\\[\n\\text{Rotación de inventario en días } +\\text{ Rotación de cuentas por cobrar en días}\n\\]\nLa mayoría de las empresas no pagan la materia prima de inmediato, sino compran a crédito e incurren en una cuenta por pagar.\n\\[\n100+90=190 \\text{ días para empresas del Valle del Cauca}\n\\]\n¿Por qué preocuparse por el ciclo de operación de una empresa? Una empresa con un ciclo de operación muy corto puede operar de manera efectiva con una cantidad relativamente pequeña de activos corrientes, y liquidez corriente y razón de prueba ácida relativamente bajas. Esta empresa tiene una liquidez relativa en un sentido “dinámico”: puede generar un producto, venderlo y cobrar en efectivo por él, todo en un periodo relativamente corto. No tiene que apoyarse en niveles de liquidez “estáticos” altos como los mide la liquidez corriente o la razón de la prueba ácida.\n\n\nRazón de rotación de activos totales\nNos indica la eficiencia relativa con la que una empresa usa sus activos totales para generar ventas.\n\\[\n\\frac{\\text{Ventas netas}}{\\text{Activos totales}}\n\\]\n\n\nCódigo\nfull_join(\ndata |&gt; \n    filter(Periodo == \"Periodo Actual\") |&gt; \n    dplyr::select(c(3,4,5,13,39,62,72)) |&gt; \n    unique() \n,\npyg |&gt; \n    filter(Periodo == \"Periodo Actual\") |&gt; \n    dplyr::select(c(3,4,5,12,13)) |&gt; \n    unique()\n) |&gt; \n    left_join(caratula[,c(3,11)], by = c(\"NIT\")) |&gt; \n    mutate(rotacion_capital = Revenue / Assets,\n           tiempo = 2024 - as.numeric(substr(`Fecha.de.constitución.(Aaaa-Mm-Dd)`,1,4))) |&gt; \n    filter(rotacion_capital &gt; 0, rotacion_capital &lt;= 5, !is.na(rotacion_capital), tiempo &gt;=0, !is.na(tiempo)) |&gt; \n    filter(tiempo &lt; 50) |&gt; \n    ggplot(aes(rotacion_capital))+\n    geom_density(col = \"orange\", size = 1.2) +\n    labs(x = \"RAZÓN ROTACIÓN ACTIVOS TOTALES\", y = \"DENSIDAD\",\n         title = \"VENTAS NETAS / ACTIVOS TOTALES EN EL VALLE DEL CAUCA\")+\n    #scale_x_continuous(breaks = c(seq(0, 100, by = 1)))+\n    theme_minimal()+\n    theme(text = element_text(color = \"#1e2c46\"))\n\n\n\n\n\n\n\n\n\n\n\nCódigo\nfull_join(\ndata |&gt; \n    filter(Periodo == \"Periodo Actual\") |&gt; \n    dplyr::select(c(3,4,5,13,39,62,72)) |&gt; \n    unique() \n,\npyg |&gt; \n    filter(Periodo == \"Periodo Actual\") |&gt; \n    dplyr::select(c(3,4,5,12,13)) |&gt; \n    unique()\n) |&gt; \n    left_join(caratula[,c(3,11)], by = c(\"NIT\")) |&gt; \n    mutate(rotacion_capital = Revenue / Assets,\n           tiempo = 2024 - as.numeric(substr(`Fecha.de.constitución.(Aaaa-Mm-Dd)`,1,4))) |&gt; \n    filter(rotacion_capital &gt; 0, rotacion_capital &lt;= 5, !is.na(rotacion_capital), tiempo &gt;=0, !is.na(tiempo)) |&gt; \n    filter(tiempo &lt; 50) |&gt; \n    with(ecdf(rotacion_capital)) |&gt; \n    estilo_summary() |&gt; \n    gt() |&gt; \n    aplicar_theme_table()\n\n\n\n\n\n\n\n\nMedida\nFrecuencia\n\n\n\n\nMin.\n0.0000\n\n\n1st Qu.\n0.1534\n\n\nMedian\n0.7450\n\n\nMean\n1.0356\n\n\n3rd Qu.\n1.5722\n\n\nMax.\n4.9878\n\n\n\n\n\n\n\nPodría existir una inversión excesiva en cuentas por cobrar y en inventarios."
  },
  {
    "objectID": "posts/2025-02-21-finantial_ratios/index.html#razones-de-rentabilidad",
    "href": "posts/2025-02-21-finantial_ratios/index.html#razones-de-rentabilidad",
    "title": "Análisis de las razones financieras",
    "section": "Razones de rentabilidad",
    "text": "Razones de rentabilidad\nRelacionan las ganancias con las ventas y la inversión.\n\nMárgen de ganancias brutas\nNos da la ganancia de la empresa relativa a las ventas, después de deducir el costo de producir los bienes. Es una medida de la eficiencia en la operación de la empresa, al igual que un indicador de cómo se asigna precio a los productos.\n\\[\n\\frac{\\text{Ventas netas - Costo de bienes vendidos}}{\\text{Ventas netas}}\n\\]\n\n\nCódigo\npyg |&gt; \n    left_join(caratula[,c(3,11)], by = c(\"NIT\")) |&gt; \n    mutate(margen_bruto = 100 * (Revenue-CostOfSales)/Revenue,\n           tiempo = 2024 - as.numeric(substr(`Fecha.de.constitución.(Aaaa-Mm-Dd)`,1,4))) |&gt; \n    filter(margen_bruto &gt; 0, margen_bruto &lt;= 200, !is.na(margen_bruto), tiempo &gt;=0, !is.na(tiempo)) |&gt; \n    ggplot(aes(margen_bruto))+\n    geom_density(col = \"orange\", size = 1.2) +\n    labs(x = \"MARGEN DE GANANCIAS BRUTAS (%)\", y = \"DENSIDAD\",\n         title = \"RENTABILIDAD (VENTAS) EN EL VALLE DEL CAUCA\")+\n    #scale_x_continuous(breaks = c(seq(0, 100, by = 1)))+\n    theme_minimal()+\n    theme(text = element_text(color = \"#1e2c46\"))\n\n\n\n\n\n\n\n\n\n\n\nCódigo\npyg |&gt; \n    left_join(caratula[,c(3,11)], by = c(\"NIT\")) |&gt; \n    mutate(margen_bruto = 100 * (Revenue-CostOfSales)/Revenue,\n           tiempo = 2024 - as.numeric(substr(`Fecha.de.constitución.(Aaaa-Mm-Dd)`,1,4))) |&gt; \n    filter(margen_bruto &gt; 0, margen_bruto &lt;= 200, !is.na(margen_bruto), tiempo &gt;=0, !is.na(tiempo)) |&gt; \n    with(ecdf(margen_bruto)) |&gt; \n    estilo_summary() |&gt; \n    gt() |&gt; \n    aplicar_theme_table()\n\n\n\n\n\n\n\n\nMedida\nFrecuencia\n\n\n\n\nMin.\n0.0747\n\n\n1st Qu.\n18.2208\n\n\nMedian\n29.5569\n\n\nMean\n35.1813\n\n\n3rd Qu.\n46.7363\n\n\nMax.\n100.0000\n\n\n\n\n\n\n\nSi el márgen de tu empresa está por encima del \\(30\\%\\) significa que es más efectiva al producir y vender productos por arriba del costo que la mitad de las empresas en la región considerada.\n\n\nMárgen de ganancia neta\nUna medida de la rentabilidad de las ventas después de impuestos de la empresa tomando en cuenta todos los gastos e impuestos sobre la renta. Nos indica el ingreso neto por peso de venta.\n\\[\n\\frac{\\text{Ganancia neta después de impuestos}}{\\text{Ventas netas}}\n\\]\n\n\nCódigo\npyg |&gt; \n    left_join(caratula[,c(3,11)], by = c(\"NIT\")) |&gt; \n    mutate(margen_neto = 100 * (ProfitLoss)/Revenue,\n           tiempo = 2024 - as.numeric(substr(`Fecha.de.constitución.(Aaaa-Mm-Dd)`,1,4))) |&gt; \n    filter(margen_neto &gt; 0, margen_neto &lt;= 30, !is.na(margen_neto), tiempo &gt;=0, !is.na(tiempo)) |&gt; \n    ggplot(aes(margen_neto))+\n    geom_density(col = \"orange\", size = 1.2) +\n    labs(x = \"MARGEN DE GANANCIAS NETAS (%)\", y = \"DENSIDAD\",\n         title = \"RENTABILIDAD (VENTAS) EN EL VALLE DEL CAUCA\")+\n    #scale_x_continuous(breaks = c(seq(0, 100, by = 1)))+\n    theme_minimal()+\n    theme(text = element_text(color = \"#1e2c46\"))\n\n\n\n\n\n\n\n\n\n\n\nCódigo\npyg |&gt; \n    left_join(caratula[,c(3,11)], by = c(\"NIT\")) |&gt; \n    mutate(margen_neto = 100 * (ProfitLoss)/Revenue,\n           tiempo = 2024 - as.numeric(substr(`Fecha.de.constitución.(Aaaa-Mm-Dd)`,1,4))) |&gt; \n    filter(margen_neto &gt; 0, margen_neto &lt;= 30, !is.na(margen_neto), tiempo &gt;=0, !is.na(tiempo)) |&gt; \n    with(ecdf(margen_neto)) |&gt; \n    estilo_summary() |&gt; \n    gt() |&gt; \n    aplicar_theme_table()\n\n\n\n\n\n\n\n\nMedida\nFrecuencia\n\n\n\n\nMin.\n0.0118\n\n\n1st Qu.\n2.1408\n\n\nMedian\n4.5822\n\n\nMean\n6.5547\n\n\n3rd Qu.\n8.5911\n\n\nMax.\n29.9613\n\n\n\n\n\n\n\nSi el margen de ganancia bruta en esencia no cambia en un periodo de varios años, pero el margen de ganancia neta disminuye en el mismo periodo, sabemos que se puede deber a gastos de ventas, generales y administrativos más altos en relación con las ventas o a una tasa de impuestos más alta. Por otro lado, si el margen de ganancia bruta disminuye, sabemos que el costo de producir bienes con respecto a las ventas ha aumentado. Este suceso, a la vez, puede deberse a precios más bajos o a menor eficiencia operativa en relación con el volumen.\n\n\nRendimiento sobre la inversión\nEs la capacidad de generar ganancias sobre los activos totales.\n\\[\n\\text{Capacidad para generar ganancias = Rentabilidad x Eficiencia de activos}\n\\]\n\\[\n\\text{RSI = Márgen de ganancia neta x Rotación de activos totales}\n\\]\nNi el margen de ganancia neta ni la razón de rotación de activos totales, por sí mismos, representan una medida adecuada de la efectividad global. El margen de ganancia neta ignora la utilización de activos, y la razón de rotación de los activos totales ignora la rentabilidad sobre las ventas. La razón del rendimiento sobre la inversión, o capacidad de generar ganancias, resuelve estas deficiencias.\nPara el Valle del Cauca:\n\\[\n\\text{4.58\\% x 0.74= 3.38\\%}\n\\]\nAquí lo calculamos usando valores de la mediana y no la media.\n\n\nRendimiento sobre capital\nCompara la ganancia neta después de impuestos (menos los dividendos de acciones preferenciales, si las hay) con el capital que los accionistas han invertido en la empresa:\n\\[\n\\frac{\\text{Ganancia neta después de impuestos}}{\\text{Capital de accionistas}}\n\\]\nO con el enfoque Du Pont:\n\\[\n\\text{Rendimiento sobre capital = Márgen de ganancia neta x Rotación de activos totales x Multiplicador de capital}\n\\]\n\n\nCódigo\ndata |&gt; \n    left_join(caratula[,c(3,11)], by = c(\"NIT\")) |&gt; \n    mutate(multiplicador = Assets/Equity,\n           tiempo = 2024 - as.numeric(substr(`Fecha.de.constitución.(Aaaa-Mm-Dd)`,1,4))) |&gt; \n    filter(multiplicador &gt; 0, multiplicador &lt;= 30, !is.na(multiplicador), tiempo &gt;=0, !is.na(tiempo)) |&gt; \n    with(ecdf(multiplicador)) |&gt; \n    estilo_summary() |&gt; \n    gt() |&gt; \n    aplicar_theme_table()\n\n\n\n\n\n\n\n\nMedida\nFrecuencia\n\n\n\n\nMin.\n1.0000\n\n\n1st Qu.\n1.2796\n\n\nMedian\n1.8143\n\n\nMean\n2.8331\n\n\n3rd Qu.\n2.9409\n\n\nMax.\n29.9845\n\n\n\n\n\n\n\nEl multiplicador de capital se calcula como \\(\\text{Activos totales / Capital accionistas}\\) por lo que para el Valle del Cauca el rendimiento sobre capital es\n\\[\n3.38\\% \\text{ x } 1.81=6.11\\%\n\\]\nAquí terminamos con las bases financieras para nuestra serie."
  },
  {
    "objectID": "posts/2025-02-24-why_use_WACC/index.html",
    "href": "posts/2025-02-24-why_use_WACC/index.html",
    "title": "Por qué usar el WACC como costo de mantener inventario?",
    "section": "",
    "text": "¿Por qué usar el WACC?\nEl costo ponderado promedio del capital de una empresa está determinado por el riesgo de sus activos, como el inventario, las propiedades, las plantas y el equipo, y los cuentas por cobrar.\nVamos a revisar qué tan representativo es el inventario para las industrias en el Valle del Cauca, en cuanto a sus activos operativos netos.\nPrimero mostramos el Estado de resultado integral que ya conocímos aquí:\n\n\nCódigo\nknitr::opts_chunk$set(message = FALSE, warning = FALSE, fig.align = \"center\")\n\nlibrary(tidyverse)\nlibrary(data.table)\nlibrary(gt)\n\nestilo_summary &lt;- function(resumen){\n    resumen |&gt; \n        summary() |&gt; \n        as.data.frame() |&gt; \n        rownames_to_column() |&gt; \n        #dplyr::select(c(Var2,Freq)) |&gt; \n        rename(Medida = rowname,\n               Frecuencia = x) |&gt; \n        mutate(Frecuencia = round(Frecuencia,4))\n}\n\naplicar_theme_table &lt;- function(gt_table) {\n    gt_table %&gt;%\n        cols_align(align = \"center\") |&gt; \n        tab_options(\n            table.border.top.color = \"orange\",\n            table.font.color = \"#1e2c46\",\n            table_body.hlines.color = \"orange\",\n            column_labels.background.color = \"#1e2c46\"\n        )\n}\n\n# Función para extraer texto dentro de parentesis\nextraer_texto &lt;- function(texto){\n    inicial &lt;- gregexpr(\"\\\\(\", texto)[[1]]\n    final &lt;- gregexpr(\"\\\\)\", texto)[[1]]\n    substring(texto, inicial + 1, final - 1)\n}\n\n# Vector con los nombres extraídos\nnuevo_nombre &lt;- function(info){\n    colnames(info) |&gt; \n    purrr::map(~last(extraer_texto(.x))) |&gt; \n    unlist()\n}\n\npyg &lt;- openxlsx::read.xlsx(\"./310030_Estado de resultado integral, resultado del periodo, por funcion de gasto(3).xlsx\") |&gt; \n    data.table() |&gt; \n    filter(Fecha.de.Corte == \"2022-12-31\")\n\n# Asignar nombres en inglés\npyg &lt;- setNames(pyg, ifelse(nuevo_nombre(pyg) != \"\", nuevo_nombre(pyg), colnames(pyg)))\n\npyg &lt;- pyg |&gt; \n    filter(Periodo == \"Periodo Actual\", \n           `Departamento.de.la.direcci&#243;n.del.domicilio` == \"VALLE\")\n\npyg |&gt; \n    gt_preview() |&gt; \n    aplicar_theme_table()\n\n\n\n\n\n\n\n\n\nPunto.de.Entrada\nNombre.Formulario\nNIT\nFecha.de.Corte\nRaz&#243;n.social.de.la.sociedad\nCIIU\nTipo.societario\nDirecci&#243;n.de.notificaci&#243;n.judicial.registrada.en.C&#225;mara.de.Comercio\nDepartamento.de.la.direcci&#243;n.del.domicilio\nCiudad.de.la.direcci&#243;n.del.domicilio\nPeriodo\nRevenue\nCostOfSales\nGrossProfit\nOtherIncome\nDistributionCosts\nAdministrativeExpense\nOtherExpenseByFunction\nOtherGainsLosses\nGananciaPerdidaPorActividadesDeOperacion\nFinanceIncome\nFinanceCosts\nProfitLossBeforeTax\nIncomeTaxExpenseContinuingOperations\nProfitLossFromContinuingOperations\nProfitLossFromDiscontinuedOperations\nProfitLoss\n\n\n\n\n1\nPymes-Individuales\nEstado de resultado integral, resultado del periodo, por funcion de gasto\n800000241\n2022-12-31\nCERERIA EL SAGRADO CORAZON LTDA\nC3290 - Otras industrias manufactureras n.c.p.\n03. SOCIEDAD LIMITADA\nKM 5.5 VIA LA BUITRERA PREDIO LA CANANEA\nVALLE\nCALI-VALLE\nPeriodo Actual\n15028675\n10346586\n4682089\nNA\n973304\n2191209\nNA\nNA\n1517576\n152265\n547097\n1122744\n413536\n709208\nNA\n709208\n\n\n2\nPymes-Individuales\nEstado de resultado integral, resultado del periodo, por funcion de gasto\n800000393\n2022-12-31\nCONFEPLASTICOS SAS\nC2229 - Fabricaci&#243;n de art&#237;culos de pl&#225;stico n.c.p.\n08. SOCIEDAD POR ACCIONES SIMPLIFICADA SAS\nCL 27 4 55\nVALLE\nCALI-VALLE\nPeriodo Actual\n2117949\n2327453\n-209504\nNA\nNA\n438142\n73654\nNA\n-721300\nNA\n232828\n-954128\nNA\n-954128\nNA\n-954128\n\n\n3\nPymes-Individuales\nEstado de resultado integral, resultado del periodo, por funcion de gasto\n800000469\n2022-12-31\nRIVERA CORREA Y CRUZ Y COMPA&#209;IA LIMITADA\nG4731 - Comercio al por menor de combustible para automotores\n03. SOCIEDAD LIMITADA\nCRA 24 12 25\nVALLE\nBUGA-VALLE\nPeriodo Actual\n5189953\n4510177\n679776\n66584\n343831\n300699\n457\nNA\n101373\n75\n87259\n14189\n9090\n5099\nNA\n5099\n\n\n4\nPymes-Individuales\nEstado de resultado integral, resultado del periodo, por funcion de gasto\n800001020\n2022-12-31\nDISTRIBUIDORA DE DROGAS LA REBAJA PRINCIPAL S.A.\nN7740 - Arrendamiento de propiedad intelectual y productos similares, excepto obras protegidas por derechos de autor\n01. SOCIEDAD AN&#211;NIMA\nCR 3 12 40 OF 1101\nVALLE\nCALI-VALLE\nPeriodo Actual\n5063032\nNA\n5063032\nNA\nNA\n1613519\n23190\nNA\n3426323\n356968\nNA\n3783291\n1317122\n2466169\nNA\n2466169\n\n\n5\nPymes-Individuales\nEstado de resultado integral, resultado del periodo, por funcion de gasto\n800001047\n2022-12-31\nMAYA Y BEDOYA LTDA\nG4773 - Comercio al por menor de productos farmac&#233;uticos y medicinales, cosm&#233;ticos y art&#237;culos de tocador en establecimientos especializados\n03. SOCIEDAD LIMITADA\nCALLE 8 6 -80\nVALLE\nCALI-VALLE\nPeriodo Actual\n17015456\n12716657\n4298799\n24143\n2581954\n1014383\n72255\nNA\n654350\n18956\n51\n673255\n265550\n407705\nNA\n407705\n\n\n6..2391\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2392\nPymes-Individuales\nEstado de resultado integral, resultado del periodo, por funcion de gasto\n901468892\n2022-12-31\nINVERSIONES ATELIER SAS\nM7490 - Otras actividades profesionales, cient&#237;ficas y t&#233;cnicas n.c.p.\n08. SOCIEDAD POR ACCIONES SIMPLIFICADA SAS\nCL 67 NORTE # 6 - 85\nVALLE\nCALI-VALLE\nPeriodo Actual\n600262\nNA\n600262\n1857\nNA\n631283\n193067\nNA\n-222231\n13805\n16544\n-224970\n22615\n-247585\nNA\n-247585\n\n\n\n\n\n\n\nY ahora el Estado de situación financiera que también vimos aquí:\n\n\nCódigo\ndata &lt;- openxlsx::read.xlsx(\"./210030_Estado de situación financiera, corriente_no corriente.xlsx\") |&gt; \n    data.table() |&gt; \n    filter(Fecha.de.Corte == \"2022-12-31\")\n\n# Asignar nombres en inglés\ndata &lt;- setNames(data, ifelse(nuevo_nombre(data) != \"\", nuevo_nombre(data), colnames(data)))\n\n\n# Cambiar otros nombres\ndata &lt;- data |&gt; \n    rename(Razon.Social = \"Raz&#243;n.social.de.la.sociedad\",\n           Direccion = \"Direcci&#243;n.de.notificaci&#243;n.judicial.registrada.en.C&#225;mara.de.Comercio\",\n           Departamento = \"Departamento.de.la.direcci&#243;n.del.domicilio\",\n           Ciudad = \"Ciudad.de.la.direcci&#243;n.del.domicilio\",\n           TotalCurrentFinancialAssetsSELL= \"Total_activos_corrientes_distintos_de_los_activos_no_corrientes_o_grupo_de_activos_para_su_disposicion_clasificados_como_mantenidos_para_la_venta_o_como_mantenidos_para_distribuir_a_los_propietarios\",\n           OtherCurrentFinancialAssetsSELL= \"Activos_no_corrientes_o_grupos_de_activos_para_su_disposicion_clasificados_como_mantenidos_para_la_venta_o_como_mantenidos_para_distribuir_a_los_propietarios\",\n           PropertyPlantAndEquipmentWithDEP= \"Propiedades_de_inversi&#243;n_al_costo_menos_depreciacion_acumulada_y_deterioro\",\n           TotalCurrentFinancialLiabilitiesSELL = \"Total_pasivos_corrientes_distintos_de_los_pasivos_incluidos_en_grupos_de_activos_para_su_disposicion_clasificados_como_mantenidos_para_la_venta\",\n           OtherCurrentFinancialLiabilitiesSELL= \"Pasivos_incluidos_en_grupos_de_activos_para_su_disposicion_clasificados_como_mantenidos_para_la_venta\")\n\n# Solo veremos el periodo final\ndata &lt;- data |&gt; \n    filter(Periodo == \"Periodo Actual\", \n           Departamento == \"VALLE\")\n\ndata |&gt; \n    gt_preview() |&gt; \n    aplicar_theme_table()\n\n\n\n\n\n\n\n\n\nPunto.de.Entrada\nNombre.Formulario\nNIT\nFecha.de.Corte\nRazon.Social\nCIIU\nTipo.societario\nDireccion\nDepartamento\nCiudad\nPeriodo\nCashAndCashEquivalents\nTradeAndOtherCurrentReceivables\nInventories\nCurrentTaxAssetsCurrent\nCurrentBiologicalAssetsAtCost\nCurrentBiologicalAssetsAtFairValue\nOtherCurrentFinancialAssets\nOtherCurrentNonfinancialAssets\nCurrentNoncashAssetsPledgedAsCollateralForWhichTransfereeHasRightByContractOrCustomToSellOrRepledgeCollateral\nTotalCurrentFinancialAssetsSELL\nOtherCurrentFinancialAssetsSELL\nCurrentAssets\nPropertyPlantAndEquipment\nPropertyPlantAndEquipmentWithDEP\nInvestmentProperty\nGoodwill\nIntangibleAssetsOtherThanGoodwill\nNoncurrentBiologicalAssetsAtCost\nNoncurrentBiologicalAssetsAtFairValue\nNoncurrentReceivables\nNoncurrentInventories\nDeferredTaxAssets\nCurrentTaxAssetsNoncurrent\nOtherNoncurrentFinancialAssets\nOtherNoncurrentNonfinancialAssets\nNoncurrentNoncashAssetsPledgedAsCollateralForWhichTransfereeHasRightByContractOrCustomToSellOrRepledgeCollateral\nNoncurrentAssets\nAssets\nCurrentProvisionsForEmployeeBenefits\nOtherShorttermProvisions\nCurrentProvisions\nTradeAndOtherCurrentPayables\nCurrentTaxLiabilitiesCurrent\nOtherCurrentFinancialLiabilities\nShorttermBorrowings\nCurrentPortionOfLongtermBorrowings\nOtherCurrentNonfinancialLiabilities\nTotalCurrentFinancialLiabilitiesSELL\nOtherCurrentFinancialLiabilitiesSELL\nCurrentLiabilities\nNoncurrentProvisionsForEmployeeBenefits\nOtherLongtermProvisions\nNoncurrentProvisions\nNoncurrentPayables\nDeferredTaxLiabilities\nCurrentTaxLiabilitiesNoncurrent\nOtherNoncurrentFinancialLiabilities\nLongtermBorrowings\nOtherNoncurrentNonfinancialLiabilities\nNoncurrentLiabilities\nLiabilities\nIssuedCapital\nSharePremium\nTreasuryShares\nInversionSuplementariaAlCapitalAsignado\nOtherEquityInterest\nSuperavitPorRevaluacion\nOtherReserves\nRetainedEarnings\nEquity\nEquityAndLiabilities\n\n\n\n\n1\nPymes-Individuales\nEstado de situaci&#243;n financiera, corriente/no corriente\n800000241\n2022-12-31\nCERERIA EL SAGRADO CORAZON LTDA\nC3290 - Otras industrias manufactureras n.c.p.\n03. SOCIEDAD LIMITADA\nKM 5.5 VIA LA BUITRERA PREDIO LA CANANEA\nVALLE\nCALI-VALLE\nPeriodo Actual\n434850\n3294074\n2412864\nNA\nNA\nNA\n51621\nNA\nNA\n6193409\nNA\n6193409\n564126\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n18708\nNA\nNA\n582834\n6776243\n114962\nNA\n114962\n2775642\n294400\n253216\n253216\nNA\nNA\n3438220\nNA\n3438220\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n3438220\n200000\nNA\nNA\nNA\nNA\n132740\n130902\n2874381\n3338023\n6776243\n\n\n2\nPymes-Individuales\nEstado de situaci&#243;n financiera, corriente/no corriente\n800000393\n2022-12-31\nCONFEPLASTICOS SAS\nC2229 - Fabricaci&#243;n de art&#237;culos de pl&#225;stico n.c.p.\n08. SOCIEDAD POR ACCIONES SIMPLIFICADA SAS\nCL 27 4 55\nVALLE\nCALI-VALLE\nPeriodo Actual\n34675\n372255\n9424\n67673\nNA\nNA\nNA\nNA\nNA\n484027\nNA\n484027\n3065089\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n3065089\n3549116\n777054\nNA\n777054\n1618837\n401720\n778820\n8121\n770699\nNA\n3576431\nNA\n3576431\nNA\n2717\n2717\nNA\nNA\nNA\n689414\n689414\nNA\n692131\n4268562\n200000\nNA\nNA\nNA\nNA\n394906\n458229\n-1772581\n-719446\n3549116\n\n\n3\nPymes-Individuales\nEstado de situaci&#243;n financiera, corriente/no corriente\n800000469\n2022-12-31\nRIVERA CORREA Y CRUZ Y COMPA&#209;IA LIMITADA\nG4731 - Comercio al por menor de combustible para automotores\n03. SOCIEDAD LIMITADA\nCRA 24 12 25\nVALLE\nBUGA-VALLE\nPeriodo Actual\n83458\n407300\n49573\nNA\nNA\nNA\n10000\nNA\nNA\n550331\n22296\n572627\n1345406\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n1345406\n1918033\n104826\nNA\n104826\n245856\n6830\n269542\n97035\n172507\nNA\n627054\nNA\n627054\nNA\nNA\nNA\nNA\n29682\nNA\nNA\nNA\n89498\n119180\n746234\n102245\nNA\nNA\nNA\nNA\nNA\n17087\n1052467\n1171799\n1918033\n\n\n4\nPymes-Individuales\nEstado de situaci&#243;n financiera, corriente/no corriente\n800001020\n2022-12-31\nDISTRIBUIDORA DE DROGAS LA REBAJA PRINCIPAL S.A.\nN7740 - Arrendamiento de propiedad intelectual y productos similares, excepto obras protegidas por derechos de autor\n01. SOCIEDAD AN&#211;NIMA\nCR 3 12 40 OF 1101\nVALLE\nCALI-VALLE\nPeriodo Actual\n6059138\n910913\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n6970051\nNA\n6970051\n19683\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n33761\nNA\n53444\n7023495\nNA\nNA\nNA\n24685\n1415386\nNA\nNA\nNA\nNA\n1440071\nNA\n1440071\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n1440071\n53497\nNA\nNA\nNA\nNA\nNA\n26749\n5503178\n5583424\n7023495\n\n\n5\nPymes-Individuales\nEstado de situaci&#243;n financiera, corriente/no corriente\n800001047\n2022-12-31\nMAYA Y BEDOYA LTDA\nG4773 - Comercio al por menor de productos farmac&#233;uticos y medicinales, cosm&#233;ticos y art&#237;culos de tocador en establecimientos especializados\n03. SOCIEDAD LIMITADA\nCALLE 8 6 -80\nVALLE\nCALI-VALLE\nPeriodo Actual\n1946480\n1162466\n1872505\nNA\nNA\nNA\nNA\n1201\nNA\n4982652\nNA\n4982652\n262823\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n10000\nNA\nNA\n272823\n5255475\n193609\nNA\n193609\n1265130\n262475\nNA\nNA\nNA\n651741\n2372955\nNA\n2372955\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n2372955\n1500000\nNA\nNA\nNA\nNA\nNA\n370959\n1011561\n2882520\n5255475\n\n\n6..2391\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2392\nPymes-Individuales\nEstado de situaci&#243;n financiera, corriente/no corriente\n901468892\n2022-12-31\nINVERSIONES ATELIER SAS\nM7490 - Otras actividades profesionales, cient&#237;ficas y t&#233;cnicas n.c.p.\n08. SOCIEDAD POR ACCIONES SIMPLIFICADA SAS\nCL 67 NORTE # 6 - 85\nVALLE\nCALI-VALLE\nPeriodo Actual\n436111\n3054731\nNA\n20822\nNA\nNA\nNA\nNA\nNA\n3511664\nNA\n3511664\n5457219\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n5457219\n8968883\n19851\nNA\n19851\n143592\n26788\nNA\nNA\nNA\nNA\n190231\nNA\n190231\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n190231\n1000\nNA\nNA\nNA\nNA\n9052026\nNA\n-274374\n8778652\n8968883\n\n\n\n\n\n\n\nNos interesa conocer la proporción de \\(deuda / capital\\) que tienen las empresas en el Valle del Cauca:\n\n\nCódigo\ncaratula &lt;- openxlsx::read.xlsx(\"./10000_Carátula.xlsx\") |&gt; \n    data.table()\n\nfull_join(\ndata |&gt; \n    filter(Periodo == \"Periodo Actual\") |&gt; \n    dplyr::select(c(3,4,5,14,62,72)) |&gt; \n    unique() \n,\npyg |&gt; \n    filter(Periodo == \"Periodo Actual\") |&gt; \n    dplyr::select(c(3,4,5,12)) |&gt; \n    unique()\n) |&gt; \n    left_join(caratula[,c(3,11)], by = c(\"NIT\")) |&gt; \n    mutate(prop_deuda = `Liabilities` / `EquityAndLiabilities`,\n           tiempo = 2024 - as.numeric(substr(`Fecha.de.constitución.(Aaaa-Mm-Dd)`,1,4))) |&gt; \n    filter(prop_deuda &gt; 0, !is.na(prop_deuda), prop_deuda&lt;=1, tiempo &gt;=0, !is.na(tiempo)) |&gt; \n    filter(tiempo &lt; 50) |&gt; \n    ggplot(aes(as.numeric(tiempo), prop_deuda, group = as.factor(tiempo)))+\n    geom_boxplot(aes(fill = \"orange\"))+\n    hrbrthemes::theme_ipsum()+\n    theme(legend.position = \"none\")+\n    labs(x = \"AÑOS DESDE CREACIÓN\",\n         y = \"PROPORCIÓN DE DEUDA (%)\")+\n    scale_y_continuous(labels = scales::percent)\n\n\n\n\n\nProporción deuda/capital\n\n\n\n\nAhora cruzamos la información de los dos reportes financieros para el mostrar el inventario como porcentaje de los activos operativos netos para una muestra de Pymes del Valle del Cauca varios sectores.\n\n\nCódigo\ndata |&gt; \n    mutate(sector = substr(CIIU,1,1)) |&gt; \n    mutate(NOA = (Assets -(\n        OtherCurrentFinancialAssets+OtherNoncurrentFinancialAssets))-\n            (Liabilities -(OtherCurrentFinancialLiabilities+\n            OtherNoncurrentFinancialLiabilities)),\n    inv_NOA = (Inventories+NoncurrentInventories)/NOA) |&gt; \n    filter(!is.nan(inv_NOA), inv_NOA &lt;=1, inv_NOA&gt;0) |&gt; \n    group_by(sector) |&gt; \n    summarise(media = mean(inv_NOA)) |&gt; \n    ggplot(aes(sector, media))+\n    geom_bar(stat = \"identity\", position = \"dodge\", fill = \"orange\")+\n    hrbrthemes::theme_ipsum()+\n    theme(axis.text.y = element_blank())+\n    labs(x = \"SECTOR (CIIU)\", y = \"INVENTARIO / ACTIVOS OPERATIVOS NETOS\")+\n    geom_text(aes(label = paste0(round(media,2)*100,\"%\")), size = 3, vjust = -0.3)\n\n\n\n\n\n\n\n\n\nAquí te muestro el listado de CIIU por división:\n\n\nCódigo\nciiu &lt;- openxlsx::read.xlsx(\"./Estructura-detallada-CIIU-4AC-2022.xlsx\")\n\nciiu |&gt; \n    filter(str_detect(División, \"SECC\")) |&gt; \n    dplyr::select(División, Descripción) |&gt; \n    gt() |&gt; \n    aplicar_theme_table()\n\n\n\n\n\n\n\n\nDivisión\nDescripción\n\n\n\n\nSECCIÓN A\nAGRICULTURA, GANADERÍA, CAZA, SILVICULTURA Y PESCA\n\n\nSECCIÓN B\nEXPLOTACIÓN DE MINAS Y CANTERAS\n\n\nSECCIÓN C\nINDUSTRIAS MANUFACTURERAS\n\n\nSECCIÓN D\nSUMINISTRO DE ELECTRICIDAD, GAS, VAPOR Y AIRE ACONDICIONADO\n\n\nSECCIÓN E\nDISTRIBUCIÓN DE AGUA; EVACUACIÓN Y TRATAMIENTO DE AGUAS RESIDUALES, GESTIÓN DE DESECHOS Y ACTIVIDADES DE SANEAMIENTO AMBIENTAL\n\n\nSECCIÓN F\nCONSTRUCCIÓN\n\n\nSECCIÓN G\nCOMERCIO AL POR MAYOR Y AL POR MENOR; REPARACIÓN DE VEHÍCULOS AUTOMOTORES Y MOTOCICLETAS\n\n\nSECCIÓN H\nTRANSPORTE Y ALMACENAMIENTO\n\n\nSECCIÓN I\nALOJAMIENTO Y SERVICIOS DE COMIDA\n\n\nSECCIÓN J\nINFORMACIÓN Y COMUNICACIONES\n\n\nSECCIÓN K\nACTIVIDADES FINANCIERAS Y DE SEGUROS\n\n\nSECCIÓN L\nACTIVIDADES INMOBILIARIAS\n\n\nSECCIÓN M\nACTIVIDADES PROFESIONALES, CIENTÍFICAS Y TÉCNICAS\n\n\nSECCIÓN N\nACTIVIDADES DE SERVICIOS ADMINISTRATIVOS Y DE APOYO\n\n\nSECCIÓN O\nADMINISTRACIÓN PÚBLICA Y DEFENSA; PLANES DE SEGURIDAD SOCIAL DE AFILIACIÓN OBLIGATORIA\n\n\nSECCIÓN P\nEDUCACIÓN\n\n\nSECCIÓN Q\nACTIVIDADES DE ATENCIÓN DE LA SALUD HUMANA Y DE ASISTENCIA SOCIAL\n\n\nSECCIÓN R\nACTIVIDADES ARTÍSTICAS, DE ENTRETENIMIENTO Y RECREACIÓN\n\n\nSECCIÓN S\nOTRAS ACTIVIDADES DE SERVICIOS\n\n\nSECCIÓN T\nACTIVIDADES DE LOS HOGARES INDIVIDUALES EN CALIDAD DE EMPLEADORES; ACTIVIDADES NO DIFERENCIADAS DE LOS HOGARES INDIVIDUALES COMO PRODUCTORES DE BIENES Y SERVICIOS PARA USO PROPIO\n\n\nSECCIÓN U\nACTIVIDADES DE ORGANIZACIONES Y ENTIDADES EXTRATERRITORIALES\n\n\n\n\n\n\n\nVemos que el inventario para las Pymes en el Valle del Cauca es representativo para: INDUSTRIAS MANUFACTURERAS, CONSTRUCCIÓN y COMERCIO AL POR MAYOR Y AL POR MENOR.\nDesde la perspectiva de un inversionista, el inventario es un contribuyente significativo al riesgo general, dado sus riesgos inherentes y su porcentaje de activos operativos. En consecuencia, es razonable aplicar el costo ponderado promedio del capital al calcular la tasa de capital del inventario.\nEl uso del costo ponderado promedio del capital es una práctica común en aquellas empresas que utilizan un sistema de gestión financiera como el valor económico agregado (EVA). Sin embargo, debes preguntarte qué costo de capital usa tu empresa? Utiliza una tasa de préstamo a corto plazo? O usa una tasa de inversión a corto plazo?.\nAmbas tasas subestiman la tasa de capital que corresponde al riesgo subyacente del inventario. Esto puede llevar a decisiones no óptimas en actividades como la selección del modo de transporte, el diseño de la red y la contratación, que equilibran la inversión en inventario frente a los gastos operativos. La discusión, en los próximos posts, describe las deficiencias de estos enfoques comunes para establecer los costos de capital.\n\n\n\nCómo citarBibTeX@online{chiquito_valencia2025,\n  author = {Chiquito Valencia, Cristian},\n  title = {Por Qué Usar El {WACC} Como Costo de Mantener Inventario?},\n  date = {2025-02-24},\n  url = {https://cchiquitovalencia.github.io/posts/2025-02-24-why_use_WACC/},\n  langid = {en}\n}\nPor favor, cita este trabajo como:\nChiquito Valencia, Cristian. 2025. “Por Qué Usar El WACC Como\nCosto de Mantener Inventario?” February 24, 2025. https://cchiquitovalencia.github.io/posts/2025-02-24-why_use_WACC/."
  },
  {
    "objectID": "posts/2025-02-25-short_term_borrowing_rate/index.html",
    "href": "posts/2025-02-25-short_term_borrowing_rate/index.html",
    "title": "Por qué no usar una tasa de préstamo?",
    "section": "",
    "text": "La Tasa de Préstamo a Corto Plazo\nUna razón para utilizar la tasa de préstamo a corto plazo es que el inventario es un activo a corto plazo financiado por préstamos a corto plazo. Técnicamente, el inventario es un activo a corto plazo, o lo que se denomina un “activo corriente”. Por ejemplo, supongamos que una empresa tiene \\(100\\) millones en inventario, y que ese inventario representa un surtido de bienes de \\(60\\) días. En promedio, los \\(100\\) millones en inventario se convierten en efectivo y/o cuentas por cobrar cada \\(60\\) días. Sin embargo, el defecto en el argumento del activo a corto plazo es que, mientras la empresa siga teniendo \\(60\\) días de inventario, necesitará invertir \\(100\\) millones en inventario para mantener sus ventas actuales. En este caso, el inventario debe considerarse como un “activo corriente permanente”, a pesar de que se renueva cada \\(60\\) días. Por lo tanto, se debe utilizar un costo de capital a largo plazo al calcular el cargo por el mantenimiento del inventario.\nOtro argumento común para utilizar la tasa de préstamo a corto plazo es que el inventario se utiliza como colateral en acuerdos de préstamos basados en activos. Es cierto que los préstamos con garantía de inventario son comunes. Sin embargo, hay varios defectos al utilizar la tasa de préstamo a corto plazo como el costo de capital general para el inventario. Uno de ellos es que los acreedores rara vez otorgan préstamos hasta el \\(100\\%\\) del valor del inventario. Un acuerdo de préstamo más típico es hasta el \\(50\\%\\) del valor. El porcentaje puede ser menor (como en el caso de alta tecnología) o mayor (como en el caso de materias primas), en función del riesgo subyacente del inventario. Además, los acuerdos de préstamo a menudo requieren que la empresa comprometa el flujo de caja de todas las demás fuentes como medio para devolver el préstamo, incluso si el inventario se utiliza como colateral.\nSupongamos que una empresa con \\(100\\) millones en inventario financia el \\(50\\%\\) (\\(\\$50\\) millones) mediante un préstamo bancario. Esto deja el \\(50\\%\\) restante para ser financiado a través de otras fuentes, como crédito comercial, bonos y capital—todas ellas con costos significativamente más altos que la tasa de préstamo a corto plazo. En particular, el crédito comercial es comúnmente visto como una fuente de financiamiento para el inventario. El crédito comercial aumenta el pasivo de la empresa compradora (cuentas por pagar) que financia el activo del inventario. Sin embargo, en los últimos años, muchas empresas compradoras han exigido plazos de crédito más largos a los proveedores.\nNuestra investigación muestra la siguiente proporción de cuentas por pagar con respecto al inventario para un grupo de empresas de muestra: industria manufacturera (35%), construcción (40%) y retail (34%). Los resultados sugieren que el crédito comercial representa el \\(30\\%\\) o más del inventario, lo que argumenta en contra del uso de una tasa a corto plazo.\nOtro defecto en el uso del costo de préstamo a corto plazo para el costo de capital del inventario es que no considera la “estructura de capital objetivo” de la empresa—es decir, qué porcentaje la empresa desea financiar a largo plazo con deuda (suma de deuda a corto y largo plazo) y qué porcentaje financiar mediante capital. La estructura de capital objetivo es una decisión de la gerencia senior que está impulsada por factores como el riesgo de los activos, el ciclo de vida del producto y la vida económica útil de los activos fijos. El nivel y el porcentaje de financiamiento con deuda que los acreedores están dispuestos a proporcionar también son factores importantes. Por ejemplo, muchos préstamos incluyen restricciones sobre la cantidad total de financiamiento con deuda en general.\nAnteriormente, demostramos que para la empresa promedio (Valle del Cauca), la estructura de capital es aproximadamente \\(60\\%\\) de capital y \\(40\\%\\) de deuda (para empresas con más de \\(15\\) años de constitución). Sin embargo, esta estructura varía según la industria. Las empresas de alta tecnología, como las que fabrican computadoras, dispositivos de almacenamiento y dispositivos periféricos, venden productos con ciclos de vida muy cortos y demanda volátil. Su estructura de capital promedio podría ser de \\(95\\%\\) de capital y \\(5\\%\\) de deuda. En el otro extremo se encuentran las empresas que proporcionan servicios eléctricos y de gas, las cuales podrían tener una estructura de capital promedio de \\(50\\%\\) de capital y \\(50\\%\\) de deuda. El mayor porcentaje de deuda refleja la demanda más estable de los servicios públicos y las largas vidas útiles de sus plantas y equipos de generación y transmisión.\nEl cálculo a continuación para una empresa de manufactura de la muestra de Pymes del Valle del Cauca ilustra la necesidad de tener en cuenta el impacto de la financiación del inventario con deuda y, a su vez, de aplicar el costo de capital correcto al estimar el costo de mantenimiento del inventario.\n\n\n\n\n\n\n\n\nCapital\nValor\nPorcentaje\n\n\n\n\nInventario\n$100m\n60%\n\n\nTodo lo otro\n$67m\n40%\n\n\nTotal\n$167m\n100%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEstructura_Capital\nValor\nPorcentaje\n\n\n\n\nDeuda\n$50m\n30%\n\n\nCapital\n$117m\n70%\n\n\nTotal\n$167m\n100%\n\n\n\n\n\n\n\nEste cálculo se basa en los resultados para una empresa con \\(100\\) millones en inventario. El inventario representa el \\(60\\%\\) del capital total, y la estructura de capital es \\(70\\%\\) de capital y \\(30\\%\\) de deuda. Todo el capital restante, que asciende a \\(\\$67\\) millones, está compuesto por la inversión neta en cuentas por cobrar, propiedades, plantas y equipos, y otros activos. Los \\(\\$50\\) millones en deuda corresponden a un préstamo sobre los \\(\\$100\\) millones en inventario. Las condiciones especifican que el \\(50\\%\\) del inventario puede ser financiado mediante el préstamo (\\(\\$50\\) millones de préstamo = \\(\\$100\\) millones de inventario × \\(50\\%\\) de financiamiento con préstamo).\nEste ejemplo destaca la necesidad de tener en cuenta el impacto del financiamiento de la deuda del inventario en la capacidad de endeudamiento de la empresa. La capacidad total de deuda de la empresa es de \\(\\$50\\) millones (\\(\\$167\\) millones de capital × \\(30\\%\\) de deuda) con una estructura de capital de \\(30\\%\\) de deuda y \\(70\\%\\) de capital. Si la empresa financia el \\(50\\%\\) del inventario con un préstamo de \\(\\$50\\) millones, no habrá deuda adicional disponible para financiar otros activos, como cuentas por cobrar, propiedades, plantas y equipos. Por lo tanto, estos activos deben ser financiados al \\(100\\%\\) mediante capital en adición a los \\(\\$50\\) millones del inventario financiados mediante capital.\nCon fines de toma de decisiones, no es razonable aplicar el \\(100\\%\\) del costo del capital a estos activos. Es por eso que la práctica financiera moderna aplica el costo ponderado de capital a la mayoría de los activos, ya que esta metodología asigna los costos de la deuda y el capital, tiene en cuenta la estructura de capital objetivo y compensa el riesgo de un activo si este no difiere significativamente del riesgo promedio de la empresa.\n\n\n\n\nCómo citarBibTeX@online{chiquito_valencia2025,\n  author = {Chiquito Valencia, Cristian},\n  title = {Por Qué No Usar Una Tasa de Préstamo?},\n  date = {2025-02-25},\n  url = {https://cchiquitovalencia.github.io/posts/2025-02-25-short_term_borrowing_rate/},\n  langid = {en}\n}\nPor favor, cita este trabajo como:\nChiquito Valencia, Cristian. 2025. “Por Qué No Usar Una Tasa de\nPréstamo?” February 25, 2025. https://cchiquitovalencia.github.io/posts/2025-02-25-short_term_borrowing_rate/."
  },
  {
    "objectID": "posts/2025-02-26-short_term_investment_rate/index.html",
    "href": "posts/2025-02-26-short_term_investment_rate/index.html",
    "title": "Qué pasa con una tasa de inversión?",
    "section": "",
    "text": "La Tasa de Inversión a Corto Plazo\nUna tasa de inversión a corto plazo, como la rentabilidad de un instrumento del mercado monetario, como el papel comercial o un certificado de depósito, también se utiliza comúnmente como el costo de oportunidad de mantener el inventario. Sin embargo, al igual que las tasas de préstamo a corto plazo, las tasas de inversión a corto plazo ignoran el principio básico de riesgo/rendimiento que subyace a la aplicación del costo de capital. Estas tasas restan significativamente al costo de capital acorde con el riesgo del inventario.\nVarios factores hacen que el papel comercial, los certificados de depósito y otros instrumentos del mercado monetario exhiban un menor riesgo y, por lo tanto, un rendimiento esperado más bajo. Específicamente:\n\nExiste una obligación contractual legalmente vinculante de que el emisor pagará a los inversionistas una cantidad fija en intereses y devolverá el principal en fechas específicas.\nDebido a que la madurez es a corto plazo (típicamente uno, tres o seis meses), los inversionistas no están expuestos al riesgo crediticio a largo plazo.\nLos instrumentos del mercado monetario son bastante líquidos y pueden venderse en mercados secundarios si los inversionistas necesitan vender la inversión antes de la fecha de vencimiento.\n\nEstos factores contrastan marcadamente con las realidades de la inversión en inventario:\n\nLa mayor parte de la inversión en inventario es especulativa, especialmente en el sector mayorista/distribución y minorista. No hay un contrato legalmente vinculante que obligue a los clientes a comprar el inventario. En los casos en los que el inventario se produce bajo pedido, el comprador a menudo puede cambiar o cancelar el pedido sin compensar plenamente a la empresa vendedora por el valor total del inventario.\nEl inventario puede renovarse cada 60 días, por ejemplo, pero la empresa debe seguir reinviertiendo en inventario para mantener las ventas. Esta es la naturaleza de “activo corriente permanente” del inventario que se discutió anteriormente.\nEl inventario generalmente no es líquido. El deshacerse del inventario antes de su venta en el curso normal de los negocios a menudo resulta en procedimientos netos que son sustancialmente menores que la inversión original en el inventario. Las excepciones son las existencias de materias primas invertidas en commodities como productos agrícolas y metales preciosos.\n\nEs razonable suponer que, para muchas empresas, el riesgo asociado con la inversión en inventario es sustancialmente mayor que el riesgo de invertir en instrumentos del mercado monetario. Utilizar la rentabilidad de un instrumento del mercado monetario como aproximación para el costo de capital del inventario reduce significativamente el cargo por mantener el inventario. Esto, a su vez, puede llevar a decisiones incorrectas relacionadas con el inventario.\nResumiendo nuestra serie de posts, ni la tasa de endeudamiento a corto plazo ni la tasa de inversión a corto plazo deberían usarse para calcular el cargo por el capital del inventario. Ambas ignoran el principio fundamental de riesgo/rendimiento que subyace al uso del costo del capital para la toma de decisiones. Además, ambas reducen significativamente el costo de oportunidad de mantener el inventario, lo que, a su vez, perjudica el proceso de toma de decisiones.\nEl costo ponderado del capital (WACC) es una tasa mucho más adecuada para calcular el cargo por el capital del inventario. El WACC es proporcional con el riesgo de mantener el inventario y con la contribución que el inventario hace al riesgo operativo general de una empresa. Además, esta metodología también tiene en cuenta la estructura de capital objetivo de la empresa y su capacidad de endeudamiento.\n\n\n\n\nCómo citarBibTeX@online{chiquito_valencia2025,\n  author = {Chiquito Valencia, Cristian},\n  title = {Qué Pasa Con Una Tasa de Inversión?},\n  date = {2025-02-26},\n  url = {https://cchiquitovalencia.github.io/posts/2025-02-26-short_term_investment_rate/},\n  langid = {en}\n}\nPor favor, cita este trabajo como:\nChiquito Valencia, Cristian. 2025. “Qué Pasa Con Una Tasa de\nInversión?” February 26, 2025. https://cchiquitovalencia.github.io/posts/2025-02-26-short_term_investment_rate/."
  },
  {
    "objectID": "posts/2025-02-27-total_cost_inventory/index.html",
    "href": "posts/2025-02-27-total_cost_inventory/index.html",
    "title": "Costos totales de mantener el inventario antes de impuestos",
    "section": "",
    "text": "Costos Totales de Mantenimiento de Inventario Antes de Impuestos\nCon el WACC en la ecuación, ahora podemos combinar los costos no capitalizados por mantenimiento del inventario con los costos de capital por mantenimiento para estimar el costo total de mantener el inventario. En nuestro ejemplo, el costo no capital por mantenimiento es el \\(10\\%\\) del saldo del inventario. Como se muestra en la Figura No.1, estos costos están compuestos por gastos operativos como obsolescencia, almacenamiento, hurto, seguro y impuestos—todos los cuales se expresan en una base antes de impuestos. El costo del capital es del \\(9\\%\\) y es el costo ponderado promedio del capital después de impuestos.\nIncluso cuando las empresas utilizan el WACC para calcular el cargo por capital del inventario, a menudo cometen el error de sumar los costos no capitalizados por mantenimiento del inventario antes de impuestos (como nuestro ejemplo del 10%) al costo del capital después de impuestos (digamos del 9%) para obtener el costo total de mantenimiento (19%). El problema es que al combinar estos costos antes y después de impuestos, se subestima el costo total de mantener el inventario y se pueden tomar decisiones no óptimas respecto al inventario.\nPara obtener una imagen real del costo de mantenimiento del inventario, los dos costos deben expresarse en la misma base—ya sea antes o después de impuestos. Hay dos opciones para hacer esto:\nOpción 1: Ajustar los costos no capitalizados por mantenimiento del inventario expresados como porcentaje antes de impuestos a una cifra después de impuestos y sumar esto al costo del capital después de impuestos.\nOpción 2: Convertir el costo del capital después de impuestos a una cifra antes de impuestos y sumarlo a los costos no capitalizados por mantenimiento expresados como porcentaje antes de impuestos.\nEl costo total de mantenimiento del inventario a menudo se utiliza para informes internos periódicos y para decisiones que se evalúan a nivel operativo en una base antes de impuestos. Para estos fines, recomendamos utilizar la Opción 2 para estimar el costo total de mantener el inventario. Para los análisis financieros tradicionales que involucran la actualización de flujos de efectivo después de impuestos, la Opción 1 es la elección requerida.\nLa siguiente ecuación muestra la derivación del costo de capital antes de impuestos y los costos totales de mantenimiento de inventario.\n\n\n\n\n\n\n\n\nConcepto\nValores\n\n\n\n\nPorcentaje Costos No Capitalizados\n10%\n\n\nWACC Después de Impuestos\n9%\n\n\nTasa de Impuestos Marginal\n40%\n\n\nCosto de Capital Antes de Impuestos (9%/(100%-40%))\n15%\n\n\nCosto Total Mantener Inventario Definitivo (% del Inventario)\n25%\n\n\n\n\n\n\n\nEl costo ponderado promedio del capital (WACC) después de impuestos del \\(9\\%\\) se restablece en una base antes de impuestos en \\(15\\%\\), lo cual representa el \\(9\\%\\) incrementado para reflejar los impuestos. La justificación es que si una empresa gana un \\(15\\%\\) antes de impuestos y paga el \\(40\\%\\) de ese \\(15\\%\\) en impuestos \\((6\\% = 15\\% × 40\\%\\)\\), obtiene una ganancia del \\(9\\%\\) después de impuestos \\((15\\% - 6\\%\\)\\).\n\n\n\nCómo citarBibTeX@online{chiquito_valencia2025,\n  author = {Chiquito Valencia, Cristian},\n  title = {Costos Totales de Mantener El Inventario Antes de Impuestos},\n  date = {2025-02-27},\n  url = {https://cchiquitovalencia.github.io/posts/2025-02-27-total_cost_inventory/},\n  langid = {en}\n}\nPor favor, cita este trabajo como:\nChiquito Valencia, Cristian. 2025. “Costos Totales de Mantener El\nInventario Antes de Impuestos.” February 27, 2025. https://cchiquitovalencia.github.io/posts/2025-02-27-total_cost_inventory/."
  },
  {
    "objectID": "posts/2025-02-28-practial_applications/index.html",
    "href": "posts/2025-02-28-practial_applications/index.html",
    "title": "Aplicaciones prácticas",
    "section": "",
    "text": "Aplicaciones prácticas\nPara ilustrar la metodología del costo total de inventario en acción, volveremos a utilizar el ejemplo de la empresa con \\(\\$100\\) millones en inventario y con márgenes de ventas y ganancia operativa promedio. El siguiente gráfico compara la diferencia entre usar el \\(25\\%\\) de costo total de mantener el inventario y usar la cifra del \\(15\\%\\).\nEl \\(15\\%\\) es la suma del \\(10\\%\\) para gastos no relacionados con el capital más un \\(5\\%\\) de costo de capital, aquí compararías con la tasa de préstamos a corto plazo. El \\(5\\%\\) es una cifra antes de impuestos y, por lo tanto, no necesita ser ajustada por impuestos. Al usar el más preciso \\(25\\%\\), se revela que el costo total en dólares de mantener el inventario es \\(\\$10\\) millones mayor que cuando se aplica el \\(15\\%\\) más bajo (\\(\\$25\\) millones de costo total de mantener el inventario frente a \\(\\$15\\) millones). Para poner la diferencia de \\(\\$10\\) millones en perspectiva práctica, el cálculo muestra que los \\(\\$25\\) millones representan más del \\(80\\%\\) de la ganancia operativa absorbida por los costos totales de mantener el inventario. En comparación, cuando se aplica el \\(15\\%\\) más bajo, los costos de inventario representan solo el \\(50\\%\\) de la ganancia operativa.\n\n\n\n\n\n\n\n\nConcepto\nCon_25\nCon_15\n\n\n\n\nInventario\n$100m\n$100m\n\n\n% del Costo Total de Mantener Inventario\n25%\n15%\n\n\nCosto Total de Mantener Inventario\n$25m\n$15m\n\n\nVentas\n$750m\n$750m\n\n\nMargen de Ingresos Operacionales*\n4%\n4%\n\n\nIngresos Operacionales\n$30m\n$30m\n\n\nIngresos Operacionales absorbidos por Costo Total de Mantener Inventario\n83%\n50%\n\n\n\n\n\n\n\n*Excluye costos no capitalizados de mantener el inventario (\\(\\$100m\\) inventario x \\(10\\%\\) costos no capitalizados)\nComunicar una estimación precisa del porcentaje de la ganancia operativa absorbida por los costos totales de mantener el inventario es una forma efectiva de:\n\nDesarrollar una mejor comprensión del costo relativo de mantener el inventario.\nMotivar una visión empresarial integral del manejo de inventario.\nEstimular iniciativas para mejorar el manejo de inventario.\n\nUna buena comunicación también crea un mayor sentido de urgencia en toda la organización para un mejor manejo del inventario.\nLa cifra más precisa del \\(25\\%\\) del costo total de inventario también puede conducir a mejores decisiones en la gestión del transporte. Considere la siguiente ilustración basada en la empresa de la muestra. Supongamos que esta empresa está explorando una iniciativa para reducir el inventario en un \\(20\\%\\), o \\(\\$20\\) millones, utilizando modos de transporte expeditados. Utilizando la cifra de costo total de mantenimiento de inventario del \\(25\\%\\), el beneficio bruto anualizado estimado de esta mejora en el transporte es de \\(\\$5\\) millones (\\(\\$20m\\) × \\(25\\%\\)). Manteniendo constantes otros factores como los niveles de servicio, esto significa que la empresa podría gastar hasta \\(\\$5\\) millones más en costos de transporte y seguir igualando. Por el contrario, utilizando la cifra de costo de inventario del \\(15\\%\\), el beneficio bruto anual estimado y el aumento máximo en los costos de transporte es solo de \\(\\$3\\) millones (\\(\\$20m\\) × \\(15\\%\\)). Para poner la diferencia de \\(\\$2\\) millones en perspectiva, los costos de transporte suelen promediar aproximadamente el \\(4\\%\\) de las ventas. Utilizando este promedio, los costos de transporte para la empresa de la muestra son de \\(\\$30\\) millones (\\(\\$750m\\) de ventas × \\(4\\%\\)). Por lo tanto, la diferencia de \\(\\$2\\) millones representa casi el \\(7\\%\\) de los actuales costos de transporte.\nResumen: el uso de un porcentaje más preciso para el costo total de mantener el inventario, que incorpora el costo ponderado promedio del capital antes de impuestos, tiene un gran impacto en las decisiones de transporte y generalmente respalda el uso de modos más rápidos. De manera similar, esta cifra más precisa a menudo afecta las decisiones sobre aprovisionamiento y optimización de la red, que implican equilibrar el gasto operativo con los niveles de inventario.\n\n\n\n\nCómo citarBibTeX@online{chiquito_valencia2025,\n  author = {Chiquito Valencia, Cristian},\n  title = {Aplicaciones Prácticas},\n  date = {2025-02-28},\n  url = {https://cchiquitovalencia.github.io/posts/2025-02-28-practical_applications/},\n  langid = {en}\n}\nPor favor, cita este trabajo como:\nChiquito Valencia, Cristian. 2025. “Aplicaciones\nPrácticas.” February 28, 2025. https://cchiquitovalencia.github.io/posts/2025-02-28-practical_applications/."
  },
  {
    "objectID": "posts/2025-03-04-next/index.html",
    "href": "posts/2025-03-04-next/index.html",
    "title": "Ideas",
    "section": "",
    "text": "AQUI MODELO WACC\nHowever, inventory management is a complex task, and the intricacies are accentuated when confronted with stochastic demand or demand uncertainty, which leads to stockouts, excessive inventory holdings, revenue losses, etc. In the context of tactical supply chain management, traditional operations research approaches continue to confront significant challenges in practice.\nSin embargo, la gestión de inventarios es una tarea compleja, y las complejidades se acentúan cuando se enfrenta a una demanda estocástica o incertidumbre en la demanda, lo que conduce a agotamientos de stock, tenencias excesivas de inventario, pérdidas de ingresos, etc. En el contexto de la gestión táctica de la cadena de suministro, los enfoques tradicionales de investigación de operaciones siguen enfrentando importantes desafíos en la práctica.\nThe primary focus of an inventory model is to determine how much to order and when to order, which historically has been focused on deterministic demand models (see [19]; [20]; [21];[22]; [23]).\nLas principales decisiones que tiene que tomar el responsable de la administración de inventarios son: cuántas unidades de cada tipo ordenar o producir, y cuándo realizar el pedido o emitir la órden de producción. Ambas decisiones se ven afectadas por la demanda del producto. Esa demanda es incierta. Lo máximo que podemos hacer es pronosticar la demanda. Esto será otra serie.\nThe applicability of such a model in real-world scenarios has been increasingly limited due to a long list of constraints and the rising uncertainty in demand patterns. In line with recent advancements, Ekren et al. [24] have introduced a demand forecasting model that not only considers demand uncertainty but also employs a robust optimization approach. Other researchers, too, made clear arguments on optimization techniques, which play an indispensable role in implementing an effective inventory system (see [25]; [26]; [27]). To explore nearly optimal control parameters for a stochastic multi-product inventory control system, Jackson [28] suggested a simulation-optimization framework, allowing for full inventory dynamics with risk and reliability analysis. More empirical studies have highlighted the importance of simulation modeling, which helps decision-makers analyze different scenarios and choose the best course of action (see [29]; [30]; [9]; [31]; [32]; [33]; [34]; [35]).\nTo put this into perspective, simulation modeling simulates the functioning of an existing system and tests various scenarios to provide evidence for decision-making. The goal of inventory optimization is to maximize the performance of the objective function (𝑓(𝑥)) in a stochastic environment by identifying an optimal set of control parameters for inventory strategy [36]. The significance of adopting data-driven, analytical, and systematic approaches is imperative to deal with the complex challenges in modern inventory management systems [1]. While several empirical works (e.g., [37]; [38]; [39], among others) delved into the Economic Order Quantity (EOQ) approach, they lacked rigorous analytical evaluations to substantiate their findings. In their work, Homem-de-Mello & Bayraksan [40] highlighted that the stochastic problem bridges two distinct research communities: optimization and simulation. The optimization community involves structural exploitation, theoretical foundations, and algorithm development, whereas the simulation community involves a black-box approach with probabilistic modeling. This study combines the strengths of both communities to develop a hybrid method that is powerful and versatile. The proposed approach allows for an inclusive exploration of the solution space to enhance the effectiveness of decision-making. To establish the strategy, Monte Carlo simulation (MCS) is used to generate demand and lead time distributions for various products based on historical demands and estimate potential profit maximization under different inventory policies.\n\n\n\nCómo citarBibTeX@online{chiquito_valencia2025,\n  author = {Chiquito Valencia, Cristian},\n  title = {Ideas},\n  date = {2025-03-04},\n  url = {https://cchiquitovalencia.github.io/posts/2025-03-04-next/},\n  langid = {en}\n}\nPor favor, cita este trabajo como:\nChiquito Valencia, Cristian. 2025. “Ideas.” March 4, 2025.\nhttps://cchiquitovalencia.github.io/posts/2025-03-04-next/."
  },
  {
    "objectID": "posts/2025-03-03-better_decisions/index.html",
    "href": "posts/2025-03-03-better_decisions/index.html",
    "title": "Toma mejores decisiones",
    "section": "",
    "text": "Objetivo: Mejor Toma de Decisiones\nResumiendo nuestra discusión, los profesionales de la gestión de la cadena de suministro deben desarrollar mejores estimaciones de los componentes del costo total de mantener el inventario: los costos de mantenimiento no relacionados con el capital y el cargo por el capital. Mejores estimaciones de estos componentes (que casi siempre son más altos que las estimaciones actuales utilizadas) proporcionan perspectivas más precisas sobre el costo total de mantener el inventario. Y conocer este costo total más preciso puede ser un poderoso catalizador para explorar nuevas soluciones para gestionar el inventario de manera más efectiva.\nEn particular, los profesionales de la cadena de suministro deben desarrollar estimaciones más creíbles de los costos de mantenimiento no relacionados con el capital: obsolescencia, almacenamiento, hurtos, daños, seguros, impuestos, y así sucesivamente. Las estimaciones actuales de estos costos a menudo no se pueden rastrear hasta costos específicos de ítems de línea e incorporar en los presupuestos. Por lo tanto, a menudo se excluyen al calcular el valor de las iniciativas de reducción de inventario, tales como inversiones en tecnología para mejorar la previsión y la visibilidad del inventario.\nLa exclusión de estos costos subestima la rentabilidad de estas iniciativas y puede resultar en el rechazo de proyectos que deberían ser aceptados. Nuevamente, como punto de partida, las empresas deberían enfocarse en estimar los componentes de costos de mantenimiento no relacionados con el capital de obsolescencia, seguros e impuestos. La información sobre estos costos tiende a estar más disponible a nivel de línea de producto, geográfico o de línea de negocio que otros costos de mantenimiento no relacionados con el capital. La obsolescencia, los seguros y los impuestos también suelen ser costos variables—que varían con el nivel de inversión en inventario.\nLas empresas también deben ser conscientes de usar un costo de capital que reduzca significativamente la carga de capital de inventario. Específicamente, a menudo utilizan una tasa de préstamo o crédito a corto plazo en lugar del más preciso costo ponderado promedio del capital (WACC). El uso del WACC puede llevar a mejores decisiones de gestión de inventarios.\nLa gestión del transporte es solo un ejemplo. El inventario se puede reducir utilizando medios de transporte más rápidos; por ejemplo, pasando de carga completa (full truckload) a carga parcial (less than truckload, LTL), o de LTL a transporte aéreo. Aunque el uso de medios de transporte más rápidos aumenta los costos de transporte, reduce el costo total de mantener el inventario.\nAplicar el WACC al calcular la carga de capital de inventario justificaría esta iniciativa. La razón: aunque los costos totales de transporte aumentan, el costo total de mantener el inventario y los costos totales de la cadena de suministro disminuyen, lo que mejora el desempeño financiero general.\nEl diseño de la red es otra área donde el uso del costo ponderado promedio del capital en el cálculo de la carga de capital conlleva a mejores decisiones. Una parte del diseño de la red es equilibrar los gastos totales de transporte contra los costos totales de mantener el inventario. Cuando se utiliza un WACC más preciso, los costos totales de mantener el inventario son mayores. Esto justifica incurrir en mayores costos de transporte con el fin de reducir los costos totales de mantener el inventario y, a su vez, los costos totales de la red. Por lo tanto, en muchos casos, una red más consolidada es óptima, incluso aunque los costos totales de transporte sean más altos.\nFinalmente, considera el impacto de conocer el costo total de los inventarios en las decisiones de aprovisionamiento. Por ejemplo, muchas empresas están pasando a un aprovisionamiento basado en Asia debido a los menores costos de compra. Sin embargo, esta práctica a menudo conduce a un mayor inversión en inventario debido a mayores niveles de inventario en tránsito y de seguridad. El uso del costo ponderado promedio del capital proporciona una visión más precisa del impacto del inventario en el costo total de importación. Resulta que la fuente con el menor costo de compra no siempre tiene el menor costo total de importación cuando se utiliza el WACC. Una vez más, conocer los verdaderos costos de mantener el inventario conduce a una mejor decisión.\n\n\n\n\nCómo citarBibTeX@online{chiquito_valencia2025,\n  author = {Chiquito Valencia, Cristian},\n  title = {Toma Mejores Decisiones},\n  date = {2025-03-03},\n  url = {https://cchiquitovalencia.github.io/posts/2025-03-03-better_decisions/},\n  langid = {en}\n}\nPor favor, cita este trabajo como:\nChiquito Valencia, Cristian. 2025. “Toma Mejores\nDecisiones.” March 3, 2025. https://cchiquitovalencia.github.io/posts/2025-03-03-better_decisions/."
  }
]